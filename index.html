<!DOCTYPE html>
<html lang="en">

<head>
    <title>ArxivDaily</title>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="robots" content="noindex, nofollow"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
    <link href="index.css" rel="stylesheet"/>
    <link href="https://cdn.jsdelivr.net/npm/remixicon@2.5.0/fonts/remixicon.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"
            integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx"
            crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js"
            integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR"
            crossorigin="anonymous"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function () {
            renderMathInElement(document.body, {
                // customised options
                // • auto-render specific keys, e.g.:
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '$', right: '$', display: false},
                    {left: '\\(', right: '\\)', display: false},
                    {left: '\\[', right: '\\]', display: true},
                    {left: "\\begin{equation}", right: "\\end{equation}", display: true},
                    {left: "\\begin{align}", right: "\\end{align}", display: true},
                    {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
                    {left: "\\begin{gather}", right: "\\end{gather}", display: true},
                    {left: "\\begin{CD}", right: "\\end{CD}", display: true},
                ],
                // • rendering keys, e.g.:
                throwOnError: false
            });
        });
    </script>
</head>

<body>
<section class="header-container">
    <div style="display:flex; justify-content:space-between; align-items:flex-end;">
        <div>
            <div class="header-title">
                MyArxiv
            </div>
        </div>

        <div class=icons>
            <label class="theme-switch" for="checkbox">
                <input type="checkbox" id="checkbox"/>
                <i id="theme-icon" class="ri-moon-line" style="font-size: 32px" rel="noopener noreferrer"></i>
            </label>
        </div>
    </div>
</section>

    <section class="day-container">
        <div class="date">
            <time datetime="2024-10-07T00:00:00Z">2024-10-07</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language <span class="chip" style="font-size: 60%">142</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Data Advisor: Dynamic Data Curation for Safety Alignment of Large
  Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05269v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05269v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fei Wang, Ninareh Mehrabi, Palash Goyal, Rahul Gupta, Kai-Wei Chang, Aram Galstyan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Data is a crucial element in large language model (LLM) alignment. Recent
studies have explored using LLMs for efficient data collection. However,
LLM-generated data often suffers from quality issues, with underrepresented or
absent aspects and low-quality datapoints. To address these problems, we
propose Data Advisor, an enhanced LLM-based method for generating data that
takes into account the characteristics of the desired dataset. Starting from a
set of pre-defined principles in hand, Data Advisor monitors the status of the
generated data, identifies weaknesses in the current dataset, and advises the
next iteration of data generation accordingly. Data Advisor can be easily
integrated into existing data generation methods to enhance data quality and
coverage. Experiments on safety alignment of three representative LLMs (i.e.,
Mistral, Llama2, and Falcon) demonstrate the effectiveness of Data Advisor in
enhancing model safety against various fine-grained safety issues without
sacrificing model utility.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Main Conference. Project website:
  https://feiwang96.github.io/DataAdvisor/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Grounding Partially-Defined Events in Multimodal Data <span class="chip">EMNLP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05267v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05267v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kate Sanders, Reno Kriz, David Etter, Hannah Recknor, Alexander Martin, Cameron Carpenter, Jingyang Lin, Benjamin Van Durme
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  How are we able to learn about complex current events just from short
snippets of video? While natural language enables straightforward ways to
represent under-specified, partially observable events, visual data does not
facilitate analogous methods and, consequently, introduces unique challenges in
event understanding. With the growing prevalence of vision-capable AI agents,
these systems must be able to model events from collections of unstructured
video data. To tackle robust event modeling in multimodal settings, we
introduce a multimodal formulation for partially-defined events and cast the
extraction of these events as a three-stage span retrieval task. We propose a
corresponding benchmark for this task, MultiVENT-G, that consists of 14.5 hours
of densely annotated current event videos and 1,168 text documents, containing
22.8K labeled event-centric entities. We propose a collection of LLM-driven
approaches to the task of multimodal event analysis, and evaluate them on
MultiVENT-G. Results illustrate the challenges that abstract event
understanding poses and demonstrates promise in event-centric video-language
systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint; 9 pages; 2024 EMNLP Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PrefixQuant: Static Quantization Beats Dynamic through Prefixed Outliers
  in LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05265v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05265v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mengzhao Chen, Yi Liu, Jiahao Wang, Yi Bin, Wenqi Shao, Ping Luo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Quantization is essential for deploying Large Language Models (LLMs) by
enhancing memory efficiency and inference speed. Existing methods for
activation quantization mainly address channel-wise outliers, often neglecting
token-wise outliers, leading to reliance on costly per-token dynamic
quantization. To address this, we introduce PrefixQuant, a novel technique that
isolates outlier tokens offline without re-training. Specifically, PrefixQuant
identifies high-frequency outlier tokens and prefixes them in the KV cache,
preventing the generation of outlier tokens during inference and simplifying
quantization. To our knowledge, PrefixQuant is the first to enable efficient
per-tensor static quantization to outperform expensive per-token dynamic
quantization. For instance, in W4A4KV4 (4- bit weight, 4-bit activation, and
4-bit KV cache) Llama-3-8B, PrefixQuant with per-tensor static quantization
achieves a 7.43 WikiText2 perplexity and 71.08% average accuracy on 5
common-sense reasoning tasks, outperforming previous per-token dynamic
quantization methods like QuaRot with 0.98 perplexity improvement and +5.98
points accuracy. Additionally, the inference speed of W4A4 quantized models
using PrefixQuant is 1.60x to 2.81x faster than FP16 models and exceeds QuaRot
models by 1.2x to 1.3x. Our code is available at
\url{https://github.com/ChenMnZ/PrefixQuant}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>A PTQ method to significantly boost the performance of static
  activation quantization</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TurtleBench: Evaluating Top Language Models via Real-World Yes/No
  Puzzles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05262v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05262v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qingchen Yu, Shichao Song, Ke Fang, Yunfeng Shi, Zifan Zheng, Hanyu Wang, Simin Niu, Zhiyu Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As the application of Large Language Models (LLMs) expands, the demand for
reliable evaluations increases. Existing LLM evaluation benchmarks primarily
rely on static datasets, making it challenging to assess model performance in
dynamic interactions with users. Moreover, these benchmarks often depend on
specific background knowledge, complicating the measurement of a model's
logical reasoning capabilities. Other dynamic evaluation methods based on
strong models or manual efforts may introduce biases and incur high costs and
time demands, hindering large-scale application. To address these issues, we
propose TurtleBench. TurtleBench collects real user guesses from our online
Turtle Soup Puzzle platform that we developed. This approach allows for the
relatively dynamic generation of evaluation datasets, mitigating the risk of
model cheating while aligning assessments more closely with genuine user needs
for reasoning capabilities, thus enhancing the reliability of evaluations.
TurtleBench includes 1,532 user guesses along with the correctness of guesses
after annotation. Using this dataset, we thoroughly evaluated nine of the most
advanced LLMs available today. Notably, the OpenAI o1 series models did not
achieve leading results in these evaluations. We propose several hypotheses for
further research, such as "the latent reasoning of o1 utilizes trivial
Chain-of-Thought (CoT) techniques" and "increasing CoT length not only provides
reasoning benefits but also incurs noise costs."
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Differential <span class="highlight-title">Transformer</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05258v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05258v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianzhu Ye, Li Dong, Yuqing Xia, Yutao Sun, Yi Zhu, Gao Huang, Furu Wei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformer tends to overallocate attention to irrelevant context. In this
work, we introduce Diff Transformer, which amplifies attention to the relevant
context while canceling noise. Specifically, the differential attention
mechanism calculates attention scores as the difference between two separate
softmax attention maps. The subtraction cancels noise, promoting the emergence
of sparse attention patterns. Experimental results on language modeling show
that Diff Transformer outperforms Transformer in various settings of scaling up
model size and training tokens. More intriguingly, it offers notable advantages
in practical applications, such as long-context modeling, key information
retrieval, hallucination mitigation, in-context learning, and reduction of
activation outliers. By being less distracted by irrelevant context, Diff
Transformer can mitigate hallucination in question answering and text
summarization. For in-context learning, Diff Transformer not only enhances
accuracy but is also more robust to order permutation, which was considered as
a chronic robustness issue. The results position Diff Transformer as a highly
effective and promising architecture to advance large language models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GLEE: A Unified Framework and Benchmark for Language-based Economic
  Environments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05254v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05254v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eilam Shapira, Omer Madmon, Itamar Reinman, Samuel Joseph Amouyal, Roi Reichart, Moshe Tennenholtz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) show significant potential in economic and
strategic interactions, where communication via natural language is often
prevalent. This raises key questions: Do LLMs behave rationally? Can they mimic
human behavior? Do they tend to reach an efficient and fair outcome? What is
the role of natural language in the strategic interaction? How do
characteristics of the economic environment influence these dynamics? These
questions become crucial concerning the economic and societal implications of
integrating LLM-based agents into real-world data-driven systems, such as
online retail platforms and recommender systems. While the ML community has
been exploring the potential of LLMs in such multi-agent setups, varying
assumptions, design choices and evaluation criteria across studies make it
difficult to draw robust and meaningful conclusions. To address this, we
introduce a benchmark for standardizing research on two-player, sequential,
language-based games. Inspired by the economic literature, we define three base
families of games with consistent parameterization, degrees of freedom and
economic measures to evaluate agents' performance (self-gain), as well as the
game outcome (efficiency and fairness). We develop an open-source framework for
interaction simulation and analysis, and utilize it to collect a dataset of LLM
vs. LLM interactions across numerous game configurations and an additional
dataset of human vs. LLM interactions. Through extensive experimentation, we
demonstrate how our framework and dataset can be used to: (i) compare the
behavior of LLM-based agents to human players in various economic contexts;
(ii) evaluate agents in both individual and collective performance measures;
and (iii) quantify the effect of the economic characteristics of the
environments on the behavior of agents.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Causal Micro-Narratives <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05252v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05252v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mourad Heddaya, Qingcheng Zeng, Chenhao Tan, Rob Voigt, Alexander Zentefis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a novel approach to classify causal micro-narratives from text.
These narratives are sentence-level explanations of the cause(s) and/or
effect(s) of a target subject. The approach requires only a subject-specific
ontology of causes and effects, and we demonstrate it with an application to
inflation narratives. Using a human-annotated dataset spanning historical and
contemporary US news articles for training, we evaluate several large language
models (LLMs) on this multi-label classification task. The best-performing
model--a fine-tuned Llama 3.1 8B--achieves F1 scores of 0.87 on narrative
detection and 0.71 on narrative classification. Comprehensive error analysis
reveals challenges arising from linguistic ambiguity and highlights how model
errors often mirror human annotator disagreements. This research establishes a
framework for extracting causal micro-narratives from real-world data, with
wide-ranging applications to social science research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Workshop on Narrative Understanding</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SFTMix: Elevating Language Model Instruction Tuning with Mixup Recipe 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05248v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05248v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxin Xiao, Shujian Zhang, Wenxuan Zhou, Marzyeh Ghassemi, Sanqiang Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To induce desired behaviors in large language models (LLMs) for
interaction-driven tasks, the instruction-tuning stage typically trains LLMs on
instruction-response pairs using the next-token prediction (NTP) loss. Previous
work aiming to improve instruction-tuning performance often emphasizes the need
for higher-quality supervised fine-tuning (SFT) datasets, which typically
involves expensive data filtering with proprietary LLMs or labor-intensive data
generation by human annotators. However, these approaches do not fully leverage
the datasets' intrinsic properties, resulting in high computational and labor
costs, thereby limiting scalability and performance gains. In this paper, we
propose SFTMix, a novel recipe that elevates instruction-tuning performance
beyond the conventional NTP paradigm, without the need for well-curated
datasets. Observing that LLMs exhibit uneven confidence across the semantic
representation space, we argue that examples with different confidence levels
should play distinct roles during the instruction-tuning process. Based on this
insight, SFTMix leverages training dynamics to identify examples with varying
confidence levels, then applies a Mixup-based regularization to mitigate
overfitting on confident examples while propagating supervision signals to
improve learning on relatively unconfident ones. This approach enables SFTMix
to significantly outperform NTP across a wide range of instruction-following
and healthcare domain-specific SFT tasks, demonstrating its adaptability to
diverse LLM families and scalability to datasets of any size. Comprehensive
ablation studies further verify the robustness of SFTMix's design choices,
underscoring its versatility in consistently enhancing performance across
different LLMs and datasets in broader natural language processing
applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Navigating the Digital World as Humans Do: Universal Visual Grounding
  for GUI Agents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05243v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05243v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Boyu Gou, Ruohan Wang, Boyuan Zheng, Yanan Xie, Cheng Chang, Yiheng Shu, Huan Sun, Yu Su
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal large language models (MLLMs) are transforming the capabilities of
graphical user interface (GUI) agents, facilitating their transition from
controlled simulations to complex, real-world applications across various
platforms. However, the effectiveness of these agents hinges on the robustness
of their grounding capability. Current GUI agents predominantly utilize
text-based representations such as HTML or accessibility trees, which, despite
their utility, often introduce noise, incompleteness, and increased
computational overhead. In this paper, we advocate a human-like embodiment for
GUI agents that perceive the environment entirely visually and directly take
pixel-level operations on the GUI. The key is visual grounding models that can
accurately map diverse referring expressions of GUI elements to their
coordinates on the GUI across different platforms. We show that a simple
recipe, which includes web-based synthetic data and slight adaptation of the
LLaVA architecture, is surprisingly effective for training such visual
grounding models. We collect the largest dataset for GUI visual grounding so
far, containing 10M GUI elements and their referring expressions over 1.3M
screenshots, and use it to train UGround, a strong universal visual grounding
model for GUI agents. Empirical results on six benchmarks spanning three
categories (grounding, offline agent, and online agent) show that 1) UGround
substantially outperforms existing visual grounding models for GUI agents, by
up to 20% absolute, and 2) agents with UGround outperform state-of-the-art
agents, despite the fact that existing agents use additional text-based input
while ours only uses visual perception. These results provide strong support
for the feasibility and promises of GUI agents that navigate the digital world
as humans do.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TuneVLSeg: <span class="highlight-title">Prompt</span> Tuning Benchmark for Vision-Language Segmentation
  Models <span class="chip">ACCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05239v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05239v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rabin Adhikari, Safal Thapaliya, Manish Dhakal, Bishesh Khanal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-Language Models (VLMs) have shown impressive performance in vision
tasks, but adapting them to new domains often requires expensive fine-tuning.
Prompt tuning techniques, including textual, visual, and multimodal prompting,
offer efficient alternatives by leveraging learnable prompts. However, their
application to Vision-Language Segmentation Models (VLSMs) and evaluation under
significant domain shifts remain unexplored. This work presents an open-source
benchmarking framework, TuneVLSeg, to integrate various unimodal and multimodal
prompt tuning techniques into VLSMs, making prompt tuning usable for downstream
segmentation datasets with any number of classes. TuneVLSeg includes $6$ prompt
tuning strategies on various prompt depths used in $2$ VLSMs totaling of $8$
different combinations. We test various prompt tuning on $8$ diverse medical
datasets, including $3$ radiology datasets (breast tumor, echocardiograph,
chest X-ray pathologies) and $5$ non-radiology datasets (polyp, ulcer, skin
cancer), and two natural domain segmentation datasets. Our study found that
textual prompt tuning struggles under significant domain shifts, from
natural-domain images to medical data. Furthermore, visual prompt tuning, with
fewer hyperparameters than multimodal prompt tuning, often achieves performance
competitive to multimodal approaches, making it a valuable first attempt. Our
work advances the understanding and applicability of different prompt-tuning
techniques for robust domain-specific segmentation. The source code is
available at https://github.com/naamiinepal/tunevlseg.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ACCV 2024 (oral presentation)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CasiMedicos-Arg: A Medical Question Answering <span class="highlight-title">Dataset</span> Annotated with
  Explanatory Argumentative Structures 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05235v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05235v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        katerina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cookbook: A framework for improving LLM generative abilities via
  programmatic data generating templates 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05224v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05224v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Avanika Narayan, Mayee F. Chen, Kush Bhatia, Christopher Ré
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Fine-tuning large language models (LLMs) on instruction datasets is a common
way to improve their generative capabilities. However, instruction datasets can
be expensive and time-consuming to manually curate, and while LLM-generated
data is less labor-intensive, it may violate user privacy agreements or terms
of service of LLM providers. Therefore, we seek a way of constructing
instruction datasets with samples that are not generated by humans or LLMs but
still improve LLM generative capabilities. In this work, we introduce Cookbook,
a framework that programmatically generates training data consisting of simple
patterns over random tokens, resulting in a scalable, cost-effective approach
that avoids legal and privacy issues. First, Cookbook uses a template -- a data
generating Python function -- to produce training data that encourages the
model to learn an explicit pattern-based rule that corresponds to a desired
task. We find that fine-tuning on Cookbook-generated data is able to improve
performance on its corresponding task by up to 52.7 accuracy points. Second,
since instruction datasets improve performance on multiple downstream tasks
simultaneously, Cookbook algorithmically learns how to mix data from various
templates to optimize performance on multiple tasks. On the standard multi-task
GPT4ALL evaluation suite, Mistral-7B fine-tuned using a Cookbook-generated
dataset attains the best accuracy on average compared to other 7B parameter
instruction-tuned models and is the best performing model on 3 out of 8 tasks.
Finally, we analyze when and why Cookbook improves performance and present a
metric that allows us to verify that the improvement is largely explained by
the model's generations adhering better to template rules.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>COLM 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Precise Model Benchmarking with Only a Few Observations <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05222v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05222v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Riccardo Fogliato, Pratik Patil, Nil-Jana Akpinar, Mathew Monfort
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  How can we precisely estimate a large language model's (LLM) accuracy on
questions belonging to a specific topic within a larger question-answering
dataset? The standard direct estimator, which averages the model's accuracy on
the questions in each subgroup, may exhibit high variance for subgroups
(topics) with small sample sizes. Synthetic regression modeling, which
leverages the model's accuracy on questions about other topics, may yield
biased estimates that are too unreliable for large subgroups. We prescribe a
simple yet effective solution: an empirical Bayes (EB) estimator that balances
direct and regression estimates for each subgroup separately, improving the
precision of subgroup-level estimates of model performance. Our experiments on
multiple datasets show that this approach consistently provides more precise
estimates of the LLM performance compared to the direct and regression
approaches, achieving substantial reductions in the mean squared error.
Confidence intervals for EB estimates also have near-nominal coverage and are
narrower compared to those for the direct estimator. Additional experiments on
tabular and vision data validate the benefits of this EB approach.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear at EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Density estimation with LLMs: a geometric investigation of in-context
  learning trajectories <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05218v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05218v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Toni J. B. Liu, Nicolas Boullé, Raphaël Sarfati, Christopher J. Earls
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) demonstrate remarkable emergent abilities to
perform in-context learning across various tasks, including time series
forecasting. This work investigates LLMs' ability to estimate probability
density functions (PDFs) from data observed in-context; such density estimation
(DE) is a fundamental task underlying many probabilistic modeling problems. We
leverage the Intensive Principal Component Analysis (InPCA) to visualize and
analyze the in-context learning dynamics of LLaMA-2 models. Our main finding is
that these LLMs all follow similar learning trajectories in a low-dimensional
InPCA space, which are distinct from those of traditional density estimation
methods like histograms and Gaussian kernel density estimation (KDE). We
interpret the LLaMA in-context DE process as a KDE with an adaptive kernel
width and shape. This custom kernel model captures a significant portion of
LLaMA's behavior despite having only two parameters. We further speculate on
why LLaMA's kernel width and shape differs from classical algorithms, providing
insights into the mechanism of in-context probabilistic reasoning in LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review as a conference paper at ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Preserving Multi-Modal Capabilities of <span class="highlight-title">Pre-train</span>ed VLMs for Improving
  Vision-Linguistic Compositionality <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05210v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05210v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Youngtaek Oh, Jae Won Cho, Dong-Jin Kim, In So Kweon, Junmo Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose a new method to enhance compositional understanding
in pre-trained vision and language models (VLMs) without sacrificing
performance in zero-shot multi-modal tasks. Traditional fine-tuning approaches
often improve compositional reasoning at the cost of degrading multi-modal
capabilities, primarily due to the use of global hard negative (HN) loss, which
contrasts global representations of images and texts. This global HN loss
pushes HN texts that are highly similar to the original ones, damaging the
model's multi-modal representations. To overcome this limitation, we propose
Fine-grained Selective Calibrated CLIP (FSC-CLIP), which integrates local hard
negative loss and selective calibrated regularization. These innovations
provide fine-grained negative supervision while preserving the model's
representational integrity. Our extensive evaluations across diverse benchmarks
for both compositionality and multi-modal tasks show that FSC-CLIP not only
achieves compositionality on par with state-of-the-art models but also retains
strong multi-modal capabilities. Code is available at:
https://github.com/ytaek-oh/fsc-clip.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 (Long, Main). Project page:
  https://ytaek-oh.github.io/fsc-clip</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Studying and Mitigating Biases in Sign Language Understanding Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05206v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05206v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Katherine Atwell, Danielle Bragg, Malihe Alikhani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ensuring that the benefits of sign language technologies are distributed
equitably among all community members is crucial. Thus, it is important to
address potential biases and inequities that may arise from the design or use
of these resources. Crowd-sourced sign language datasets, such as the ASL
Citizen dataset, are great resources for improving accessibility and preserving
linguistic diversity, but they must be used thoughtfully to avoid reinforcing
existing biases.
  In this work, we utilize the rich information about participant demographics
and lexical features present in the ASL Citizen dataset to study and document
the biases that may result from models trained on crowd-sourced sign datasets.
Further, we apply several bias mitigation techniques during model training, and
find that these techniques reduce performance disparities without decreasing
accuracy. With the publication of this work, we release the demographic
information about the participants in the ASL Citizen dataset to encourage
future bias mitigation work in this space.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RevisEval: Improving LLM-as-a-Judge via Response-Adapted References 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05193v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05193v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qiyuan Zhang, Yufei Wang, Tiezheng YU, Yuxin Jiang, Chuhan Wu, Liangyou Li, Yasheng Wang, Xin Jiang, Lifeng Shang, Ruiming Tang, Fuyuan Lyu, Chen Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With significant efforts in recent studies, LLM-as-a-Judge has become a
cost-effective alternative to human evaluation for assessing the text
generation quality in a wide range of tasks. However, there still remains a
reliability gap between LLM-as-a-Judge and human evaluation. One important
reason is the lack of guided oracles in the evaluation process. Motivated by
the role of reference pervasively used in classic text evaluation, we introduce
RevisEval, a novel text generation evaluation paradigm via the response-adapted
references. RevisEval is driven by the key observation that an ideal reference
should maintain the necessary relevance to the response to be evaluated.
Specifically, RevisEval leverages the text revision capabilities of large
language models (LLMs) to adaptively revise the response, then treat the
revised text as the reference (response-adapted reference) for the subsequent
evaluation. Extensive experiments demonstrate that RevisEval outperforms
traditional reference-free and reference-based evaluation paradigms that use
LLM-as-a-Judge across NLG tasks and open-ended instruction-following tasks.
More importantly, our response-adapted references can further boost the
classical text metrics, e.g., BLEU and BERTScore, compared to traditional
references and even rival the LLM-as-a-Judge. A detailed analysis is also
conducted to confirm RevisEval's effectiveness in bias reduction, the impact of
inference cost, and reference relevance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Understanding Warmup-Stable-Decay Learning Rates: A River Valley Loss
  Landscape Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05192v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05192v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaiyue Wen, Zhiyuan Li, Jason Wang, David Hall, Percy Liang, Tengyu Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Training language models currently requires pre-determining a fixed compute
budget because the typical cosine learning rate schedule depends on the total
number of steps. In contrast, the Warmup-Stable-Decay (WSD) schedule uses a
constant learning rate to produce a main branch of iterates that can in
principle continue indefinitely without a pre-specified compute budget. Then,
given any compute budget, one can branch out from the main branch at a proper
at any time with a rapidly decaying learning rate to produce a strong model.
Empirically, WSD generates a non-traditional loss curve: the loss remains
elevated during the stable phase but sharply declines during the decay phase.
Towards explaining this phenomenon, we conjecture that pretraining loss
exhibits a river valley landscape, which resembles a deep valley with a river
at its bottom. Under this assumption, we show that during the stable phase, the
iterate undergoes large oscillations due to the high learning rate, yet it
progresses swiftly along the river. During the decay phase, the rapidly
dropping learning rate minimizes the iterate's oscillations, moving it closer
to the river and revealing true optimization progress. Therefore, the sustained
high learning rate phase and fast decaying phase are responsible for progress
in the river and the mountain directions respectively, and are both critical.
Our analysis predicts phenomenons consistent with empirical observations and
shows that this landscape can emerge from pretraining on a simple bi-gram
dataset. Inspired by the theory, we introduce WSD-S, a variant of WSD that
reuses previous checkpoints' decay phases and keeps only one main branch, where
we resume from a decayed checkpoint. WSD-S empirically outperforms WSD and
Cyclic-Cosine in obtaining multiple language model checkpoints across various
compute budgets in a single run for parameters scaling from 0.1B to 1.2B.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>45 pages,13 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Beyond Correlation: Interpretable Evaluation of Machine Translation
  Metrics <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05183v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05183v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Stefano Perrella, Lorenzo Proietti, Pere-Lluís Huguet Cabot, Edoardo Barba, Roberto Navigli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine Translation (MT) evaluation metrics assess translation quality
automatically. Recently, researchers have employed MT metrics for various new
use cases, such as data filtering and translation re-ranking. However, most MT
metrics return assessments as scalar scores that are difficult to interpret,
posing a challenge to making informed design choices. Moreover, MT metrics'
capabilities have historically been evaluated using correlation with human
judgment, which, despite its efficacy, falls short of providing intuitive
insights into metric performance, especially in terms of new metric use cases.
To address these issues, we introduce an interpretable evaluation framework for
MT metrics. Within this framework, we evaluate metrics in two scenarios that
serve as proxies for the data filtering and translation re-ranking use cases.
Furthermore, by measuring the performance of MT metrics using Precision,
Recall, and F-score, we offer clearer insights into their capabilities than
correlation with human judgments. Finally, we raise concerns regarding the
reliability of manually curated data following the Direct Assessments+Scalar
Quality Metrics (DA+SQM) guidelines, reporting a notably low agreement with
Multidimensional Quality Metrics (MQM) annotations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024 Main Conference. 26 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Equity in Large Language Models for Medical Applications 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05180v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05180v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuelyu Ji, Wenhe Ma, Sonish Sivarajkumar, Hang Zhang, Eugene Mathew Sadhu, Zhuochun Li, Xizhi Wu, Shyam Visweswaran, Yanshan Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements have highlighted the potential of large language models
(LLMs) in medical applications, notably in automating Clinical Trial Matching
for translational research and providing medical question-answering for
clinical decision support. However, our study reveals significant inequities in
the use of LLMs, particularly for individuals from specific racial, gender, and
underrepresented groups influenced by social determinants of health. These
disparities could worsen existing health inequities if LLMs are broadly adopted
in healthcare. To address this, we propose and evaluate a novel framework,
EquityGuard, designed to detect and mitigate biases in LLM-based medical
applications. EquityGuard incorporates a Bias Detection Mechanism capable of
identifying and correcting unfair predictions, thus enhancing outcomes and
promoting equity across diverse population groups.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ReasoningRank: Teaching Student Models to Rank through Reasoning-Based
  Knowledge Distillation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05168v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05168v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuelyu Ji, Zhuochun Li, Rui Meng, Daqing He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reranking documents based on their relevance to a given query is critical in
information retrieval. Traditional reranking methods often focus on improving
the initial rankings but lack transparency, failing to explain why one document
is ranked higher. In this paper, we introduce ReasoningRank, a novel reranking
approach that enhances clarity by generating two types of reasoning: explicit
reasoning, which explains how a document addresses the query, and comparison
reasoning, which justifies the relevance of one document over another. We
leverage large language models (LLMs) as teacher models to generate these
explanations and distill this knowledge into smaller, more resource-efficient
student models. While the student models may not outperform LLMs in speed, they
significantly reduce the computational burden by requiring fewer resources,
making them more suitable for large-scale or resource-constrained settings.
These student models are trained to both generate meaningful reasoning and
rerank documents, achieving competitive performance across multiple datasets,
including MSMARCO and BRIGHT. Experiments demonstrate that ReasoningRank
improves reranking accuracy and provides valuable insights into the
decision-making process, offering a structured and interpretable solution for
reranking tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient Inference for Large Language Model-based Generative
  Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05165v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05165v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyu Lin, Chaoqun Yang, Wenjie Wang, Yongqi Li, Cunxiao Du, Fuli Feng, See-Kiong Ng, Tat-Seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Model (LLM)-based generative recommendation has achieved
notable success, yet its practical deployment is costly particularly due to
excessive inference latency caused by autoregressive decoding. For lossless LLM
decoding acceleration, Speculative Decoding (SD) has emerged as a promising
solution. However, applying SD to generative recommendation presents unique
challenges due to the requirement of generating top-K items (i.e., K distinct
token sequences) as a recommendation list by beam search. This leads to more
stringent verification in SD, where all the top-K sequences from the target LLM
must be successfully drafted by the draft model at each decoding step. To
alleviate this, we consider 1) boosting top-K sequence alignment between the
draft model and the target LLM, and 2) relaxing the verification strategy to
reduce trivial LLM calls. To this end, we propose an alignment framework named
AtSpeed, which presents the AtSpeed-S optimization objective for top-K
alignment under the strict top-K verification. Moreover, we introduce a relaxed
sampling verification strategy that allows high-probability non-top-K drafted
sequences to be accepted, significantly reducing LLM calls. Correspondingly, we
propose AtSpeed-R for top-K alignment under this relaxed sampling verification.
Empirical results on two real-world datasets demonstrate that AtSpeed
significantly accelerates LLM-based generative recommendation, e.g., near 2x
speedup under strict top-K verification and up to 2.5 speedup under relaxed
sampling verification. The codes and datasets will be released in the near
future.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deciphering the Interplay of Parametric and Non-parametric Memory in
  Retrieval-augmented Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05162v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05162v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mehrdad Farahani, Richard Johansson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative language models often struggle with specialized or less-discussed
knowledge. A potential solution is found in Retrieval-Augmented Generation
(RAG) models which act like retrieving information before generating responses.
In this study, we explore how the \textsc{Atlas} approach, a RAG model, decides
between what it already knows (parametric) and what it retrieves
(non-parametric). We use causal mediation analysis and controlled experiments
to examine how internal representations influence information processing. Our
findings disentangle the effects of parametric knowledge and the retrieved
context. They indicate that in cases where the model can choose between both
types of information (parametric and non-parametric), it relies more on the
context than the parametric knowledge. Furthermore, the analysis investigates
the computations involved in \emph{how} the model uses the information from the
context. We find that multiple mechanisms are active within the model and can
be detected with mediation analysis: first, the decision of \emph{whether the
context is relevant}, and second, how the encoder computes output
representations to support copying when relevant.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VLM2Vec: Training Vision-Language Models for Massive Multimodal
  Embedding Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05160v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05160v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziyan Jiang, Rui Meng, Xinyi Yang, Semih Yavuz, Yingbo Zhou, Wenhu Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Embedding models have been crucial in enabling various downstream tasks such
as semantic similarity, information retrieval, and clustering. Recently, there
has been a surge of interest in developing universal text embedding models that
can generalize across tasks (e.g., MTEB). However, progress in learning
universal multimodal embedding models has been relatively slow despite their
importance. In this work, we aim to explore the potential for building
universal embeddings capable of handling a wide range of downstream tasks. Our
contributions are twofold: (1) MMEB (Massive Multimodal Embedding Benchmark),
which covers 4 meta-tasks (i.e. classification, visual question answering,
multimodal retrieval, and visual grounding) and 36 datasets, including 20
training and 16 evaluation datasets, and (2) VLM2Vec (Vision-Language Model ->
Vector), a contrastive training framework that converts any state-of-the-art
vision-language model into an embedding model via training on MMEB. Unlike
previous models such as CLIP and BLIP, VLM2Vec can process any combination of
images and text to generate a fixed-dimensional vector based on task
instructions. We build a series of VLM2Vec models on Phi-3.5-V and evaluate
them on MMEB's evaluation split. Our results show that \model achieves an
absolute average improvement of 10% to 20% over existing multimodal embedding
models on both in-distribution and out-of-distribution datasets in MMEB.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical Report</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CTC-GMM: CTC guided modality matching for fast and accurate streaming
  speech translation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05146v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05146v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Zhao, Jinyu Li, Ruchao Fan, Matt Post
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Models for streaming speech translation (ST) can achieve high accuracy and
low latency if they're developed with vast amounts of paired audio in the
source language and written text in the target language. Yet, these text labels
for the target language are often pseudo labels due to the prohibitive cost of
manual ST data labeling. In this paper, we introduce a methodology named
Connectionist Temporal Classification guided modality matching (CTC-GMM) that
enhances the streaming ST model by leveraging extensive machine translation
(MT) text data. This technique employs CTC to compress the speech sequence into
a compact embedding sequence that matches the corresponding text sequence,
allowing us to utilize matched {source-target} language text pairs from the MT
corpora to refine the streaming ST model further. Our evaluations with FLEURS
and CoVoST2 show that the CTC-GMM approach can increase translation accuracy
relatively by 13.9% and 6.4% respectively, while also boosting decoding speed
by 59.7% on GPU.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IEEE Spoken Language Technology Workshop (SLT 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SparsePO: Controlling Preference Alignment of LLMs via Sparse Token
  Masks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05102v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05102v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fenia Christopoulou, Ronald Cardenas, Gerasimos Lampouras, Haitham Bou-Ammar, Jun Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Preference Optimization (PO) has proven an effective step for aligning
language models to human-desired behaviors. Current variants, following the
offline Direct Preference Optimization objective, have focused on a strict
setting where all tokens are contributing signals of KL divergence and rewards
to the loss function. However, human preference is not affected by each word in
a sequence equally but is often dependent on specific words or phrases, e.g.
existence of toxic terms leads to non-preferred responses. Based on this
observation, we argue that not all tokens should be weighted equally during PO
and propose a flexible objective termed SparsePO, that aims to automatically
learn to weight the KL divergence and reward corresponding to each token during
PO training. We propose two different variants of weight-masks that can either
be derived from the reference model itself or learned on the fly. Notably, our
method induces sparsity in the learned masks, allowing the model to learn how
to best weight reward and KL divergence contributions at the token level,
learning an optimal level of mask sparsity. Extensive experiments on multiple
domains, including sentiment control, dialogue, text summarization and
text-to-code generation, illustrate that our approach assigns meaningful
weights to tokens according to the target task, generates more responses with
the desired preference and improves reasoning tasks by up to 2 percentage
points compared to other token- and response-level PO methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 papges, 9 figures, 5 tables. Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Investigating large language models for their competence in extracting
  grammatically sound sentences from transcribed noisy utterances <span class="chip">CoNLL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05099v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05099v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alina Wróblewska
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Selectively processing noisy utterances while effectively disregarding
speech-specific elements poses no considerable challenge for humans, as they
exhibit remarkable cognitive abilities to separate semantically significant
content from speech-specific noise (i.e. filled pauses, disfluencies, and
restarts). These abilities may be driven by mechanisms based on acquired
grammatical rules that compose abstract syntactic-semantic structures within
utterances. Segments without syntactic and semantic significance are
consistently disregarded in these structures. The structures, in tandem with
lexis, likely underpin language comprehension and thus facilitate effective
communication. In our study, grounded in linguistically motivated experiments,
we investigate whether large language models (LLMs) can effectively perform
analogical speech comprehension tasks. In particular, we examine the ability of
LLMs to extract well-structured utterances from transcriptions of noisy
dialogues. We conduct two evaluation experiments in the Polish language
scenario, using a~dataset presumably unfamiliar to LLMs to mitigate the risk of
data contamination. Our results show that not all extracted utterances are
correctly structured, indicating that either LLMs do not fully acquire
syntactic-semantic rules or they acquire them but cannot apply them
effectively. We conclude that the ability of LLMs to comprehend noisy
utterances is still relatively superficial compared to human proficiency in
processing them.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at CoNLL 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Explanation sensitivity to the randomness of large language models: the
  case of journalistic text classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05085v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05085v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jeremie Bogaert, Marie-Catherine de Marneffe, Antonin Descampe, Louis Escouflaire, Cedrick Fairon, Francois-Xavier Standaert
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) perform very well in several natural language
processing tasks but raise explainability challenges. In this paper, we examine
the effect of random elements in the training of LLMs on the explainability of
their predictions. We do so on a task of opinionated journalistic text
classification in French. Using a fine-tuned CamemBERT model and an explanation
method based on relevance propagation, we find that training with different
random seeds produces models with similar accuracy but variable explanations.
We therefore claim that characterizing the explanations' statistical
distribution is needed for the explainability of LLMs. We then explore a
simpler model based on textual features which offers stable explanations but is
less accurate. Hence, this simpler model corresponds to a different tradeoff
between accuracy and explainability. We show that it can be improved by
inserting features derived from CamemBERT's explanations. We finally discuss
new research directions suggested by our results, in particular regarding the
origin of the sensitivity observed in the training randomness.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper is a faithful translation of a paper which was
  peer-reviewed and published in the French journal Traitement Automatique des
  Langues, n. 64</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ScienceAgentBench: Toward Rigorous Assessment of Language Agents for
  Data-Driven Scientific Discovery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05080v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05080v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziru Chen, Shijie Chen, Yuting Ning, Qianheng Zhang, Boshi Wang, Botao Yu, Yifei Li, Zeyi Liao, Chen Wei, Zitong Lu, Vishal Dey, Mingyi Xue, Frazier N. Baker, Benjamin Burns, Daniel Adu-Ampratwum, Xuhui Huang, Xia Ning, Song Gao, Yu Su, Huan Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The advancements of language language models (LLMs) have piqued growing
interest in developing LLM-based language agents to automate scientific
discovery end-to-end, which has sparked both excitement and skepticism about
the true capabilities of such agents. In this work, we argue that for an agent
to fully automate scientific discovery, it must be able to complete all
essential tasks in the workflow. Thus, we call for rigorous assessment of
agents on individual tasks in a scientific workflow before making bold claims
on end-to-end automation. To this end, we present ScienceAgentBench, a new
benchmark for evaluating language agents for data-driven scientific discovery.
To ensure the scientific authenticity and real-world relevance of our
benchmark, we extract 102 tasks from 44 peer-reviewed publications in four
disciplines and engage nine subject matter experts to validate them. We unify
the target output for every task to a self-contained Python program file and
employ an array of evaluation metrics to examine the generated programs,
execution results, and costs. Each task goes through multiple rounds of manual
validation by annotators and subject matter experts to ensure its annotation
quality and scientific plausibility. We also propose two effective strategies
to mitigate data contamination concerns. Using our benchmark, we evaluate five
open-weight and proprietary LLMs, each with three frameworks: direct prompting,
OpenHands, and self-debug. Given three attempts for each task, the
best-performing agent can only solve 32.4% of the tasks independently and 34.3%
with expert-provided knowledge. These results underscore the limited capacities
of current language agents in generating code for data-driven discovery, let
alone end-to-end automation for scientific research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>55 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense
  Question Answering <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05077v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05077v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Francesco Maria Molfese, Simone Conia, Riccardo Orlando, Roberto Navigli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current Large Language Models (LLMs) have shown strong reasoning capabilities
in commonsense question answering benchmarks, but the process underlying their
success remains largely opaque. As a consequence, recent approaches have
equipped LLMs with mechanisms for knowledge retrieval, reasoning and
introspection, not only to improve their capabilities but also to enhance the
interpretability of their outputs. However, these methods require additional
training, hand-crafted templates or human-written explanations. To address
these issues, we introduce ZEBRA, a zero-shot question answering framework that
combines retrieval, case-based reasoning and introspection and dispenses with
the need for additional training of the LLM. Given an input question, ZEBRA
retrieves relevant question-knowledge pairs from a knowledge base and generates
new knowledge by reasoning over the relationships in these pairs. This
generated knowledge is then used to answer the input question, improving the
model's performance and interpretability. We evaluate our approach across 8
well-established commonsense reasoning benchmarks, demonstrating that ZEBRA
consistently outperforms strong LLMs and previous knowledge integration
approaches, achieving an average accuracy improvement of up to 4.5 points.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TidalDecode: Fast and Accurate LLM Decoding with Position Persistent
  Sparse Attention 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05076v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05076v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lijie Yang, Zhihao Zhang, Zhuofu Chen, Zikun Li, Zhihao Jia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have driven significant advancements across
diverse NLP tasks, with long-context models gaining prominence for handling
extended inputs. However, the expanding key-value (KV) cache size required by
Transformer architectures intensifies the memory constraints, particularly
during the decoding phase, creating a significant bottleneck. Existing sparse
attention mechanisms designed to address this bottleneck have two limitations:
(1) they often fail to reliably identify the most relevant tokens for
attention, and (2) they overlook the spatial coherence of token selection
across consecutive Transformer layers, which can lead to performance
degradation and substantial overhead in token selection. This paper introduces
TidalDecode, a simple yet effective algorithm and system for fast and accurate
LLM decoding through position persistent sparse attention. TidalDecode
leverages the spatial coherence of tokens selected by existing sparse attention
methods and introduces a few token selection layers that perform full attention
to identify the tokens with the highest attention scores, while all other
layers perform sparse attention with the pre-selected tokens. This design
enables TidalDecode to substantially reduce the overhead of token selection for
sparse attention without sacrificing the quality of the generated results.
Evaluation on a diverse set of LLMs and tasks shows that TidalDecode closely
matches the generative performance of full attention methods while reducing the
LLM decoding latency by up to 2.1x.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Initialization of Large Language Models via Reparameterization to
  Mitigate Loss Spikes <span class="chip">EMNLP2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05052v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05052v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kosuke Nishida, Kyosuke Nishida, Kuniko Saito
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Loss spikes, a phenomenon in which the loss value diverges suddenly, is a
fundamental issue in the pre-training of large language models. This paper
supposes that the non-uniformity of the norm of the parameters is one of the
causes of loss spikes. Here, in training of neural networks, the scale of the
gradients is required to be kept constant throughout the layers to avoid the
vanishing and exploding gradients problem. However, to meet these requirements
in the Transformer model, the norm of the model parameters must be non-uniform,
and thus, parameters whose norm is smaller are more sensitive to the parameter
update. To address this issue, we propose a novel technique, weight scaling as
reparameterization (WeSaR). WeSaR introduces a gate parameter per parameter
matrix and adjusts it to the value satisfying the requirements. Because of the
gate parameter, WeSaR sets the norm of the original parameters uniformly, which
results in stable training. Experimental results with the Transformer decoders
consisting of 130 million, 1.3 billion, and 13 billion parameters showed that
WeSaR stabilizes and accelerates training and that it outperformed compared
methods including popular initialization methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP2024 accepted</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A test suite of <span class="highlight-title">prompt</span> injection attacks for LLM-based machine
  translation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05047v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05047v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Antonio Valerio Miceli-Barone, Zhifan Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLM-based NLP systems typically work by embedding their input data into
prompt templates which contain instructions and/or in-context examples,
creating queries which are submitted to a LLM, and then parsing the LLM
response in order to generate the system outputs. Prompt Injection Attacks
(PIAs) are a type of subversion of these systems where a malicious user crafts
special inputs which interfere with the prompt templates, causing the LLM to
respond in ways unintended by the system designer.
  Recently, Sun and Miceli-Barone proposed a class of PIAs against LLM-based
machine translation. Specifically, the task is to translate questions from the
TruthfulQA test suite, where an adversarial prompt is prepended to the
questions, instructing the system to ignore the translation instruction and
answer the questions instead.
  In this test suite, we extend this approach to all the language pairs of the
WMT 2024 General Machine Translation task. Moreover, we include additional
attack formats in addition to the one originally studied.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Named Clinical Entity Recognition Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05046v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05046v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wadood M Abdul, Marco AF Pimentel, Muhammad Umar Salman, Tathagata Raha, Clément Christophe, Praveen K Kanithi, Nasir Hayat, Ronnie Rajan, Shadab Khan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This technical report introduces a Named Clinical Entity Recognition
Benchmark for evaluating language models in healthcare, addressing the crucial
natural language processing (NLP) task of extracting structured information
from clinical narratives to support applications like automated coding,
clinical trial cohort identification, and clinical decision support.
  The leaderboard provides a standardized platform for assessing diverse
language models, including encoder and decoder architectures, on their ability
to identify and classify clinical entities across multiple medical domains. A
curated collection of openly available clinical datasets is utilized,
encompassing entities such as diseases, symptoms, medications, procedures, and
laboratory measurements. Importantly, these entities are standardized according
to the Observational Medical Outcomes Partnership (OMOP) Common Data Model,
ensuring consistency and interoperability across different healthcare systems
and datasets, and a comprehensive evaluation of model performance. Performance
of models is primarily assessed using the F1-score, and it is complemented by
various assessment modes to provide comprehensive insights into model
performance. The report also includes a brief analysis of models evaluated to
date, highlighting observed trends and limitations.
  By establishing this benchmarking framework, the leaderboard aims to promote
transparency, facilitate comparative analyses, and drive innovation in clinical
entity recognition tasks, addressing the need for robust evaluation methods in
healthcare NLP.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical Report</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Can LLMs plan paths with extra hints from solvers? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05045v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05045v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Erik Wu, Sayan Mitra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have shown remarkable capabilities in natural
language processing, mathematical problem solving, and tasks related to program
synthesis. However, their effectiveness in long-term planning and higher-order
reasoning has been noted to be limited and fragile. This paper explores an
approach for enhancing LLM performance in solving a classical robotic planning
task by integrating solver-generated feedback. We explore four different
strategies for providing feedback, including visual feedback, we utilize
fine-tuning, and we evaluate the performance of three different LLMs across a
10 standard and 100 more randomly generated planning problems. Our results
suggest that the solver-generated feedback improves the LLM's ability to solve
the moderately difficult problems, but the harder problems still remain out of
reach. The study provides detailed analysis of the effects of the different
hinting strategies and the different planning tendencies of the evaluated LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DEPT: Decoupled Embeddings for <span class="highlight-title">Pre-train</span>ing Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05021v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05021v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alex Iacob, Lorenzo Sani, Meghdad Kurmanji, William F. Shen, Xinchi Qiu, Dongqi Cai, Yan Gao, Nicholas D. Lane
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language Model pre-training benefits from a broader data mixture to enhance
performance across domains and languages. However, training on such
heterogeneous text corpora is complex, requiring extensive and cost-intensive
efforts. Since these data sources vary in lexical, syntactic, and semantic
aspects, they cause negative interference or the "curse of multilinguality". We
propose a novel pre-training framework to alleviate this curse. Our method,
DEPT, decouples the embedding layers from the transformer body while
simultaneously training the latter in multiple contexts. DEPT enables the model
to train without being bound to a shared global vocabulary. DEPT: (1) can train
robustly and effectively under significant data heterogeneity, (2) reduces the
parameter count of the token embeddings by up to 80% and the communication
costs by 675x for billion-scale models (3) enhances model generalization and
plasticity in adapting to new languages and domains, and (4) allows training
with custom optimized vocabulary per data source. We prove DEPT's potential by
performing the first vocabulary-agnostic federated multilingual pre-training of
a 1.3 billion-parameter model across high and low-resource languages, reducing
its parameter count by 409 million.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On the Biased Assessment of Expert Finding Systems <span class="chip">RecSys</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05018v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05018v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jens-Joris Decorte, Jeroen Van Hautte, Chris Develder, Thomas Demeester
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In large organisations, identifying experts on a given topic is crucial in
leveraging the internal knowledge spread across teams and departments.
So-called enterprise expert retrieval systems automatically discover and
structure employees' expertise based on the vast amount of heterogeneous data
available about them and the work they perform. Evaluating these systems
requires comprehensive ground truth expert annotations, which are hard to
obtain. Therefore, the annotation process typically relies on automated
recommendations of knowledge areas to validate. This case study provides an
analysis of how these recommendations can impact the evaluation of expert
finding systems. We demonstrate on a popular benchmark that system-validated
annotations lead to overestimated performance of traditional term-based
retrieval models and even invalidate comparisons with more recent neural
methods. We also augment knowledge areas with synonyms to uncover a strong bias
towards literal mentions of their constituent words. Finally, we propose
constraints to the annotation process to prevent these biased evaluations, and
show that this still allows annotation suggestions of high utility. These
findings should inform benchmark creation or selection for expert finding, to
guarantee meaningful comparison of methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the 4th Workshop on Recommender Systems for Human
  Resources (RecSys in HR 2024) as part of RecSys 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SkillMatch: Evaluating <span class="highlight-title">Self-supervised</span> Learning of Skill Relatedness <span class="chip">ECML-PKDD 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05006v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05006v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jens-Joris Decorte, Jeroen Van Hautte, Thomas Demeester, Chris Develder
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurately modeling the relationships between skills is a crucial part of
human resources processes such as recruitment and employee development. Yet, no
benchmarks exist to evaluate such methods directly. We construct and release
SkillMatch, a benchmark for the task of skill relatedness, based on expert
knowledge mining from millions of job ads. Additionally, we propose a scalable
self-supervised learning technique to adapt a Sentence-BERT model based on
skill co-occurrence in job ads. This new method greatly surpasses traditional
models for skill relatedness as measured on SkillMatch. By releasing SkillMatch
publicly, we aim to contribute a foundation for research towards increased
accuracy and transparency of skill-based recommendation systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the International workshop on AI for Human Resources and
  Public Employment Services (AI4HR&PES) as part of ECML-PKDD 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On the Rigour of Scientific Writing: Criteria, Analysis, and Insights <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04981v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04981v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joseph James, Chenghao Xiao, Yucheng Li, Chenghua Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Rigour is crucial for scientific research as it ensures the reproducibility
and validity of results and findings. Despite its importance, little work
exists on modelling rigour computationally, and there is a lack of analysis on
whether these criteria can effectively signal or measure the rigour of
scientific papers in practice. In this paper, we introduce a bottom-up,
data-driven framework to automatically identify and define rigour criteria and
assess their relevance in scientific writing. Our framework includes rigour
keyword extraction, detailed rigour definition generation, and salient criteria
identification. Furthermore, our framework is domain-agnostic and can be
tailored to the evaluation of scientific rigour for different areas,
accommodating the distinct salient criteria across fields. We conducted
comprehensive experiments based on datasets collected from two high impact
venues for Machine Learning and NLP (i.e., ICLR and ACL) to demonstrate the
effectiveness of our framework in modelling rigour. In addition, we analyse
linguistic patterns of rigour, revealing that framing certainty is crucial for
enhancing the perception of scientific rigour, while suggestion certainty and
probability uncertainty diminish it.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted Findings at EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Activation Scaling for Steering and Interpreting Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04962v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04962v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Niklas Stoehr, Kevin Du, Vésteinn Snæbjarnarson, Robert West, Ryan Cotterell, Aaron Schein
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Given the prompt "Rome is in", can we steer a language model to flip its
prediction of an incorrect token "France" to a correct token "Italy" by only
multiplying a few relevant activation vectors with scalars? We argue that
successfully intervening on a model is a prerequisite for interpreting its
internal workings. Concretely, we establish a three-term objective: a
successful intervention should flip the correct with the wrong token and vice
versa (effectiveness), and leave other tokens unaffected (faithfulness), all
while being sparse (minimality). Using gradient-based optimization, this
objective lets us learn (and later evaluate) a specific kind of efficient and
interpretable intervention: activation scaling only modifies the signed
magnitude of activation vectors to strengthen, weaken, or reverse the steering
directions already encoded in the model. On synthetic tasks, this intervention
performs comparably with steering vectors in terms of effectiveness and
faithfulness, but is much more minimal allowing us to pinpoint interpretable
model components. We evaluate activation scaling from different angles, compare
performance on different datasets, and make activation scalars a learnable
function of the activation vectors themselves to generalize to varying-length
prompts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Findings of the Association for Computational Linguistics: EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Intent Classification for Bank Chatbots through LLM Fine-Tuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04925v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04925v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bibiána Lajčinová, Patrik Valábek, Michal Spišiak
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study evaluates the application of large language models (LLMs) for
intent classification within a chatbot with predetermined responses designed
for banking industry websites. Specifically, the research examines the
effectiveness of fine-tuning SlovakBERT compared to employing multilingual
generative models, such as Llama 8b instruct and Gemma 7b instruct, in both
their pre-trained and fine-tuned versions. The findings indicate that
SlovakBERT outperforms the other models in terms of in-scope accuracy and
out-of-scope false positive rate, establishing it as the benchmark for this
application.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, no figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Leveraging Grammar Induction for Language Understanding and Generation <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04878v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04878v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jushi Kai, Shengyuan Hou, Yusheng Huang, Zhouhan Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Grammar induction has made significant progress in recent years. However, it
is not clear how the application of induced grammar could enhance practical
performance in downstream tasks. In this work, we introduce an unsupervised
grammar induction method for language understanding and generation. We
construct a grammar parser to induce constituency structures and dependency
relations, which is simultaneously trained on downstream tasks without
additional syntax annotations. The induced grammar features are subsequently
incorporated into Transformer as a syntactic mask to guide self-attention. We
evaluate and apply our method to multiple machine translation tasks and natural
language understanding tasks. Our method demonstrates superior performance
compared to the original Transformer and other models enhanced with external
parsers. Experimental results indicate that our method is effective in both
from-scratch and pre-trained scenarios. Additionally, our research highlights
the contribution of explicitly modeling the grammatical structure of texts to
neural network models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rationale-Aware Answer Verification by Pairwise Self-Evaluation <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04838v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04838v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Akira Kawabata, Saku Sugawara
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Answer verification identifies correct solutions among candidates generated
by large language models (LLMs). Current approaches typically train verifier
models by labeling solutions as correct or incorrect based solely on whether
the final answer matches the gold answer. However, this approach neglects any
flawed rationale in the solution yielding the correct answer, undermining the
verifier's ability to distinguish between sound and flawed rationales. We
empirically show that in StrategyQA, only 19% of LLM-generated solutions with
correct answers have valid rationales, thus leading to an unreliable verifier.
Furthermore, we demonstrate that training a verifier on valid rationales
significantly improves its ability to distinguish valid and flawed rationale.
To make a better verifier without extra human supervision, we introduce REPS
(Rationale Enhancement through Pairwise Selection), a method for selecting
valid rationales from candidates by iteratively applying pairwise
self-evaluation using the same LLM that generates the solutions. Verifiers
trained on solutions selected by REPS outperform those trained using
conventional training methods on three reasoning benchmarks (ARC-Challenge,
DROP, and StrategyQA). Our results suggest that training reliable verifiers
requires ensuring the validity of rationales in addition to the correctness of
the final answers, which would be critical for models assisting humans in
solving complex reasoning tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ As Simple as Fine-tuning: LLM Alignment via Bidirectional Negative
  Feedback Loss 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04834v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04834v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xin Mao, Feng-Lin Li, Huimin Xu, Wei Zhang, Wang Chen, Anh Tuan Luu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Direct Preference Optimization (DPO) has emerged as a more computationally
efficient alternative to Reinforcement Learning from Human Feedback (RLHF) with
Proximal Policy Optimization (PPO), eliminating the need for reward models and
online sampling. Despite these benefits, DPO and its variants remain sensitive
to hyper-parameters and prone to instability, particularly on mathematical
datasets. We argue that these issues arise from the unidirectional
likelihood-derivative negative feedback inherent in the log-likelihood loss
function. To address this, we propose a novel LLM alignment loss that
establishes a stable Bidirectional Negative Feedback (BNF) during optimization.
Our proposed BNF loss eliminates the need for pairwise contrastive losses and
does not require any extra tunable hyper-parameters or pairwise preference
data, streamlining the alignment pipeline to be as simple as supervised
fine-tuning. We conduct extensive experiments across two challenging QA
benchmarks and four reasoning benchmarks. The experimental results show that
BNF achieves comparable performance to the best methods on QA benchmarks, while
its performance decrease on the four reasoning benchmarks is significantly
lower compared to the best methods, thus striking a better balance between
value alignment and reasoning ability. In addition, we further validate the
performance of BNF on non-pairwise datasets, and conduct in-depth analysis of
log-likelihood and logit shifts across different preference optimization
methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MINER: Mining the Underlying Pattern of Modality-Specific Neurons in
  Multimodal Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04819v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04819v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaichen Huang, Jiahao Huo, Yibo Yan, Kun Wang, Yutao Yue, Xuming Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, multimodal large language models (MLLMs) have significantly
advanced, integrating more modalities into diverse applications. However, the
lack of explainability remains a major barrier to their use in scenarios
requiring decision transparency. Current neuron-level explanation paradigms
mainly focus on knowledge localization or language- and domain-specific
analyses, leaving the exploration of multimodality largely unaddressed. To
tackle these challenges, we propose MINER, a transferable framework for mining
modality-specific neurons (MSNs) in MLLMs, which comprises four stages: (1)
modality separation, (2) importance score calculation, (3) importance score
aggregation, (4) modality-specific neuron selection. Extensive experiments
across six benchmarks and two representative MLLMs show that (I) deactivating
ONLY 2% of MSNs significantly reduces MLLMs performance (0.56 to 0.24 for
Qwen2-VL, 0.69 to 0.31 for Qwen2-Audio), (II) different modalities mainly
converge in the lower layers, (III) MSNs influence how key information from
various modalities converges to the last token, (IV) two intriguing phenomena
worth further investigation, i.e., semantic probing and semantic telomeres. The
source code is available at this URL.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LPZero: Language Model Zero-cost Proxy Search from Zero 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04808v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04808v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peijie Dong, Lujun Li, Xiang Liu, Zhenheng Tang, Xuebo Liu, Qiang Wang, Xiaowen Chu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In spite of the outstanding performance, Neural Architecture Search (NAS) is
criticized for massive computation. Recently, Zero-shot NAS has emerged as a
promising approach by exploiting Zero-cost (ZC) proxies, which markedly reduce
computational demands. Despite this, existing ZC proxies heavily rely on expert
knowledge and incur significant trial-and-error costs. Particularly in NLP
tasks, most existing ZC proxies fail to surpass the performance of the naive
baseline. To address these challenges, we introduce a novel framework,
\textbf{LPZero}, which is the first to automatically design ZC proxies for
various tasks, achieving higher ranking consistency than human-designed
proxies. Specifically, we model the ZC proxy as a symbolic equation and
incorporate a unified proxy search space that encompasses existing ZC proxies,
which are composed of a predefined set of mathematical symbols. To
heuristically search for the best ZC proxy, LPZero incorporates genetic
programming to find the optimal symbolic composition. We propose a
\textit{Rule-based Pruning Strategy (RPS),} which preemptively eliminates
unpromising proxies, thereby mitigating the risk of proxy degradation.
Extensive experiments on FlexiBERT, GPT-2, and LLaMA-7B demonstrate LPZero's
superior ranking ability and performance on downstream tasks compared to
current approaches.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 7 figures, 10 appendix</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DAPE V2: Process Attention Score as Feature Map for Length Extrapolation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04798v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04798v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chuanyang Zheng, Yihang Gao, Han Shi, Jing Xiong, Jiankai Sun, Jingyao Li, Minbin Huang, Xiaozhe Ren, Michael Ng, Xin Jiang, Zhenguo Li, Yu Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The attention mechanism is a fundamental component of the Transformer model,
contributing to interactions among distinct tokens, in contrast to earlier
feed-forward neural networks. In general, the attention scores are determined
simply by the key-query products. However, this work's occasional trial
(combining DAPE and NoPE) of including additional MLPs on attention scores
without position encoding indicates that the classical key-query multiplication
may limit the performance of Transformers. In this work, we conceptualize
attention as a feature map and apply the convolution operator (for neighboring
attention scores across different heads) to mimic the processing methods in
computer vision. Specifically, the main contribution of this paper is
identifying and interpreting the Transformer length extrapolation problem as a
result of the limited expressiveness of the naive query and key dot product,
and we successfully translate the length extrapolation issue into a
well-understood feature map processing problem. The novel insight, which can be
adapted to various attention-related models, reveals that the current
Transformer architecture has the potential for further evolution. Extensive
experiments demonstrate that treating attention as a feature map and applying
convolution as a processing method significantly enhances Transformer
performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Tech Report. arXiv admin note: text overlap with arXiv:2405.14722</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Representing the Under-Represented: Cultural and Core Capability
  Benchmarks for Developing Thai Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04795v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04795v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dahyun Kim, Sukyung Lee, Yungi Kim, Attapol Rutherford, Chanjun Park
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid advancement of large language models (LLMs) has highlighted the
need for robust evaluation frameworks that assess their core capabilities, such
as reasoning, knowledge, and commonsense, leading to the inception of certain
widely-used benchmark suites such as the H6 benchmark. However, these benchmark
suites are primarily built for the English language, and there exists a lack
thereof for under-represented languages, in terms of LLM development, such as
Thai. On the other hand, developing LLMs for Thai should also include enhancing
the cultural understanding as well as core capabilities. To address these dual
challenge in Thai LLM research, we propose two key benchmarks: Thai-H6 and Thai
Cultural and Linguistic Intelligence Benchmark (ThaiCLI). Through a thorough
evaluation of various LLMs with multi-lingual capabilities, we provide a
comprehensive analysis of the proposed benchmarks and how they contribute to
Thai LLM development. Furthermore, we will make both the datasets and
evaluation code publicly available to encourage further research and
development for Thai LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GARLIC: LLM-Guided Dynamic Progress Control with Hierarchical Weighted
  Graph for Long Document QA 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04790v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04790v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyu Wang, Yanzheng Xiang, Lin Gui, Yulan He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the past, Retrieval-Augmented Generation (RAG) methods split text into
chunks to enable language models to handle long documents. Recent tree-based
RAG methods are able to retrieve detailed information while preserving global
context. However, with the advent of more powerful LLMs, such as Llama 3.1,
which offer better comprehension and support for longer inputs, we found that
even recent tree-based RAG methods perform worse than directly feeding the
entire document into Llama 3.1, although RAG methods still hold an advantage in
reducing computational costs. In this paper, we propose a new retrieval method,
called LLM-Guided Dynamic Progress Control with Hierarchical Weighted Graph
(GARLIC), which outperforms previous state-of-the-art baselines, including
Llama 3.1, while retaining the computational efficiency of RAG methods. Our
method introduces several improvements: (1) Rather than using a tree structure,
we construct a Hierarchical Weighted Directed Acyclic Graph with many-to-many
summarization, where the graph edges are derived from attention mechanisms, and
each node focuses on a single event or very few events. (2) We introduce a
novel retrieval method that leverages the attention weights of LLMs rather than
dense embedding similarity. Our method allows for searching the graph along
multiple paths and can terminate at any depth. (3) We use the LLM to control
the retrieval process, enabling it to dynamically adjust the amount and depth
of information retrieved for different queries. Experimental results show that
our method outperforms previous state-of-the-art baselines, including Llama
3.1, on two single-document and two multi-document QA datasets, while
maintaining similar computational complexity to traditional RAG methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Formality is Favored: Unraveling the Learning Preferences of Large
  Language Models on Data with Conflicting Knowledge <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04784v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04784v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiahuan Li, Yiqing Cao, Shujian Huang, Jiajun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Having been trained on massive pretraining data, large language models have
shown excellent performance on many knowledge-intensive tasks. However,
pretraining data tends to contain misleading and even conflicting information,
and it is intriguing to understand how LLMs handle these noisy data during
training. In this study, we systematically analyze LLMs' learning preferences
for data with conflicting knowledge. We find that pretrained LLMs establish
learning preferences similar to humans, i.e., preferences towards formal texts
and texts with fewer spelling errors, resulting in faster learning and more
favorable treatment of knowledge in data with such features when facing
conflicts. This finding is generalizable across models and languages and is
more evident in larger models. An in-depth analysis reveals that LLMs tend to
trust data with features that signify consistency with the majority of data,
and it is possible to instill new preferences and erase old ones by
manipulating the degree of consistency with the majority data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accepted by EMNLP 2024, main conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ImProver: Agent-Based Automated Proof Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04753v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04753v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Riyaz Ahuja, Jeremy Avigad, Prasad Tetali, Sean Welleck
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have been used to generate formal proofs of
mathematical theorems in proofs assistants such as Lean. However, we often want
to optimize a formal proof with respect to various criteria, depending on its
downstream use. For example, we may want a proof to adhere to a certain style,
or to be readable, concise, or modularly structured. Having suitably optimized
proofs is also important for learning tasks, especially since human-written
proofs may not optimal for that purpose. To this end, we study a new problem of
automated proof optimization: rewriting a proof so that it is correct and
optimizes for an arbitrary criterion, such as length or readability. As a first
method for automated proof optimization, we present ImProver, a
large-language-model agent that rewrites proofs to optimize arbitrary
user-defined metrics in Lean. We find that naively applying LLMs to proof
optimization falls short, and we incorporate various improvements into
ImProver, such as the use of symbolic Lean context in a novel Chain-of-States
technique, as well as error-correction and retrieval. We test ImProver on
rewriting real-world undergraduate, competition, and research-level mathematics
theorems, finding that ImProver is capable of rewriting proofs so that they are
substantially shorter, more modular, and more readable.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 21 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Document-level Causal Relation Extraction with Knowledge-guided Binary
  Question Answering <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04752v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04752v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zimu Wang, Lei Xia, Wei Wang, Xinya Du
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As an essential task in information extraction (IE), Event-Event Causal
Relation Extraction (ECRE) aims to identify and classify the causal
relationships between event mentions in natural language texts. However,
existing research on ECRE has highlighted two critical challenges, including
the lack of document-level modeling and causal hallucinations. In this paper,
we propose a Knowledge-guided binary Question Answering (KnowQA) method with
event structures for ECRE, consisting of two stages: Event Structure
Construction and Binary Question Answering. We conduct extensive experiments
under both zero-shot and fine-tuning settings with large language models (LLMs)
on the MECI and MAVEN-ERE datasets. Experimental results demonstrate the
usefulness of event structures on document-level ECRE and the effectiveness of
KnowQA by achieving state-of-the-art on the MECI dataset. We observe not only
the effectiveness but also the high generalizability and low inconsistency of
our method, particularly when with complete event structures after fine-tuning
the models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at Findings of EMNLP 2024. Camera-ready version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Intriguing Properties of Large Language and Vision Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04751v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04751v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Young-Jun Lee, Byungsoo Ko, Han-Gyu Kim, Yechan Hwang, Ho-Jin Choi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, large language and vision models (LLVMs) have received significant
attention and development efforts due to their remarkable generalization
performance across a wide range of tasks requiring perception and cognitive
abilities. A key factor behind their success is their simple architecture,
which consists of a vision encoder, a projector, and a large language model
(LLM). Despite their achievements in advanced reasoning tasks, their
performance on fundamental perception-related tasks (e.g., MMVP) remains
surprisingly low. This discrepancy raises the question of how LLVMs truly
perceive images and exploit the advantages of the vision encoder. To address
this, we systematically investigate this question regarding several aspects:
permutation invariance, robustness, math reasoning, alignment preserving and
importance, by evaluating the most common LLVM's families (i.e., LLaVA) across
10 evaluation benchmarks. Our extensive experiments reveal several intriguing
properties of current LLVMs: (1) they internally process the image in a global
manner, even when the order of visual patch sequences is randomly permuted; (2)
they are sometimes able to solve math problems without fully perceiving
detailed numerical information; (3) the cross-modal alignment is overfitted to
complex reasoning tasks, thereby, causing them to lose some of the original
perceptual capabilities of their vision encoder; (4) the representation space
in the lower layers (<25%) plays a crucial role in determining performance and
enhancing visual understanding. Lastly, based on the above observations, we
suggest potential future directions for building better LLVMs and constructing
more challenging evaluation benchmarks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code is available in https://github.com/passing2961/IP-LLVM</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TableRAG: Million-Token Table Understanding with Language Models <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04739v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04739v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Si-An Chen, Lesly Miculicich, Julian Martin Eisenschlos, Zifeng Wang, Zilong Wang, Yanfei Chen, Yasuhisa Fujii, Hsuan-Tien Lin, Chen-Yu Lee, Tomas Pfister
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in language models (LMs) have notably enhanced their
ability to reason with tabular data, primarily through program-aided mechanisms
that manipulate and analyze tables. However, these methods often require the
entire table as input, leading to scalability challenges due to the positional
bias or context length constraints. In response to these challenges, we
introduce TableRAG, a Retrieval-Augmented Generation (RAG) framework
specifically designed for LM-based table understanding. TableRAG leverages
query expansion combined with schema and cell retrieval to pinpoint crucial
information before providing it to the LMs. This enables more efficient data
encoding and precise retrieval, significantly reducing prompt lengths and
mitigating information loss. We have developed two new million-token benchmarks
from the Arcade and BIRD-SQL datasets to thoroughly evaluate TableRAG's
effectiveness at scale. Our results demonstrate that TableRAG's retrieval
design achieves the highest retrieval quality, leading to the new
state-of-the-art performance on large-scale table understanding.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TLDR: Token-Level Detective Reward Model for Large Vision Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04734v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04734v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Deqing Fu, Tong Xiao, Rui Wang, Wang Zhu, Pengchuan Zhang, Guan Pang, Robin Jia, Lawrence Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although reward models have been successful in improving multimodal large
language models, the reward models themselves remain brutal and contain minimal
information. Notably, existing reward models only mimic human annotations by
assigning only one binary feedback to any text, no matter how long the text is.
In the realm of multimodal language models, where models are required to
process both images and texts, a naive reward model may learn implicit biases
toward texts and become less grounded in images. In this paper, we propose a
$\textbf{T}$oken-$\textbf{L}$evel $\textbf{D}$etective $\textbf{R}$eward Model
($\textbf{TLDR}$) to provide fine-grained annotations to each text token. We
first introduce a perturbation-based method to generate synthetic hard
negatives and their token-level labels to train TLDR models. Then we show the
rich usefulness of TLDR models both in assisting off-the-shelf models to
self-correct their generations, and in serving as a hallucination evaluation
tool. Finally, we show that TLDR models can significantly speed up human
annotation by 3 times to acquire a broader range of high-quality vision
language data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work done at Meta</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient <span class="highlight-title">transformer</span> with reinforced position embedding for language
  models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04731v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04731v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yen-Che Hsiao, Abhishek Dutta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose an efficient transformer architecture that uses
reinforced positional embedding to obtain superior performance with half the
number of encoder decoder layers. We demonstrate that concatenating positional
encoding with trainable token embeddings, normalizing columns in the token
embedding matrix, and using the normalized token embedding matrix as the value
of the attention layer improve the training and validation loss and the
training time in an encoder-decoder Transformer model for a Portuguese-English
translation task with 10 epochs or 12 hours of training across 10 trials. Our
method, with roughly a threefold parameter reduction compared to the baseline
model, yields a mean training loss of 1.21, a mean validation loss of 1.51, and
an average training time of 1352.27 seconds per epoch, surpassing the baseline
model with the same embedding dimension that employs addition of positional
encoding and token embeddings, which achieves a mean training loss of 1.96, a
validation loss of 2.18, and an average training time of 4297.79 seconds per
epoch. Additionally, we evaluated our proposed architecture and the baseline
across 14 diverse translation datasets from TensorFlow. The results indicate
that our method consistently achieves lower or comparable training and
validation losses, suggesting enhanced learning efficiency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Forgetting Curve: A Reliable Method for Evaluating Memorization
  Capability for Long-context Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04727v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04727v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyu Liu, Runsong Zhao, Pengcheng Huang, Chunyang Xiao, Bei Li, Jingang Wang, Tong Xiao, Jingbo Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Numerous recent works target to extend effective context length for language
models and various methods, tasks and benchmarks exist to measure model's
effective memorization length. However, through thorough investigations, we
find limitations for currently existing evaluations on model's memorization
capability. We provide an extensive survey for limitations in this work and
propose a new method called forgetting curve to measure the memorization
capability of long-context models. We show that forgetting curve has the
advantage of being robust to the tested corpus and the experimental settings,
of not relying on prompts and can be applied to any model size.
  We apply our forgetting curve to a large variety of models involving both
transformer and RNN/SSM based architectures. Our measurement provides empirical
evidence for the effectiveness of transformer extension techniques while raises
questions for the effective length of RNN/SSM based models. We also examine the
difference between our measurement and existing benchmarks as well as popular
metrics for various models. Our code and results can be found at
https://github.com/1azybug/ForgettingCurve.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ $\textbf{Only-IF}$:Revealing the Decisive Effect of Instruction
  Diversity on Generalization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04717v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04717v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dylan Zhang, Justin Wang, Francois Charton
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding and accurately following instructions is critical for large
language models (LLMs) to be effective across diverse tasks. In this work, we
rigorously examine the key factors that enable models to generalize to unseen
instructions, providing insights to guide the collection of data for
instruction-tuning. Through controlled experiments, inspired by the
Turing-complete Markov algorithm, we demonstrate that such generalization
$\textbf{only emerges}$ when training data is diversified enough across
semantic domains. Our findings also reveal that merely diversifying within
limited domains fails to ensure robust generalization. In contrast,
cross-domain data diversification, even under constrained data budgets,
significantly enhances a model's adaptability. We further extend our analysis
to real-world scenarios, including fine-tuning of
$\textit{$\textbf{specialist}$}$ and $\textit{$\textbf{generalist}$}$ models.
In both cases, we demonstrate that 1) better performance can be achieved by
increasing the diversity of an established dataset while keeping the data size
constant, and 2) when scaling up the data, diversifying the semantics of
instructions is more effective than simply increasing the quantity of similar
data. Our research provides important insights for dataset collation,
particularly when optimizing model performance by expanding training data for
both specialist and generalist scenarios. We show that careful consideration of
data diversification is key: training specialist models with data extending
beyond their core domain leads to significant performance improvements, while
generalist models benefit from diverse data mixtures that enhance their overall
instruction-following capabilities across a wide range of applications. Our
results highlight the critical role of strategic diversification and offer
clear guidelines for improving data quality.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rule-based Data Selection for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04715v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04715v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaomin Li, Mingye Gao, Zhiwei Zhang, Chang Yue, Hong Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The quality of training data significantly impacts the performance of large
language models (LLMs). There are increasing studies using LLMs to rate and
select data based on several human-crafted metrics (rules). However, these
conventional rule-based approaches often depend too heavily on human
heuristics, lack effective metrics for assessing rules, and exhibit limited
adaptability to new tasks. In our study, we introduce an innovative rule-based
framework that utilizes the orthogonality of score vectors associated with
rules as a novel metric for rule evaluations. Our approach includes an
automated pipeline that first uses LLMs to generate a diverse set of rules,
encompassing various rating dimensions to evaluate data quality. Then it rates
a batch of data based on these rules and uses the determinantal point process
(DPP) from random matrix theory to select the most orthogonal score vectors,
thereby identifying a set of independent rules. These rules are subsequently
used to evaluate all data, selecting samples with the highest average scores
for downstream tasks such as LLM training. We verify the effectiveness of our
method through two experimental setups: 1) comparisons with ground truth
ratings and 2) benchmarking LLMs trained with the chosen data. Our
comprehensive experiments cover a range of scenarios, including general
pre-training and domain-specific fine-tuning in areas such as IMDB, Medical,
Math, and Code. The outcomes demonstrate that our DPP-based rule rating method
consistently outperforms other approaches, including rule-free rating, uniform
sampling, importance resampling, and QuRating, in terms of both rating
precision and model performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning How Hard to Think: Input-Adaptive Allocation of LM Computation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04707v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04707v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mehul Damani, Idan Shenfeld, Andi Peng, Andreea Bobu, Jacob Andreas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Computationally intensive decoding procedures--including search, reranking,
and self-critique--can improve the quality of language model (LM) outputs in
problems spanning code generation, numerical reasoning, and dialog. Existing
work typically applies the same decoding procedure for every input to an LM.
But not all inputs require the same amount of computation to process. Can we
allocate decoding computation adaptively, using more resources to answer
questions whose answers will be harder to compute? We present an approach that
predicts the distribution of rewards given an input and computation budget,
then allocates additional computation to inputs for which it is predicted to be
most useful. We apply this approach in two decoding procedures: first, an
adaptive best-of-k procedure that dynamically selects the number of samples to
generate as input to a reranker; second, a routing procedure that dynamically
responds to a query using a decoding procedure that is expensive but accurate,
or one that is cheaper but less capable. Across a suite of programming,
mathematics, and dialog tasks, we show that accurate computation-allocation
procedures can be learned, and reduce computation by up to 50% at no cost to
response quality, or improve quality by up to 10% at a fixed computational
budget.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Modeling and Estimation of Vocal Tract and Glottal Source Parameters
  Using ARMAX-LF Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04704v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04704v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kai Lia, Masato Akagia, Yongwei Lib, Masashi Unokia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modeling and estimation of the vocal tract and glottal source parameters of
vowels from raw speech can be typically done by using the Auto-Regressive with
eXogenous input (ARX) model and Liljencrants-Fant (LF) model with an
iteration-based estimation approach. However, the all-pole autoregressive model
in the modeling of vocal tract filters cannot provide the locations of
anti-formants (zeros), which increases the estimation errors in certain classes
of speech sounds, such as nasal, fricative, and stop consonants. In this paper,
we propose the Auto-Regressive Moving Average eXogenous with LF (ARMAX-LF)
model to extend the ARX-LF model to a wider variety of speech sounds, including
vowels and nasalized consonants. The LF model represents the glottal source
derivative as a parametrized time-domain model, and the ARMAX model represents
the vocal tract as a pole-zero filter with an additional exogenous LF
excitation as input. To estimate multiple parameters with fewer errors, we
first utilize the powerful nonlinear fitting ability of deep neural networks
(DNNs) to build a mapping from extracted glottal source derivatives or speech
waveforms to corresponding LF parameters. Then, glottal source and vocal tract
parameters can be estimated with fewer estimation errors and without any
iterations as in the analysis-by-synthesis strategy. Experimental results with
synthesized speech using the linear source-filter model, synthesized speech
using the physical model, and real speech signals showed that the proposed
ARMAX-LF model with a DNN-based estimation method can estimate the parameters
of both vowels and nasalized sounds with fewer errors and estimation time.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The LLM Effect: Are Humans Truly Using LLMs, or Are They Being
  Influenced By Them Instead? <span class="chip">EMNLP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04699v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04699v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexander S. Choi, Syeda Sabrina Akter, JP Singh, Antonios Anastasopoulos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have shown capabilities close to human
performance in various analytical tasks, leading researchers to use them for
time and labor-intensive analyses. However, their capability to handle highly
specialized and open-ended tasks in domains like policy studies remains in
question. This paper investigates the efficiency and accuracy of LLMs in
specialized tasks through a structured user study focusing on Human-LLM
partnership. The study, conducted in two stages-Topic Discovery and Topic
Assignment-integrates LLMs with expert annotators to observe the impact of LLM
suggestions on what is usually human-only analysis. Results indicate that
LLM-generated topic lists have significant overlap with human generated topic
lists, with minor hiccups in missing document-specific topics. However, LLM
suggestions may significantly improve task completion speed, but at the same
time introduce anchoring bias, potentially affecting the depth and nuance of
the analysis, raising a critical question about the trade-off between increased
efficiency and the risk of biased analysis.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP Main 2024. First two authors contributed equally</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MathHay: An Automated Benchmark for Long-Context Mathematical Reasoning
  in LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04698v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04698v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lei Wang, Shan Dong, Yuhui Xu, Hanze Dong, Yalu Wang, Amrita Saha, Ee-Peng Lim, Caiming Xiong, Doyen Sahoo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent large language models (LLMs) have demonstrated versatile capabilities
in long-context scenarios. Although some recent benchmarks have been developed
to evaluate the long-context capabilities of LLMs, there is a lack of
benchmarks evaluating the mathematical reasoning abilities of LLMs over long
contexts, which is crucial for LLMs' application in real-world scenarios. In
this paper, we introduce MathHay, an automated benchmark designed to assess the
long-context mathematical reasoning capabilities of LLMs. Unlike previous
benchmarks like Needle in a Haystack, which focus primarily on information
retrieval within long texts, MathHay demands models with both
information-seeking and complex mathematical reasoning abilities. We conduct
extensive experiments on MathHay to assess the long-context mathematical
reasoning abilities of eight top-performing LLMs. Even the best-performing
model, Gemini-1.5-Pro-002, still struggles with mathematical reasoning over
long contexts, achieving only 51.26% accuracy at 128K tokens. This highlights
the significant room for improvement on the MathHay benchmark.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work-in-Progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deeper Insights Without Updates: The Power of In-Context Learning Over
  Fine-Tuning <span class="chip">EMNLP'24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04691v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04691v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qingyu Yin, Xuzheng He, Luoao Deng, Chak Tou Leong, Fan Wang, Yanzhao Yan, Xiaoyu Shen, Qiang Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Fine-tuning and in-context learning (ICL) are two prevalent methods in
imbuing large language models with task-specific knowledge. It is commonly
believed that fine-tuning can surpass ICL given sufficient training samples as
it allows the model to adjust its internal parameters based on the data.
However, this paper presents a counterintuitive finding: For tasks with
implicit patterns, ICL captures these patterns significantly better than
fine-tuning. We developed several datasets featuring implicit patterns, such as
sequences determining answers through parity or identifying reducible terms in
calculations. We then evaluated the models' understanding of these patterns
under both fine-tuning and ICL across models ranging from 0.5B to 7B
parameters. The results indicate that models employing ICL can quickly grasp
deep patterns and significantly improve accuracy. In contrast, fine-tuning,
despite utilizing thousands of times more training samples than ICL, achieved
only limited improvements. We also proposed circuit shift theory from a
mechanistic interpretability's view to explain why ICL wins.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP'24 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Adversarial Multi-Agent Evaluation of Large Language Models through
  Iterative Debates 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04663v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04663v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chaithanya Bandi, Hari Bandi, Abir Harrasse
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper explores optimal architectures for evaluating the outputs of large
language models (LLMs) using LLMs themselves. We propose a novel framework that
interprets LLMs as advocates within an ensemble of interacting agents, allowing
them to defend their answers and reach conclusions through a judge and jury
system. This approach offers a more dynamic and comprehensive evaluation
process compared to traditional human-based assessments or automated metrics.
We discuss the motivation behind this framework, its key components, and
comparative advantages. We also present a probabilistic model to evaluate the
error reduction achieved by iterative advocate systems. Finally, we outline
experiments to validate the effectiveness of multi-advocate architectures and
discuss future research directions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Contrastive Learning to Improve Retrieval for Real-world Fact Checking <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04657v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04657v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aniruddh Sriram, Fangyuan Xu, Eunsol Choi, Greg Durrett
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent work on fact-checking addresses a realistic setting where models
incorporate evidence retrieved from the web to decide the veracity of claims. A
bottleneck in this pipeline is in retrieving relevant evidence: traditional
methods may surface documents directly related to a claim, but fact-checking
complex claims requires more inferences. For instance, a document about how a
vaccine was developed is relevant to addressing claims about what it might
contain, even if it does not address them directly. We present Contrastive
Fact-Checking Reranker (CFR), an improved retriever for this setting. By
leveraging the AVeriTeC dataset, which annotates subquestions for claims with
human written answers from evidence documents, we fine-tune Contriever with a
contrastive objective based on multiple training signals, including
distillation from GPT-4, evaluating subquestion answers, and gold labels in the
dataset. We evaluate our model on both retrieval and end-to-end veracity
judgments about claims. On the AVeriTeC dataset, we find a 6\% improvement in
veracity classification accuracy. We also show our gains can be transferred to
FEVER, ClaimDecomp, HotpotQA, and a synthetic dataset requiring retrievers to
make inferences.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 FEVER Workshop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ mDPO: Conditional Preference Optimization for Multimodal Large Language
  Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11839v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11839v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fei Wang, Wenxuan Zhou, James Y. Huang, Nan Xu, Sheng Zhang, Hoifung Poon, Muhao Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Direct preference optimization (DPO) has shown to be an effective method for
large language model (LLM) alignment. Recent works have attempted to apply DPO
to multimodal scenarios but have found it challenging to achieve consistent
improvement. Through a comparative experiment, we identify the unconditional
preference problem in multimodal preference optimization, where the model
overlooks the image condition. To address this problem, we propose mDPO, a
multimodal DPO objective that prevents the over-prioritization of language-only
preferences by also optimizing image preference. Moreover, we introduce a
reward anchor that forces the reward to be positive for chosen responses,
thereby avoiding the decrease in their likelihood -- an intrinsic problem of
relative preference optimization. Experiments on two multimodal LLMs of
different sizes and three widely used benchmarks demonstrate that mDPO
effectively addresses the unconditional preference problem in multimodal
preference optimization and significantly improves model performance,
particularly in reducing hallucination.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Main Conference. Project website:
  https://feiwang96.github.io/mDPO</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SoK: Membership Inference Attacks on LLMs are Rushing Nowhere (and How
  to Fix It) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17975v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17975v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matthieu Meeus, Igor Shilov, Shubham Jain, Manuel Faysse, Marek Rei, Yves-Alexandre de Montjoye
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Whether LLMs memorize their training data and what this means, from privacy
leakage to detecting copyright violations -- has become a rapidly growing area
of research over the last two years. In recent months, more than 10 new methods
have been proposed to perform Membership Inference Attacks (MIAs) against LLMs.
Contrary to traditional MIAs which rely on fixed -- but randomized -- records
or models, these methods are mostly evaluated on datasets collected post-hoc.
Sets of members and non-members, used to evaluate the MIA, are constructed
using informed guesses after the release of a model. This lack of randomization
raises concerns of a distribution shift between members and non-members. In the
first part, we review the literature on MIAs against LLMs. While most work
focuses on sequence-level MIAs evaluated in post-hoc setups, we show that a
range of target models, motivations and units of interest have been considered
in the literature. We then quantify distribution shifts present in the 6
datasets used in the literature, ranging from books to papers, using a bag of
word classifier. Our analysis reveals that all of them suffer from severe
distribution shifts. This challenges the validity of using such setups to
measure LLM memorization and may undermine the benchmarking of recently
proposed methods. Yet, all hope might not be lost. In the second part, we
introduce important considerations to properly evaluate MIAs against LLMs and
discuss potential ways forward: randomized test splits, injections of
randomized (unique) sequences, randomized finetuning, and post-hoc control
methods. While each option comes with its advantages and limitations, we
believe they collectively provide solid grounds to guide the development of MIA
methods and study LLM memorization. We conclude by proposing comprehensive,
easy-to-use benchmarks for sequence- and document-level MIAs against LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MMLU-Pro: A More Robust and Challenging Multi-Task Language
  Understanding Benchmark (Published at NeurIPS 2024 Track <span class="highlight-title">Dataset</span>s and
  Benchmarks) <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.01574v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.01574v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yubo Wang, Xueguang Ma, Ge Zhang, Yuansheng Ni, Abhranil Chandra, Shiguang Guo, Weiming Ren, Aaran Arulraj, Xuan He, Ziyan Jiang, Tianle Li, Max Ku, Kai Wang, Alex Zhuang, Rongqi Fan, Xiang Yue, Wenhu Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the age of large-scale language models, benchmarks like the Massive
Multitask Language Understanding (MMLU) have been pivotal in pushing the
boundaries of what AI can achieve in language comprehension and reasoning
across diverse domains. However, as models continue to improve, their
performance on these benchmarks has begun to plateau, making it increasingly
difficult to discern differences in model capabilities. This paper introduces
MMLU-Pro, an enhanced dataset designed to extend the mostly knowledge-driven
MMLU benchmark by integrating more challenging, reasoning-focused questions and
expanding the choice set from four to ten options. Additionally, MMLU-Pro
eliminates the trivial and noisy questions in MMLU. Our experimental results
show that MMLU-Pro not only raises the challenge, causing a significant drop in
accuracy by 16% to 33% compared to MMLU but also demonstrates greater stability
under varying prompts. With 24 different prompt styles tested, the sensitivity
of model scores to prompt variations decreased from 4-5% in MMLU to just 2% in
MMLU-Pro. Additionally, we found that models utilizing Chain of Thought (CoT)
reasoning achieved better performance on MMLU-Pro compared to direct answering,
which is in stark contrast to the findings on the original MMLU, indicating
that MMLU-Pro includes more complex reasoning questions. Our assessments
confirm that MMLU-Pro is a more discriminative benchmark to better track
progress in the field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This version has been accepted and published at NeurIPS 2024 Track
  Datasets and Benchmarks (Spotlight)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BigCodeBench: Benchmarking Code Generation with Diverse Function Calls
  and Complex Instructions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.15877v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.15877v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Terry Yue Zhuo, Minh Chien Vu, Jenny Chim, Han Hu, Wenhao Yu, Ratnadira Widyasari, Imam Nur Bani Yusuf, Haolan Zhan, Junda He, Indraneil Paul, Simon Brunner, Chen Gong, Thong Hoang, Armel Randy Zebaze, Xiaoheng Hong, Wen-Ding Li, Jean Kaddour, Ming Xu, Zhihan Zhang, Prateek Yadav, Naman Jain, Alex Gu, Zhoujun Cheng, Jiawei Liu, Qian Liu, Zijian Wang, David Lo, Binyuan Hui, Niklas Muennighoff, Daniel Fried, Xiaoning Du, Harm de Vries, Leandro Von Werra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Task automation has been greatly empowered by the recent advances in Large
Language Models (LLMs) via Python code, where the tasks ranging from software
engineering development to general-purpose reasoning. While current benchmarks
have shown that LLMs can solve tasks using programs like human developers, the
majority of their evaluations are limited to short and self-contained
algorithmic tasks or standalone function calls. Solving challenging and
practical requires the capability of utilizing diverse function calls as tools
to efficiently implement functionalities like data analysis and web
development. In addition, using multiple tools to solve a task needs
compositional reasoning by accurately understanding complex instructions.
Fulfilling both of these characteristics can pose a great challenge for LLMs.To
assess how well LLMs can solve challenging and practical tasks via programs, we
introduce BigCodeBench, a benchmark that challenges LLMs to invoke multiple
function calls as tools from 139 libraries and 7 domains for 1,140 fine-grained
tasks. To evaluate LLMs rigorously, each task encompasses 5.6 test cases with
an average branch coverage of 99%. In addition, we propose a
natural-language-oriented variant of BigCodeBench, BigCodeBench-Instruct, that
automatically transforms the original docstrings into short instructions only
with essential information. Our extensive evaluation of 60 LLMs shows that LLMs
are not yet capable of following complex instructions to use function calls
precisely, with scores up to 60%, significantly lower than the human
performance of 97%. The results underscore the need for further advancements in
this area.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>44 pages, 14 figures, 7 tables, built with love by the BigCode
  community :)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Augmenting Black-box LLMs with Medical Textbooks for Biomedical Question
  Answering (Published in Findings of EMNLP 2024) <span class="chip">EMNLP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.02233v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.02233v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yubo Wang, Xueguang Ma, Wenhu Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large-scale language models (LLMs) like ChatGPT have demonstrated impressive
abilities in generating responses based on human instructions. However, their
use in the medical field can be challenging due to their lack of specific,
in-depth knowledge. In this study, we present a system called LLMs Augmented
with Medical Textbooks (LLM-AMT) designed to enhance the proficiency of LLMs in
specialized domains. LLM-AMT integrates authoritative medical textbooks into
the LLMs' framework using plug-and-play modules. These modules include a Query
Augmenter, a Hybrid Textbook Retriever, and a Knowledge Self-Refiner. Together,
they incorporate authoritative medical knowledge. Additionally, an LLM Reader
aids in contextual understanding. Our experimental results on three medical QA
tasks demonstrate that LLMAMT significantly improves response quality, with
accuracy gains ranging from 11.6% to 16.6%. Notably, with GPT-4-Turbo as the
base model, LLM-AMT outperforms the specialized Med-PaLM 2 model pre-trained on
a massive amount of medical corpus by 2-3%. We found that despite being 100x
smaller in size, medical textbooks as a retrieval corpus is proven to be a more
effective knowledge database than Wikipedia in the medical domain, boosting
performance by 7.8%-13.7%.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This version has been accepted and published at EMNLP Findings 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Annotation alignment: Comparing LLM and human annotations of
  conversational safety <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.06369v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.06369v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rajiv Movva, Pang Wei Koh, Emma Pierson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Do LLMs align with human perceptions of safety? We study this question via
annotation alignment, the extent to which LLMs and humans agree when annotating
the safety of user-chatbot conversations. We leverage the recent DICES dataset
(Aroyo et al., 2023), in which 350 conversations are each rated for safety by
112 annotators spanning 10 race-gender groups. GPT-4 achieves a Pearson
correlation of $r = 0.59$ with the average annotator rating, \textit{higher}
than the median annotator's correlation with the average ($r=0.51$). We show
that larger datasets are needed to resolve whether LLMs exhibit disparities in
how well they correlate with different demographic groups. Also, there is
substantial idiosyncratic variation in correlation within groups, suggesting
that race & gender do not fully capture differences in alignment. Finally, we
find that GPT-4 cannot predict when one demographic group finds a conversation
more unsafe than another.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 (Main). Main text contains 6 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Contextual Document Embeddings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02525v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02525v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        John X. Morris, Alexander M. Rush
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dense document embeddings are central to neural retrieval. The dominant
paradigm is to train and construct embeddings by running encoders directly on
individual documents. In this work, we argue that these embeddings, while
effective, are implicitly out-of-context for targeted use cases of retrieval,
and that a contextualized document embedding should take into account both the
document and neighboring documents in context - analogous to contextualized
word embeddings. We propose two complementary methods for contextualized
document embeddings: first, an alternative contrastive learning objective that
explicitly incorporates the document neighbors into the intra-batch contextual
loss; second, a new contextual architecture that explicitly encodes neighbor
document information into the encoded representation. Results show that both
methods achieve better performance than biencoders in several settings, with
differences especially pronounced out-of-domain. We achieve state-of-the-art
results on the MTEB benchmark with no hard negative mining, score distillation,
dataset-specific instructions, intra-GPU example-sharing, or extremely large
batch sizes. Our method can be applied to improve performance on any
contrastive learning dataset and any biencoder.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Creative Beam Search: LLM-as-a-Judge For Improving Response Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.00099v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.00099v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Giorgio Franceschelli, Mirco Musolesi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models are revolutionizing several areas, including artificial
creativity. However, the process of generation in machines profoundly diverges
from that observed in humans. In particular, machine generation is
characterized by a lack of intentionality and an underlying creative process.
We propose a method called Creative Beam Search that uses Diverse Beam Search
and LLM-as-a-Judge to perform response generation and response validation. The
results of a qualitative experiment show how our approach can provide better
output than standard sampling techniques. We also show that the response
validation step is a necessary complement to the response generation step.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Presented as a short paper at the 15th International Conference on
  Computational Creativity (ICCC'24)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MetaMetrics: Calibrating Metrics For Generation Tasks Using Human
  Preferences 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02381v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02381v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Genta Indra Winata, David Anugraha, Lucky Susanto, Garry Kuwanto, Derry Tanti Wijaya
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding the quality of a performance evaluation metric is crucial for
ensuring that model outputs align with human preferences. However, it remains
unclear how well each metric captures the diverse aspects of these preferences,
as metrics often excel in one particular area but not across all dimensions. To
address this, it is essential to systematically calibrate metrics to specific
aspects of human preference, catering to the unique characteristics of each
aspect. We introduce MetaMetrics, a calibrated meta-metric designed to evaluate
generation tasks across different modalities in a supervised manner.
MetaMetrics optimizes the combination of existing metrics to enhance their
alignment with human preferences. Our metric demonstrates flexibility and
effectiveness in both language and vision downstream tasks, showing significant
benefits across various multilingual and multi-domain scenarios. MetaMetrics
aligns closely with human preferences and is highly extendable and easily
integrable into any application. This makes MetaMetrics a powerful tool for
improving the evaluation of generation tasks, ensuring that metrics are more
representative of human judgment across diverse contexts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Usage-centric Take on Intent Understanding in E-Commerce <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.14901v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.14901v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wendi Zhou, Tianyi Li, Pavlos Vougiouklis, Mark Steedman, Jeff Z. Pan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Identifying and understanding user intents is a pivotal task for E-Commerce.
Despite its essential role in product recommendation and business user
profiling analysis, intent understanding has not been consistently defined or
accurately benchmarked. In this paper, we focus on predicative user intents as
"how a customer uses a product", and pose intent understanding as a natural
language reasoning task, independent of product ontologies. We identify two
weaknesses of FolkScope, the SOTA E-Commerce Intent Knowledge Graph:
category-rigidity and property-ambiguity. They limit its ability to strongly
align user intents with products having the most desirable property, and to
recommend useful products across diverse categories. Following these
observations, we introduce a Product Recovery Benchmark featuring a novel
evaluation framework and an example dataset. We further validate the above
FolkScope weaknesses on this benchmark. Our code and dataset are available at
https://github.com/stayones/Usgae-Centric-Intent-Understanding.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Acepted by EMNLP 2024 main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficient Model-Agnostic Multi-Group Equivariant Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.09675v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.09675v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Razan Baltaji, Sourya Basu, Lav R. Varshney
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Constructing model-agnostic group equivariant networks, such as equitune
(Basu et al., 2023b) and its generalizations (Kim et al., 2023), can be
computationally expensive for large product groups. We address this problem by
providing efficient model-agnostic equivariant designs for two related
problems: one where the network has multiple inputs each with potentially
different groups acting on them, and another where there is a single input but
the group acting on it is a large product group. For the first design, we
initially consider a linear model and characterize the entire equivariant space
that satisfies this constraint. This characterization gives rise to a novel
fusion layer between different channels that satisfies an invariance-symmetry
(IS) constraint, which we call an IS layer. We then extend this design beyond
linear models, similar to equitune, consisting of equivariant and IS layers. We
also show that the IS layer is a universal approximator of invariant-symmetric
functions. Inspired by the first design, we use the notion of the IS property
to design a second efficient model-agnostic equivariant design for large
product groups acting on a single input. For the first design, we provide
experiments on multi-image classification where each view is transformed
independently with transformations such as rotations. We find equivariant
models are robust to such transformations and perform competitively otherwise.
For the second design, we consider three applications: language
compositionality on the SCAN dataset to product groups; fairness in natural
language generation from GPT-2 to address intersectionality; and robust
zero-shot image classification with CLIP. Overall, our methods are simple and
general, competitive with equitune and its variants, while also being
computationally more efficient.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ When "A Helpful Assistant" Is Not Really Helpful: Personas in System
  <span class="highlight-title">Prompt</span>s Do Not Improve Performances of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.10054v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.10054v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingqian Zheng, Jiaxin Pei, Lajanugen Logeswaran, Moontae Lee, David Jurgens
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prompting serves as the major way humans interact with Large Language Models
(LLM). Commercial AI systems commonly define the role of the LLM in system
prompts. For example, ChatGPT uses "You are a helpful assistant" as part of its
default system prompt. Despite current practices of adding personas to system
prompts, it remains unclear how different personas affect a model's performance
on objective tasks. In this study, we present a systematic evaluation of
personas in system prompts. We curate a list of 162 roles covering 6 types of
interpersonal relationships and 8 domains of expertise. Through extensive
analysis of 4 popular families of LLMs and 2,410 factual questions, we
demonstrate that adding personas in system prompts does not improve model
performance across a range of questions compared to the control setting where
no persona is added. Nevertheless, further analysis suggests that the gender,
type, and domain of the persona can all influence the resulting prediction
accuracies. We further experimented with a list of persona search strategies
and found that, while aggregating results from the best persona for each
question significantly improves prediction accuracy, automatically identifying
the best persona is challenging, with predictions often performing no better
than random selection. Overall, our findings suggest that while adding a
persona may lead to performance gains in certain settings, the effect of each
persona can be largely random. Code and data are available at
https://github.com/Jiaxin-Pei/Prompting-with-Social-Roles.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Better Instruction-Following Through Minimum Bayes Risk 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02902v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02902v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ian Wu, Patrick Fernandes, Amanda Bertsch, Seungone Kim, Sina Pakazad, Graham Neubig
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  General-purpose LLM judges capable of human-level evaluation provide not only
a scalable and accurate way of evaluating instruction-following LLMs but also
new avenues for supervising and improving their performance. One promising way
of leveraging LLM judges for supervision is through Minimum Bayes Risk (MBR)
decoding, which uses a reference-based evaluator to select a high-quality
output from amongst a set of candidate outputs. In the first part of this work,
we explore using MBR decoding as a method for improving the test-time
performance of instruction-following LLMs. We find that MBR decoding with
reference-based LLM judges substantially improves over greedy decoding,
best-of-N decoding with reference-free judges and MBR decoding with lexical and
embedding-based metrics on AlpacaEval and MT-Bench. These gains are consistent
across LLMs with up to 70B parameters, demonstrating that smaller LLM judges
can be used to supervise much larger LLMs. Then, seeking to retain the
improvements from MBR decoding while mitigating additional test-time costs, we
explore iterative self-training on MBR-decoded outputs. We find that
self-training using Direct Preference Optimisation leads to significant
performance gains, such that the self-trained models with greedy decoding
generally match and sometimes exceed the performance of their base models with
MBR decoding.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Representation noising effectively prevents harmful fine-tuning on LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.14577v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.14577v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Domenic Rosati, Jan Wehner, Kai Williams, Łukasz Bartoszcze, David Atanasov, Robie Gonzales, Subhabrata Majumdar, Carsten Maple, Hassan Sajjad, Frank Rudzicz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Releasing open-source large language models (LLMs) presents a dual-use risk
since bad actors can easily fine-tune these models for harmful purposes. Even
without the open release of weights, weight stealing and fine-tuning APIs make
closed models vulnerable to harmful fine-tuning attacks (HFAs). While safety
measures like preventing jailbreaks and improving safety guardrails are
important, such measures can easily be reversed through fine-tuning. In this
work, we propose Representation Noising (RepNoise), a defence mechanism that is
effective even when attackers have access to the weights. RepNoise works by
removing information about harmful representations such that it is difficult to
recover them during fine-tuning. Importantly, our defence is also able to
generalize across different subsets of harm that have not been seen during the
defence process as long as they are drawn from the same distribution of the
attack set. Our method does not degrade the general capability of LLMs and
retains the ability to train the model on harmless tasks. We provide empirical
evidence that the effectiveness of our defence lies in its "depth": the degree
to which information about harmful representations is removed across all layers
of the LLM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published in NeurIPs 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Social Bias Probing: Fairness Benchmarking for Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.09090v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.09090v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marta Marchiori Manerba, Karolina Stańczak, Riccardo Guidotti, Isabelle Augenstein
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While the impact of social biases in language models has been recognized,
prior methods for bias evaluation have been limited to binary association tests
on small datasets, limiting our understanding of bias complexities. This paper
proposes a novel framework for probing language models for social biases by
assessing disparate treatment, which involves treating individuals differently
according to their affiliation with a sensitive demographic group. We curate
SoFa, a large-scale benchmark designed to address the limitations of existing
fairness collections. SoFa expands the analysis beyond the binary comparison of
stereotypical versus anti-stereotypical identities to include a diverse range
of identities and stereotypes. Comparing our methodology with existing
benchmarks, we reveal that biases within language models are more nuanced than
acknowledged, indicating a broader scope of encoded biases than previously
recognized. Benchmarking LMs on SoFa, we expose how identities expressing
different religions lead to the most pronounced disparate treatments across all
models. Finally, our findings indicate that real-life adversities faced by
various groups such as women and people with disabilities are mirrored in the
behavior of these models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fine-Tuning and <span class="highlight-title">Prompt</span> Optimization: Two Great Steps that Work Better
  Together <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10930v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10930v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dilara Soylu, Christopher Potts, Omar Khattab
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Natural Language Processing (NLP) systems are increasingly taking the form of
sophisticated modular pipelines, e.g., Retrieval Augmented Generation (RAG),
where each module may involve a distinct Language Model (LM) and an associated
prompt template. These compound systems often lack intermediate labels or
gradient flow to optimize each module, making their end-to-end optimization
challenging. Here we seek strategies to optimize both the module-level LM
weights and the associated prompt templates of such systems to maximize a
downstream task metric. We propose for the first time combining the weight and
prompt optimization strategies to optimize a modular LM pipeline by alternating
between the two to get the same LM to teach itself. In experiments with
multi-hop QA, mathematical reasoning, and feature-based classification using
mistral-7b, llama-2-7b, and llama-3-8b, these BetterTogether strategies
optimizing the weights and prompts of a pipeline together outperform directly
optimizing weights alone and prompts alone by up to 60% and 6%, respectively,
on average across LMs and tasks. BetterTogether optimizer is released in DSPy
at http://dspy.ai
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FAC$^2$E: Better Understanding Large Language Model Capabilities by
  Dissociating Language and Cognition <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.00126v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.00126v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoqiang Wang, Lingfei Wu, Tengfei Ma, Bang Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) are primarily evaluated by overall performance
on various text understanding and generation tasks. However, such a paradigm
fails to comprehensively differentiate the fine-grained language and cognitive
skills, rendering the lack of sufficient interpretation to LLMs' capabilities.
In this paper, we present FAC$^2$E, a framework for Fine-grAined and
Cognition-grounded LLMs' Capability Evaluation. Specifically, we formulate
LLMs' evaluation in a multi-dimensional and explainable manner by dissociating
the language-related capabilities and the cognition-related ones. Besides,
through extracting the intermediate reasoning from LLMs, we further break down
the process of applying a specific capability into three sub-steps: recalling
relevant knowledge, utilizing knowledge, and solving problems. Finally,
FAC$^2$E evaluates each sub-step of each fine-grained capability, providing a
two-faceted diagnosis for LLMs. Utilizing FAC$^2$E, we identify a common
shortfall in knowledge utilization among models and propose a straightforward,
knowledge-enhanced method to mitigate this issue. Our results not only showcase
promising performance enhancements but also highlight a direction for future
LLM advancements.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024 main conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Non-Invasive Suicide Risk Prediction Through Speech Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.12132v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.12132v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shahin Amiriparian, Maurice Gerczuk, Justina Lutz, Wolfgang Strube, Irina Papazova, Alkomiet Hasan, Alexander Kathan, Björn W. Schuller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The delayed access to specialized psychiatric assessments and care for
patients at risk of suicidal tendencies in emergency departments creates a
notable gap in timely intervention, hindering the provision of adequate mental
health support during critical situations. To address this, we present a
non-invasive, speech-based approach for automatic suicide risk assessment. For
our study, we collected a novel speech recording dataset from $20$ patients. We
extract three sets of features, including wav2vec, interpretable speech and
acoustic features, and deep learning-based spectral representations. We proceed
by conducting a binary classification to assess suicide risk in a
leave-one-subject-out fashion. Our most effective speech model achieves a
balanced accuracy of $66.2\,\%$. Moreover, we show that integrating our speech
model with a series of patients' metadata, such as the history of suicide
attempts or access to firearms, improves the overall result. The metadata
integration yields a balanced accuracy of $94.4\,\%$, marking an absolute
improvement of $28.2\,\%$, demonstrating the efficacy of our proposed
approaches for automatic suicide risk assessment in emergency medicine.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Native Design Bias: Studying the Impact of English Nativeness on
  Language Model Performance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17385v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17385v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manon Reusens, Philipp Borchert, Jochen De Weerdt, Bart Baesens
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) excel at providing information acquired during
pretraining on large-scale corpora and following instructions through user
prompts. This study investigates whether the quality of LLM responses varies
depending on the demographic profile of users. Considering English as the
global lingua franca, along with the diversity of its dialects among speakers
of different native languages, we explore whether non-native English speakers
receive lower-quality or even factually incorrect responses from LLMs more
frequently. Our results show that performance discrepancies occur when LLMs are
prompted by native versus non-native English speakers and persist when
comparing native speakers from Western countries with others. Additionally, we
find a strong anchoring effect when the model recognizes or is made aware of
the user's nativeness, which further degrades the response quality when
interacting with non-native speakers. Our analysis is based on a newly
collected dataset with over 12,000 unique annotations from 124 annotators,
including information on their native language and English proficiency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ UPCS: Unbiased Persona Construction for Dialogue Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05257v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05257v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kuiyun Chen, Yanbin Wei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Narrative systems, such as dialogue and storytelling systems, often utilize
persona profiles to enhance personalized interactions. Existing persona
profiles frequently exhibit biases, posing risks to system integrity and
fairness. To address this, we introduce the UPCS framework, which categorizes
character descriptions into eight dimensions, including bias mitigation
strategies. Experimental results demonstrate UPCS's superiority in accuracy,
diversity, bias elimination, and user satisfaction, marking a significant
advancement in persona construction for reliable narrative systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Diversity Over Size: On the Effect of Sample and Topic Sizes for
  Topic-Dependent Argument Mining <span class="highlight-title">Dataset</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2205.11472v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2205.11472v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Benjamin Schiller, Johannes Daxenberger, Andreas Waldis, Iryna Gurevych
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The task of Argument Mining, that is extracting and classifying argument
components for a specific topic from large document sources, is an inherently
difficult task for machine learning models and humans alike, as large Argument
Mining datasets are rare and recognition of argument components requires expert
knowledge. The task becomes even more difficult if it also involves stance
detection of retrieved arguments. In this work, we investigate the effect of
Argument Mining dataset composition in few- and zero-shot settings. Our
findings show that, while fine-tuning is mandatory to achieve acceptable model
performance, using carefully composed training samples and reducing the
training sample size by up to almost 90% can still yield 95% of the maximum
performance. This gain is consistent across three Argument Mining tasks on
three different datasets. We also publish a new dataset for future
benchmarking.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ KV-Compress: Paged KV-Cache Compression with Variable Compression Rates
  per Attention Head 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00161v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00161v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Isaac Rehg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Context lengths of Large Language Models (LLMs) have exploded in recent
years, with 128k-token context becoming a standard and million-token context
becoming a reality. Efficiently supporting long-context inference remains
challenging as the memory that must be allocated in key-value (KV) cache for a
generation scales with its context length, limiting the number of long-context
requests that can be served concurrently under a given memory budget. KV cache
compression can mitigate this issue by removing under-utilized KVs from each
attention head's cache and reducing its memory footprint. Higher theoretical
compression rates can be achieved when the number of removed KVs varies across
attention heads, but application of such a strategy within existing inference
frameworks adds fragmentation and cannot realize the theoretical compression
rates in physical memory. We introduce KV-Compress, a novel compression method
that evicts contiguous KV blocks within a PagedAttention framework, reducing
the memory footprint of the KV cache proportionally to this theoretical
compression rate. Our method achieves state-of-the-art performance on LongBench
for both Mistral-7B-Instruct-v0.2 and Llama-3.1-8B-Instruct while lowering the
total number of compressed KVs by 4x compared with prior methods. Evaluations
on Llama-3.1-8B-Instruct and Llama-3.1-70B-Instruct-FP8 achieve compression
rates up to 8x with negligible impact on performance, and up to 64x while
retaining over 90% of full-cache performance for all but three of the suite's
subsets. We benchmark an integration of our method with vLLM that increases
total throughput by up to 5.18x by enabling larger decoding batches.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Decoding Intelligence: A Framework for Certifying Knowledge
  Comprehension in LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.15929v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.15929v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Isha Chaudhary, Vedaant V. Jain, Gagandeep Singh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge comprehension capability is an important aspect of human
intelligence. As Large Language Models (LLMs) are being envisioned as
superhuman agents, it is crucial for them to be proficient at knowledge
comprehension. However, existing benchmarking studies do not provide
consistent, generalizable, and formal guarantees on the knowledge comprehension
capabilities of LLMs. In this work, we propose the first framework to certify
knowledge comprehension in LLMs with formal probabilistic guarantees. Our
certificates are quantitative -- they consist of high-confidence, tight bounds
on the probability that a target LLM gives the correct answer on any knowledge
comprehension prompt sampled from a distribution. We design and certify novel
specifications that precisely represent distributions of knowledge
comprehension prompts leveraging knowledge graphs. We certify SOTA LLMs for
specifications over the Wikidata5m knowledge graph. We find that the knowledge
comprehension capability improves significantly with scaling the size of the
models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ First Heuristic Then Rational: Dynamic Use of Heuristics in Language
  Model Reasoning <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.16078v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.16078v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yoichi Aoki, Keito Kudo, Tatsuki Kuribayashi, Shusaku Sone, Masaya Taniguchi, Keisuke Sakaguchi, Kentaro Inui
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-step reasoning instruction, such as chain-of-thought prompting, is
widely adopted to explore better language models (LMs) performance. We report
on the systematic strategy that LMs employ in such a multi-step reasoning
process. Our controlled experiments reveal that LMs rely more heavily on
heuristics, such as lexical overlap, in the earlier stages of reasoning, where
more reasoning steps remain to reach a goal. Conversely, their reliance on
heuristics decreases as LMs progress closer to the final answer through
multiple reasoning steps. This suggests that LMs can backtrack only a limited
number of future steps and dynamically combine heuristic strategies with
rationale ones in tasks involving multi-step reasoning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper is accepted at EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LLMs Know More Than They Show: On the Intrinsic Representation of LLM
  Hallucinations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02707v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02707v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hadas Orgad, Michael Toker, Zorik Gekhman, Roi Reichart, Idan Szpektor, Hadas Kotek, Yonatan Belinkov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) often produce errors, including factual
inaccuracies, biases, and reasoning failures, collectively referred to as
"hallucinations". Recent studies have demonstrated that LLMs' internal states
encode information regarding the truthfulness of their outputs, and that this
information can be utilized to detect errors. In this work, we show that the
internal representations of LLMs encode much more information about
truthfulness than previously recognized. We first discover that the
truthfulness information is concentrated in specific tokens, and leveraging
this property significantly enhances error detection performance. Yet, we show
that such error detectors fail to generalize across datasets, implying that --
contrary to prior claims -- truthfulness encoding is not universal but rather
multifaceted. Next, we show that internal representations can also be used for
predicting the types of errors the model is likely to make, facilitating the
development of tailored mitigation strategies. Lastly, we reveal a discrepancy
between LLMs' internal encoding and external behavior: they may encode the
correct answer, yet consistently generate an incorrect one. Taken together,
these insights deepen our understanding of LLM errors from the model's internal
perspective, which can guide future research on enhancing error analysis and
mitigation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ StructLM: Towards Building Generalist Models for Structured Knowledge
  Grounding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.16671v7">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.16671v7.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alex Zhuang, Ge Zhang, Tianyu Zheng, Xinrun Du, Junjie Wang, Weiming Ren, Stephen W. Huang, Jie Fu, Xiang Yue, Wenhu Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Structured data sources, such as tables, graphs, and databases, are
ubiquitous knowledge sources. Despite the demonstrated capabilities of large
language models (LLMs) on plain text, their proficiency in interpreting and
utilizing structured data remains limited. Our investigation reveals a notable
deficiency in LLMs' ability to process structured data, e.g., ChatGPT lags
behind state-of-the-art (SoTA) model by an average of 35%. To augment the
Structured Knowledge Grounding (SKG) capabilities in LLMs, we have developed a
comprehensive instruction tuning dataset comprising 1.1 million examples.
Utilizing this dataset, we train a series of models, referred to as StructLM,
based on the Mistral and the CodeLlama model family, ranging from 7B to 34B
parameters. Our StructLM series surpasses task-specific models on 16 out of 18
evaluated datasets and establishes new SoTA performance on 8 SKG tasks.
Furthermore, StructLM demonstrates strong generalization across 6 novel
held-out SKG tasks, outperforming TableLlama by an average of 35\% and Flan-UL2
20B by an average of 10\%. Contrary to expectations, we observe that scaling
model size offers marginal benefits, with StructLM-34B showing only slight
improvements over StructLM-7B. This suggests that structured knowledge
grounding is still a challenging task and requires more innovative design to
push to a new level.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical Report</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ WISE: Rethinking the Knowledge Memory for Lifelong Model Editing of
  Large Language Models <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.14768v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.14768v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peng Wang, Zexi Li, Ningyu Zhang, Ziwen Xu, Yunzhi Yao, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) need knowledge updates to meet the ever-growing
world facts and correct the hallucinated responses, facilitating the methods of
lifelong model editing. Where the updated knowledge resides in memories is a
fundamental question for model editing. In this paper, we find that editing
either long-term memory (direct model parameters) or working memory
(non-parametric knowledge of neural network activations/representations by
retrieval) will result in an impossible triangle -- reliability,
generalization, and locality can not be realized together in the lifelong
editing settings. For long-term memory, directly editing the parameters will
cause conflicts with irrelevant pretrained knowledge or previous edits (poor
reliability and locality). For working memory, retrieval-based activations can
hardly make the model understand the edits and generalize (poor
generalization). Therefore, we propose WISE to bridge the gap between memories.
In WISE, we design a dual parametric memory scheme, which consists of the main
memory for the pretrained knowledge and a side memory for the edited knowledge.
We only edit the knowledge in the side memory and train a router to decide
which memory to go through when given a query. For continual editing, we devise
a knowledge-sharding mechanism where different sets of edits reside in distinct
subspaces of parameters, and are subsequently merged into a shared memory
without conflicts. Extensive experiments show that WISE can outperform previous
model editing methods and overcome the impossible triangle under lifelong model
editing of question answering, hallucination, and out-of-distribution settings
across trending LLM architectures, e.g., GPT, LLaMA, and Mistral. Code is
available at https://github.com/zjunlp/EasyEdit.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Self-MoE: Towards Compositional Large Language Models with
  Self-Specialized Experts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12034v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12034v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junmo Kang, Leonid Karlinsky, Hongyin Luo, Zhen Wang, Jacob Hansen, James Glass, David Cox, Rameswar Panda, Rogerio Feris, Alan Ritter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present Self-MoE, an approach that transforms a monolithic LLM into a
compositional, modular system of self-specialized experts, named MiXSE (MiXture
of Self-specialized Experts). Our approach leverages self-specialization, which
constructs expert modules using self-generated synthetic data, each equipping a
shared base LLM with distinct domain-specific capabilities, activated via
self-optimized routing. This allows for dynamic and capability-specific
handling of various target tasks, enhancing overall capabilities, without
extensive human-labeled data and added parameters. Our empirical results reveal
that specializing LLMs may exhibit potential trade-offs in performances on
non-specialized tasks. On the other hand, our Self-MoE demonstrates substantial
improvements (6.5%p on average) over the base LLM across diverse benchmarks
such as knowledge, reasoning, math, and coding. It also consistently
outperforms other methods, including instance merging and weight merging, while
offering better flexibility and interpretability by design with semantic
experts and routing. Our findings highlight the critical role of modularity,
the applicability of Self-MoE to multiple base LLMs, and the potential of
self-improvement in achieving efficient, scalable, and adaptable systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Russian Jeopardy! Data Set for Question-Answering Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2112.02325v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2112.02325v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elena Mikhalkova
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Question answering (QA) is one of the most common NLP tasks that relates to
named entity recognition, fact extraction, semantic search and some other
fields. In industry, it is much appreciated in chatbots and corporate
information systems. It is also a challenging task that attracted the attention
of a very general audience at the quiz show Jeopardy! In this article we
describe a Jeopardy!-like Russian QA data set collected from the official
Russian quiz database Chgk (che ge ka). The data set includes 379,284 quiz-like
questions with 29,375 from the Russian analogue of Jeopardy! - "Own Game". We
observe its linguistic features and the related QA-task. We conclude about
perspectives of a QA competition based on the data set collected from this
database.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PEAR: Position-Embedding-Agnostic Attention Re-weighting Enhances
  Retrieval-Augmented Generation with Zero Inference Overhead 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19745v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19745v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tao Tan, Yining Qian, Ang Lv, Hongzhan Lin, Songhao Wu, Yongbo Wang, Feng Wang, Jingtong Wu, Xin Lu, Rui Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) enhanced with retrieval-augmented generation
(RAG) have introduced a new paradigm for web search. However, the limited
context awareness of LLMs degrades their performance on RAG tasks. Existing
methods to enhance context awareness are often inefficient, incurring time or
memory overhead during inference, and many are tailored to specific position
embeddings. In this paper, we propose Position-Embedding-Agnostic attention
Re-weighting (PEAR), which enhances the context awareness of LLMs with zero
inference overhead. Specifically, on a proxy task focused on context copying,
we first detect heads which suppress the models' context awareness thereby
diminishing RAG performance. To weaken the impact of these heads, we re-weight
their outputs with learnable coefficients. The LLM (with frozen parameters) is
optimized by adjusting these coefficients to minimize loss on the proxy task.
As a result, the coefficients are optimized to values less than one, thereby
reducing their tendency to suppress RAG performance. During inference, the
optimized coefficients are fixed to re-weight these heads, regardless of the
specific task at hand. Our proposed PEAR offers two major advantages over
previous approaches: (1) It introduces zero additional inference overhead in
terms of memory usage or inference time, while outperforming competitive
baselines in accuracy and efficiency across various RAG tasks. (2) It is
independent of position embedding algorithms, ensuring broader applicability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ WellDunn: On the Robustness and Explainability of Language Models and
  Large Language Models in Identifying Wellness Dimensions <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12058v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12058v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seyedali Mohammadi, Edward Raff, Jinendra Malekar, Vedant Palit, Francis Ferraro, Manas Gaur
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language Models (LMs) are being proposed for mental health applications where
the heightened risk of adverse outcomes means predictive performance may not be
a sufficient litmus test of a model's utility in clinical practice. A model
that can be trusted for practice should have a correspondence between
explanation and clinical determination, yet no prior research has examined the
attention fidelity of these models and their effect on ground truth
explanations. We introduce an evaluation design that focuses on the robustness
and explainability of LMs in identifying Wellness Dimensions (WDs). We focus on
two existing mental health and well-being datasets: (a) Multi-label
Classification-based MultiWD, and (b) WellXplain for evaluating attention
mechanism veracity against expert-labeled explanations. The labels are based on
Halbert Dunn's theory of wellness, which gives grounding to our evaluation. We
reveal four surprising results about LMs/LLMs: (1) Despite their human-like
capabilities, GPT-3.5/4 lag behind RoBERTa, and MedAlpaca, a fine-tuned LLM on
WellXplain fails to deliver any remarkable improvements in performance or
explanations. (2) Re-examining LMs' predictions based on a confidence-oriented
loss function reveals a significant performance drop. (3) Across all LMs/LLMs,
the alignment between attention and explanations remains low, with LLMs scoring
a dismal 0.0. (4) Most mental health-specific LMs/LLMs overlook domain-specific
knowledge and undervalue explanations, causing these discrepancies. This study
highlights the need for further research into their consistency and
explanations in mental health and well-being.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in BlackboxNLP @ EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ When Can <span class="highlight-title">Transformer</span>s Count to n? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.15160v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.15160v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gilad Yehudai, Haim Kaplan, Asma Ghandeharioun, Mor Geva, Amir Globerson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models based on the transformer architectures can solve highly
complex tasks. But are there simple tasks that such models cannot solve? Here
we focus on very simple counting tasks, that involve counting how many times a
token in the vocabulary have appeared in a string. We show that if the
dimension of the transformer state is linear in the context length, this task
can be solved. However, the solution we propose does not scale beyond this
limit, and we provide theoretical arguments for why it is likely impossible for
a size limited transformer to implement this task. Our empirical results
demonstrate the same phase-transition in performance, as anticipated by the
theoretical argument. Our results demonstrate the importance of understanding
how transformers can solve simple tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tokenization Is More Than Compression <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.18376v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.18376v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Craig W. Schmidt, Varshini Reddy, Haoran Zhang, Alec Alameddine, Omri Uzan, Yuval Pinter, Chris Tanner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tokenization is a foundational step in natural language processing (NLP)
tasks, bridging raw text and language models. Existing tokenization approaches
like Byte-Pair Encoding (BPE) originate from the field of data compression, and
it has been suggested that the effectiveness of BPE stems from its ability to
condense text into a relatively small number of tokens. We test the hypothesis
that fewer tokens lead to better downstream performance by introducing
PathPiece, a new tokenizer that segments a document's text into the minimum
number of tokens for a given vocabulary. Through extensive experimentation we
find this hypothesis not to be the case, casting doubt on the understanding of
the reasons for effective tokenization. To examine which other factors play a
role, we evaluate design decisions across all three phases of tokenization:
pre-tokenization, vocabulary construction, and segmentation, offering new
insights into the design of effective tokenizers. Specifically, we illustrate
the importance of pre-tokenization and the benefits of using BPE to initialize
vocabulary construction. We train 64 language models with varying tokenization,
ranging in size from 350M to 2.4B parameters, all of which are made publicly
available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ComplexTempQA: A Large-Scale <span class="highlight-title">Dataset</span> for Complex Temporal Question
  Answering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.04866v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.04866v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Raphael Gruber, Abdelrahman Abdallah, Michael Färber, Adam Jatowt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce ComplexTempQA, a large-scale dataset consisting of over 100
million question-answer pairs designed to tackle the challenges in temporal
question answering. ComplexTempQA significantly surpasses existing benchmarks
like HOTPOTQA, TORQUE, and TEQUILA in scale and scope. Utilizing data from
Wikipedia and Wikidata, the dataset covers questions spanning over two decades
and offers an unmatched breadth of topics. We introduce a unique taxonomy that
categorizes questions as attributes, comparisons, and counting questions, each
revolving around events, entities, and time periods. One standout feature of
ComplexTempQA is the high complexity of its questions, which demand effective
capabilities for answering such as across-time comparison, temporal
aggregation, and multi-hop reasoning involving temporal event ordering and
entity recognition. Additionally, each question is accompanied by detailed
metadata, including specific time scopes, allowing for comprehensive evaluation
and enhancement of the temporal reasoning abilities of large language models.
ComplexTempQA serves both as a testing ground for developing sophisticated AI
models and as a foundation for advancing research in question answering,
information retrieval, and language understanding.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Reconstruct Your Previous Conversations! Comprehensively Investigating
  Privacy Leakage Risks in Conversations with <span class="highlight-title">GPT</span> Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.02987v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.02987v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junjie Chu, Zeyang Sha, Michael Backes, Yang Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Significant advancements have recently been made in large language models
represented by GPT models. Users frequently have multi-round private
conversations with cloud-hosted GPT models for task optimization. Yet, this
operational paradigm introduces additional attack surfaces, particularly in
custom GPTs and hijacked chat sessions. In this paper, we introduce a
straightforward yet potent Conversation Reconstruction Attack. This attack
targets the contents of previous conversations between GPT models and benign
users, i.e., the benign users' input contents during their interaction with GPT
models. The adversary could induce GPT models to leak such contents by querying
them with designed malicious prompts. Our comprehensive examination of privacy
risks during the interactions with GPT models under this attack reveals GPT-4's
considerable resilience. We present two advanced attacks targeting improved
reconstruction of past conversations, demonstrating significant privacy leakage
across all models under these advanced techniques. Evaluating various defense
mechanisms, we find them ineffective against these attacks. Our findings
highlight the ease with which privacy can be compromised in interactions with
GPT models, urging the community to safeguard against potential abuses of these
models' capabilities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in EMNLP 2024. 14 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Visual Question Decomposition on Multimodal Large Language Models <span class="chip">EMNLP2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19339v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19339v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haowei Zhang, Jianzhe Liu, Zhen Han, Shuo Chen, Bailan He, Volker Tresp, Zhiqiang Xu, Jindong Gu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Question decomposition has emerged as an effective strategy for prompting
Large Language Models (LLMs) to answer complex questions. However, while
existing methods primarily focus on unimodal language models, the question
decomposition capability of Multimodal Large Language Models (MLLMs) has yet to
be explored. To this end, this paper explores visual question decomposition on
MLLMs. Specifically, we introduce a systematic evaluation framework including a
dataset and several evaluation criteria to assess the quality of the decomposed
sub-questions, revealing that existing MLLMs struggle to produce high-quality
sub-questions. To address this limitation, we propose a specific finetuning
dataset, DecoVQA+, for enhancing the model's question decomposition capability.
Aiming at enabling models to perform appropriate selective decomposition, we
propose an efficient finetuning pipeline. The finetuning pipeline consists of
our proposed dataset and a training objective for selective decomposition.
Finetuned MLLMs demonstrate significant improvements in the quality of
sub-questions and the policy of selective question decomposition. Additionally,
the models also achieve higher accuracy with selective decomposition on VQA
benchmark datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DYNAMICQA: Tracing Internal Knowledge Conflicts in Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.17023v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.17023v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sara Vera Marjanović, Haeun Yu, Pepa Atanasova, Maria Maistro, Christina Lioma, Isabelle Augenstein
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge-intensive language understanding tasks require Language Models
(LMs) to integrate relevant context, mitigating their inherent weaknesses, such
as incomplete or outdated knowledge. However, conflicting knowledge can be
present in the LM's parameters, termed intra-memory conflict, which can affect
a model's propensity to accept contextual knowledge. To study the effect of
intra-memory conflict on an LM's ability to accept relevant context, we utilize
two knowledge conflict measures and a novel dataset containing inherently
conflicting data, DynamicQA. This dataset includes facts with a temporal
dynamic nature where facts can change over time and disputable dynamic facts,
which can change depending on the viewpoint. DynamicQA is the first to include
real-world knowledge conflicts and provide context to study the link between
the different types of knowledge conflicts. We also evaluate several measures
on their ability to reflect the presence of intra-memory conflict: semantic
entropy and a novel coherent persuasion score. With our extensive experiments,
we verify that LMs exhibit a greater degree of intra-memory conflict with
dynamic facts compared to facts that have a single truth value. Furthermore, we
reveal that facts with intra-memory conflict are harder to update with context,
suggesting that retrieval-augmented generation will struggle with the most
commonly adapted facts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 6 figures, Accepted to Findings of EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Residual Stream Analysis with Multi-Layer SAEs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04185v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04185v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tim Lawson, Lucy Farnik, Conor Houghton, Laurence Aitchison
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sparse autoencoders (SAEs) are a promising approach to interpreting the
internal representations of transformer language models. However, SAEs are
usually trained separately on each transformer layer, making it difficult to
use them to study how information flows across layers. To solve this problem,
we introduce the multi-layer SAE (MLSAE): a single SAE trained on the residual
stream activation vectors from every transformer layer. Given that the residual
stream is understood to preserve information across layers, we expected MLSAE
latents to `switch on' at a token position and remain active at later layers.
Interestingly, we find that individual latents are often active at a single
layer for a given token or prompt, but this layer may differ for different
tokens or prompts. We quantify these phenomena by defining a distribution over
layers and considering its variance. We find that the variance of the
distributions of latent activations over layers is about two orders of
magnitude greater when aggregating over tokens compared with a single token.
For larger underlying models, the degree to which latents are active at
multiple layers increases, which is consistent with the fact that the residual
stream activation vectors at adjacent layers become more similar. Finally, we
relax the assumption that the residual stream basis is the same at every layer
by applying pre-trained tuned-lens transformations, but our findings remain
qualitatively similar. Our results represent a new approach to understanding
how representations change as they flow through transformers. We release our
code to train and analyze MLSAEs at https://github.com/tim-lawson/mlsae.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>34 pages, 26 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Think-on-Graph 2.0: Deep and Faithful Large Language Model Reasoning
  with Knowledge-guided Retrieval Augmented Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10805v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10805v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shengjie Ma, Chengjin Xu, Xuhui Jiang, Muzhi Li, Huaren Qu, Cehao Yang, Jiaxin Mao, Jian Guo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) has enhanced large language models
(LLMs) by using knowledge retrieval to address knowledge gaps. However,
existing RAG approaches often fail to ensure the depth and completeness of the
information retrieved, which is essential for complex reasoning tasks. In this
work, we present Think-on-Graph 2.0 (ToG-2), a hybrid RAG framework that
iteratively retrieves information from both unstructured and structured
knowledge sources in a tightly integrated manner. Specifically, ToG-2 leverages
knowledge graphs (KGs) to connect documents via entities, facilitating deep and
knowledge-guided context retrieval. Simultaneously, it uses documents as entity
contexts to enable precise and efficient graph retrieval.
  ToG-2 alternates between graph retrieval and context retrieval to search for
in-depth clues relevant to the question, enabling LLMs to generate accurate
answers. We conduct a series of experiments to demonstrate the following
advantages of ToG-2: (1) ToG-2 tightly integrates context retrieval and graph
retrieval, enhancing context retrieval through the KG while enabling reliable
graph retrieval based on contexts; (2) it achieves deep and faithful reasoning
in LLMs through an iterative knowledge retrieval process that integrates
contexts and the KG; and (3) ToG-2 is training-free and compatible with various
LLMs as a plug-and-play solution. Extensive experiments show that ToG-2
achieves state-of-the-art (SOTA) performance on 6 out of 7 knowledge-intensive
datasets with GPT-3.5, and can elevate the performance of smaller models (e.g.,
LLAMA-2-13B) to the level of GPT-3.5's direct reasoning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Language in Vivo vs. in Silico: Size Matters but Larger Language Models
  Still Do Not Comprehend Language on a Par with Humans 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.14883v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.14883v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vittoria Dentella, Fritz Guenther, Evelina Leivada
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding the limits of language is a prerequisite for Large Language
Models (LLMs) to act as theories of natural language. LLM performance in some
language tasks presents both quantitative and qualitative differences from that
of humans, however it remains to be determined whether such differences are
amenable to model size. This work investigates the critical role of model
scaling, determining whether increases in size make up for such differences
between humans and models. We test three LLMs from different families (Bard,
137 billion parameters; ChatGPT-3.5, 175 billion; ChatGPT-4, 1.5 trillion) on a
grammaticality judgment task featuring anaphora, center embedding,
comparatives, and negative polarity. N=1,200 judgments are collected and scored
for accuracy, stability, and improvements in accuracy upon repeated
presentation of a prompt. Results of the best performing LLM, ChatGPT-4, are
compared to results of n=80 humans on the same stimuli. We find that humans are
overall less accurate than ChatGPT-4 (76% vs. 80% accuracy, respectively), but
that this is due to ChatGPT-4 outperforming humans only in one task condition,
namely on grammatical sentences. Additionally, ChatGPT-4 wavers more than
humans in its answers (12.5% vs. 9.6% likelihood of an oscillating answer,
respectively). Thus, while increased model size may lead to better performance,
LLMs are still not sensitive to (un)grammaticality the same way as humans are.
It seems possible but unlikely that scaling alone can fix this issue. We
interpret these results by comparing language learning in vivo and in silico,
identifying three critical differences concerning (i) the type of evidence,
(ii) the poverty of the stimulus, and (iii) the occurrence of semantic
hallucinations due to impenetrable linguistic reference.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.05930v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.05930v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jushi Kai, Tianhang Zhang, Hai Hu, Zhouhan Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) demonstrate great performance in text
generation. However, LLMs are still suffering from hallucinations. In this
work, we propose an inference-time method, Self-Highlighted Hesitation (SH2),
to help LLMs decode more truthfully. SH2 is based on a simple fact rooted in
information theory that for an LLM, the tokens predicted with lower
probabilities are prone to be more informative than others. Our analysis shows
that the tokens assigned with lower probabilities by an LLM are more likely to
be closely related to factual information, such as nouns, proper nouns, and
adjectives. Therefore, we propose to ''highlight'' the factual information by
selecting the tokens with the lowest probabilities and concatenating them to
the original context, thus forcing the model to repeatedly read and hesitate on
these tokens before generation. During decoding, we also adopt contrastive
decoding to emphasize the difference in the output probabilities brought by the
hesitation. Experimental results demonstrate that our SH2, requiring no
additional data or models, can effectively help LLMs elicit factual knowledge
and distinguish hallucinated contexts. Significant and consistent improvements
are achieved by SH2 for LLaMA-7b, LLaMA2-7b and Mistral-7b on multiple
hallucination tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CBF-LLM: Safe Control for LLM Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.15625v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.15625v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuya Miyaoka, Masaki Inoue
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes a control-based framework for aligning large language
models (LLMs) by leveraging a control barrier function (CBF) to ensure
user-desirable text generation. The presented framework applies the safety
filter, designed based on the CBF, to the output generation of the baseline
LLM, i.e., the sequence of the token, with the aim of intervening in the
generated text. The overall text-generation system is implemented with Llama 3
and a RoBERTa model, and the source code is available at
https://github.com/Mya-Mya/CBF-LLM. The experiment demonstrates its control
ability and effectiveness in reducing the number of interventions needed for
user-specified alignment tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Comparison of Language Modeling and Translation as Multilingual
  <span class="highlight-title">Pretrain</span>ing Objectives <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.15489v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.15489v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zihao Li, Shaoxiong Ji, Timothee Mickus, Vincent Segonne, Jörg Tiedemann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pretrained language models (PLMs) display impressive performances and have
captured the attention of the NLP community. Establishing best practices in
pretraining has, therefore, become a major focus of NLP research, especially
since insights gained from monolingual English models may not necessarily apply
to more complex multilingual models. One significant caveat of the current
state of the art is that different works are rarely comparable: they often
discuss different parameter counts, training data, and evaluation methodology.
  This paper proposes a comparison of multilingual pretraining objectives in a
controlled methodological environment. We ensure that training data and model
architectures are comparable, and discuss the downstream performances across 6
languages that we observe in probing and fine-tuning scenarios. We make two key
observations: (1) the architecture dictates which pretraining objective is
optimal; (2) multilingual translation is a very effective pretraining objective
under the right conditions. We make our code, data, and model weights available
at \texttt{\url{https://github.com/Helsinki-NLP/lm-vs-mt}}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Proceedings of EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ What the Harm? Quantifying the Tangible Impact of Gender Bias in Machine
  Translation with a Human-centered Study <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00545v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00545v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Beatrice Savoldi, Sara Papi, Matteo Negri, Ana Guerberof, Luisa Bentivogli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Gender bias in machine translation (MT) is recognized as an issue that can
harm people and society. And yet, advancements in the field rarely involve
people, the final MT users, or inform how they might be impacted by biased
technologies. Current evaluations are often restricted to automatic methods,
which offer an opaque estimate of what the downstream impact of gender
disparities might be. We conduct an extensive human-centered study to examine
if and to what extent bias in MT brings harms with tangible costs, such as
quality of service gaps across women and men. To this aim, we collect
behavioral data from 90 participants, who post-edited MT outputs to ensure
correct gender translation. Across multiple datasets, languages, and types of
users, our study shows that feminine post-editing demands significantly more
technical and temporal effort, also corresponding to higher financial costs.
Existing bias measurements, however, fail to reflect the found disparities. Our
findings advocate for human-centered approaches that can inform the societal
impact of bias.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted ad EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ OffsetBias: Leveraging Debiased Data for Tuning Evaluators <span class="chip">EMNLP2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.06551v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.06551v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junsoo Park, Seungyeon Jwa, Meiying Ren, Daeyoung Kim, Sanghyuk Choi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Employing Large Language Models (LLMs) to assess the quality of generated
responses, such as prompting instruct-tuned models or fine-tuning judge models,
has become a widely adopted evaluation method. It is also known that such
evaluators are vulnerable to biases, such as favoring longer responses. While
it is important to overcome this problem, the specifics of these biases remain
under-explored. In this work, we qualitatively identify six types of biases
inherent in various judge models. We propose EvalBiasBench as a meta-evaluation
collection of hand-crafted test cases for each bias type. Additionally, we
present de-biasing dataset construction methods and the associated preference
dataset OffsetBias. Experimental results demonstrate that fine-tuning on our
dataset significantly enhances the robustness of judge models against biases
and improves performance across most evaluation scenarios. We release our
datasets and the fine-tuned judge model to public.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Can Large Language Models Understand Symbolic Graphics Programs? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.08313v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.08313v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zeju Qiu, Weiyang Liu, Haiwen Feng, Zhen Liu, Tim Z. Xiao, Katherine M. Collins, Joshua B. Tenenbaum, Adrian Weller, Michael J. Black, Bernhard Schölkopf
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Against the backdrop of enthusiasm for large language models (LLMs), there is
an urgent need to scientifically assess their capabilities and shortcomings.
This is nontrivial in part because it is difficult to find tasks which the
models have not encountered during training. Utilizing symbolic graphics
programs, we propose a domain well-suited to test multiple spatial-semantic
reasoning skills of LLMs. Popular in computer graphics, these programs
procedurally generate visual data. While LLMs exhibit impressive skills in
general program synthesis and analysis, symbolic graphics programs offer a new
layer of evaluation: they allow us to test an LLM's ability to answer
different-grained semantic-level questions of the images or 3D geometries
without a vision encoder. To semantically understand the symbolic programs,
LLMs would need to possess the ability to "imagine" and reason how the
corresponding graphics content would look with only the symbolic description.
We use this task to evaluate LLMs by creating a large benchmark for the
semantic visual understanding of symbolic graphics programs, built procedurally
with minimal human effort. Particular emphasis is placed on transformations of
images that leave the image level semantics invariant while introducing
significant changes to the underlying program. We evaluate commercial and
open-source LLMs on our benchmark to assess their ability to reason about
visual output of programs, finding that LLMs considered stronger at reasoning
generally perform better. Lastly, we introduce a novel method to improve this
ability -- Symbolic Instruction Tuning (SIT), in which the LLM is finetuned
with pre-collected instruction data on symbolic graphics programs.
Interestingly, we find that SIT not only improves LLM's understanding on
symbolic programs, but it also improves general reasoning ability on various
other benchmarks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical Report v2 (46 pages, 24 figures, project page:
  https://sgp-bench.github.io/, substantial update from v1)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Jailbreak Antidote: Runtime Safety-Utility Balance via Sparse
  Representation Adjustment in Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02298v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02298v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guobin Shen, Dongcheng Zhao, Yiting Dong, Xiang He, Yi Zeng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As large language models (LLMs) become integral to various applications,
ensuring both their safety and utility is paramount. Jailbreak attacks, which
manipulate LLMs into generating harmful content, pose significant challenges to
this balance. Existing defenses, such as prompt engineering and safety
fine-tuning, often introduce computational overhead, increase inference
latency, and lack runtime flexibility. Moreover, overly restrictive safety
measures can degrade model utility by causing refusals of benign queries. In
this paper, we introduce Jailbreak Antidote, a method that enables real-time
adjustment of LLM safety preferences by manipulating a sparse subset of the
model's internal states during inference. By shifting the model's hidden
representations along a safety direction with varying strengths, we achieve
flexible control over the safety-utility balance without additional token
overhead or inference delays. Our analysis reveals that safety-related
information in LLMs is sparsely distributed; adjusting approximately 5% of the
internal state is as effective as modifying the entire state. Extensive
experiments on nine LLMs (ranging from 2 billion to 72 billion parameters),
evaluated against ten jailbreak attack methods and compared with six defense
strategies, validate the effectiveness and efficiency of our approach. By
directly manipulating internal states during reasoning, Jailbreak Antidote
offers a lightweight, scalable solution that enhances LLM safety while
preserving utility, opening new possibilities for real-time safety mechanisms
in widely-deployed AI systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards a Universal Method for Meaningful Signal Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.00016v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.00016v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Louis Mahon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  It is known that human speech and certain animal vocalizations can convey
meaningful content because we can decipher the content that a given utterance
does convey. This paper explores an alternative approach to determining whether
a signal is meaningful, one that analyzes only the signal itself and is
independent of what the conveyed meaning might be. We devise a method that
takes a waveform as input and outputs a score indicating its degree of
`meaningfulness`. We cluster contiguous portions of the input to minimize the
total description length, and then take the length of the code of the assigned
cluster labels as meaningfulness score. We evaluate our method empirically,
against several baselines, and show that it is the only one to give a high
score to human speech in various languages and with various speakers, a
moderate score to animal vocalizations from birds and orcas, and a low score to
ambient noise from various sources.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Beyond Persuasion: Towards Conversational Recommender System with
  Credible Explanations <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.14399v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.14399v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peixin Qin, Chen Huang, Yang Deng, Wenqiang Lei, Tat-Seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the aid of large language models, current conversational recommender
system (CRS) has gaining strong abilities to persuade users to accept
recommended items. While these CRSs are highly persuasive, they can mislead
users by incorporating incredible information in their explanations, ultimately
damaging the long-term trust between users and the CRS. To address this, we
propose a simple yet effective method, called PC-CRS, to enhance the
credibility of CRS's explanations during persuasion. It guides the explanation
generation through our proposed credibility-aware persuasive strategies and
then gradually refines explanations via post-hoc self-reflection. Experimental
results demonstrate the efficacy of PC-CRS in promoting persuasive and credible
explanations. Further analysis reveals the reason behind current methods
producing incredible explanations and the potential of credible explanations to
improve recommendation accuracy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Findings of EMNLP 2024. Our code is available at
  https://github.com/mumen798/PC-CRS</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ColPali: Efficient Document Retrieval with Vision Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.01449v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.01449v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manuel Faysse, Hugues Sibille, Tony Wu, Bilel Omrani, Gautier Viaud, Céline Hudelot, Pierre Colombo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Documents are visually rich structures that convey information through text,
as well as tables, figures, page layouts, or fonts. While modern document
retrieval systems exhibit strong performance on query-to-text matching, they
struggle to exploit visual cues efficiently, hindering their performance on
practical document retrieval applications such as Retrieval Augmented
Generation. To benchmark current systems on visually rich document retrieval,
we introduce the Visual Document Retrieval Benchmark ViDoRe, composed of
various page-level retrieving tasks spanning multiple domains, languages, and
settings. The inherent shortcomings of modern systems motivate the introduction
of a new retrieval model architecture, ColPali, which leverages the document
understanding capabilities of recent Vision Language Models to produce
high-quality contextualized embeddings solely from images of document pages.
Combined with a late interaction matching mechanism, ColPali largely
outperforms modern document retrieval pipelines while being drastically faster
and end-to-end trainable.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Lighthouse: A User-Friendly Library for Reproducible Video Moment
  Retrieval and Highlight Detection <span class="chip">EMNLP2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.02901v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.02901v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Taichi Nishimura, Shota Nakada, Hokuto Munakata, Tatsuya Komatsu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose Lighthouse, a user-friendly library for reproducible video moment
retrieval and highlight detection (MR-HD). Although researchers proposed
various MR-HD approaches, the research community holds two main issues. The
first is a lack of comprehensive and reproducible experiments across various
methods, datasets, and video-text features. This is because no unified training
and evaluation codebase covers multiple settings. The second is user-unfriendly
design. Because previous works use different libraries, researchers set up
individual environments. In addition, most works release only the training
codes, requiring users to implement the whole inference process of MR-HD.
Lighthouse addresses these issues by implementing a unified reproducible
codebase that includes six models, three features, and five datasets. In
addition, it provides an inference API and web demo to make these methods
easily accessible for researchers and developers. Our experiments demonstrate
that Lighthouse generally reproduces the reported scores in the reference
papers. The code is available at https://github.com/line/lighthouse.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accepted at EMNLP2024 - system demonstration track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Typing to Listen at the Cocktail Party: Text-Guided Target Speaker
  Extraction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.07284v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.07284v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiang Hao, Jibin Wu, Jianwei Yu, Chenglin Xu, Kay Chen Tan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Humans can easily isolate a single speaker from a complex acoustic
environment, a capability referred to as the "Cocktail Party Effect." However,
replicating this ability has been a significant challenge in the field of
target speaker extraction (TSE). Traditional TSE approaches predominantly rely
on voiceprints, which raise privacy concerns and face issues related to the
quality and availability of enrollment samples, as well as intra-speaker
variability. To address these issues, this work introduces a novel text-guided
TSE paradigm named LLM-TSE. In this paradigm, a state-of-the-art large language
model, LLaMA 2, processes typed text input from users to extract semantic cues.
We demonstrate that textual descriptions alone can effectively serve as cues
for extraction, thus addressing privacy concerns and reducing dependency on
voiceprints. Furthermore, our approach offers flexibility by allowing the user
to specify the extraction or suppression of a speaker and enhances robustness
against intra-speaker variability by incorporating context-dependent textual
information. Experimental results show competitive performance with text-based
cues alone and demonstrate the effectiveness of using text as a task selector.
Additionally, they achieve a new state-of-the-art when combining text-based
cues with pre-registered cues. This work represents the first integration of
LLMs with TSE, potentially establishing a new benchmark in solving the cocktail
party problem and expanding the scope of TSE applications by providing a
versatile, privacy-conscious solution.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review, https://github.com/haoxiangsnr/llm-tse</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Adaptive Contrastive Decoding in Retrieval-Augmented Generation for
  Handling Noisy Contexts <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.01084v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.01084v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Youna Kim, Hyuhng Joon Kim, Cheonbok Park, Choonghyun Park, Hyunsoo Cho, Junyeob Kim, Kang Min Yoo, Sang-goo Lee, Taeuk Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  When using large language models (LLMs) in knowledge-intensive tasks, such as
open-domain question answering, external context can bridge the gap between
external knowledge and the LLMs' parametric knowledge. Recent research has been
developed to amplify contextual knowledge over the parametric knowledge of LLMs
with contrastive decoding approaches. While these approaches could yield
truthful responses when relevant context is provided, they are prone to
vulnerabilities when faced with noisy contexts. We extend the scope of previous
studies to encompass noisy contexts and propose adaptive contrastive decoding
(ACD) to leverage contextual influence effectively. ACD demonstrates
improvements in open-domain question answering tasks compared to baselines,
especially in robustness by remaining undistracted by noisy contexts in
retrieval-augmented generation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ IndicVoices-R: Unlocking a Massive Multilingual Multi-speaker Speech
  Corpus for Scaling Indian TTS <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05356v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05356v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ashwin Sankar, Srija Anand, Praveen Srinivasa Varadhan, Sherry Thomas, Mehak Singal, Shridhar Kumar, Deovrat Mehendale, Aditi Krishana, Giri Raju, Mitesh Khapra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in text-to-speech (TTS) synthesis show that large-scale
models trained with extensive web data produce highly natural-sounding output.
However, such data is scarce for Indian languages due to the lack of
high-quality, manually subtitled data on platforms like LibriVox or YouTube. To
address this gap, we enhance existing large-scale ASR datasets containing
natural conversations collected in low-quality environments to generate
high-quality TTS training data. Our pipeline leverages the cross-lingual
generalization of denoising and speech enhancement models trained on English
and applied to Indian languages. This results in IndicVoices-R (IV-R), the
largest multilingual Indian TTS dataset derived from an ASR dataset, with 1,704
hours of high-quality speech from 10,496 speakers across 22 Indian languages.
IV-R matches the quality of gold-standard TTS datasets like LJSpeech, LibriTTS,
and IndicTTS. We also introduce the IV-R Benchmark, the first to assess
zero-shot, few-shot, and many-shot speaker generalization capabilities of TTS
models on Indian voices, ensuring diversity in age, gender, and style. We
demonstrate that fine-tuning an English pre-trained model on a combined dataset
of high-quality IndicTTS and our IV-R dataset results in better zero-shot
speaker generalization compared to fine-tuning on the IndicTTS dataset alone.
Further, our evaluation reveals limited zero-shot generalization for Indian
voices in TTS models trained on prior datasets, which we improve by fine-tuning
the model on our data containing diverse set of speakers across language
families. We open-source all data and code, releasing the first TTS model for
all 22 official Indian languages.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to NeurIPS 2024 Datasets and Benchmarks track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CMR Scaling Law: Predicting Critical Mixture Ratios for Continual
  <span class="highlight-title">Pre-train</span>ing of Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.17467v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.17467v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiawei Gu, Zacc Yang, Chuanghao Ding, Rui Zhao, Fei Tan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) excel in diverse tasks but often underperform in
specialized fields due to limited domain-specific or proprietary corpus.
Continual pre-training (CPT) enhances LLM capabilities by imbuing new
domain-specific or proprietary knowledge while replaying general corpus to
prevent catastrophic forgetting. The data mixture ratio of general corpus and
domain-specific corpus, however, has been chosen heuristically, leading to
sub-optimal training efficiency in practice. In this context, we attempt to
re-visit the scaling behavior of LLMs under the hood of CPT, and discover a
power-law relationship between loss, mixture ratio, and training tokens scale.
We formalize the trade-off between general and domain-specific capabilities,
leading to a well-defined Critical Mixture Ratio (CMR) of general and domain
data. By striking the balance, CMR maintains the model's general ability and
achieves the desired domain transfer, ensuring the highest utilization of
available resources. Considering the balance between efficiency and
effectiveness, CMR can be regarded as the optimal mixture ratio. Through
extensive experiments, we ascertain the predictability of CMR, propose CMR
scaling law and have substantiated its generalization. These findings offer
practical guidelines for optimizing LLM training in specialized domains,
ensuring both general and domain-specific performance while efficiently
managing training resources.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 main conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DAPE: Data-Adaptive Positional Encoding for Length Extrapolation <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.14722v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.14722v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chuanyang Zheng, Yihang Gao, Han Shi, Minbin Huang, Jingyao Li, Jing Xiong, Xiaozhe Ren, Michael Ng, Xin Jiang, Zhenguo Li, Yu Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Positional encoding plays a crucial role in transformers, significantly
impacting model performance and length generalization. Prior research has
introduced absolute positional encoding (APE) and relative positional encoding
(RPE) to distinguish token positions in given sequences. However, both APE and
RPE remain fixed after model training regardless of input data, limiting their
adaptability and flexibility. Hence, we expect that the desired positional
encoding should be data-adaptive and can be dynamically adjusted with the given
attention. In this paper, we propose a Data-Adaptive Positional Encoding (DAPE)
method, which dynamically and semantically adjusts based on input context and
learned fixed priors. Experimental validation on real-world datasets (Arxiv,
Books3, and CHE) demonstrates that DAPE enhances model performances in terms of
trained length and length generalization, where the improvements are
statistically significant. The model visualization suggests that our model can
keep both local and anti-local information. Finally, we successfully train the
model on sequence length 128 and achieve better performance at evaluation
sequence length 8192, compared with other static positional encoding methods,
revealing the benefit of the adaptive positional encoding method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Progressive-Hint <span class="highlight-title">Prompt</span>ing Improves Reasoning in Large Language Models <span class="chip">ICML</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2304.09797v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2304.09797v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chuanyang Zheng, Zhengying Liu, Enze Xie, Zhenguo Li, Yu Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The performance of Large Language Models (LLMs) in reasoning tasks depends
heavily on prompt design, with Chain-of-Thought (CoT) and self-consistency
being critical methods that enhance this ability. However, these methods do not
fully exploit the answers generated by the LLM to guide subsequent responses.
This paper proposes a new prompting method, named Progressive-Hint Prompting
(PHP), that enables automatic multiple interactions between users and LLMs by
using previously generated answers as hints to progressively guide toward the
correct answers. PHP is orthogonal to CoT and self-consistency, making it easy
to combine with state-of-the-art techniques to further improve performance. We
conducted extensive and comprehensive experiments on seven benchmarks. The
results show that PHP significantly improves accuracy while remaining highly
efficient. For instance, with text-davinci-003, we observed a 4.2% improvement
on GSM8K with greedy decoding compared to Complex CoT, and a 46.17% reduction
in sample paths with self-consistency. With GPT-4 and PHP, we achieve
state-of-the-art performances on SVAMP (89.1% -> 91.9%), GSM8K (92% -> 95.5%),
AQuA (76.4% -> 79.9%) and MATH (50.3% -> 53.9%).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ICML AI4MATH 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ sDPO: Don't Use Your Data All at Once 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.19270v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.19270v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dahyun Kim, Yungi Kim, Wonho Song, Hyeonwoo Kim, Yunsu Kim, Sanghoon Kim, Chanjun Park
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As development of large language models (LLM) progresses, aligning them with
human preferences has become increasingly important. We propose stepwise DPO
(sDPO), an extension of the recently popularized direct preference optimization
(DPO) for alignment tuning. This approach involves dividing the available
preference datasets and utilizing them in a stepwise manner, rather than
employing it all at once. We demonstrate that this method facilitates the use
of more precisely aligned reference models within the DPO training framework.
Furthermore, sDPO trains the final model to be more performant, even
outperforming other popular LLMs with more parameters.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ "I Like Sunnie More Than I Expected!": Exploring User Expectation and
  Perception of an Anthropomorphic LLM-based Conversational Agent for
  Well-Being Support 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.13803v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.13803v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siyi Wu, Julie Y. A. Cachia, Feixue Han, Bingsheng Yao, Tianyi Xie, Xuan Zhao, Dakuo Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The human-computer interaction (HCI) research community has a longstanding
interest in exploring the mismatch between users' actual experiences and
expectation toward new technologies, for instance, large language models
(LLMs). In this study, we compared users' (N = 38) initial expectations against
their post-interaction perceptions of two LLM-powered mental well-being
intervention activity recommendation systems. Both systems have a built-in LLM
to recommend a personalized well-being intervention activity, but one system
(Sunnie) has an anthropomorphic conversational interaction design via elements
such as appearance, persona, and natural conversation. Results showed that user
engagement was high with both systems, and both systems exceeded users'
expectations along the utility dimension, highlighting AI's potential to offer
useful intervention activity recommendations. In addition, Sunnie further
outperformed the non-anthropomorphic baseline system in relational warmth.
These findings suggest that anthropomorphic conversational interaction design
may be particularly effective in fostering warmth in mental health support
contexts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>In Submission</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MAG-SQL: Multi-Agent Generative Approach with Soft Schema Linking and
  Iterative Sub-SQL Refinement for Text-to-SQL 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.07930v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.07930v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenxuan Xie, Gaochen Wu, Bowen Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent In-Context Learning based methods have achieved remarkable success in
Text-to-SQL task. However, there is still a large gap between the performance
of these models and human performance on datasets with complex database schema
and difficult questions, such as BIRD. Besides, existing work has neglected to
supervise intermediate steps when solving questions iteratively with question
decomposition methods, and the schema linking methods used in these works are
very rudimentary. To address these issues, we propose MAG-SQL, a multi-agent
generative approach with soft schema linking and iterative Sub-SQL refinement.
In our framework, an entity-based method with tables' summary is used to select
the columns in database, and a novel targets-conditions decomposition method is
introduced to decompose those complex questions. Additionally, we build a
iterative generating module which includes a Sub-SQL Generator and Sub-SQL
Refiner, introducing external oversight for each step of generation. Through a
series of ablation studies, the effectiveness of each agent in our framework
has been demonstrated. When evaluated on the BIRD benchmark with GPT-4, MAG-SQL
achieves an execution accuracy of 61.08%, compared to the baseline accuracy of
46.35% for vanilla GPT-4 and the baseline accuracy of 57.56% for MAC-SQL.
Besides, our approach makes similar progress on Spider.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages, 14 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Representation Tuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.06927v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.06927v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Christopher M. Ackerman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Activation engineering is becoming increasingly popular as a means of online
control of large language models (LLMs). In this work, I extend the idea of
active steering with vectors that represent a behavioral direction of interest
to tuning those vectors directly into the model, obviating the need for online
control. First, I identify activation vectors related to honesty in an
open-source LLM (Llama- 2-13b-chat). Next, I demonstrate that model output can
be made more or less honest by adding positive or negative multiples of these
vectors to residual stream activations during generation. Then, I show that a
similar effect can be achieved by fine-tuning the vectors directly into the
model, by use of a dual loss function based on the cosine similarity of
residual stream activations to the vectors combined with a standard token-based
loss ("representation tuning"). Finally, I compare the generations in response
to honesty-probing prompts from the resulting models to those from models
fine-tuned with a token-based loss alone, and to those from the untuned model
subjected to online steering. Overall, fine-tuning the vectors into the models
using the cosine similarity plus token loss showed a stronger effect than
online steering, and generalized better than using the standard loss,
suggesting the potential utility of this approach as a safety measure. Code and
data are available at https://github.com/cma1114/representation_tuning; tuned
models are available at https://huggingface.co/collections/cackerman/
representation-tuning-66da1e5ab41cd1b824687d9f.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 6 figures, 6 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multi-LogiEval: Towards Evaluating Multi-Step Logical Reasoning Ability
  of Large Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17169v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17169v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nisarg Patel, Mohith Kulkarni, Mihir Parmar, Aashna Budhiraja, Mutsumi Nakamura, Neeraj Varshney, Chitta Baral
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As Large Language Models (LLMs) continue to exhibit remarkable performance in
natural language understanding tasks, there is a crucial need to measure their
ability for human-like multi-step logical reasoning. Existing logical reasoning
evaluation benchmarks often focus primarily on simplistic single-step or
multi-step reasoning with a limited set of inference rules. Furthermore, the
lack of datasets for evaluating non-monotonic reasoning represents a crucial
gap since it aligns more closely with human-like reasoning. To address these
limitations, we propose Multi-LogiEval, a comprehensive evaluation dataset
encompassing multi-step logical reasoning with various inference rules and
depths. Multi-LogiEval covers three logic types--propositional, first-order,
and non-monotonic--consisting of more than 30 inference rules and more than 60
of their combinations with various depths. Leveraging this dataset, we conduct
evaluations on a range of LLMs including GPT-4, ChatGPT, Gemini-Pro, Yi, Orca,
and Mistral, employing a zero-shot chain-of-thought. Experimental results show
that there is a significant drop in the performance of LLMs as the reasoning
steps/depth increases (average accuracy of ~68% at depth-1 to ~43% at depth-5).
We further conduct a thorough investigation of reasoning chains generated by
LLMs which reveals several important findings. We believe that Multi-LogiEval
facilitates future research for evaluating and enhancing the logical reasoning
ability of LLMs. Data is available at
https://github.com/Mihir3009/Multi-LogiEval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Revisiting Who's Harry Potter: Towards Targeted Unlearning from a Causal
  Intervention Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.16997v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.16997v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yujian Liu, Yang Zhang, Tommi Jaakkola, Shiyu Chang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper investigates Who's Harry Potter (WHP), a pioneering yet
insufficiently understood method for LLM unlearning. We explore it in two
steps. First, we introduce a new task of LLM targeted unlearning, where given
an unlearning target (e.g., a person) and some unlearning documents, we aim to
unlearn only the information about the target, rather than everything in the
unlearning documents. We further argue that a successful unlearning should
satisfy criteria such as not outputting gibberish, not fabricating facts about
the unlearning target, and not releasing factual information under jailbreak
attacks. Second, we construct a causal intervention framework for targeted
unlearning, where the knowledge of the unlearning target is modeled as a
confounder between LLM input and output, and the unlearning process as a
deconfounding process. This framework justifies and extends WHP, deriving a
simple unlearning algorithm that includes WHP as a special case. Experiments on
existing and new datasets show that our approach, without explicitly optimizing
for the aforementioned criteria, achieves competitive performance in all of
them. Our code is available at
https://github.com/UCSB-NLP-Chang/causal_unlearn.git.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PILLOW: Enhancing Efficient Instruction Fine-tuning via <span class="highlight-title">Prompt</span> Matching <span class="chip">EMNLP 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.05621v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.05621v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenting Qi, Xiaoyu Tan, Shaojie Shi, Chao Qu, Yinghui Xu, Yuan Qi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Instruction fine-tuning has conventionally been employed to adapt Large
Language Models (LLMs) to a variety of tasks. Nonetheless, this technique often
necessitates substantial computational resources, making it impractical for
deployment by individuals or small-scale entities. Recently, Low-Rank
Adaptation (LoRA) has become a promising alternative, offering high
capabilities on par with full tuning with reduced resource overhead. However,
attaining satisfactory performance through the fine-tuning of LoRA is a
non-trivial challenge. In this paper, we propose PILLOW, which aims to improve
LoRA's performance by a discrimination-based prompting method, leveraging LLMs'
In-Context Learning ability. PILLOW incorporates a matching network that
selects prompts from a user-defined prompt pool, concatenates the selected
prompts with the user instruction as input, and performs inference using the
LoRA-fine-tuned LLMs. Trained with Reinforcement Learning, PILLOW exhibits
commensurate performance on various evaluation metrics compared with typical
instruction fine-tuning methods, utilizing only consumer-grade GPU resources
and exhibiting a large reduction in computational costs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2023 (Industry Track), Oral Presentation</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MetaAligner: Towards Generalizable Multi-Objective Alignment of Language
  Models <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.17141v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.17141v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kailai Yang, Zhiwei Liu, Qianqian Xie, Jimin Huang, Tianlin Zhang, Sophia Ananiadou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in large language models (LLMs) focus on aligning to
heterogeneous human expectations and values via multi-objective preference
alignment. However, existing methods are dependent on the policy model
parameters, which require high-cost repetition of their alignment algorithms
for each new policy model, and they cannot expand to unseen objectives due to
their static alignment objectives. In this work, we propose Meta-Objective
Aligner (MetaAligner), the first policy-agnostic and generalizable method for
multi-objective preference alignment. MetaAligner models multi-objective
alignment into three stages: (1) dynamic objectives reformulation algorithm
reorganizes traditional alignment datasets to supervise the model on performing
flexible alignment across different objectives; (2) conditional weak-to-strong
correction paradigm aligns the weak outputs of fixed policy models to approach
strong outputs with higher preferences in the corresponding alignment
objectives, enabling plug-and-play inferences on any policy models, which
significantly reduces training costs and facilitates alignment on close-source
policy models; (3) generalizable inference method flexibly adjusts target
objectives by updating their text descriptions in the prompts, facilitating
generalizable alignment to unseen objectives. Experimental results show that
MetaAligner achieves significant and balanced improvements in multi-objective
alignments on 10 state-of-the-art policy models, and saves up to 93.63% of GPU
training hours compared to previous alignment methods. The model also
effectively aligns unseen objectives, marking the first step towards
generalizable multi-objective preference alignment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by NeurIPS 2024 main track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Spectra: A Comprehensive Study of Ternary, Quantized, and FP16 Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12327v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12327v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ayush Kaushal, Tejas Vaidhya, Arnab Kumar Mondal, Tejas Pandey, Aaryan Bhagat, Irina Rish
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Rapid advancements in GPU computational power has outpaced memory capacity
and bandwidth growth, creating bottlenecks in Large Language Model (LLM)
inference. Post-training quantization is the leading method for addressing
memory-related bottlenecks in LLM inference, but it suffers from significant
performance degradation below 4-bit precision. This paper addresses these
challenges by investigating the pretraining of low-bitwidth models specifically
Ternary Language Models (TriLMs) as an alternative to traditional
floating-point models (FloatLMs) and their post-training quantized versions
(QuantLMs). We present Spectra LLM suite, the first open suite of LLMs spanning
multiple bit-widths, including FloatLMs, QuantLMs, and TriLMs, ranging from 99M
to 3.9B parameters trained on 300B tokens. Our comprehensive evaluation
demonstrates that TriLMs offer superior scaling behavior in terms of model size
(in bits). Surprisingly, at scales exceeding one billion parameters, TriLMs
consistently outperform their QuantLM and FloatLM counterparts for a given bit
size across various benchmarks. Notably, the 3.9B parameter TriLM matches the
performance of the FloatLM 3.9B across all benchmarks, despite having fewer
bits than FloatLM 830M. Overall, this research provides valuable insights into
the feasibility and scalability of low-bitwidth language models, paving the way
for the development of more efficient LLMs.
  To enhance understanding of low-bitwidth models, we are releasing 500+
intermediate checkpoints of the Spectra suite at
\href{https://github.com/NolanoOrg/SpectraSuite}{https://github.com/NolanoOrg/SpectraSuite}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>42 pages, 21 figures, and 13 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evaluating and Safeguarding the Adversarial Robustness of
  Retrieval-Based In-Context Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.15984v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.15984v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Simon Yu, Jie He, Pasquale Minervini, Jeff Z. Pan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the emergence of large language models, such as LLaMA and OpenAI GPT-3,
In-Context Learning (ICL) gained significant attention due to its effectiveness
and efficiency. However, ICL is very sensitive to the choice, order, and
verbaliser used to encode the demonstrations in the prompt. Retrieval-Augmented
ICL methods try to address this problem by leveraging retrievers to extract
semantically related examples as demonstrations. While this approach yields
more accurate results, its robustness against various types of adversarial
attacks, including perturbations on test samples, demonstrations, and retrieved
data, remains under-explored. Our study reveals that retrieval-augmented models
can enhance robustness against test sample attacks, outperforming vanilla ICL
with a 4.87% reduction in Attack Success Rate (ASR); however, they exhibit
overconfidence in the demonstrations, leading to a 2% increase in ASR for
demonstration attacks. Adversarial training can help improve the robustness of
ICL methods to adversarial attacks; however, such a training scheme can be too
costly in the context of LLMs. As an alternative, we introduce an effective
training-free adversarial defence method, DARD, which enriches the example pool
with those attacked samples. We show that DARD yields improvements in
performance and robustness, achieving a 15% reduction in ASR over the
baselines. Code and data are released to encourage further research:
https://github.com/simonucl/adv-retreival-icl
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>COLM 2024, 30 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FacLens: Transferable Probe for Foreseeing Non-Factuality in Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.05328v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.05328v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanling Wang, Haoyang Li, Hao Zou, Jing Zhang, Xinlei He, Qi Li, Ke Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite advancements in large language models (LLMs), non-factual responses
remain prevalent. Unlike extensive studies on post-hoc detection of such
responses, this work studies non-factuality prediction (NFP), aiming to predict
whether an LLM will generate a non-factual response to a question before the
generation process. Previous efforts on NFP have demonstrated LLMs' awareness
of their internal knowledge, but they still face challenges in efficiency and
transferability. In this work, we propose a lightweight NFP model named
Factuality Lens (FacLens), which effectively probes hidden representations of
questions for the NFP task. Besides, we discover that hidden question
representations sourced from different LLMs exhibit similar NFP patterns, which
enables the transferability of FacLens across LLMs to reduce development costs.
Extensive experiments highlight FacLens's superiority in both effectiveness and
efficiency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Frame-Voyager: Learning to Query Frames for Video Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03226v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03226v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sicheng Yu, Chengkai Jin, Huanyu Wang, Zhenghao Chen, Sheng Jin, Zhongrong Zuo, Xiaolei Xu, Zhenbang Sun, Bingni Zhang, Jiawei Wu, Hao Zhang, Qianru Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video Large Language Models (Video-LLMs) have made remarkable progress in
video understanding tasks. However, they are constrained by the maximum length
of input tokens, making it impractical to input entire videos. Existing frame
selection approaches, such as uniform frame sampling and text-frame retrieval,
fail to account for the information density variations in the videos or the
complex instructions in the tasks, leading to sub-optimal performance. In this
paper, we propose Frame-Voyager that learns to query informative frame
combinations, based on the given textual queries in the task. To train
Frame-Voyager, we introduce a new data collection and labeling pipeline, by
ranking frame combinations using a pre-trained Video-LLM. Given a video of M
frames, we traverse its T-frame combinations, feed them into a Video-LLM, and
rank them based on Video-LLM's prediction losses. Using this ranking as
supervision, we train Frame-Voyager to query the frame combinations with lower
losses. In experiments, we evaluate Frame-Voyager on four Video Question
Answering benchmarks by plugging it into two different Video-LLMs. The
experimental results demonstrate that Frame-Voyager achieves impressive results
in all settings, highlighting its potential as a plug-and-play solution for
Video-LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Auto-Arena: Automating LLM Evaluations with Agent Peer Battles and
  Committee Discussions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.20267v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.20267v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruochen Zhao, Wenxuan Zhang, Yew Ken Chia, Weiwen Xu, Deli Zhao, Lidong Bing
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As LLMs continuously evolve, there is an urgent need for a reliable
evaluation method that delivers trustworthy results promptly. Currently, static
benchmarks suffer from inflexibility and unreliability, leading users to prefer
human voting platforms like Chatbot Arena. However, human evaluations require
significant manual effort. To address this, we propose the Auto-Arena, an
innovative framework that automates the entire evaluation process using
LLM-powered agents. Firstly, an LLM examiner generates questions. Then, two LLM
candidates engage in a multi-round peer battle based on individual questions,
aiming at revealing their true performance differences. Finally, a committee of
LLM judges collaboratively discusses and decides the winner, reducing bias and
enhancing fairness. During the peer battles, we observe intriguing scenarios
where the LLM candidates display competitive behaviors and even learn from the
opponents. In our extensive experiments involving 15 recent LLMs, Auto-Arena
shows a 92.14% correlation with human preferences, surpassing all previous
expert-annotated benchmarks without any manual efforts. As a result, Auto-Arena
offers a promising alternative to current human evaluation platforms for
evaluating LLMs automatically.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evalverse: Unified and Accessible Library for Large Language Model
  Evaluation <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.00943v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.00943v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jihoo Kim, Wonho Song, Dahyun Kim, Yunsu Kim, Yungi Kim, Chanjun Park
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces Evalverse, a novel library that streamlines the
evaluation of Large Language Models (LLMs) by unifying disparate evaluation
tools into a single, user-friendly framework. Evalverse enables individuals
with limited knowledge of artificial intelligence to easily request LLM
evaluations and receive detailed reports, facilitated by an integration with
communication platforms like Slack. Thus, Evalverse serves as a powerful tool
for the comprehensive assessment of LLMs, offering both researchers and
practitioners a centralized and easily accessible evaluation framework.
Finally, we also provide a demo video for Evalverse, showcasing its
capabilities and implementation in a two-minute format.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Demo Track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Corrective Retrieval Augmented Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.15884v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.15884v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shi-Qi Yan, Jia-Chen Gu, Yun Zhu, Zhen-Hua Ling
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) inevitably exhibit hallucinations since the
accuracy of generated texts cannot be secured solely by the parametric
knowledge they encapsulate. Although retrieval-augmented generation (RAG) is a
practicable complement to LLMs, it relies heavily on the relevance of retrieved
documents, raising concerns about how the model behaves if retrieval goes
wrong. To this end, we propose the Corrective Retrieval Augmented Generation
(CRAG) to improve the robustness of generation. Specifically, a lightweight
retrieval evaluator is designed to assess the overall quality of retrieved
documents for a query, returning a confidence degree based on which different
knowledge retrieval actions can be triggered. Since retrieval from static and
limited corpora can only return sub-optimal documents, large-scale web searches
are utilized as an extension for augmenting the retrieval results. Besides, a
decompose-then-recompose algorithm is designed for retrieved documents to
selectively focus on key information and filter out irrelevant information in
them. CRAG is plug-and-play and can be seamlessly coupled with various
RAG-based approaches. Experiments on four datasets covering short- and
long-form generation tasks show that CRAG can significantly improve the
performance of RAG-based approaches.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Update results, add more analysis, and fix typos</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Magpie: Alignment Data Synthesis from Scratch by <span class="highlight-title">Prompt</span>ing Aligned LLMs
  with Nothing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.08464v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.08464v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhangchen Xu, Fengqing Jiang, Luyao Niu, Yuntian Deng, Radha Poovendran, Yejin Choi, Bill Yuchen Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  High-quality instruction data is critical for aligning large language models
(LLMs). Although some models, such as Llama-3-Instruct, have open weights,
their alignment data remain private, which hinders the democratization of AI.
High human labor costs and a limited, predefined scope for prompting prevent
existing open-source data creation methods from scaling effectively,
potentially limiting the diversity and quality of public alignment datasets. Is
it possible to synthesize high-quality instruction data at scale by extracting
it directly from an aligned LLM? We present a self-synthesis method for
generating large-scale alignment data named Magpie. Our key observation is that
aligned LLMs like Llama-3-Instruct can generate a user query when we input only
the left-side templates up to the position reserved for user messages, thanks
to their auto-regressive nature. We use this method to prompt Llama-3-Instruct
and generate 4 million instructions along with their corresponding responses.
We perform a comprehensive analysis of the extracted data and select 300K
high-quality instances. To compare Magpie data with other public instruction
datasets, we fine-tune Llama-3-8B-Base with each dataset and evaluate the
performance of the fine-tuned models. Our results indicate that in some tasks,
models fine-tuned with Magpie perform comparably to the official
Llama-3-8B-Instruct, despite the latter being enhanced with 10 million data
points through supervised fine-tuning (SFT) and subsequent feedback learning.
We also show that using Magpie solely for SFT can surpass the performance of
previous public datasets utilized for both SFT and preference optimization,
such as direct preference optimization with UltraFeedback. This advantage is
evident on alignment benchmarks such as AlpacaEval, ArenaHard, and WildBench.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Link: https://magpie-align.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SpinQuant: LLM quantization with learned rotations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.16406v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.16406v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zechun Liu, Changsheng Zhao, Igor Fedorov, Bilge Soran, Dhruv Choudhary, Raghuraman Krishnamoorthi, Vikas Chandra, Yuandong Tian, Tijmen Blankevoort
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Post-training quantization (PTQ) techniques applied to weights, activations,
and the KV cache greatly reduce memory usage, latency, and power consumption of
Large Language Models (LLMs), but may lead to large quantization errors when
outliers are present. Rotating activation or weight matrices helps remove
outliers and benefits quantization. In this work, we identify a collection of
applicable rotation parameterizations that lead to identical outputs in
full-precision Transformer architectures while enhancing quantization accuracy.
In addition, we find that some random rotations lead to much better
quantization than others, with an up to 13 points difference in downstream
zero-shot reasoning performance. As a result, we propose SpinQuant, a novel
approach that incorporates learned rotation matrices for optimal quantized
network accuracy. With 4-bit quantization of weight, activation, and KV-cache,
SpinQuant narrows the accuracy gap on zero-shot reasoning tasks with full
precision to merely 2.9 points on the LLaMA-2 7B model, surpassing LLM-QAT by
19.1 points and SmoothQuant by 25.0 points. Furthermore, SpinQuant also
outperforms concurrent work QuaRot, which applies random rotations to remove
outliers. In particular, for LLaMA-3 8B models that are hard to quantize,
SpinQuant reduces the gap to full precision by up to 45.1% relative to QuaRot.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FoodPuzzle: Developing Large Language Model Agents as Flavor Scientists 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.12832v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.12832v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tenghao Huang, Donghee Lee, John Sweeney, Jiatong Shi, Emily Steliotes, Matthew Lange, Jonathan May, Muhao Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Flavor development in the food industry is increasingly challenged by the
need for rapid innovation and precise flavor profile creation. Traditional
flavor research methods typically rely on iterative, subjective testing, which
lacks the efficiency and scalability required for modern demands. This paper
presents three contributions to address the challenges. Firstly, we define a
new problem domain for scientific agents in flavor science, conceptualized as
the generation of hypotheses for flavor profile sourcing and understanding. To
facilitate research in this area, we introduce the FoodPuzzle, a challenging
benchmark consisting of 978 food items and 1,766 flavor molecules profiles. We
propose a novel Scientific Agent approach, integrating in-context learning and
retrieval augmented techniques to generate grounded hypotheses in the domain of
food science. Experimental results indicate that our model significantly
surpasses traditional methods in flavor profile prediction tasks, demonstrating
its potential to transform flavor development practices.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Generation Gap: Exploring Age Bias in the Value Systems of Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.08760v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.08760v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siyang Liu, Trish Maturi, Bowen Yi, Siqi Shen, Rada Mihalcea
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We explore the alignment of values in Large Language Models (LLMs) with
specific age groups, leveraging data from the World Value Survey across
thirteen categories. Through a diverse set of prompts tailored to ensure
response robustness, we find a general inclination of LLM values towards
younger demographics, especially when compared to the US population. Although a
general inclination can be observed, we also found that this inclination toward
younger groups can be different across different value categories.
Additionally, we explore the impact of incorporating age identity information
in prompts and observe challenges in mitigating value discrepancies with
different age cohorts. Our findings highlight the age bias in LLMs and provide
insights for future work. Materials for our analysis are available at \url{
https://github.com/MichiganNLP/Age-Bias-In-LLMs}
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 pages</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Sound <span class="chip" style="font-size: 60%">19</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Presto! Distilling Steps and Layers for Accelerating Music Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05167v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05167v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zachary Novack, Ge Zhu, Jonah Casebeer, Julian McAuley, Taylor Berg-Kirkpatrick, Nicholas J. Bryan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite advances in diffusion-based text-to-music (TTM) methods, efficient,
high-quality generation remains a challenge. We introduce Presto!, an approach
to inference acceleration for score-based diffusion transformers via reducing
both sampling steps and cost per step. To reduce steps, we develop a new
score-based distribution matching distillation (DMD) method for the EDM-family
of diffusion models, the first GAN-based distillation method for TTM. To reduce
the cost per step, we develop a simple, but powerful improvement to a recent
layer distillation method that improves learning via better preserving hidden
state variance. Finally, we combine our step and layer distillation methods
together for a dual-faceted approach. We evaluate our step and layer
distillation methods independently and show each yield best-in-class
performance. Our combined distillation method can generate high-quality outputs
with improved diversity, accelerating our base model by 10-18x (230/435ms
latency for 32 second mono/stereo 44.1kHz, 15x faster than comparable SOTA) --
the fastest high-quality TTM to our knowledge. Sound examples can be found at
https://presto-music.github.io/web/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Editing Music with Melody and Text: Using ControlNet for Diffusion
  <span class="highlight-title">Transformer</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05151v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05151v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siyuan Hou, Shansong Liu, Ruibin Yuan, Wei Xue, Ying Shan, Mangsuo Zhao, Chao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the significant progress in controllable music generation and
editing, challenges remain in the quality and length of generated music due to
the use of Mel-spectrogram representations and UNet-based model structures. To
address these limitations, we propose a novel approach using a Diffusion
Transformer (DiT) augmented with an additional control branch using ControlNet.
This allows for long-form and variable-length music generation and editing
controlled by text and melody prompts. For more precise and fine-grained melody
control, we introduce a novel top-$k$ constant-Q Transform representation as
the melody prompt, reducing ambiguity compared to previous representations
(e.g., chroma), particularly for music with multiple tracks or a wide range of
pitch values. To effectively balance the control signals from text and melody
prompts, we adopt a curriculum learning strategy that progressively masks the
melody prompt, resulting in a more stable training process. Experiments have
been performed on text-to-music generation and music-style transfer tasks using
open-source instrumental recording data. The results demonstrate that by
extending StableAudio, a pre-trained text-controlled DiT model, our approach
enables superior melody-controlled editing while retaining good text-to-music
generation performance. These results outperform a strong MusicGen baseline in
terms of both text-based generation and melody preservation for editing. Audio
examples can be found at https://stable-audio-control.github.io/web/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CR-CTC: Consistency regularization on CTC for improved speech
  recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05101v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05101v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zengwei Yao, Wei Kang, Xiaoyu Yang, Fangjun Kuang, Liyong Guo, Han Zhu, Zengrui Jin, Zhaoqing Li, Long Lin, Daniel Povey
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Connectionist Temporal Classification (CTC) is a widely used method for
automatic speech recognition (ASR), renowned for its simplicity and
computational efficiency. However, it often falls short in recognition
performance compared to transducer or systems combining CTC and attention-based
encoder-decoder (CTC/AED). In this work, we propose the Consistency-Regularized
CTC (CR-CTC), which enforces consistency between two CTC distributions obtained
from different augmented views of the input speech mel-spectrogram. We provide
in-depth insights into its essential behaviors from three perspectives: 1) it
conducts self-distillation between random pairs of sub-models that process
different augmented views; 2) it learns contextual representation through
masked prediction for positions within time-masked regions, especially when we
increase the amount of time masking; 3) it suppresses the extremely peaky CTC
distributions, thereby reducing overfitting and improving the generalization
ability. Extensive experiments on LibriSpeech, Aishell-1, and GigaSpeech
datasets demonstrate the effectiveness of our CR-CTC, which achieves
performance comparable to, or even slightly better than, that of transducer and
CTC/AED.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving Speaker Representations Using Contrastive Losses on
  Multi-scale Features 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05037v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05037v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Satvik Dixit, Massa Baali, Rita Singh, Bhiksha Raj
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Speaker verification systems have seen significant advancements with the
introduction of Multi-scale Feature Aggregation (MFA) architectures, such as
MFA-Conformer and ECAPA-TDNN. These models leverage information from various
network depths by concatenating intermediate feature maps before the pooling
and projection layers, demonstrating that even shallower feature maps encode
valuable speaker-specific information. Building upon this foundation, we
propose a Multi-scale Feature Contrastive (MFCon) loss that directly enhances
the quality of these intermediate representations. Our MFCon loss applies
contrastive learning to all feature maps within the network, encouraging the
model to learn more discriminative representations at the intermediate stage
itself. By enforcing better feature map learning, we show that the resulting
speaker embeddings exhibit increased discriminative power. Our method achieves
a 9.05% improvement in equal error rate (EER) compared to the standard
MFA-Conformer on the VoxCeleb-1O test set.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RelUNet: Relative Channel Fusion U-Net for Multichannel Speech
  Enhancement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05019v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05019v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ibrahim Aldarmaki, Thamar Solorio, Bhiksha Raj, Hanan Aldarmaki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural multi-channel speech enhancement models, in particular those based on
the U-Net architecture, demonstrate promising performance and generalization
potential. These models typically encode input channels independently, and
integrate the channels during later stages of the network. In this paper, we
propose a novel modification of these models by incorporating relative
information from the outset, where each channel is processed in conjunction
with a reference channel through stacking. This input strategy exploits
comparative differences to adaptively fuse information between channels,
thereby capturing crucial spatial information and enhancing the overall
performance. The experiments conducted on the CHiME-3 dataset demonstrate
improvements in speech enhancement metrics across various architectures.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Stage-Wise and Prior-Aware Neural Speech Phase Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04990v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04990v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fei Liu, Yang Ai, Hui-Peng Du, Ye-Xin Lu, Rui-Chen Zheng, Zhen-Hua Ling
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes a novel Stage-wise and Prior-aware Neural Speech Phase
Prediction (SP-NSPP) model, which predicts the phase spectrum from input
amplitude spectrum by two-stage neural networks. In the initial
prior-construction stage, we preliminarily predict a rough prior phase spectrum
from the amplitude spectrum. The subsequent refinement stage transforms the
amplitude spectrum into a refined high-quality phase spectrum conditioned on
the prior phase. Networks in both stages use ConvNeXt v2 blocks as the backbone
and adopt adversarial training by innovatively introducing a phase spectrum
discriminator (PSD). To further improve the continuity of the refined phase, we
also incorporate a time-frequency integrated difference (TFID) loss in the
refinement stage. Experimental results confirm that, compared to neural
network-based no-prior phase prediction methods, the proposed SP-NSPP achieves
higher phase prediction accuracy, thanks to introducing the coarse phase priors
and diverse training criteria. Compared to iterative phase estimation
algorithms, our proposed SP-NSPP does not require multiple rounds of staged
iterations, resulting in higher generation efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by SLT2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A decade of DCASE: Achievements, practices, evaluations and future
  challenges <span class="chip">ICASSP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04951v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04951v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Annamaria Mesaros, Romain Serizel, Toni Heittola, Tuomas Virtanen, Mark D. Plumbley
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces briefly the history and growth of the Detection and
Classification of Acoustic Scenes and Events (DCASE) challenge, workshop,
research area and research community. Created in 2013 as a data evaluation
challenge, DCASE has become a major research topic in the Audio and Acoustic
Signal Processing area. Its success comes from a combination of factors: the
challenge offers a large variety of tasks that are renewed each year; and the
workshop offers a channel for dissemination of related work, engaging a young
and dynamic community. At the same time, DCASE faces its own challenges,
growing and expanding to different areas. One of the core principles of DCASE
is open science and reproducibility: publicly available datasets, baseline
systems, technical reports and workshop publications. While the DCASE challenge
and workshop are independent of IEEE SPS, the challenge receives annual
endorsement from the AASP TC, and the DCASE community contributes significantly
to the ICASSP flagship conference and the success of SPS in many of its
activities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to ICASSP 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Art2Mus: Bridging Visual Arts and Music through Cross-Modal Generation <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04906v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04906v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ivan Rinaldi, Nicola Fanelli, Giovanna Castellano, Gennaro Vessio
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Artificial Intelligence and generative models have revolutionized music
creation, with many models leveraging textual or visual prompts for guidance.
However, existing image-to-music models are limited to simple images, lacking
the capability to generate music from complex digitized artworks. To address
this gap, we introduce $\mathcal{A}\textit{rt2}\mathcal{M}\textit{us}$, a novel
model designed to create music from digitized artworks or text inputs.
$\mathcal{A}\textit{rt2}\mathcal{M}\textit{us}$ extends the AudioLDM~2
architecture, a text-to-audio model, and employs our newly curated datasets,
created via ImageBind, which pair digitized artworks with music. Experimental
results demonstrate that $\mathcal{A}\textit{rt2}\mathcal{M}\textit{us}$ can
generate music that resonates with the input stimuli. These findings suggest
promising applications in multimedia art, interactive installations, and
AI-driven creative tools.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Presented at the AI for Visual Arts (AI4VA) workshop at ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Attentive-based Multi-level Feature Fusion for Voice Disorder Diagnosis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04797v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04797v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lipeng Shen, Yifan Xiong, Dongyue Guo, Wei Mo, Lingyu Yu, Hui Yang, Yi Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Voice disorders negatively impact the quality of daily life in various ways.
However, accurately recognizing the category of pathological features from raw
audio remains a considerable challenge due to the limited dataset. A promising
method to handle this issue is extracting multi-level pathological information
from speech in a comprehensive manner by fusing features in the latent space.
In this paper, a novel framework is designed to explore the way of high-quality
feature fusion for effective and generalized detection performance.
Specifically, the proposed model follows a two-stage training paradigm: (1)
ECAPA-TDNN and Wav2vec 2.0 which have shown remarkable effectiveness in various
domains are employed to learn the universal pathological information from raw
audio; (2) An attentive fusion module is dedicatedly designed to establish the
interaction between pathological features projected by EcapTdnn and Wav2vec 2.0
respectively and guide the multi-layer fusion, the entire model is jointly
fine-tuned from pre-trained features by the automatic voice pathology detection
task. Finally, comprehensive experiments on the FEMH and SVD datasets
demonstrate that the proposed framework outperforms the competitive baselines,
and achieves the accuracy of 90.51% and 87.68%.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Ultra-Low-Power Neuromorphic Speech Enhancement with
  Spiking-FullSubNet 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04785v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04785v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiang Hao, Chenxiang Ma, Qu Yang, Jibin Wu, Kay Chen Tan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Speech enhancement is critical for improving speech intelligibility and
quality in various audio devices. In recent years, deep learning-based methods
have significantly improved speech enhancement performance, but they often come
with a high computational cost, which is prohibitive for a large number of edge
devices, such as headsets and hearing aids. This work proposes an
ultra-low-power speech enhancement system based on the brain-inspired spiking
neural network (SNN) called Spiking-FullSubNet. Spiking-FullSubNet follows a
full-band and sub-band fusioned approach to effectively capture both global and
local spectral information. To enhance the efficiency of computationally
expensive sub-band modeling, we introduce a frequency partitioning method
inspired by the sensitivity profile of the human peripheral auditory system.
Furthermore, we introduce a novel spiking neuron model that can dynamically
control the input information integration and forgetting, enhancing the
multi-scale temporal processing capability of SNN, which is critical for speech
denoising. Experiments conducted on the recent Intel Neuromorphic Deep Noise
Suppression (N-DNS) Challenge dataset show that the Spiking-FullSubNet
surpasses state-of-the-art methods by large margins in terms of both speech
quality and energy efficiency metrics. Notably, our system won the championship
of the Intel N-DNS Challenge (Algorithmic Track), opening up a myriad of
opportunities for ultra-low-power speech enhancement at the edge. Our source
code and model checkpoints are publicly available at
https://github.com/haoxiangsnr/spiking-fullsubnet.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Modeling and Estimation of Vocal Tract and Glottal Source Parameters
  Using ARMAX-LF Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04704v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04704v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kai Lia, Masato Akagia, Yongwei Lib, Masashi Unokia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modeling and estimation of the vocal tract and glottal source parameters of
vowels from raw speech can be typically done by using the Auto-Regressive with
eXogenous input (ARX) model and Liljencrants-Fant (LF) model with an
iteration-based estimation approach. However, the all-pole autoregressive model
in the modeling of vocal tract filters cannot provide the locations of
anti-formants (zeros), which increases the estimation errors in certain classes
of speech sounds, such as nasal, fricative, and stop consonants. In this paper,
we propose the Auto-Regressive Moving Average eXogenous with LF (ARMAX-LF)
model to extend the ARX-LF model to a wider variety of speech sounds, including
vowels and nasalized consonants. The LF model represents the glottal source
derivative as a parametrized time-domain model, and the ARMAX model represents
the vocal tract as a pole-zero filter with an additional exogenous LF
excitation as input. To estimate multiple parameters with fewer errors, we
first utilize the powerful nonlinear fitting ability of deep neural networks
(DNNs) to build a mapping from extracted glottal source derivatives or speech
waveforms to corresponding LF parameters. Then, glottal source and vocal tract
parameters can be estimated with fewer estimation errors and without any
iterations as in the analysis-by-synthesis strategy. Experimental results with
synthesized speech using the linear source-filter model, synthesized speech
using the physical model, and real speech signals showed that the proposed
ARMAX-LF model with a DNN-based estimation method can estimate the parameters
of both vowels and nasalized sounds with fewer errors and estimation time.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Demo of Zero-Shot Guitar Amplifier Modelling: Enhancing Modeling with
  Hyper Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04702v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04702v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu-Hua Chen, Yuan-Chiao Cheng, Yen-Tung Yeh, Jui-Te Wu, Yu-Hsiang Ho, Jyh-Shing Roger Jang, Yi-Hsuan Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Electric guitar tone modeling typically focuses on the non-linear
transformation from clean to amplifier-rendered audio. Traditional methods rely
on one-to-one mappings, incorporating device parameters into neural models to
replicate specific amplifiers. However, these methods are limited by the need
for specific training data. In this paper, we adapt a model based on the
previous work, which leverages a tone embedding encoder and a feature wise
linear modulation (FiLM) condition method. In this work, we altered
conditioning method using a hypernetwork-based gated convolutional network
(GCN) to generate audio that blends clean input with the tone characteristics
of reference audio. By extending the training data to cover a wider variety of
amplifier tones, our model is able to capture a broader range of tones.
Additionally, we developed a real-time plugin to demonstrate the system's
practical application, allowing users to experience its performance
interactively. Our results indicate that the proposed system achieves superior
tone modeling versatility compared to traditional methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>demo of the ISMIR paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Non-Invasive Suicide Risk Prediction Through Speech Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.12132v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.12132v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shahin Amiriparian, Maurice Gerczuk, Justina Lutz, Wolfgang Strube, Irina Papazova, Alkomiet Hasan, Alexander Kathan, Björn W. Schuller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The delayed access to specialized psychiatric assessments and care for
patients at risk of suicidal tendencies in emergency departments creates a
notable gap in timely intervention, hindering the provision of adequate mental
health support during critical situations. To address this, we present a
non-invasive, speech-based approach for automatic suicide risk assessment. For
our study, we collected a novel speech recording dataset from $20$ patients. We
extract three sets of features, including wav2vec, interpretable speech and
acoustic features, and deep learning-based spectral representations. We proceed
by conducting a binary classification to assess suicide risk in a
leave-one-subject-out fashion. Our most effective speech model achieves a
balanced accuracy of $66.2\,\%$. Moreover, we show that integrating our speech
model with a series of patients' metadata, such as the history of suicide
attempts or access to firearms, improves the overall result. The metadata
integration yields a balanced accuracy of $94.4\,\%$, marking an absolute
improvement of $28.2\,\%$, demonstrating the efficacy of our proposed
approaches for automatic suicide risk assessment in emergency medicine.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ NeRAF: 3D Scene Infused Neural Radiance and Acoustic Fields 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.18213v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.18213v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amandine Brunetto, Sascha Hornauer, Fabien Moutarde
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sound plays a major role in human perception. Along with vision, it provides
essential information for understanding our surroundings. Despite advances in
neural implicit representations, learning acoustics that align with visual
scenes remains a challenge. We propose NeRAF, a method that jointly learns
acoustic and radiance fields. NeRAF synthesizes both novel views and
spatialized room impulse responses (RIR) at new positions by conditioning the
acoustic field on 3D scene geometric and appearance priors from the radiance
field. The generated RIR can be applied to auralize any audio signal. Each
modality can be rendered independently and at spatially distinct positions,
offering greater versatility. We demonstrate that NeRAF generates high-quality
audio on SoundSpaces and RAF datasets, achieving significant performance
improvements over prior methods while being more data-efficient. Additionally,
NeRAF enhances novel view synthesis of complex scenes trained with sparse data
through cross-modal learning. NeRAF is designed as a Nerfstudio module,
providing convenient access to realistic audio-visual generation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project Page: https://amandinebtto.github.io/NeRAF</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Machine listening in a neonatal intensive care unit 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.11439v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.11439v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Modan Tailleur, Vincent Lostanlen, Jean-Philippe Rivière, Pierre Aumond
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Oxygenators, alarm devices, and footsteps are some of the most common sound
sources in a hospital. Detecting them has scientific value for environmental
psychology but comes with challenges of its own: namely, privacy preservation
and limited labeled data. In this paper, we address these two challenges via a
combination of edge computing and cloud computing. For privacy preservation, we
have designed an acoustic sensor which computes third-octave spectrograms on
the fly instead of recording audio waveforms. For sample-efficient machine
learning, we have repurposed a pretrained audio neural network (PANN) via
spectral transcoding and label space adaptation. A small-scale study in a
neonatological intensive care unit (NICU) confirms that the time series of
detected events align with another modality of measurement: i.e., electronic
badges for parents and healthcare professionals. Hence, this paper demonstrates
the feasibility of polyphonic machine listening in a hospital ward while
guaranteeing privacy by design.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards a Universal Method for Meaningful Signal Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.00016v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.00016v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Louis Mahon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  It is known that human speech and certain animal vocalizations can convey
meaningful content because we can decipher the content that a given utterance
does convey. This paper explores an alternative approach to determining whether
a signal is meaningful, one that analyzes only the signal itself and is
independent of what the conveyed meaning might be. We devise a method that
takes a waveform as input and outputs a score indicating its degree of
`meaningfulness`. We cluster contiguous portions of the input to minimize the
total description length, and then take the length of the code of the assigned
cluster labels as meaningfulness score. We evaluate our method empirically,
against several baselines, and show that it is the only one to give a high
score to human speech in various languages and with various speakers, a
moderate score to animal vocalizations from birds and orcas, and a low score to
ambient noise from various sources.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Few-Shot Learning Approach for Sound Source Distance Estimation Using
  Relation Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2109.10561v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2109.10561v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amirreza Sobhdel, Roozbeh Razavi-Far, Vasile Palade
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we study the performance of few-shot learning, specifically
meta learning empowered few-shot relation networks, over supervised deep
learning and conventional machine learning approaches in the problem of Sound
Source Distance Estimation (SSDE). In previous research on deep supervised
SSDE, low accuracies have often resulted from the mismatch between the training
data (from known environments) and the test data (from unknown environments).
By performing comparative experiments on a sufficient amount of data, we show
that the few-shot relation network outperforms other competitors including
eXtreme Gradient Boosting (XGBoost), Support Vector Machine (SVM),
Convolutional Neural Network (CNN), and MultiLayer Perceptron (MLP). Hence it
is possible to calibrate a microphone-equipped system, with a few labeled
samples of audio recorded in a particular unknown environment to adjust and
generalize our classifier to the possible input data and gain higher
accuracies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ IndicVoices-R: Unlocking a Massive Multilingual Multi-speaker Speech
  Corpus for Scaling Indian TTS <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05356v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05356v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ashwin Sankar, Srija Anand, Praveen Srinivasa Varadhan, Sherry Thomas, Mehak Singal, Shridhar Kumar, Deovrat Mehendale, Aditi Krishana, Giri Raju, Mitesh Khapra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in text-to-speech (TTS) synthesis show that large-scale
models trained with extensive web data produce highly natural-sounding output.
However, such data is scarce for Indian languages due to the lack of
high-quality, manually subtitled data on platforms like LibriVox or YouTube. To
address this gap, we enhance existing large-scale ASR datasets containing
natural conversations collected in low-quality environments to generate
high-quality TTS training data. Our pipeline leverages the cross-lingual
generalization of denoising and speech enhancement models trained on English
and applied to Indian languages. This results in IndicVoices-R (IV-R), the
largest multilingual Indian TTS dataset derived from an ASR dataset, with 1,704
hours of high-quality speech from 10,496 speakers across 22 Indian languages.
IV-R matches the quality of gold-standard TTS datasets like LJSpeech, LibriTTS,
and IndicTTS. We also introduce the IV-R Benchmark, the first to assess
zero-shot, few-shot, and many-shot speaker generalization capabilities of TTS
models on Indian voices, ensuring diversity in age, gender, and style. We
demonstrate that fine-tuning an English pre-trained model on a combined dataset
of high-quality IndicTTS and our IV-R dataset results in better zero-shot
speaker generalization compared to fine-tuning on the IndicTTS dataset alone.
Further, our evaluation reveals limited zero-shot generalization for Indian
voices in TTS models trained on prior datasets, which we improve by fine-tuning
the model on our data containing diverse set of speakers across language
families. We open-source all data and code, releasing the first TTS model for
all 22 official Indian languages.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to NeurIPS 2024 Datasets and Benchmarks track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RFWave: Multi-band Rectified Flow for Audio Waveform Reconstruction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.05010v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.05010v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peng Liu, Dongyang Dai, Zhiyong Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in generative modeling have significantly enhanced the
reconstruction of audio waveforms from various representations. While diffusion
models are adept at this task, they are hindered by latency issues due to their
operation at the individual sample point level and the need for numerous
sampling steps. In this study, we introduce RFWave, a cutting-edge multi-band
Rectified Flow approach designed to reconstruct high-fidelity audio waveforms
from Mel-spectrograms or discrete acoustic tokens. RFWave uniquely generates
complex spectrograms and operates at the frame level, processing all subbands
simultaneously to boost efficiency. Leveraging Rectified Flow, which targets a
straight transport trajectory, RFWave achieves reconstruction with just 10
sampling steps. Our empirical evaluations show that RFWave not only provides
outstanding reconstruction quality but also offers vastly superior
computational efficiency, enabling audio generation at speeds up to 160 times
faster than real-time on a GPU. An online demonstration is available at:
https://rfwave-demo.github.io/rfwave/.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Speech Processing <span class="chip" style="font-size: 60%">22</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Presto! Distilling Steps and Layers for Accelerating Music Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05167v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05167v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zachary Novack, Ge Zhu, Jonah Casebeer, Julian McAuley, Taylor Berg-Kirkpatrick, Nicholas J. Bryan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite advances in diffusion-based text-to-music (TTM) methods, efficient,
high-quality generation remains a challenge. We introduce Presto!, an approach
to inference acceleration for score-based diffusion transformers via reducing
both sampling steps and cost per step. To reduce steps, we develop a new
score-based distribution matching distillation (DMD) method for the EDM-family
of diffusion models, the first GAN-based distillation method for TTM. To reduce
the cost per step, we develop a simple, but powerful improvement to a recent
layer distillation method that improves learning via better preserving hidden
state variance. Finally, we combine our step and layer distillation methods
together for a dual-faceted approach. We evaluate our step and layer
distillation methods independently and show each yield best-in-class
performance. Our combined distillation method can generate high-quality outputs
with improved diversity, accelerating our base model by 10-18x (230/435ms
latency for 32 second mono/stereo 44.1kHz, 15x faster than comparable SOTA) --
the fastest high-quality TTM to our knowledge. Sound examples can be found at
https://presto-music.github.io/web/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Editing Music with Melody and Text: Using ControlNet for Diffusion
  <span class="highlight-title">Transformer</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05151v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05151v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siyuan Hou, Shansong Liu, Ruibin Yuan, Wei Xue, Ying Shan, Mangsuo Zhao, Chao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the significant progress in controllable music generation and
editing, challenges remain in the quality and length of generated music due to
the use of Mel-spectrogram representations and UNet-based model structures. To
address these limitations, we propose a novel approach using a Diffusion
Transformer (DiT) augmented with an additional control branch using ControlNet.
This allows for long-form and variable-length music generation and editing
controlled by text and melody prompts. For more precise and fine-grained melody
control, we introduce a novel top-$k$ constant-Q Transform representation as
the melody prompt, reducing ambiguity compared to previous representations
(e.g., chroma), particularly for music with multiple tracks or a wide range of
pitch values. To effectively balance the control signals from text and melody
prompts, we adopt a curriculum learning strategy that progressively masks the
melody prompt, resulting in a more stable training process. Experiments have
been performed on text-to-music generation and music-style transfer tasks using
open-source instrumental recording data. The results demonstrate that by
extending StableAudio, a pre-trained text-controlled DiT model, our approach
enables superior melody-controlled editing while retaining good text-to-music
generation performance. These results outperform a strong MusicGen baseline in
terms of both text-based generation and melody preservation for editing. Audio
examples can be found at https://stable-audio-control.github.io/web/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CTC-GMM: CTC guided modality matching for fast and accurate streaming
  speech translation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05146v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05146v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Zhao, Jinyu Li, Ruchao Fan, Matt Post
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Models for streaming speech translation (ST) can achieve high accuracy and
low latency if they're developed with vast amounts of paired audio in the
source language and written text in the target language. Yet, these text labels
for the target language are often pseudo labels due to the prohibitive cost of
manual ST data labeling. In this paper, we introduce a methodology named
Connectionist Temporal Classification guided modality matching (CTC-GMM) that
enhances the streaming ST model by leveraging extensive machine translation
(MT) text data. This technique employs CTC to compress the speech sequence into
a compact embedding sequence that matches the corresponding text sequence,
allowing us to utilize matched {source-target} language text pairs from the MT
corpora to refine the streaming ST model further. Our evaluations with FLEURS
and CoVoST2 show that the CTC-GMM approach can increase translation accuracy
relatively by 13.9% and 6.4% respectively, while also boosting decoding speed
by 59.7% on GPU.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IEEE Spoken Language Technology Workshop (SLT 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CR-CTC: Consistency regularization on CTC for improved speech
  recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05101v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05101v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zengwei Yao, Wei Kang, Xiaoyu Yang, Fangjun Kuang, Liyong Guo, Han Zhu, Zengrui Jin, Zhaoqing Li, Long Lin, Daniel Povey
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Connectionist Temporal Classification (CTC) is a widely used method for
automatic speech recognition (ASR), renowned for its simplicity and
computational efficiency. However, it often falls short in recognition
performance compared to transducer or systems combining CTC and attention-based
encoder-decoder (CTC/AED). In this work, we propose the Consistency-Regularized
CTC (CR-CTC), which enforces consistency between two CTC distributions obtained
from different augmented views of the input speech mel-spectrogram. We provide
in-depth insights into its essential behaviors from three perspectives: 1) it
conducts self-distillation between random pairs of sub-models that process
different augmented views; 2) it learns contextual representation through
masked prediction for positions within time-masked regions, especially when we
increase the amount of time masking; 3) it suppresses the extremely peaky CTC
distributions, thereby reducing overfitting and improving the generalization
ability. Extensive experiments on LibriSpeech, Aishell-1, and GigaSpeech
datasets demonstrate the effectiveness of our CR-CTC, which achieves
performance comparable to, or even slightly better than, that of transducer and
CTC/AED.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving Speaker Representations Using Contrastive Losses on
  Multi-scale Features 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05037v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05037v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Satvik Dixit, Massa Baali, Rita Singh, Bhiksha Raj
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Speaker verification systems have seen significant advancements with the
introduction of Multi-scale Feature Aggregation (MFA) architectures, such as
MFA-Conformer and ECAPA-TDNN. These models leverage information from various
network depths by concatenating intermediate feature maps before the pooling
and projection layers, demonstrating that even shallower feature maps encode
valuable speaker-specific information. Building upon this foundation, we
propose a Multi-scale Feature Contrastive (MFCon) loss that directly enhances
the quality of these intermediate representations. Our MFCon loss applies
contrastive learning to all feature maps within the network, encouraging the
model to learn more discriminative representations at the intermediate stage
itself. By enforcing better feature map learning, we show that the resulting
speaker embeddings exhibit increased discriminative power. Our method achieves
a 9.05% improvement in equal error rate (EER) compared to the standard
MFA-Conformer on the VoxCeleb-1O test set.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RelUNet: Relative Channel Fusion U-Net for Multichannel Speech
  Enhancement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05019v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05019v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ibrahim Aldarmaki, Thamar Solorio, Bhiksha Raj, Hanan Aldarmaki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural multi-channel speech enhancement models, in particular those based on
the U-Net architecture, demonstrate promising performance and generalization
potential. These models typically encode input channels independently, and
integrate the channels during later stages of the network. In this paper, we
propose a novel modification of these models by incorporating relative
information from the outset, where each channel is processed in conjunction
with a reference channel through stacking. This input strategy exploits
comparative differences to adaptively fuse information between channels,
thereby capturing crucial spatial information and enhancing the overall
performance. The experiments conducted on the CHiME-3 dataset demonstrate
improvements in speech enhancement metrics across various architectures.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Stage-Wise and Prior-Aware Neural Speech Phase Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04990v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04990v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fei Liu, Yang Ai, Hui-Peng Du, Ye-Xin Lu, Rui-Chen Zheng, Zhen-Hua Ling
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes a novel Stage-wise and Prior-aware Neural Speech Phase
Prediction (SP-NSPP) model, which predicts the phase spectrum from input
amplitude spectrum by two-stage neural networks. In the initial
prior-construction stage, we preliminarily predict a rough prior phase spectrum
from the amplitude spectrum. The subsequent refinement stage transforms the
amplitude spectrum into a refined high-quality phase spectrum conditioned on
the prior phase. Networks in both stages use ConvNeXt v2 blocks as the backbone
and adopt adversarial training by innovatively introducing a phase spectrum
discriminator (PSD). To further improve the continuity of the refined phase, we
also incorporate a time-frequency integrated difference (TFID) loss in the
refinement stage. Experimental results confirm that, compared to neural
network-based no-prior phase prediction methods, the proposed SP-NSPP achieves
higher phase prediction accuracy, thanks to introducing the coarse phase priors
and diverse training criteria. Compared to iterative phase estimation
algorithms, our proposed SP-NSPP does not require multiple rounds of staged
iterations, resulting in higher generation efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by SLT2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A decade of DCASE: Achievements, practices, evaluations and future
  challenges <span class="chip">ICASSP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04951v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04951v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Annamaria Mesaros, Romain Serizel, Toni Heittola, Tuomas Virtanen, Mark D. Plumbley
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces briefly the history and growth of the Detection and
Classification of Acoustic Scenes and Events (DCASE) challenge, workshop,
research area and research community. Created in 2013 as a data evaluation
challenge, DCASE has become a major research topic in the Audio and Acoustic
Signal Processing area. Its success comes from a combination of factors: the
challenge offers a large variety of tasks that are renewed each year; and the
workshop offers a channel for dissemination of related work, engaging a young
and dynamic community. At the same time, DCASE faces its own challenges,
growing and expanding to different areas. One of the core principles of DCASE
is open science and reproducibility: publicly available datasets, baseline
systems, technical reports and workshop publications. While the DCASE challenge
and workshop are independent of IEEE SPS, the challenge receives annual
endorsement from the AASP TC, and the DCASE community contributes significantly
to the ICASSP flagship conference and the success of SPS in many of its
activities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to ICASSP 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Art2Mus: Bridging Visual Arts and Music through Cross-Modal Generation <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04906v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04906v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ivan Rinaldi, Nicola Fanelli, Giovanna Castellano, Gennaro Vessio
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Artificial Intelligence and generative models have revolutionized music
creation, with many models leveraging textual or visual prompts for guidance.
However, existing image-to-music models are limited to simple images, lacking
the capability to generate music from complex digitized artworks. To address
this gap, we introduce $\mathcal{A}\textit{rt2}\mathcal{M}\textit{us}$, a novel
model designed to create music from digitized artworks or text inputs.
$\mathcal{A}\textit{rt2}\mathcal{M}\textit{us}$ extends the AudioLDM~2
architecture, a text-to-audio model, and employs our newly curated datasets,
created via ImageBind, which pair digitized artworks with music. Experimental
results demonstrate that $\mathcal{A}\textit{rt2}\mathcal{M}\textit{us}$ can
generate music that resonates with the input stimuli. These findings suggest
promising applications in multimedia art, interactive installations, and
AI-driven creative tools.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Presented at the AI for Visual Arts (AI4VA) workshop at ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Attentive-based Multi-level Feature Fusion for Voice Disorder Diagnosis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04797v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04797v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lipeng Shen, Yifan Xiong, Dongyue Guo, Wei Mo, Lingyu Yu, Hui Yang, Yi Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Voice disorders negatively impact the quality of daily life in various ways.
However, accurately recognizing the category of pathological features from raw
audio remains a considerable challenge due to the limited dataset. A promising
method to handle this issue is extracting multi-level pathological information
from speech in a comprehensive manner by fusing features in the latent space.
In this paper, a novel framework is designed to explore the way of high-quality
feature fusion for effective and generalized detection performance.
Specifically, the proposed model follows a two-stage training paradigm: (1)
ECAPA-TDNN and Wav2vec 2.0 which have shown remarkable effectiveness in various
domains are employed to learn the universal pathological information from raw
audio; (2) An attentive fusion module is dedicatedly designed to establish the
interaction between pathological features projected by EcapTdnn and Wav2vec 2.0
respectively and guide the multi-layer fusion, the entire model is jointly
fine-tuned from pre-trained features by the automatic voice pathology detection
task. Finally, comprehensive experiments on the FEMH and SVD datasets
demonstrate that the proposed framework outperforms the competitive baselines,
and achieves the accuracy of 90.51% and 87.68%.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Ultra-Low-Power Neuromorphic Speech Enhancement with
  Spiking-FullSubNet 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04785v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04785v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiang Hao, Chenxiang Ma, Qu Yang, Jibin Wu, Kay Chen Tan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Speech enhancement is critical for improving speech intelligibility and
quality in various audio devices. In recent years, deep learning-based methods
have significantly improved speech enhancement performance, but they often come
with a high computational cost, which is prohibitive for a large number of edge
devices, such as headsets and hearing aids. This work proposes an
ultra-low-power speech enhancement system based on the brain-inspired spiking
neural network (SNN) called Spiking-FullSubNet. Spiking-FullSubNet follows a
full-band and sub-band fusioned approach to effectively capture both global and
local spectral information. To enhance the efficiency of computationally
expensive sub-band modeling, we introduce a frequency partitioning method
inspired by the sensitivity profile of the human peripheral auditory system.
Furthermore, we introduce a novel spiking neuron model that can dynamically
control the input information integration and forgetting, enhancing the
multi-scale temporal processing capability of SNN, which is critical for speech
denoising. Experiments conducted on the recent Intel Neuromorphic Deep Noise
Suppression (N-DNS) Challenge dataset show that the Spiking-FullSubNet
surpasses state-of-the-art methods by large margins in terms of both speech
quality and energy efficiency metrics. Notably, our system won the championship
of the Intel N-DNS Challenge (Algorithmic Track), opening up a myriad of
opportunities for ultra-low-power speech enhancement at the edge. Our source
code and model checkpoints are publicly available at
https://github.com/haoxiangsnr/spiking-fullsubnet.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Modeling and Estimation of Vocal Tract and Glottal Source Parameters
  Using ARMAX-LF Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04704v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04704v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kai Lia, Masato Akagia, Yongwei Lib, Masashi Unokia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modeling and estimation of the vocal tract and glottal source parameters of
vowels from raw speech can be typically done by using the Auto-Regressive with
eXogenous input (ARX) model and Liljencrants-Fant (LF) model with an
iteration-based estimation approach. However, the all-pole autoregressive model
in the modeling of vocal tract filters cannot provide the locations of
anti-formants (zeros), which increases the estimation errors in certain classes
of speech sounds, such as nasal, fricative, and stop consonants. In this paper,
we propose the Auto-Regressive Moving Average eXogenous with LF (ARMAX-LF)
model to extend the ARX-LF model to a wider variety of speech sounds, including
vowels and nasalized consonants. The LF model represents the glottal source
derivative as a parametrized time-domain model, and the ARMAX model represents
the vocal tract as a pole-zero filter with an additional exogenous LF
excitation as input. To estimate multiple parameters with fewer errors, we
first utilize the powerful nonlinear fitting ability of deep neural networks
(DNNs) to build a mapping from extracted glottal source derivatives or speech
waveforms to corresponding LF parameters. Then, glottal source and vocal tract
parameters can be estimated with fewer estimation errors and without any
iterations as in the analysis-by-synthesis strategy. Experimental results with
synthesized speech using the linear source-filter model, synthesized speech
using the physical model, and real speech signals showed that the proposed
ARMAX-LF model with a DNN-based estimation method can estimate the parameters
of both vowels and nasalized sounds with fewer errors and estimation time.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Demo of Zero-Shot Guitar Amplifier Modelling: Enhancing Modeling with
  Hyper Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04702v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04702v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu-Hua Chen, Yuan-Chiao Cheng, Yen-Tung Yeh, Jui-Te Wu, Yu-Hsiang Ho, Jyh-Shing Roger Jang, Yi-Hsuan Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Electric guitar tone modeling typically focuses on the non-linear
transformation from clean to amplifier-rendered audio. Traditional methods rely
on one-to-one mappings, incorporating device parameters into neural models to
replicate specific amplifiers. However, these methods are limited by the need
for specific training data. In this paper, we adapt a model based on the
previous work, which leverages a tone embedding encoder and a feature wise
linear modulation (FiLM) condition method. In this work, we altered
conditioning method using a hypernetwork-based gated convolutional network
(GCN) to generate audio that blends clean input with the tone characteristics
of reference audio. By extending the training data to cover a wider variety of
amplifier tones, our model is able to capture a broader range of tones.
Additionally, we developed a real-time plugin to demonstrate the system's
practical application, allowing users to experience its performance
interactively. Our results indicate that the proposed system achieves superior
tone modeling versatility compared to traditional methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>demo of the ISMIR paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SegINR: Segment-wise Implicit Neural Representation for Sequence
  Alignment in Neural Text-to-Speech 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04690v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04690v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minchan Kim, Myeonghun Jeong, Joun Yeop Lee, Nam Soo Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present SegINR, a novel approach to neural Text-to-Speech (TTS) that
addresses sequence alignment without relying on an auxiliary duration predictor
and complex autoregressive (AR) or non-autoregressive (NAR) frame-level
sequence modeling. SegINR simplifies the process by converting text sequences
directly into frame-level features. It leverages an optimal text encoder to
extract embeddings, transforming each into a segment of frame-level features
using a conditional implicit neural representation (INR). This method, named
segment-wise INR (SegINR), models temporal dynamics within each segment and
autonomously defines segment boundaries, reducing computational costs. We
integrate SegINR into a two-stage TTS framework, using it for semantic token
prediction. Our experiments in zero-shot adaptive TTS scenarios demonstrate
that SegINR outperforms conventional methods in speech quality with
computational efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Non-Invasive Suicide Risk Prediction Through Speech Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.12132v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.12132v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shahin Amiriparian, Maurice Gerczuk, Justina Lutz, Wolfgang Strube, Irina Papazova, Alkomiet Hasan, Alexander Kathan, Björn W. Schuller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The delayed access to specialized psychiatric assessments and care for
patients at risk of suicidal tendencies in emergency departments creates a
notable gap in timely intervention, hindering the provision of adequate mental
health support during critical situations. To address this, we present a
non-invasive, speech-based approach for automatic suicide risk assessment. For
our study, we collected a novel speech recording dataset from $20$ patients. We
extract three sets of features, including wav2vec, interpretable speech and
acoustic features, and deep learning-based spectral representations. We proceed
by conducting a binary classification to assess suicide risk in a
leave-one-subject-out fashion. Our most effective speech model achieves a
balanced accuracy of $66.2\,\%$. Moreover, we show that integrating our speech
model with a series of patients' metadata, such as the history of suicide
attempts or access to firearms, improves the overall result. The metadata
integration yields a balanced accuracy of $94.4\,\%$, marking an absolute
improvement of $28.2\,\%$, demonstrating the efficacy of our proposed
approaches for automatic suicide risk assessment in emergency medicine.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving Robustness and Clinical Applicability of Automatic Respiratory
  Sound Classification Using Deep Learning-Based Audio Enhancement: Algorithm
  Development and Validation Study <span class="chip">SC</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13895v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13895v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jing-Tong Tzeng, Jeng-Lin Li, Huan-Yu Chen, Chun-Hsiang Huang, Chi-Hsin Chen, Cheng-Yi Fan, Edward Pei-Chuan Huang, Chi-Chun Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep learning techniques have shown promising results in the automatic
classification of respiratory sounds. However, accurately distinguishing these
sounds in real-world noisy conditions poses challenges for clinical deployment.
Additionally, predicting signals with only background noise could undermine
user trust in the system. This paper aims to investigate the feasibility and
effectiveness of incorporating a deep learning-based audio enhancement
preprocessing step into automatic respiratory sound classification systems to
improve robustness and clinical applicability. Multiple experiments were
conducted using different audio enhancement model structures and classification
models. The classification performance was compared to the baseline method of
noise injection data augmentation. Experiments were performed on two datasets:
the ICBHI respiratory sound dataset, which includes 5.5 hours of recordings,
and the Formosa Archive of Breath Sounds (FABS) dataset, comprising 14.6 hours
of recordings. Additionally, a physician validation study was conducted by 7
senior physicians to assess the clinical utility of the system.The integration
of the audio enhancement pipeline resulted in a 21.88% increase in the ICBHI
classification score on the ICBHI dataset and a 4.10% improvement on the FABS
dataset in multi-class noisy scenarios. Quantitative analysis from the
physician validation study revealed improvements in efficiency, diagnostic
confidence, and trust during model-assisted diagnosis, with workflows
integrating enhanced audio leading to an 11.61% increase in diagnostic
sensitivity and facilitating high-confidence diagnoses. Incorporating an audio
enhancement algorithm significantly enhances the robustness and clinical
utility of automatic respiratory sound classification systems, improving
performance in noisy environments and fostering greater trust among medical
professionals.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Demo website: https://rogertzeng.github.io/ReSC-AE/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ NeRAF: 3D Scene Infused Neural Radiance and Acoustic Fields 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.18213v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.18213v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amandine Brunetto, Sascha Hornauer, Fabien Moutarde
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sound plays a major role in human perception. Along with vision, it provides
essential information for understanding our surroundings. Despite advances in
neural implicit representations, learning acoustics that align with visual
scenes remains a challenge. We propose NeRAF, a method that jointly learns
acoustic and radiance fields. NeRAF synthesizes both novel views and
spatialized room impulse responses (RIR) at new positions by conditioning the
acoustic field on 3D scene geometric and appearance priors from the radiance
field. The generated RIR can be applied to auralize any audio signal. Each
modality can be rendered independently and at spatially distinct positions,
offering greater versatility. We demonstrate that NeRAF generates high-quality
audio on SoundSpaces and RAF datasets, achieving significant performance
improvements over prior methods while being more data-efficient. Additionally,
NeRAF enhances novel view synthesis of complex scenes trained with sparse data
through cross-modal learning. NeRAF is designed as a Nerfstudio module,
providing convenient access to realistic audio-visual generation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project Page: https://amandinebtto.github.io/NeRAF</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Machine listening in a neonatal intensive care unit 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.11439v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.11439v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Modan Tailleur, Vincent Lostanlen, Jean-Philippe Rivière, Pierre Aumond
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Oxygenators, alarm devices, and footsteps are some of the most common sound
sources in a hospital. Detecting them has scientific value for environmental
psychology but comes with challenges of its own: namely, privacy preservation
and limited labeled data. In this paper, we address these two challenges via a
combination of edge computing and cloud computing. For privacy preservation, we
have designed an acoustic sensor which computes third-octave spectrograms on
the fly instead of recording audio waveforms. For sample-efficient machine
learning, we have repurposed a pretrained audio neural network (PANN) via
spectral transcoding and label space adaptation. A small-scale study in a
neonatological intensive care unit (NICU) confirms that the time series of
detected events align with another modality of measurement: i.e., electronic
badges for parents and healthcare professionals. Hence, this paper demonstrates
the feasibility of polyphonic machine listening in a hospital ward while
guaranteeing privacy by design.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards a Universal Method for Meaningful Signal Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.00016v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.00016v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Louis Mahon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  It is known that human speech and certain animal vocalizations can convey
meaningful content because we can decipher the content that a given utterance
does convey. This paper explores an alternative approach to determining whether
a signal is meaningful, one that analyzes only the signal itself and is
independent of what the conveyed meaning might be. We devise a method that
takes a waveform as input and outputs a score indicating its degree of
`meaningfulness`. We cluster contiguous portions of the input to minimize the
total description length, and then take the length of the code of the assigned
cluster labels as meaningfulness score. We evaluate our method empirically,
against several baselines, and show that it is the only one to give a high
score to human speech in various languages and with various speakers, a
moderate score to animal vocalizations from birds and orcas, and a low score to
ambient noise from various sources.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Few-Shot Learning Approach for Sound Source Distance Estimation Using
  Relation Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2109.10561v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2109.10561v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amirreza Sobhdel, Roozbeh Razavi-Far, Vasile Palade
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we study the performance of few-shot learning, specifically
meta learning empowered few-shot relation networks, over supervised deep
learning and conventional machine learning approaches in the problem of Sound
Source Distance Estimation (SSDE). In previous research on deep supervised
SSDE, low accuracies have often resulted from the mismatch between the training
data (from known environments) and the test data (from unknown environments).
By performing comparative experiments on a sufficient amount of data, we show
that the few-shot relation network outperforms other competitors including
eXtreme Gradient Boosting (XGBoost), Support Vector Machine (SVM),
Convolutional Neural Network (CNN), and MultiLayer Perceptron (MLP). Hence it
is possible to calibrate a microphone-equipped system, with a few labeled
samples of audio recorded in a particular unknown environment to adjust and
generalize our classifier to the possible input data and gain higher
accuracies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Typing to Listen at the Cocktail Party: Text-Guided Target Speaker
  Extraction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.07284v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.07284v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiang Hao, Jibin Wu, Jianwei Yu, Chenglin Xu, Kay Chen Tan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Humans can easily isolate a single speaker from a complex acoustic
environment, a capability referred to as the "Cocktail Party Effect." However,
replicating this ability has been a significant challenge in the field of
target speaker extraction (TSE). Traditional TSE approaches predominantly rely
on voiceprints, which raise privacy concerns and face issues related to the
quality and availability of enrollment samples, as well as intra-speaker
variability. To address these issues, this work introduces a novel text-guided
TSE paradigm named LLM-TSE. In this paradigm, a state-of-the-art large language
model, LLaMA 2, processes typed text input from users to extract semantic cues.
We demonstrate that textual descriptions alone can effectively serve as cues
for extraction, thus addressing privacy concerns and reducing dependency on
voiceprints. Furthermore, our approach offers flexibility by allowing the user
to specify the extraction or suppression of a speaker and enhances robustness
against intra-speaker variability by incorporating context-dependent textual
information. Experimental results show competitive performance with text-based
cues alone and demonstrate the effectiveness of using text as a task selector.
Additionally, they achieve a new state-of-the-art when combining text-based
cues with pre-registered cues. This work represents the first integration of
LLMs with TSE, potentially establishing a new benchmark in solving the cocktail
party problem and expanding the scope of TSE applications by providing a
versatile, privacy-conscious solution.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review, https://github.com/haoxiangsnr/llm-tse</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RFWave: Multi-band Rectified Flow for Audio Waveform Reconstruction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.05010v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.05010v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peng Liu, Dongyang Dai, Zhiyong Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in generative modeling have significantly enhanced the
reconstruction of audio waveforms from various representations. While diffusion
models are adept at this task, they are hindered by latency issues due to their
operation at the individual sample point level and the need for numerous
sampling steps. In this study, we introduce RFWave, a cutting-edge multi-band
Rectified Flow approach designed to reconstruct high-fidelity audio waveforms
from Mel-spectrograms or discrete acoustic tokens. RFWave uniquely generates
complex spectrograms and operates at the frame level, processing all subbands
simultaneously to boost efficiency. Leveraging Rectified Flow, which targets a
straight transport trajectory, RFWave achieves reconstruction with just 10
sampling steps. Our empirical evaluations show that RFWave not only provides
outstanding reconstruction quality but also offers vastly superior
computational efficiency, enabling audio generation at speeds up to 160 times
faster than real-time on a GPU. An online demonstration is available at:
https://rfwave-demo.github.io/rfwave/.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-10-06T00:00:00Z">2024-10-06</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language <span class="chip" style="font-size: 60%">8</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Cross-Lingual Meta-Learning Method Based on Domain Adaptation for
  Speech Emotion Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04633v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04633v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David-Gabriel Ion, Răzvan-Alexandru Smădu, Dumitru-Clementin Cercel, Florin Pop, Mihaela-Claudia Cercel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Best-performing speech models are trained on large amounts of data in the
language they are meant to work for. However, most languages have sparse data,
making training models challenging. This shortage of data is even more
prevalent in speech emotion recognition. Our work explores the model's
performance in limited data, specifically for speech emotion recognition.
Meta-learning specializes in improving the few-shot learning. As a result, we
employ meta-learning techniques on speech emotion recognition tasks, accent
recognition, and person identification. To this end, we propose a series of
improvements over the multistage meta-learning method. Unlike other works
focusing on smaller models due to the high computational cost of meta-learning
algorithms, we take a more practical approach. We incorporate a large
pre-trained backbone and a prototypical network, making our methods more
feasible and applicable. Our most notable contribution is an improved
fine-tuning technique during meta-testing that significantly boosts the
performance on out-of-distribution datasets. This result, together with
incremental improvements from several other works, helped us achieve accuracy
scores of 83.78% and 56.30% for Greek and Romanian speech emotion recognition
datasets not included in the training or validation splits in the context of
4-way 5-shot learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 1 figure, Accepted by WISE 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Survey</span> of Query-based Text Summarization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2211.11548v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2211.11548v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hang Yu, Jiawei Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Query-based text summarization is an important real world problem that
requires to condense the prolix text data into a summary under the guidance of
the query information provided by users. The topic has been studied for a long
time and there are many existing interesting research related to query-based
text summarization. Yet much of the work is not systematically surveyed. This
survey aims at summarizing some interesting work in query-based text
summarization methods as well as related generic text summarization methods.
Not all taxonomies in this paper exist the related work to the best of our
knowledge and some analysis will be presented.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Prompt</span>s have evil twins <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.07064v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.07064v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rimon Melamed, Lucas H. McCabe, Tanay Wakhare, Yejin Kim, H. Howie Huang, Enric Boix-Adsera
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We discover that many natural-language prompts can be replaced by
corresponding prompts that are unintelligible to humans but that provably
elicit similar behavior in language models. We call these prompts "evil twins"
because they are obfuscated and uninterpretable (evil), but at the same time
mimic the functionality of the original natural-language prompts (twins).
Remarkably, evil twins transfer between models. We find these prompts by
solving a maximum-likelihood problem which has applications of independent
interest.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Main, camera-ready</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ An Adversarial Perspective on Machine Unlearning for AI Safety 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18025v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18025v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jakub Łucki, Boyi Wei, Yangsibo Huang, Peter Henderson, Florian Tramèr, Javier Rando
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models are finetuned to refuse questions about hazardous
knowledge, but these protections can often be bypassed. Unlearning methods aim
at completely removing hazardous capabilities from models and make them
inaccessible to adversaries. This work challenges the fundamental differences
between unlearning and traditional safety post-training from an adversarial
perspective. We demonstrate that existing jailbreak methods, previously
reported as ineffective against unlearning, can be successful when applied
carefully. Furthermore, we develop a variety of adaptive methods that recover
most supposedly unlearned capabilities. For instance, we show that finetuning
on 10 unrelated examples or removing specific directions in the activation
space can recover most hazardous capabilities for models edited with RMU, a
state-of-the-art unlearning method. Our findings challenge the robustness of
current unlearning approaches and question their advantages over safety
training.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On Efficient Language and Vision Assistants for Visually-Situated
  Natural Language Understanding: What Matters in Reading and Reasoning <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11823v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11823v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Geewook Kim, Minjoon Seo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in language and vision assistants have showcased
impressive capabilities but suffer from a lack of transparency, limiting
broader research and reproducibility. While open-source models handle general
image tasks effectively, they face challenges with the high computational
demands of complex visually-situated text understanding. Such tasks often
require increased token inputs and large vision modules to harness
high-resolution information. Striking a balance between model size and data
importance remains an open question. This study aims to redefine the design of
vision-language models by identifying key components and creating efficient
models with constrained inference costs. By strategically formulating datasets,
optimizing vision modules, and enhancing supervision techniques, we achieve
significant improvements in inference throughput while maintaining high
performance. Extensive experiments across models ranging from 160M to 13B
parameters offer insights into model optimization. We will fully open-source
our codebase, models, and datasets at https://github.com/naver-ai/elva.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Cybench: A Framework for Evaluating Cybersecurity Capabilities and Risks
  of Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.08926v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.08926v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andy K. Zhang, Neil Perry, Riya Dulepet, Joey Ji, Justin W. Lin, Eliot Jones, Celeste Menders, Gashon Hussein, Samantha Liu, Donovan Jasper, Pura Peetathawatchai, Ari Glenn, Vikram Sivashankar, Daniel Zamoshchin, Leo Glikbarg, Derek Askaryar, Mike Yang, Teddy Zhang, Rishi Alluri, Nathan Tran, Rinnara Sangpisit, Polycarpos Yiorkadjis, Kenny Osele, Gautham Raghupathi, Dan Boneh, Daniel E. Ho, Percy Liang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language Model (LM) agents for cybersecurity that are capable of autonomously
identifying vulnerabilities and executing exploits have the potential to cause
real-world impact. Policymakers, model providers, and other researchers in the
AI and cybersecurity communities are interested in quantifying the capabilities
of such agents to help mitigate cyberrisk and investigate opportunities for
penetration testing. Toward that end, we introduce Cybench, a framework for
specifying cybersecurity tasks and evaluating agents on those tasks. We include
40 professional-level Capture the Flag (CTF) tasks from 4 distinct CTF
competitions, chosen to be recent, meaningful, and spanning a wide range of
difficulties. Each task includes its own description, starter files, and is
initialized in an environment where an agent can execute bash commands and
observe outputs. Since many tasks are beyond the capabilities of existing LM
agents, we introduce subtasks for each task, which break down a task into
intermediary steps for a more detailed evaluation. To evaluate agent
capabilities, we construct a cybersecurity agent and evaluate 8 models: GPT-4o,
OpenAI o1-preview, Claude 3 Opus, Claude 3.5 Sonnet, Mixtral 8x22b Instruct,
Gemini 1.5 Pro, Llama 3 70B Chat, and Llama 3.1 405B Instruct. Without subtask
guidance, agents leveraging Claude 3.5 Sonnet, GPT-4o, OpenAI o1-preview, and
Claude 3 Opus successfully solved complete tasks that took human teams up to 11
minutes to solve. In comparison, the most difficult task took human teams 24
hours and 54 minutes to solve. All code and data are publicly available at
https://cybench.github.io
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>78 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for
  Aligning Large Language Models to Online Communities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12074v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12074v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zihao He, Minh Duc Chu, Rebecca Dorn, Siyi Guo, Kristina Lerman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Social scientists use surveys to probe the opinions and beliefs of
populations, but these methods are slow, costly, and prone to biases. Recent
advances in large language models (LLMs) enable the creating of computational
representations or "digital twins" of populations that generate human-like
responses mimicking the population's language, styles, and attitudes. We
introduce Community-Cross-Instruct, an unsupervised framework for aligning LLMs
to online communities to elicit their beliefs. Given a corpus of a community's
online discussions, Community-Cross-Instruct automatically generates
instruction-output pairs by an advanced LLM to (1) finetune a foundational LLM
to faithfully represent that community, and (2) evaluate the alignment of the
finetuned model to the community. We demonstrate the method's utility in
accurately representing political and diet communities on Reddit. Unlike prior
methods requiring human-authored instructions, Community-Cross-Instruct
generates instructions in a fully unsupervised manner, enhancing scalability
and generalization across domains. This work enables cost-effective and
automated surveying of diverse online communities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Superposed Decoding: Multiple Generations from a Single Autoregressive
  Inference Pass 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.18400v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.18400v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ethan Shen, Alan Fan, Sarah M. Pratt, Jae Sung Park, Matthew Wallingford, Sham M. Kakade, Ari Holtzman, Ranjay Krishna, Ali Farhadi, Aditya Kusupati
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many applications today provide users with multiple auto-complete drafts as
they type, including GitHub's code completion, Gmail's smart compose, and
Apple's messaging auto-suggestions. Under the hood, language models support
this by running an autoregressive inference pass to provide a draft.
Consequently, providing $k$ drafts to the user requires running an expensive
language model $k$ times. To alleviate the computation cost of running $k$
inference passes, we propose Superposed Decoding, a new decoding algorithm that
generates $k$ drafts at the computation cost of one autoregressive inference
pass. We achieve this by feeding a superposition of the most recent token
embeddings from the $k$ drafts as input to the next decoding step of the
language model. At every inference step we combine the $k$ drafts with the
top-$k$ tokens to get $k^2$ new drafts and cache the $k$ most likely options,
using an n-gram interpolation with minimal compute overhead to filter out
incoherent generations. Our experiments show that $k$ drafts from Superposed
Decoding are at least as coherent and factual as Nucleus Sampling and Greedy
Decoding respectively, while being at least $2.44\times$ faster for $k\ge3$. In
a compute-normalized setting, user evaluations demonstrably favor text
generated by Superposed Decoding over Nucleus Sampling. Superposed Decoding can
also be combined with other decoding strategies, resulting in universal
coverage gains when scaling inference time compute. Code and more examples
open-sourced at https://github.com/RAIVNLab/SuperposedDecoding.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages, 16 figures</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Sound <span class="chip" style="font-size: 60%">9</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ UniMuMo: Unified Text, Music and Motion Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04534v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04534v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Han Yang, Kun Su, Yutong Zhang, Jiaben Chen, Kaizhi Qian, Gaowen Liu, Chuang Gan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce UniMuMo, a unified multimodal model capable of taking arbitrary
text, music, and motion data as input conditions to generate outputs across all
three modalities. To address the lack of time-synchronized data, we align
unpaired music and motion data based on rhythmic patterns to leverage existing
large-scale music-only and motion-only datasets. By converting music, motion,
and text into token-based representation, our model bridges these modalities
through a unified encoder-decoder transformer architecture. To support multiple
generation tasks within a single framework, we introduce several architectural
improvements. We propose encoding motion with a music codebook, mapping motion
into the same feature space as music. We introduce a music-motion parallel
generation scheme that unifies all music and motion generation tasks into a
single transformer decoder architecture with a single training task of
music-motion joint generation. Moreover, the model is designed by fine-tuning
existing pre-trained single-modality models, significantly reducing
computational demands. Extensive experiments demonstrate that UniMuMo achieves
competitive results on all unidirectional generation benchmarks across music,
motion, and text modalities. Quantitative results are available in the
\href{https://hanyangclarence.github.io/unimumo_demo/}{project page}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Configurable Multilingual ASR with Speech Summary Representations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04478v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04478v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Harrison Zhu, Ivan Fung, Yingke Zhu, Lahiru Samarakoon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Approximately half of the world's population is multilingual, making
multilingual ASR (MASR) essential. Deploying multiple monolingual models is
challenging when the ground-truth language is unknown in advance. This
motivates research efforts on configurable multilingual MASR models that can be
prompted manually or adapted automatically to recognise specific languages. In
this paper, we present the Configurable MASR model with Summary Vector
(csvMASR), a novel architecture designed to enhance configurability. Our
approach leverages adapters and introduces speech summary vector
representations, inspired by conversational summary representations in speech
diarization, to combine outputs from language-specific components at the
utterance level. We also incorporate an auxiliary language classification loss
to enhance configurability. Using data from 7 languages in the Multilingual
Librispeech (MLS) dataset, csvMASR outperforms existing MASR models and reduces
the word error rate (WER) from 10.33\% to 9.95\% when compared with the
baseline. Additionally, csvMASR demonstrates superior performance in language
classification and prompting tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>A preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SONAR: A Synthetic AI-Audio Detection Framework~and Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04324v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04324v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiang Li, Pin-Yu Chen, Wenqi Wei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in Text-to-Speech (TTS) and Voice-Conversion (VC) using
generative Artificial Intelligence (AI) technology have made it possible to
generate high-quality and realistic human-like audio. This introduces
significant challenges to distinguishing AI-synthesized speech from the
authentic human voice and could raise potential issues of misuse for malicious
purposes such as impersonation and fraud, spreading misinformation, deepfakes,
and scams. However, existing detection techniques for AI-synthesized audio have
not kept pace and often exhibit poor generalization across diverse datasets. In
this paper, we introduce SONAR, a synthetic AI-Audio Detection Framework and
Benchmark, aiming to provide a comprehensive evaluation for distinguishing
cutting-edge AI-synthesized auditory content. SONAR includes a novel evaluation
dataset sourced from 9 diverse audio synthesis platforms, including leading TTS
providers and state-of-the-art TTS models. It is the first framework to
uniformly benchmark AI-audio detection across both traditional and foundation
model-based deepfake detection systems. Through extensive experiments, we
reveal the generalization limitations of existing detection methods and
demonstrate that foundation models exhibit stronger generalization
capabilities, which can be attributed to their model size and the scale and
quality of pretraining data. Additionally, we explore the effectiveness and
efficiency of few-shot fine-tuning in improving generalization, highlighting
its potential for tailored applications, such as personalized detection systems
for specific entities or individuals. Code and dataset are available at
https://github.com/Jessegator/SONAR.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Content-based Controls For Music Large Language Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.17162v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.17162v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liwei Lin, Gus Xia, Junyan Jiang, Yixiao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent years have witnessed a rapid growth of large-scale language models in
the domain of music audio. Such models enable end-to-end generation of
higher-quality music, and some allow conditioned generation using text
descriptions. However, the control power of text controls on music is
intrinsically limited, as they can only describe music indirectly through
meta-data (such as singers and instruments) or high-level representations (such
as genre and emotion). We aim to further equip the models with direct and
content-based controls on innate music languages such as pitch, chords and drum
track. To this end, we contribute Coco-Mulla, a content-based control method
for music large language modeling. It uses a parameter-efficient fine-tuning
(PEFT) method tailored for Transformer-based audio models. Experiments show
that our approach achieved high-quality music generation with low-resource
semi-supervised learning, tuning with less than 4% parameters compared to the
original model and training on a small dataset with fewer than 300 songs.
Moreover, our approach enables effective content-based controls, and we
illustrate the control power via chords and rhythms, two of the most salient
features of music audio. Furthermore, we show that by combining content-based
controls and text descriptions, our system achieves flexible music variation
generation and arrangement. Our source codes and demos are available online.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Arrange, Inpaint, and Refine: Steerable Long-term Music Audio Generation
  and Editing via Content-based Controls 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.09508v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.09508v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liwei Lin, Gus Xia, Yixiao Zhang, Junyan Jiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Controllable music generation plays a vital role in human-AI music
co-creation. While Large Language Models (LLMs) have shown promise in
generating high-quality music, their focus on autoregressive generation limits
their utility in music editing tasks. To address this gap, we propose a novel
approach leveraging a parameter-efficient heterogeneous adapter combined with a
masking training scheme. This approach enables autoregressive language models
to seamlessly address music inpainting tasks. Additionally, our method
integrates frame-level content-based controls, facilitating track-conditioned
music refinement and score-conditioned music arrangement. We apply this method
to fine-tune MusicGen, a leading autoregressive music generation model. Our
experiments demonstrate promising results across multiple music editing tasks,
offering more flexible controls for future AI-driven music editing tools. The
source codes and a demo page showcasing our work are available at
https://kikyo-16.github.io/AIR.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unsupervised TTS Acoustic Modeling for TTS with Conditional Disentangled
  Sequential VAE 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2206.02512v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2206.02512v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiachen Lian, Chunlei Zhang, Gopala Krishna Anumanchipalli, Dong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose a novel unsupervised text-to-speech acoustic model
training scheme, named UTTS, which does not require text-audio pairs. UTTS is a
multi-speaker speech synthesizer that supports zero-shot voice cloning, it is
developed from a perspective of disentangled speech representation learning.
The framework offers a flexible choice of a speaker's duration model, timbre
feature (identity) and content for TTS inference. We leverage recent
advancements in self-supervised speech representation learning as well as
speech synthesis front-end techniques for system development. Specifically, we
employ our recently formulated Conditional Disentangled Sequential Variational
Auto-encoder (C-DSVAE) as the backbone UTTS AM, which offers well-structured
content representations given unsupervised alignment (UA) as condition during
training. For UTTS inference, we utilize a lexicon to map input text to the
phoneme sequence, which is expanded to the frame-level forced alignment (FA)
with a speaker-dependent duration model. Then, we develop an alignment mapping
module that converts FA to UA. Finally, the C-DSVAE, serving as the
self-supervised TTS AM, takes the predicted UA and a target speaker embedding
to generate the mel spectrogram, which is ultimately converted to waveform with
a neural vocoder. We show how our method enables speech synthesis without using
a paired TTS corpus in AM development stage. Experiments demonstrate that UTTS
can synthesize speech of high naturalness and intelligibility measured by human
and objective evaluations. Audio samples are available at our demo page
https://neurtts.github.io/utts\_demo/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>IEEE/ACM Transactions on Audio, Speech, and Language Processing (
  Volume: 31)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DDTSE: Discriminative Diffusion Model for Target Speech Extraction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.13874v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.13874v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Leying Zhang, Yao Qian, Linfeng Yu, Heming Wang, Hemin Yang, Long Zhou, Shujie Liu, Yanmin Qian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models have gained attention in speech enhancement tasks, providing
an alternative to conventional discriminative methods. However, research on
target speech extraction under multi-speaker noisy conditions remains
relatively unexplored. Moreover, the superior quality of diffusion methods
typically comes at the cost of slower inference speed. In this paper, we
introduce the Discriminative Diffusion model for Target Speech Extraction
(DDTSE). We apply the same forward process as diffusion models and utilize the
reconstruction loss similar to discriminative methods. Furthermore, we devise a
two-stage training strategy to emulate the inference process during model
training. DDTSE not only works as a standalone system, but also can further
improve the performance of discriminative models without additional retraining.
Experimental results demonstrate that DDTSE not only achieves higher perceptual
quality but also accelerates the inference process by 3 times compared to the
conventional diffusion model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by SLT2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SONICS: Synthetic Or Not -- Identifying Counterfeit Songs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.14080v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.14080v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Md Awsafur Rahman, Zaber Ibn Abdul Hakim, Najibul Haque Sarker, Bishmoy Paul, Shaikh Anowarul Fattah
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The recent surge in AI-generated songs presents exciting possibilities and
challenges. While these inventions democratize music creation, they also
necessitate the ability to distinguish between human-composed and synthetic
songs to safeguard artistic integrity and protect human musical artistry.
Existing research and datasets in fake song detection only focus on singing
voice deepfake detection (SVDD), where the vocals are AI-generated but the
instrumental music is sourced from real songs. However, these approaches are
inadequate for detecting contemporary end-to-end artificial songs where all
components (vocals, music, lyrics, and style) could be AI-generated.
Additionally, existing datasets lack music-lyrics diversity, long-duration
songs, and open-access fake songs. To address these gaps, we introduce SONICS,
a novel dataset for end-to-end Synthetic Song Detection (SSD), comprising over
97k songs (4,751 hours) with over 49k synthetic songs from popular platforms
like Suno and Udio. Furthermore, we highlight the importance of modeling
long-range temporal dependencies in songs for effective authenticity detection,
an aspect entirely overlooked in existing methods. To utilize long-range
patterns, we introduce SpecTTTra, a novel architecture that significantly
improves time and memory efficiency over conventional CNN and Transformer-based
models. In particular, for long audio samples, our top-performing variant
outperforms ViT by 8% F1 score while being 38% faster and using 26% less
memory. Additionally, in comparison with ConvNeXt, our model achieves 1% gain
in F1 score with 20% boost in speed and 67% reduction in memory usage. Other
variants of our model family provide even better speed and memory efficiency
with competitive performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Updated with correction</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Faetar Benchmark: Speech Recognition in a Very Under-Resourced
  Language 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.08103v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.08103v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michael Ong, Sean Robertson, Leo Peckham, Alba Jorquera Jimenez de Aberasturi, Paula Arkhangorodsky, Robin Huo, Aman Sakhardande, Mark Hallap, Naomi Nagy, Ewan Dunbar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce the Faetar Automatic Speech Recognition Benchmark, a benchmark
corpus designed to push the limits of current approaches to low-resource speech
recognition. Faetar, a Franco-Proven\c{c}al variety spoken primarily in Italy,
has no standard orthography, has virtually no existing textual or speech
resources other than what is included in the benchmark, and is quite different
from other forms of Franco-Proven\c{c}al. The corpus comes from field
recordings, most of which are noisy, for which only 5 hrs have matching
transcriptions, and for which forced alignment is of variable quality. The
corpus contains an additional 20 hrs of unlabelled speech. We report baseline
results from state-of-the-art multilingual speech foundation models with a best
phone error rate of 30.4%, using a pipeline that continues pre-training on the
foundation model using the unlabelled set.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Speech Processing <span class="chip" style="font-size: 60%">10</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ UniMuMo: Unified Text, Music and Motion Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04534v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04534v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Han Yang, Kun Su, Yutong Zhang, Jiaben Chen, Kaizhi Qian, Gaowen Liu, Chuang Gan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce UniMuMo, a unified multimodal model capable of taking arbitrary
text, music, and motion data as input conditions to generate outputs across all
three modalities. To address the lack of time-synchronized data, we align
unpaired music and motion data based on rhythmic patterns to leverage existing
large-scale music-only and motion-only datasets. By converting music, motion,
and text into token-based representation, our model bridges these modalities
through a unified encoder-decoder transformer architecture. To support multiple
generation tasks within a single framework, we introduce several architectural
improvements. We propose encoding motion with a music codebook, mapping motion
into the same feature space as music. We introduce a music-motion parallel
generation scheme that unifies all music and motion generation tasks into a
single transformer decoder architecture with a single training task of
music-motion joint generation. Moreover, the model is designed by fine-tuning
existing pre-trained single-modality models, significantly reducing
computational demands. Extensive experiments demonstrate that UniMuMo achieves
competitive results on all unidirectional generation benchmarks across music,
motion, and text modalities. Quantitative results are available in the
\href{https://hanyangclarence.github.io/unimumo_demo/}{project page}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Configurable Multilingual ASR with Speech Summary Representations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04478v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04478v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Harrison Zhu, Ivan Fung, Yingke Zhu, Lahiru Samarakoon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Approximately half of the world's population is multilingual, making
multilingual ASR (MASR) essential. Deploying multiple monolingual models is
challenging when the ground-truth language is unknown in advance. This
motivates research efforts on configurable multilingual MASR models that can be
prompted manually or adapted automatically to recognise specific languages. In
this paper, we present the Configurable MASR model with Summary Vector
(csvMASR), a novel architecture designed to enhance configurability. Our
approach leverages adapters and introduces speech summary vector
representations, inspired by conversational summary representations in speech
diarization, to combine outputs from language-specific components at the
utterance level. We also incorporate an auxiliary language classification loss
to enhance configurability. Using data from 7 languages in the Multilingual
Librispeech (MLS) dataset, csvMASR outperforms existing MASR models and reduces
the word error rate (WER) from 10.33\% to 9.95\% when compared with the
baseline. Additionally, csvMASR demonstrates superior performance in language
classification and prompting tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>A preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HALL-E: Hierarchical Neural Codec Language Model for Minute-Long
  Zero-Shot Text-to-Speech Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04380v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04380v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuto Nishimura, Takumi Hirose, Masanari Ohi, Hideki Nakayama, Nakamasa Inoue
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, Text-to-speech (TTS) models based on large language models (LLMs)
that translate natural language text into sequences of discrete audio tokens
have gained great research attention, with advances in neural audio codec (NAC)
models using residual vector quantization (RVQ). However, long-form speech
synthesis remains a significant challenge due to the high frame rate, which
increases the length of audio tokens and makes it difficult for autoregressive
language models to generate audio tokens for even a minute of speech. To
address this challenge, this paper introduces two novel post-training
approaches: 1) Multi-Resolution Requantization (MReQ) and 2) HALL-E. MReQ is a
framework to reduce the frame rate of pre-trained NAC models. Specifically, it
incorporates multi-resolution residual vector quantization (MRVQ) module that
hierarchically reorganizes discrete audio tokens through teacher-student
distillation. HALL-E is an LLM-based TTS model designed to predict hierarchical
tokens of MReQ. Specifically, it incorporates the technique of using MRVQ
sub-modules and continues training from a pre-trained LLM-based TTS model.
Furthermore, to promote TTS research, we create MinutesSpeech, a new benchmark
dataset consisting of 40k hours of filtered speech data for training and
evaluating speech synthesis ranging from 3s up to 180s. In experiments, we
demonstrated the effectiveness of our approaches by applying our post-training
framework to VALL-E. We achieved the frame rate down to as low as 8 Hz,
enabling the stable minitue-long speech synthesis in a single inference step.
Audio samples, dataset, codes and pre-trained models are available at
https://yutonishimura-v2.github.io/HALL-E_DEMO/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SONAR: A Synthetic AI-Audio Detection Framework~and Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04324v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04324v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiang Li, Pin-Yu Chen, Wenqi Wei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in Text-to-Speech (TTS) and Voice-Conversion (VC) using
generative Artificial Intelligence (AI) technology have made it possible to
generate high-quality and realistic human-like audio. This introduces
significant challenges to distinguishing AI-synthesized speech from the
authentic human voice and could raise potential issues of misuse for malicious
purposes such as impersonation and fraud, spreading misinformation, deepfakes,
and scams. However, existing detection techniques for AI-synthesized audio have
not kept pace and often exhibit poor generalization across diverse datasets. In
this paper, we introduce SONAR, a synthetic AI-Audio Detection Framework and
Benchmark, aiming to provide a comprehensive evaluation for distinguishing
cutting-edge AI-synthesized auditory content. SONAR includes a novel evaluation
dataset sourced from 9 diverse audio synthesis platforms, including leading TTS
providers and state-of-the-art TTS models. It is the first framework to
uniformly benchmark AI-audio detection across both traditional and foundation
model-based deepfake detection systems. Through extensive experiments, we
reveal the generalization limitations of existing detection methods and
demonstrate that foundation models exhibit stronger generalization
capabilities, which can be attributed to their model size and the scale and
quality of pretraining data. Additionally, we explore the effectiveness and
efficiency of few-shot fine-tuning in improving generalization, highlighting
its potential for tailored applications, such as personalized detection systems
for specific entities or individuals. Code and dataset are available at
https://github.com/Jessegator/SONAR.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Content-based Controls For Music Large Language Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.17162v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.17162v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liwei Lin, Gus Xia, Junyan Jiang, Yixiao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent years have witnessed a rapid growth of large-scale language models in
the domain of music audio. Such models enable end-to-end generation of
higher-quality music, and some allow conditioned generation using text
descriptions. However, the control power of text controls on music is
intrinsically limited, as they can only describe music indirectly through
meta-data (such as singers and instruments) or high-level representations (such
as genre and emotion). We aim to further equip the models with direct and
content-based controls on innate music languages such as pitch, chords and drum
track. To this end, we contribute Coco-Mulla, a content-based control method
for music large language modeling. It uses a parameter-efficient fine-tuning
(PEFT) method tailored for Transformer-based audio models. Experiments show
that our approach achieved high-quality music generation with low-resource
semi-supervised learning, tuning with less than 4% parameters compared to the
original model and training on a small dataset with fewer than 300 songs.
Moreover, our approach enables effective content-based controls, and we
illustrate the control power via chords and rhythms, two of the most salient
features of music audio. Furthermore, we show that by combining content-based
controls and text descriptions, our system achieves flexible music variation
generation and arrangement. Our source codes and demos are available online.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Arrange, Inpaint, and Refine: Steerable Long-term Music Audio Generation
  and Editing via Content-based Controls 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.09508v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.09508v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liwei Lin, Gus Xia, Yixiao Zhang, Junyan Jiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Controllable music generation plays a vital role in human-AI music
co-creation. While Large Language Models (LLMs) have shown promise in
generating high-quality music, their focus on autoregressive generation limits
their utility in music editing tasks. To address this gap, we propose a novel
approach leveraging a parameter-efficient heterogeneous adapter combined with a
masking training scheme. This approach enables autoregressive language models
to seamlessly address music inpainting tasks. Additionally, our method
integrates frame-level content-based controls, facilitating track-conditioned
music refinement and score-conditioned music arrangement. We apply this method
to fine-tune MusicGen, a leading autoregressive music generation model. Our
experiments demonstrate promising results across multiple music editing tasks,
offering more flexible controls for future AI-driven music editing tools. The
source codes and a demo page showcasing our work are available at
https://kikyo-16.github.io/AIR.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unsupervised TTS Acoustic Modeling for TTS with Conditional Disentangled
  Sequential VAE 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2206.02512v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2206.02512v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiachen Lian, Chunlei Zhang, Gopala Krishna Anumanchipalli, Dong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose a novel unsupervised text-to-speech acoustic model
training scheme, named UTTS, which does not require text-audio pairs. UTTS is a
multi-speaker speech synthesizer that supports zero-shot voice cloning, it is
developed from a perspective of disentangled speech representation learning.
The framework offers a flexible choice of a speaker's duration model, timbre
feature (identity) and content for TTS inference. We leverage recent
advancements in self-supervised speech representation learning as well as
speech synthesis front-end techniques for system development. Specifically, we
employ our recently formulated Conditional Disentangled Sequential Variational
Auto-encoder (C-DSVAE) as the backbone UTTS AM, which offers well-structured
content representations given unsupervised alignment (UA) as condition during
training. For UTTS inference, we utilize a lexicon to map input text to the
phoneme sequence, which is expanded to the frame-level forced alignment (FA)
with a speaker-dependent duration model. Then, we develop an alignment mapping
module that converts FA to UA. Finally, the C-DSVAE, serving as the
self-supervised TTS AM, takes the predicted UA and a target speaker embedding
to generate the mel spectrogram, which is ultimately converted to waveform with
a neural vocoder. We show how our method enables speech synthesis without using
a paired TTS corpus in AM development stage. Experiments demonstrate that UTTS
can synthesize speech of high naturalness and intelligibility measured by human
and objective evaluations. Audio samples are available at our demo page
https://neurtts.github.io/utts\_demo/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>IEEE/ACM Transactions on Audio, Speech, and Language Processing (
  Volume: 31)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DDTSE: Discriminative Diffusion Model for Target Speech Extraction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.13874v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.13874v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Leying Zhang, Yao Qian, Linfeng Yu, Heming Wang, Hemin Yang, Long Zhou, Shujie Liu, Yanmin Qian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models have gained attention in speech enhancement tasks, providing
an alternative to conventional discriminative methods. However, research on
target speech extraction under multi-speaker noisy conditions remains
relatively unexplored. Moreover, the superior quality of diffusion methods
typically comes at the cost of slower inference speed. In this paper, we
introduce the Discriminative Diffusion model for Target Speech Extraction
(DDTSE). We apply the same forward process as diffusion models and utilize the
reconstruction loss similar to discriminative methods. Furthermore, we devise a
two-stage training strategy to emulate the inference process during model
training. DDTSE not only works as a standalone system, but also can further
improve the performance of discriminative models without additional retraining.
Experimental results demonstrate that DDTSE not only achieves higher perceptual
quality but also accelerates the inference process by 3 times compared to the
conventional diffusion model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by SLT2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SONICS: Synthetic Or Not -- Identifying Counterfeit Songs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.14080v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.14080v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Md Awsafur Rahman, Zaber Ibn Abdul Hakim, Najibul Haque Sarker, Bishmoy Paul, Shaikh Anowarul Fattah
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The recent surge in AI-generated songs presents exciting possibilities and
challenges. While these inventions democratize music creation, they also
necessitate the ability to distinguish between human-composed and synthetic
songs to safeguard artistic integrity and protect human musical artistry.
Existing research and datasets in fake song detection only focus on singing
voice deepfake detection (SVDD), where the vocals are AI-generated but the
instrumental music is sourced from real songs. However, these approaches are
inadequate for detecting contemporary end-to-end artificial songs where all
components (vocals, music, lyrics, and style) could be AI-generated.
Additionally, existing datasets lack music-lyrics diversity, long-duration
songs, and open-access fake songs. To address these gaps, we introduce SONICS,
a novel dataset for end-to-end Synthetic Song Detection (SSD), comprising over
97k songs (4,751 hours) with over 49k synthetic songs from popular platforms
like Suno and Udio. Furthermore, we highlight the importance of modeling
long-range temporal dependencies in songs for effective authenticity detection,
an aspect entirely overlooked in existing methods. To utilize long-range
patterns, we introduce SpecTTTra, a novel architecture that significantly
improves time and memory efficiency over conventional CNN and Transformer-based
models. In particular, for long audio samples, our top-performing variant
outperforms ViT by 8% F1 score while being 38% faster and using 26% less
memory. Additionally, in comparison with ConvNeXt, our model achieves 1% gain
in F1 score with 20% boost in speed and 67% reduction in memory usage. Other
variants of our model family provide even better speed and memory efficiency
with competitive performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Updated with correction</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Faetar Benchmark: Speech Recognition in a Very Under-Resourced
  Language 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.08103v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.08103v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michael Ong, Sean Robertson, Leo Peckham, Alba Jorquera Jimenez de Aberasturi, Paula Arkhangorodsky, Robin Huo, Aman Sakhardande, Mark Hallap, Naomi Nagy, Ewan Dunbar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce the Faetar Automatic Speech Recognition Benchmark, a benchmark
corpus designed to push the limits of current approaches to low-resource speech
recognition. Faetar, a Franco-Proven\c{c}al variety spoken primarily in Italy,
has no standard orthography, has virtually no existing textual or speech
resources other than what is included in the benchmark, and is quite different
from other forms of Franco-Proven\c{c}al. The corpus comes from field
recordings, most of which are noisy, for which only 5 hrs have matching
transcriptions, and for which forced alignment is of variable quality. The
corpus contains an additional 20 hrs of unlabelled speech. We report baseline
results from state-of-the-art multilingual speech foundation models with a best
phone error rate of 30.4%, using a pipeline that continues pre-training on the
foundation model using the unlabelled set.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-10-05T00:00:00Z">2024-10-05</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Sound <span class="chip" style="font-size: 60%">12</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient and Robust Long-Form Speech Recognition with Hybrid
  H3-Conformer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04159v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04159v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tomoki Honda, Shinsuke Sakai, Tatsuya Kawahara
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, Conformer has achieved state-of-the-art performance in many speech
recognition tasks. However, the Transformer-based models show significant
deterioration for long-form speech, such as lectures, because the
self-attention mechanism becomes unreliable with the computation of the square
order of the input length. To solve the problem, we incorporate a kind of
state-space model, Hungry Hungry Hippos (H3), to replace or complement the
multi-head self-attention (MHSA). H3 allows for efficient modeling of long-form
sequences with a linear-order computation. In experiments using two datasets of
CSJ and LibriSpeech, our proposed H3-Conformer model performs efficient and
robust recognition of long-form speech. Moreover, we propose a hybrid of H3 and
MHSA and show that using H3 in higher layers and MHSA in lower layers provides
significant improvement in online recognition. We also investigate a parallel
use of H3 and MHSA in all layers, resulting in the best performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to InterSpeech2024, Sample code is available at
  https://github.com/mirrormouse/Hybrid-H3-Conformer</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The OCON model: an old but green solution for distributable supervised
  classification for acoustic monitoring in smart cities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04098v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04098v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Stefano Giacomelli, Marco Giordano, Claudia Rinaldi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper explores a structured application of the One-Class approach and
the One-Class-One-Network model for supervised classification tasks, focusing
on vowel phonemes classification and speakers recognition for the Automatic
Speech Recognition (ASR) domain. For our case-study, the ASR model runs on a
proprietary sensing and lightning system, exploited to monitor acoustic and air
pollution on urban streets. We formalize combinations of pseudo-Neural
Architecture Search and Hyper-Parameters Tuning experiments, using an informed
grid-search methodology, to achieve classification accuracy comparable to
nowadays most complex architectures, delving into the speaker recognition and
energy efficiency aspects. Despite its simplicity, our model proposal has a
very good chance to generalize the language and speaker genders context for
widespread applicability in computational constrained contexts, proved by
relevant statistical and performance metrics. Our experiments code is openly
accessible on our GitHub.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at "IEEE 5th International Symposium on the Internet of
  Sounds, 30 Sep / 2 Oct 2024, Erlangen, Germany"</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cross-Lingual Query-by-Example Spoken Term Detection: A
  <span class="highlight-title">Transformer</span>-Based Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04091v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04091v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Allahdadi Fatemeh, Mahdian Toroghi Rahil, Zareian Hassan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Query-by-example spoken term detection (QbE-STD) is typically constrained by
transcribed data scarcity and language specificity. This paper introduces a
novel, language-agnostic QbE-STD model leveraging image processing techniques
and transformer architecture. By employing a pre-trained XLSR-53 network for
feature extraction and a Hough transform for detection, our model effectively
searches for user-defined spoken terms within any audio file. Experimental
results across four languages demonstrate significant performance gains
(19-54%) over a CNN-based baseline. While processing time is improved compared
to DTW, accuracy remains inferior. Notably, our model offers the advantage of
accurately counting query term repetitions within the target audio.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MusicHiFi: Fast High-Fidelity Stereo Vocoding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.10493v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.10493v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ge Zhu, Juan-Pablo Caceres, Zhiyao Duan, Nicholas J. Bryan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion-based audio and music generation models commonly perform generation
by constructing an image representation of audio (e.g., a mel-spectrogram) and
then convert it to audio using a phase reconstruction model or vocoder. Typical
vocoders, however, produce monophonic audio at lower resolutions (e.g., 16-24
kHz), which limits their usefulness. We propose MusicHiFi -- an efficient
high-fidelity stereophonic vocoder. Our method employs a cascade of three
generative adversarial networks (GANs) that convert low-resolution
mel-spectrograms to audio, upsamples to high-resolution audio via bandwidth
extension, and upmixes to stereophonic audio. Compared to past work, we propose
1) a unified GAN-based generator and discriminator architecture and training
procedure for each stage of our cascade, 2) a new fast, near
downsampling-compatible bandwidth extension module, and 3) a new fast
downmix-compatible mono-to-stereo upmixer that ensures the preservation of
monophonic content in the output. We evaluate our approach using objective and
subjective listening tests and find our approach yields comparable or better
audio quality, better spatialization control, and significantly faster
inference speed compared to past work. Sound examples are at
\url{https://MusicHiFi.github.io/web/}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to IEEE Signal Processing Letters</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Prosody Analysis of Audiobooks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.06930v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.06930v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Charuta Pethe, Bach Pham, Felix D Childress, Yunting Yin, Steven Skiena
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in text-to-speech have made it possible to generate
natural-sounding audio from text. However, audiobook narrations involve
dramatic vocalizations and intonations by the reader, with greater reliance on
emotions, dialogues, and descriptions in the narrative. Using our dataset of 93
aligned book-audiobook pairs, we present improved models for prosody prediction
properties (pitch, volume, and rate of speech) from narrative text using
language modeling. Our predicted prosody attributes correlate much better with
human audiobook readings than results from a state-of-the-art commercial TTS
system: our predicted pitch shows a higher correlation with human reading for
22 out of the 24 books, while our predicted volume attribute proves more
similar to human reading for 23 out of the 24 books. Finally, we present a
human evaluation study to quantify the extent that people prefer
prosody-enhanced audiobook readings over commercial text-to-speech systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Integrating Text-to-Music Models with Language Models: Composing Long
  Structured Music Pieces 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00344v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00344v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lilac Atassi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent music generation methods based on transformers have a context window
of up to a minute. The music generated by these methods is largely unstructured
beyond the context window. With a longer context window, learning long-scale
structures from musical data is a prohibitively challenging problem. This paper
proposes integrating a text-to-music model with a large language model to
generate music with form. The papers discusses the solutions to the challenges
of such integration. The experimental results show that the proposed method can
generate 2.5-minute-long music that is highly structured, strongly organized,
and cohesive.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: substantial text overlap with arXiv:2404.11976</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Semantic MIMO Systems for Speech-to-Text Transmission 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.08096v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.08096v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenzi Weng, Zhijin Qin, Huiqiang Xie, Xiaoming Tao, Khaled B. Letaief
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Semantic communications have been utilized to execute numerous intelligent
tasks by transmitting task-related semantic information instead of bits. In
this article, we propose a semantic-aware speech-to-text transmission system
for the single-user multiple-input multiple-output (MIMO) and multi-user MIMO
communication scenarios, named SAC-ST. Particularly, a semantic communication
system to serve the speech-to-text task at the receiver is first designed,
which compresses the semantic information and generates the low-dimensional
semantic features by leveraging the transformer module. In addition, a novel
semantic-aware network is proposed to facilitate transmission with high
semantic fidelity by identifying the critical semantic information and
guaranteeing its accurate recovery. Furthermore, we extend the SAC-ST with a
neural network-enabled channel estimation network to mitigate the dependence on
accurate channel state information and validate the feasibility of SAC-ST in
practical communication environments. Simulation results will show that the
proposed SAC-ST outperforms the communication framework without the
semantic-aware network for speech-to-text transmission over the MIMO channels
in terms of the speech-to-text metrics, especially in the low signal-to-noise
regime. Moreover, the SAC-ST with the developed channel estimation network is
comparable to the SAC-ST with perfect channel state information.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Selective-Memory Meta-Learning with Environment Representations for
  Sound Event Localization and Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.16422v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.16422v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinbo Hu, Yin Cao, Ming Wu, Qiuqiang Kong, Feiran Yang, Mark D. Plumbley, Jun Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Environment shifts and conflicts present significant challenges for
learning-based sound event localization and detection (SELD) methods. SELD
systems, when trained in particular acoustic settings, often show restricted
generalization capabilities for diverse acoustic environments. Furthermore,
obtaining annotated samples for spatial sound events is notably costly.
Deploying a SELD system in a new environment requires extensive time for
re-training and fine-tuning. To overcome these challenges, we propose
environment-adaptive Meta-SELD, designed for efficient adaptation to new
environments using minimal data. Our method specifically utilizes
computationally synthesized spatial data and employs Model-Agnostic
Meta-Learning (MAML) on a pre-trained, environment-independent model. The
method then utilizes fast adaptation to unseen real-world environments using
limited samples from the respective environments. Inspired by the
Learning-to-Forget approach, we introduce the concept of selective memory as a
strategy for resolving conflicts across environments. This approach involves
selectively memorizing target-environment-relevant information and adapting to
the new environments through the selective attenuation of model parameters. In
addition, we introduce environment representations to characterize different
acoustic settings, enhancing the adaptability of our attenuation approach to
various environments. We evaluate our proposed method on the development set of
the Sony-TAu Realistic Spatial Soundscapes 2023 (STARSS23) dataset and
computationally synthesized scenes. Experimental results demonstrate the
superior performance of the proposed method compared to conventional supervised
learning methods, particularly in localization.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 11 figures, accepted by IEEE/ACM Transactions on Audio,
  Speech, and Language Processing (TASLP)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Task Arithmetic can Mitigate Synthetic-to-Real Gap in Automatic Speech
  Recognition <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.02925v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.02925v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hsuan Su, Hua Farn, Fan-Yun Sun, Shang-Tse Chen, Hung-yi Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Synthetic data is widely used in speech recognition due to the availability
of text-to-speech models, which facilitate adapting models to previously unseen
text domains. However, existing methods suffer in performance when they
fine-tune an automatic speech recognition (ASR) model on synthetic data as they
suffer from the distributional shift commonly referred to as the
synthetic-to-real gap. In this paper, we find that task vector arithmetic is
effective at mitigating this gap. Our proposed method, SYN2REAL task vector,
shows an average improvement of 10.03\% improvement in word error rate over
baselines on the SLURP dataset. Additionally, we show that an average of
SYN2REAL task vectors, when we have real speeches from multiple different
domains, can further adapt the original ASR model to perform better on the
target text domain.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Advancing Test-Time Adaptation in Wild Acoustic Test Settings <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.09505v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.09505v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongfu Liu, Hengguan Huang, Ye Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Acoustic foundation models, fine-tuned for Automatic Speech Recognition
(ASR), suffer from performance degradation in wild acoustic test settings when
deployed in real-world scenarios. Stabilizing online Test-Time Adaptation (TTA)
under these conditions remains an open and unexplored question. Existing wild
vision TTA methods often fail to handle speech data effectively due to the
unique characteristics of high-entropy speech frames, which are unreliably
filtered out even when containing crucial semantic content. Furthermore, unlike
static vision data, speech signals follow short-term consistency, requiring
specialized adaptation strategies. In this work, we propose a novel wild
acoustic TTA method tailored for ASR fine-tuned acoustic foundation models. Our
method, Confidence-Enhanced Adaptation, performs frame-level adaptation using a
confidence-aware weight scheme to avoid filtering out essential information in
high-entropy frames. Additionally, we apply consistency regularization during
test-time optimization to leverage the inherent short-term consistency of
speech signals. Our experiments on both synthetic and real-world datasets
demonstrate that our approach outperforms existing baselines under various wild
acoustic test settings, including Gaussian noise, environmental sounds, accent
variations, and sung speech.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Benchmarking Cross-Domain Audio-Visual Deception Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.06995v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.06995v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaobao Guo, Zitong Yu, Nithish Muthuchamy Selvaraj, Bingquan Shen, Adams Wai-Kin Kong, Alex C. Kot
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automated deception detection is crucial for assisting humans in accurately
assessing truthfulness and identifying deceptive behavior. Conventional
contact-based techniques, like polygraph devices, rely on physiological signals
to determine the authenticity of an individual's statements. Nevertheless,
recent developments in automated deception detection have demonstrated that
multimodal features derived from both audio and video modalities may outperform
human observers on publicly available datasets. Despite these positive
findings, the generalizability of existing audio-visual deception detection
approaches across different scenarios remains largely unexplored. To close this
gap, we present the first cross-domain audio-visual deception detection
benchmark, that enables us to assess how well these methods generalize for use
in real-world scenarios. We used widely adopted audio and visual features and
different architectures for benchmarking, comparing single-to-single and
multi-to-single domain generalization performance. To further exploit the
impacts using data from multiple source domains for training, we investigate
three types of domain sampling strategies, including domain-simultaneous,
domain-alternating, and domain-by-domain for multi-to-single domain
generalization evaluation. We also propose an algorithm to enhance the
generalization performance by maximizing the gradient inner products between
modality encoders, named ``MM-IDGM". Furthermore, we proposed the
Attention-Mixer fusion method to improve performance, and we believe that this
new cross-domain benchmark will facilitate future research in audio-visual
deception detection.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving curriculum learning for target speaker extraction with
  synthetic speakers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00811v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00811v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yun Liu, Xuechen Liu, Junichi Yamagishi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Target speaker extraction (TSE) aims to isolate individual speaker voices
from complex speech environments. The effectiveness of TSE systems is often
compromised when the speaker characteristics are similar to each other. Recent
research has introduced curriculum learning (CL), in which TSE models are
trained incrementally on speech samples of increasing complexity. In CL
training, the model is first trained on samples with low speaker similarity
between the target and interference speakers, and then on samples with high
speaker similarity. To further improve CL, this paper uses a $k$-nearest
neighbor-based voice conversion method to simulate and generate speech of
diverse interference speakers, and then uses the generated data as part of the
CL. Experiments demonstrate that training data based on synthetic speakers can
effectively enhance the model's capabilities and significantly improve the
performance of multiple TSE systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by SLT2024</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Speech Processing <span class="chip" style="font-size: 60%">17</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DJ Mix Transcription with Multi-Pass Non-Negative Matrix Factorization <span class="chip">ICASSP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04198v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04198v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Étienne Paul André, Dominique Fourer, Diemo Schwarz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  DJ mix transcription is a crucial step towards DJ mix reverse engineering,
which estimates the set of parameters and audio effects applied to a set of
existing tracks to produce a performative DJ mix. We introduce a new approach
based on a multi-pass NMF algorithm where the dictionary matrix corresponds to
a set of spectrogram slices of the source tracks present in the mix.
  The multi-pass strategy is motivated by the high computational cost resulting
from the use of a large NMF dictionary. The proposed method uses inter-pass
filtering to favor temporal continuity and sparseness and is evaluated on a
publicly available dataset.
  Our comparative results considering a baseline method based on dynamic time
warping (DTW) are promising and pave the way of future NMF-based applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to ICASSP 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient and Robust Long-Form Speech Recognition with Hybrid
  H3-Conformer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04159v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04159v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tomoki Honda, Shinsuke Sakai, Tatsuya Kawahara
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, Conformer has achieved state-of-the-art performance in many speech
recognition tasks. However, the Transformer-based models show significant
deterioration for long-form speech, such as lectures, because the
self-attention mechanism becomes unreliable with the computation of the square
order of the input length. To solve the problem, we incorporate a kind of
state-space model, Hungry Hungry Hippos (H3), to replace or complement the
multi-head self-attention (MHSA). H3 allows for efficient modeling of long-form
sequences with a linear-order computation. In experiments using two datasets of
CSJ and LibriSpeech, our proposed H3-Conformer model performs efficient and
robust recognition of long-form speech. Moreover, we propose a hybrid of H3 and
MHSA and show that using H3 in higher layers and MHSA in lower layers provides
significant improvement in online recognition. We also investigate a parallel
use of H3 and MHSA in all layers, resulting in the best performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to InterSpeech2024, Sample code is available at
  https://github.com/mirrormouse/Hybrid-H3-Conformer</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The OCON model: an old but green solution for distributable supervised
  classification for acoustic monitoring in smart cities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04098v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04098v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Stefano Giacomelli, Marco Giordano, Claudia Rinaldi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper explores a structured application of the One-Class approach and
the One-Class-One-Network model for supervised classification tasks, focusing
on vowel phonemes classification and speakers recognition for the Automatic
Speech Recognition (ASR) domain. For our case-study, the ASR model runs on a
proprietary sensing and lightning system, exploited to monitor acoustic and air
pollution on urban streets. We formalize combinations of pseudo-Neural
Architecture Search and Hyper-Parameters Tuning experiments, using an informed
grid-search methodology, to achieve classification accuracy comparable to
nowadays most complex architectures, delving into the speaker recognition and
energy efficiency aspects. Despite its simplicity, our model proposal has a
very good chance to generalize the language and speaker genders context for
widespread applicability in computational constrained contexts, proved by
relevant statistical and performance metrics. Our experiments code is openly
accessible on our GitHub.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at "IEEE 5th International Symposium on the Internet of
  Sounds, 30 Sep / 2 Oct 2024, Erlangen, Germany"</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancement of Dysarthric Speech Reconstruction by Contrastive Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04092v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04092v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Keshvari Fatemeh, Mahdian Toroghi Rahil, Zareian Hassan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dysarthric speech reconstruction is challenging due to its pathological sound
patterns. Preserving speaker identity, especially without access to normal
speech, is a key challenge. Our proposed approach uses contrastive learning to
extract speaker embedding for reconstruction, while employing XLS-R
representations instead of filter banks. The results show improved speech
quality, naturalness, intelligibility, speaker identity preservation, and
gender consistency for female speakers. Reconstructed speech exhibits 1.51 and
2.12 MOS score improvements and reduces word error rates by 25.45% and 32.1%
for moderate and moderate-severe dysarthria speakers using Jasper speech
recognition system, respectively. This approach offers promising advancements
in dysarthric speech reconstruction.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cross-Lingual Query-by-Example Spoken Term Detection: A
  <span class="highlight-title">Transformer</span>-Based Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04091v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04091v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Allahdadi Fatemeh, Mahdian Toroghi Rahil, Zareian Hassan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Query-by-example spoken term detection (QbE-STD) is typically constrained by
transcribed data scarcity and language specificity. This paper introduces a
novel, language-agnostic QbE-STD model leveraging image processing techniques
and transformer architecture. By employing a pre-trained XLSR-53 network for
feature extraction and a Hough transform for detection, our model effectively
searches for user-defined spoken terms within any audio file. Experimental
results across four languages demonstrate significant performance gains
(19-54%) over a CNN-based baseline. While processing time is improved compared
to DTW, accuracy remains inferior. Notably, our model offers the advantage of
accurately counting query term repetitions within the target audio.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SyllableLM: Learning Coarse Semantic Units for Speech Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04029v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04029v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alan Baade, Puyuan Peng, David Harwath
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language models require tokenized inputs. However, tokenization strategies
for continuous data like audio and vision are often based on simple heuristics
such as fixed sized convolutions or discrete clustering, which do not
necessarily align with the semantic structure of the data. For speech in
particular, the high resolution of waveforms (16,000 samples/second or more)
presents a significant challenge as speech-based language models have had to
use several times more tokens per word than text-based language models. In this
work, we introduce a controllable self-supervised technique to merge speech
representations into coarser syllable-like units while still preserving
semantic information. We do this by 1) extracting noisy boundaries through
analyzing correlations in pretrained encoder losses and 2) iteratively
improving model representations with a novel distillation technique. Our method
produces controllable-rate semantic units at as low as 5Hz and 60bps and
achieves SotA in syllabic segmentation and clustering. Using these coarse
tokens, we successfully train SyllableLM, a Speech Language Model (SpeechLM)
that matches or outperforms current SotA SpeechLMs on a range of spoken
language modeling tasks. SyllableLM also achieves significant improvements in
efficiency with a 30x reduction in training compute and a 4x wall-clock
inference speedup.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Adversarial Attacks and Robust Defenses in Speaker Embedding based
  Zero-Shot Text-to-Speech System 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.04017v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.04017v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ze Li, Yao Shi, Yunfei Xu, Ming Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Speaker embedding based zero-shot Text-to-Speech (TTS) systems enable
high-quality speech synthesis for unseen speakers using minimal data. However,
these systems are vulnerable to adversarial attacks, where an attacker
introduces imperceptible perturbations to the original speaker's audio
waveform, leading to synthesized speech sounds like another person. This
vulnerability poses significant security risks, including speaker identity
spoofing and unauthorized voice manipulation. This paper investigates two
primary defense strategies to address these threats: adversarial training and
adversarial purification. Adversarial training enhances the model's robustness
by integrating adversarial examples during the training process, thereby
improving resistance to such attacks. Adversarial purification, on the other
hand, employs diffusion probabilistic models to revert adversarially perturbed
audio to its clean form. Experimental results demonstrate that these defense
mechanisms can significantly reduce the impact of adversarial perturbations,
enhancing the security and reliability of speaker embedding based zero-shot TTS
systems in adversarial environments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MusicHiFi: Fast High-Fidelity Stereo Vocoding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.10493v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.10493v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ge Zhu, Juan-Pablo Caceres, Zhiyao Duan, Nicholas J. Bryan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion-based audio and music generation models commonly perform generation
by constructing an image representation of audio (e.g., a mel-spectrogram) and
then convert it to audio using a phase reconstruction model or vocoder. Typical
vocoders, however, produce monophonic audio at lower resolutions (e.g., 16-24
kHz), which limits their usefulness. We propose MusicHiFi -- an efficient
high-fidelity stereophonic vocoder. Our method employs a cascade of three
generative adversarial networks (GANs) that convert low-resolution
mel-spectrograms to audio, upsamples to high-resolution audio via bandwidth
extension, and upmixes to stereophonic audio. Compared to past work, we propose
1) a unified GAN-based generator and discriminator architecture and training
procedure for each stage of our cascade, 2) a new fast, near
downsampling-compatible bandwidth extension module, and 3) a new fast
downmix-compatible mono-to-stereo upmixer that ensures the preservation of
monophonic content in the output. We evaluate our approach using objective and
subjective listening tests and find our approach yields comparable or better
audio quality, better spatialization control, and significantly faster
inference speed compared to past work. Sound examples are at
\url{https://MusicHiFi.github.io/web/}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to IEEE Signal Processing Letters</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Prosody Analysis of Audiobooks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.06930v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.06930v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Charuta Pethe, Bach Pham, Felix D Childress, Yunting Yin, Steven Skiena
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in text-to-speech have made it possible to generate
natural-sounding audio from text. However, audiobook narrations involve
dramatic vocalizations and intonations by the reader, with greater reliance on
emotions, dialogues, and descriptions in the narrative. Using our dataset of 93
aligned book-audiobook pairs, we present improved models for prosody prediction
properties (pitch, volume, and rate of speech) from narrative text using
language modeling. Our predicted prosody attributes correlate much better with
human audiobook readings than results from a state-of-the-art commercial TTS
system: our predicted pitch shows a higher correlation with human reading for
22 out of the 24 books, while our predicted volume attribute proves more
similar to human reading for 23 out of the 24 books. Finally, we present a
human evaluation study to quantify the extent that people prefer
prosody-enhanced audiobook readings over commercial text-to-speech systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Integrating Text-to-Music Models with Language Models: Composing Long
  Structured Music Pieces 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00344v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00344v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lilac Atassi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent music generation methods based on transformers have a context window
of up to a minute. The music generated by these methods is largely unstructured
beyond the context window. With a longer context window, learning long-scale
structures from musical data is a prohibitively challenging problem. This paper
proposes integrating a text-to-music model with a large language model to
generate music with form. The papers discusses the solutions to the challenges
of such integration. The experimental results show that the proposed method can
generate 2.5-minute-long music that is highly structured, strongly organized,
and cohesive.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: substantial text overlap with arXiv:2404.11976</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Semantic MIMO Systems for Speech-to-Text Transmission 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.08096v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.08096v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenzi Weng, Zhijin Qin, Huiqiang Xie, Xiaoming Tao, Khaled B. Letaief
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Semantic communications have been utilized to execute numerous intelligent
tasks by transmitting task-related semantic information instead of bits. In
this article, we propose a semantic-aware speech-to-text transmission system
for the single-user multiple-input multiple-output (MIMO) and multi-user MIMO
communication scenarios, named SAC-ST. Particularly, a semantic communication
system to serve the speech-to-text task at the receiver is first designed,
which compresses the semantic information and generates the low-dimensional
semantic features by leveraging the transformer module. In addition, a novel
semantic-aware network is proposed to facilitate transmission with high
semantic fidelity by identifying the critical semantic information and
guaranteeing its accurate recovery. Furthermore, we extend the SAC-ST with a
neural network-enabled channel estimation network to mitigate the dependence on
accurate channel state information and validate the feasibility of SAC-ST in
practical communication environments. Simulation results will show that the
proposed SAC-ST outperforms the communication framework without the
semantic-aware network for speech-to-text transmission over the MIMO channels
in terms of the speech-to-text metrics, especially in the low signal-to-noise
regime. Moreover, the SAC-ST with the developed channel estimation network is
comparable to the SAC-ST with perfect channel state information.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Selective-Memory Meta-Learning with Environment Representations for
  Sound Event Localization and Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.16422v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.16422v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinbo Hu, Yin Cao, Ming Wu, Qiuqiang Kong, Feiran Yang, Mark D. Plumbley, Jun Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Environment shifts and conflicts present significant challenges for
learning-based sound event localization and detection (SELD) methods. SELD
systems, when trained in particular acoustic settings, often show restricted
generalization capabilities for diverse acoustic environments. Furthermore,
obtaining annotated samples for spatial sound events is notably costly.
Deploying a SELD system in a new environment requires extensive time for
re-training and fine-tuning. To overcome these challenges, we propose
environment-adaptive Meta-SELD, designed for efficient adaptation to new
environments using minimal data. Our method specifically utilizes
computationally synthesized spatial data and employs Model-Agnostic
Meta-Learning (MAML) on a pre-trained, environment-independent model. The
method then utilizes fast adaptation to unseen real-world environments using
limited samples from the respective environments. Inspired by the
Learning-to-Forget approach, we introduce the concept of selective memory as a
strategy for resolving conflicts across environments. This approach involves
selectively memorizing target-environment-relevant information and adapting to
the new environments through the selective attenuation of model parameters. In
addition, we introduce environment representations to characterize different
acoustic settings, enhancing the adaptability of our attenuation approach to
various environments. We evaluate our proposed method on the development set of
the Sony-TAu Realistic Spatial Soundscapes 2023 (STARSS23) dataset and
computationally synthesized scenes. Experimental results demonstrate the
superior performance of the proposed method compared to conventional supervised
learning methods, particularly in localization.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 11 figures, accepted by IEEE/ACM Transactions on Audio,
  Speech, and Language Processing (TASLP)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Task Arithmetic can Mitigate Synthetic-to-Real Gap in Automatic Speech
  Recognition <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.02925v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.02925v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hsuan Su, Hua Farn, Fan-Yun Sun, Shang-Tse Chen, Hung-yi Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Synthetic data is widely used in speech recognition due to the availability
of text-to-speech models, which facilitate adapting models to previously unseen
text domains. However, existing methods suffer in performance when they
fine-tune an automatic speech recognition (ASR) model on synthetic data as they
suffer from the distributional shift commonly referred to as the
synthetic-to-real gap. In this paper, we find that task vector arithmetic is
effective at mitigating this gap. Our proposed method, SYN2REAL task vector,
shows an average improvement of 10.03\% improvement in word error rate over
baselines on the SLURP dataset. Additionally, we show that an average of
SYN2REAL task vectors, when we have real speeches from multiple different
domains, can further adapt the original ASR model to perform better on the
target text domain.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Advancing Test-Time Adaptation in Wild Acoustic Test Settings <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.09505v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.09505v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongfu Liu, Hengguan Huang, Ye Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Acoustic foundation models, fine-tuned for Automatic Speech Recognition
(ASR), suffer from performance degradation in wild acoustic test settings when
deployed in real-world scenarios. Stabilizing online Test-Time Adaptation (TTA)
under these conditions remains an open and unexplored question. Existing wild
vision TTA methods often fail to handle speech data effectively due to the
unique characteristics of high-entropy speech frames, which are unreliably
filtered out even when containing crucial semantic content. Furthermore, unlike
static vision data, speech signals follow short-term consistency, requiring
specialized adaptation strategies. In this work, we propose a novel wild
acoustic TTA method tailored for ASR fine-tuned acoustic foundation models. Our
method, Confidence-Enhanced Adaptation, performs frame-level adaptation using a
confidence-aware weight scheme to avoid filtering out essential information in
high-entropy frames. Additionally, we apply consistency regularization during
test-time optimization to leverage the inherent short-term consistency of
speech signals. Our experiments on both synthetic and real-world datasets
demonstrate that our approach outperforms existing baselines under various wild
acoustic test settings, including Gaussian noise, environmental sounds, accent
variations, and sung speech.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Benchmarking Cross-Domain Audio-Visual Deception Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.06995v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.06995v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaobao Guo, Zitong Yu, Nithish Muthuchamy Selvaraj, Bingquan Shen, Adams Wai-Kin Kong, Alex C. Kot
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automated deception detection is crucial for assisting humans in accurately
assessing truthfulness and identifying deceptive behavior. Conventional
contact-based techniques, like polygraph devices, rely on physiological signals
to determine the authenticity of an individual's statements. Nevertheless,
recent developments in automated deception detection have demonstrated that
multimodal features derived from both audio and video modalities may outperform
human observers on publicly available datasets. Despite these positive
findings, the generalizability of existing audio-visual deception detection
approaches across different scenarios remains largely unexplored. To close this
gap, we present the first cross-domain audio-visual deception detection
benchmark, that enables us to assess how well these methods generalize for use
in real-world scenarios. We used widely adopted audio and visual features and
different architectures for benchmarking, comparing single-to-single and
multi-to-single domain generalization performance. To further exploit the
impacts using data from multiple source domains for training, we investigate
three types of domain sampling strategies, including domain-simultaneous,
domain-alternating, and domain-by-domain for multi-to-single domain
generalization evaluation. We also propose an algorithm to enhance the
generalization performance by maximizing the gradient inner products between
modality encoders, named ``MM-IDGM". Furthermore, we proposed the
Attention-Mixer fusion method to improve performance, and we believe that this
new cross-domain benchmark will facilitate future research in audio-visual
deception detection.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving curriculum learning for target speaker extraction with
  synthetic speakers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00811v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00811v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yun Liu, Xuechen Liu, Junichi Yamagishi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Target speaker extraction (TSE) aims to isolate individual speaker voices
from complex speech environments. The effectiveness of TSE systems is often
compromised when the speaker characteristics are similar to each other. Recent
research has introduced curriculum learning (CL), in which TSE models are
trained incrementally on speech samples of increasing complexity. In CL
training, the model is first trained on samples with low speaker similarity
between the target and interference speakers, and then on samples with high
speaker similarity. To further improve CL, this paper uses a $k$-nearest
neighbor-based voice conversion method to simulate and generate speech of
diverse interference speakers, and then uses the generated data as part of the
CL. Experiments demonstrate that training data based on synthetic speakers can
effectively enhance the model's capabilities and significantly improve the
performance of multiple TSE systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by SLT2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Database and Benchmark for the Source Speaker Tracing Challenge 2024 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.04951v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.04951v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ze Li, Yuke Lin, Tian Yao, Hongbin Suo, Pengyuan Zhang, Yanzhen Ren, Zexin Cai, Hiromitsu Nishizaki, Ming Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Voice conversion (VC) systems can transform audio to mimic another speaker's
voice, thereby attacking speaker verification (SV) systems. However, ongoing
studies on source speaker verification (SSV) are hindered by limited data
availability and methodological constraints. This paper presents the Source
Speaker Tracking Challenge (SSTC) on STL 2024, which aims to fill the gap in
the database and benchmark for the SSV task. In this study, we generate a
large-scale converted speech database with 16 common VC methods and train a
batch of baseline systems based on the MFA-Conformer architecture. In addition,
we introduced a related task called conversion method recognition, with the aim
of assisting the SSV task. We expect SSTC to be a platform for advancing the
development of the SSV task and provide further insights into the performance
and limitations of current SV systems against VC attacks. Further details about
SSTC can be found in https://sstc-challenge.github.io/.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-10-04T00:00:00Z">2024-10-04</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language <span class="chip" style="font-size: 60%">150</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhance Reasoning by Learning from Mistakes: Peer-<span class="highlight-title">Review</span> Knowledge
  Distillation from Multiple Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03663v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03663v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhuochun Li, Yuelyu Ji, Rui Meng, Daqing He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have exhibited complex reasoning abilities by
generating question rationales and demonstrated exceptional performance in
natural language processing (NLP) tasks. However, these reasoning capabilities
generally emerge in models with tens of billions of parameters, creating
significant computational challenges for real-world deployment. Recent research
has concentrated on improving open-source smaller models through knowledge
distillation (KD) from commercial LLMs. Nevertheless, most of these studies
rely solely on the responses from one single LLM as the gold rationale for
training. In this paper, we introduce a novel Mistake-Aware Peer-Review
Distillation (MAPD) approach: 1) Instead of merely obtaining gold rationales
from teachers, our method asks teachers to identify and explain the student's
mistakes, providing customized instruction learning data. 2) We design a
simulated peer-review process between teacher LLMs, which selects only the
generated rationales above the acceptance threshold. This reduces the chance of
teachers guessing correctly with flawed rationale, improving instructional data
quality. Comprehensive experiments and analysis on mathematical, commonsense,
and logical reasoning tasks demonstrate the effectiveness of our method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unraveling Cross-Modality Knowledge Conflict in Large Vision-Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03659v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03659v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tinghui Zhu, Qin Liu, Fei Wang, Zhengzhong Tu, Muhao Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Vision-Language Models (LVLMs) have demonstrated impressive
capabilities for capturing and reasoning over multimodal inputs. However, these
models are prone to parametric knowledge conflicts, which arise from
inconsistencies of represented knowledge between their vision and language
components. In this paper, we formally define the problem of
$\textbf{cross-modality parametric knowledge conflict}$ and present a
systematic approach to detect, interpret, and mitigate them. We introduce a
pipeline that identifies conflicts between visual and textual answers, showing
a persistently high conflict rate across modalities in recent LVLMs regardless
of the model size. We further investigate how these conflicts interfere with
the inference process and propose a contrastive metric to discern the
conflicting samples from the others. Building on these insights, we develop a
novel dynamic contrastive decoding method that removes undesirable logits
inferred from the less confident modality components based on answer
confidence. For models that do not provide logits, we also introduce two
prompt-based strategies to mitigate the conflicts. Our methods achieve
promising improvements in accuracy on both the ViQuAE and InfoSeek datasets.
Specifically, using LLaVA-34B, our proposed dynamic contrastive decoding
improves an average accuracy of 2.24%.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Website:
  https://darthzhu.github.io/cross-modality-knowledge-conflict/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RAFT: Realistic Attacks to Fool Text Detectors <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03658v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03658v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        James Wang, Ran Li, Junfeng Yang, Chengzhi Mao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have exhibited remarkable fluency across various
tasks. However, their unethical applications, such as disseminating
disinformation, have become a growing concern. Although recent works have
proposed a number of LLM detection methods, their robustness and reliability
remain unclear. In this paper, we present RAFT: a grammar error-free black-box
attack against existing LLM detectors. In contrast to previous attacks for
language models, our method exploits the transferability of LLM embeddings at
the word-level while preserving the original text quality. We leverage an
auxiliary embedding to greedily select candidate words to perturb against the
target detector. Experiments reveal that our attack effectively compromises all
detectors in the study across various domains by up to 99%, and are
transferable across source models. Manual human evaluation studies show our
attacks are realistic and indistinguishable from original human-written text.
We also show that examples generated by RAFT can be used to train adversarially
robust detectors. Our work shows that current LLM detectors are not
adversarially robust, underscoring the urgent need for more resilient detection
mechanisms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Aligning LLMs with Individual Preferences via Interaction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03642v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03642v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shujin Wu, May Fung, Cheng Qian, Jeonghwan Kim, Dilek Hakkani-Tur, Heng Ji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As large language models (LLMs) demonstrate increasingly advanced
capabilities, aligning their behaviors with human values and preferences
becomes crucial for their wide adoption. While previous research focuses on
general alignment to principles such as helpfulness, harmlessness, and honesty,
the need to account for individual and diverse preferences has been largely
overlooked, potentially undermining customized human experiences. To address
this gap, we train LLMs that can ''interact to align'', essentially cultivating
the meta-skill of LLMs to implicitly infer the unspoken personalized
preferences of the current user through multi-turn conversations, and then
dynamically align their following behaviors and responses to these inferred
preferences. Our approach involves establishing a diverse pool of 3,310
distinct user personas by initially creating seed examples, which are then
expanded through iterative self-generation and filtering. Guided by distinct
user personas, we leverage multi-LLM collaboration to develop a multi-turn
preference dataset containing 3K+ multi-turn conversations in tree structures.
Finally, we apply supervised fine-tuning and reinforcement learning to enhance
LLMs using this dataset. For evaluation, we establish the ALOE (ALign With
CustOmized PrEferences) benchmark, consisting of 100 carefully selected
examples and well-designed metrics to measure the customized alignment
performance during conversations. Experimental results demonstrate the
effectiveness of our method in enabling dynamic, personalized alignment via
interaction.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The code and dataset are made public at
  https://github.com/ShujinWu-0814/ALOE</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ What Matters for Model Merging at Scale? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03617v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03617v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Prateek Yadav, Tu Vu, Jonathan Lai, Alexandra Chronopoulou, Manaal Faruqui, Mohit Bansal, Tsendsuren Munkhdalai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Model merging aims to combine multiple expert models into a more capable
single model, offering benefits such as reduced storage and serving costs,
improved generalization, and support for decentralized model development.
Despite its promise, previous studies have primarily focused on merging a few
small models. This leaves many unanswered questions about the effect of scaling
model size and how it interplays with other key factors -- like the base model
quality and number of expert models -- , to affect the merged model's
performance. This work systematically evaluates the utility of model merging at
scale, examining the impact of these different factors. We experiment with
merging fully fine-tuned models using 4 popular merging methods -- Averaging,
Task~Arithmetic, Dare, and TIES -- across model sizes ranging from 1B-64B
parameters and merging up to 8 different expert models. We evaluate the merged
models on both held-in tasks, i.e., the expert's training tasks, and zero-shot
generalization to unseen held-out tasks. Our experiments provide several new
insights about model merging at scale and the interplay between different
factors. First, we find that merging is more effective when experts are created
from strong base models, i.e., models with good zero-shot performance. Second,
larger models facilitate easier merging. Third merging consistently improves
generalization capabilities. Notably, when merging 8 large expert models, the
merged models often generalize better compared to the multitask trained models.
Fourth, we can better merge more expert models when working with larger models.
Fifth, different merging methods behave very similarly at larger scales.
Overall, our findings shed light on some interesting properties of model
merging while also highlighting some limitations. We hope that this study will
serve as a reference point on large-scale merging for upcoming research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 Pages, 7 Figures, 4 Tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TICKing All the Boxes: Generated Checklists Improve LLM Evaluation and
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03608v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03608v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jonathan Cook, Tim Rocktäschel, Jakob Foerster, Dennis Aumiller, Alex Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Given the widespread adoption and usage of Large Language Models (LLMs), it
is crucial to have flexible and interpretable evaluations of their
instruction-following ability. Preference judgments between model outputs have
become the de facto evaluation standard, despite distilling complex,
multi-faceted preferences into a single ranking. Furthermore, as human
annotation is slow and costly, LLMs are increasingly used to make these
judgments, at the expense of reliability and interpretability. In this work, we
propose TICK (Targeted Instruct-evaluation with ChecKlists), a fully automated,
interpretable evaluation protocol that structures evaluations with
LLM-generated, instruction-specific checklists. We first show that, given an
instruction, LLMs can reliably produce high-quality, tailored evaluation
checklists that decompose the instruction into a series of YES/NO questions.
Each question asks whether a candidate response meets a specific requirement of
the instruction. We demonstrate that using TICK leads to a significant increase
(46.4% $\to$ 52.2%) in the frequency of exact agreements between LLM judgements
and human preferences, as compared to having an LLM directly score an output.
We then show that STICK (Self-TICK) can be used to improve generation quality
across multiple benchmarks via self-refinement and Best-of-N selection. STICK
self-refinement on LiveBench reasoning tasks leads to an absolute gain of
$+$7.8%, whilst Best-of-N selection with STICK attains $+$6.3% absolute
improvement on the real-world instruction dataset, WildBench. In light of this,
structured, multi-faceted self-improvement is shown to be a promising way to
further advance LLM capabilities. Finally, by providing LLM-generated
checklists to human evaluators tasked with directly scoring LLM responses to
WildBench instructions, we notably increase inter-annotator agreement (0.194
$\to$ 0.256).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficiently Identifying Watermarked Segments in Mixed-Source Texts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03600v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03600v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuandong Zhao, Chenwen Liao, Yu-Xiang Wang, Lei Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text watermarks in large language models (LLMs) are increasingly used to
detect synthetic text, mitigating misuse cases like fake news and academic
dishonesty. While existing watermarking detection techniques primarily focus on
classifying entire documents as watermarked or not, they often neglect the
common scenario of identifying individual watermark segments within longer,
mixed-source documents. Drawing inspiration from plagiarism detection systems,
we propose two novel methods for partial watermark detection. First, we develop
a geometry cover detection framework aimed at determining whether there is a
watermark segment in long text. Second, we introduce an adaptive online
learning algorithm to pinpoint the precise location of watermark segments
within the text. Evaluated on three popular watermarking techniques
(KGW-Watermark, Unigram-Watermark, and Gumbel-Watermark), our approach achieves
high accuracy, significantly outperforming baseline methods. Moreover, our
framework is adaptable to other watermarking techniques, offering new insights
for precise watermark detection.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Understanding Reasoning in Chain-of-Thought from the Hopfieldian View 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03595v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03595v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lijie Hu, Liang Liu, Shu Yang, Xin Chen, Zhen Tan, Muhammad Asif Ali, Mengdi Li, Di Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models have demonstrated remarkable abilities across various
tasks, with Chain-of-Thought (CoT) prompting emerging as a key technique to
enhance reasoning capabilities. However, existing research primarily focuses on
improving performance, lacking a comprehensive framework to explain and
understand the fundamental factors behind CoT's success. To bridge this gap, we
introduce a novel perspective grounded in the Hopfieldian view of cognition in
cognitive neuroscience. We establish a connection between CoT reasoning and key
cognitive elements such as stimuli, actions, neural populations, and
representation spaces. From our view, we can understand the reasoning process
as the movement between these representation spaces. Building on this insight,
we develop a method for localizing reasoning errors in the response of CoTs.
Moreover, we propose the Representation-of-Thought (RoT) framework, which
leverages the robustness of low-dimensional representation spaces to enhance
the robustness of the reasoning process in CoTs. Experimental results
demonstrate that RoT improves the robustness and interpretability of CoT
reasoning while offering fine-grained control over the reasoning process.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>28 pages, a new version of "A Hopfieldian View-based Interpretation
  for Chain-of-Thought Reasoning"</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Explicit, Implicit, and Scattered: Revisiting Event Extraction to
  Capture Complex Arguments <span class="chip">EMNLP-2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03594v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03594v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Omar Sharif, Joseph Gatto, Madhusudan Basak, Sarah M. Preum
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prior works formulate the extraction of event-specific arguments as a span
extraction problem, where event arguments are explicit -- i.e. assumed to be
contiguous spans of text in a document. In this study, we revisit this
definition of Event Extraction (EE) by introducing two key argument types that
cannot be modeled by existing EE frameworks. First, implicit arguments are
event arguments which are not explicitly mentioned in the text, but can be
inferred through context. Second, scattered arguments are event arguments that
are composed of information scattered throughout the text. These two argument
types are crucial to elicit the full breadth of information required for proper
event modeling.
  To support the extraction of explicit, implicit, and scattered arguments, we
develop a novel dataset, DiscourseEE, which includes 7,464 argument annotations
from online health discourse. Notably, 51.2% of the arguments are implicit, and
17.4% are scattered, making DiscourseEE a unique corpus for complex event
extraction. Additionally, we formulate argument extraction as a text generation
problem to facilitate the extraction of complex argument types. We provide a
comprehensive evaluation of state-of-the-art models and highlight critical open
challenges in generative event extraction. Our data and codebase are available
at https://omar-sharif03.github.io/DiscourseEE.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in EMNLP-2024 (Main). 21 pages, 8 figures, and 11 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Table Question Answering for Low-resourced Indic Languages <span class="chip">EMNLP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03576v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03576v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vaishali Pal, Evangelos Kanoulas, Andrew Yates, Maarten de Rijke
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  TableQA is the task of answering questions over tables of structured
information, returning individual cells or tables as output. TableQA research
has focused primarily on high-resource languages, leaving medium- and
low-resource languages with little progress due to scarcity of annotated data
and neural models. We address this gap by introducing a fully automatic
large-scale tableQA data generation process for low-resource languages with
limited budget. We incorporate our data generation method on two Indic
languages, Bengali and Hindi, which have no tableQA datasets or models. TableQA
models trained on our large-scale datasets outperform state-of-the-art LLMs. We
further study the trained models on different aspects, including mathematical
reasoning capabilities and zero-shot cross-lingual transfer. Our work is the
first on low-resource tableQA focusing on scalable data generation and
evaluation procedures. Our proposed data generation method can be applied to
any low-resource language with a web presence. We release datasets, models, and
code (https://github.com/kolk/Low-Resource-TableQA-Indic-languages).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP,2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Linguistically-Aware and Language-Independent Tokenization for
  Large Language Models (LLMs) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03568v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03568v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abrar Rahman, Garry Bowlin, Binit Mohanty, Sean McGunigal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a comprehensive study on the tokenization techniques
employed by state-of-the-art large language models (LLMs) and their
implications on the cost and availability of services across different
languages, especially low resource languages. The analysis considers multiple
LLMs, including GPT-4 (using cl100k_base embeddings), GPT-3 (with p50k_base
embeddings), and DaVinci (employing r50k_base embeddings), as well as the
widely used BERT base tokenizer. The study evaluates the tokenization
variability observed across these models and investigates the challenges of
linguistic representation in subword tokenization. The research underscores the
importance of fostering linguistically-aware development practices, especially
for languages that are traditionally under-resourced. Moreover, this paper
introduces case studies that highlight the real-world implications of
tokenization choices, particularly in the context of electronic health record
(EHR) systems. This research aims to promote generalizable Internationalization
(I18N) practices in the development of AI services in this domain and beyond,
with a strong emphasis on inclusivity, particularly for languages traditionally
underrepresented in AI applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Structure-Enhanced Protein Instruction Tuning: Towards General-Purpose
  Protein Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03553v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03553v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Wu, Chao Wang, Liyi Chen, Mingze Yin, Yiheng Zhu, Kun Fu, Jieping Ye, Hui Xiong, Zheng Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Proteins, as essential biomolecules, play a central role in biological
processes, including metabolic reactions and DNA replication. Accurate
prediction of their properties and functions is crucial in biological
applications. Recent development of protein language models (pLMs) with
supervised fine tuning provides a promising solution to this problem. However,
the fine-tuned model is tailored for particular downstream prediction task, and
achieving general-purpose protein understanding remains a challenge. In this
paper, we introduce Structure-Enhanced Protein Instruction Tuning (SEPIT)
framework to bridge this gap. Our approach integrates a noval structure-aware
module into pLMs to inform them with structural knowledge, and then connects
these enhanced pLMs to large language models (LLMs) to generate understanding
of proteins. In this framework, we propose a novel two-stage instruction tuning
pipeline that first establishes a basic understanding of proteins through
caption-based instructions and then refines this understanding using a mixture
of experts (MoEs) to learn more complex properties and functional information
with the same amount of activated parameters. Moreover, we construct the
largest and most comprehensive protein instruction dataset to date, which
allows us to train and evaluate the general-purpose protein understanding
model. Extensive experimental results on open-ended generation and closed-set
answer tasks demonstrate the superior performance of SEPIT over both
closed-source general LLMs and open-source LLMs trained with protein knowledge.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Data Quality through Simple De-duplication: Navigating
  Responsible Computational Social Science Research <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03545v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03545v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yida Mu, Mali Jin, Xingyi Song, Nikolaos Aletras
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Research in natural language processing (NLP) for Computational Social
Science (CSS) heavily relies on data from social media platforms. This data
plays a crucial role in the development of models for analysing
socio-linguistic phenomena within online communities. In this work, we conduct
an in-depth examination of 20 datasets extensively used in NLP for CSS to
comprehensively examine data quality. Our analysis reveals that social media
datasets exhibit varying levels of data duplication. Consequently, this gives
rise to challenges like label inconsistencies and data leakage, compromising
the reliability of models. Our findings also suggest that data duplication has
an impact on the current claims of state-of-the-art performance, potentially
leading to an overestimation of model effectiveness in real-world scenarios.
Finally, we propose new protocols and best practices for improving dataset
development from social media data and its usage.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Re-examining Sexism and Misogyny Classification with Annotator Attitudes <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03543v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03543v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aiqi Jiang, Nikolas Vitsakis, Tanvi Dinkar, Gavin Abercrombie, Ioannis Konstas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Gender-Based Violence (GBV) is an increasing problem online, but existing
datasets fail to capture the plurality of possible annotator perspectives or
ensure the representation of affected groups. We revisit two important stages
in the moderation pipeline for GBV: (1) manual data labelling; and (2)
automated classification. For (1), we examine two datasets to investigate the
relationship between annotator identities and attitudes and the responses they
give to two GBV labelling tasks. To this end, we collect demographic and
attitudinal information from crowd-sourced annotators using three validated
surveys from Social Psychology. We find that higher Right Wing Authoritarianism
scores are associated with a higher propensity to label text as sexist, while
for Social Dominance Orientation and Neosexist Attitudes, higher scores are
associated with a negative tendency to do so. For (2), we conduct
classification experiments using Large Language Models and five prompting
strategies, including infusing prompts with annotator information. We find: (i)
annotator attitudes affect the ability of classifiers to predict their labels;
(ii) including attitudinal information can boost performance when we use
well-structured brief annotator descriptions; and (iii) models struggle to
reflect the increased complexity and imbalanced classes of the new label sets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MARE: Multi-Aspect Rationale Extractor on Unsupervised Rationale
  Extraction <span class="chip">EMNLP2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03531v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03531v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Han Jiang, Junwen Duan, Zhe Qu, Jianxin Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Unsupervised rationale extraction aims to extract text snippets to support
model predictions without explicit rationale annotation. Researchers have made
many efforts to solve this task. Previous works often encode each aspect
independently, which may limit their ability to capture meaningful internal
correlations between aspects. While there has been significant work on
mitigating spurious correlations, our approach focuses on leveraging the
beneficial internal correlations to improve multi-aspect rationale extraction.
In this paper, we propose a Multi-Aspect Rationale Extractor (MARE) to explain
and predict multiple aspects simultaneously. Concretely, we propose a
Multi-Aspect Multi-Head Attention (MAMHA) mechanism based on hard deletion to
encode multiple text chunks simultaneously. Furthermore, multiple special
tokens are prepended in front of the text with each corresponding to one
certain aspect. Finally, multi-task training is deployed to reduce the training
overhead. Experimental results on two unsupervised rationale extraction
benchmarks show that MARE achieves state-of-the-art performance. Ablation
studies further demonstrate the effectiveness of our method. Our codes have
been available at https://github.com/CSU-NLP-Group/MARE.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in EMNLP2024(Main) conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ No Need to Talk: Asynchronous Mixture of Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03529v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03529v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anastasiia Filippova, Angelos Katharopoulos, David Grangier, Ronan Collobert
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce SmallTalk LM, an innovative method for training a mixture of
language models in an almost asynchronous manner. Each model of the mixture
specializes in distinct parts of the data distribution, without the need of
high-bandwidth communication between the nodes training each model. At
inference, a lightweight router directs a given sequence to a single expert,
according to a short prefix. This inference scheme naturally uses a fraction of
the parameters from the overall mixture model. Our experiments on language
modeling demonstrate tha SmallTalk LM achieves significantly lower perplexity
than dense model baselines for the same total training FLOPs and an almost
identical inference cost. Finally, in our downstream evaluations we outperform
the dense baseline on $75\%$ of the tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Steering Large Language Models between Code Execution and Textual
  Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03524v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03524v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yongchao Chen, Harsh Jhamtani, Srinagesh Sharma, Chuchu Fan, Chi Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While a lot of recent research focuses on enhancing the textual reasoning
capabilities of Large Language Models (LLMs) by optimizing the multi-agent
framework or reasoning chains, several benchmark tasks can be solved with 100%
success through direct coding, which is more scalable and avoids the
computational overhead associated with textual iterating and searching. Textual
reasoning has inherent limitations in solving tasks with challenges in math,
logics, optimization, and searching, which is unlikely to be solved by simply
scaling up the model and data size. The recently released OpenAI GPT Code
Interpreter and multi-agent frameworks such as AutoGen have demonstrated
remarkable proficiency of integrating code generation and execution to solve
complex tasks using LLMs. However, based on our experiments on 7 existing
popular methods for steering code/text generation in both single- and
multi-turn settings with 14 tasks and 6 types of LLMs (including the new
O1-preview), currently there is no optimal method to correctly steer LLMs to
write code when needed. We discover some interesting patterns on when models
use code vs. textual reasoning with the evolution to task complexity and model
sizes, which even result in an astonishingly inverse scaling law. We also
discover that results from LLM written code are not always better than using
textual reasoning, even if the task could be solved through code. To mitigate
the above issues, we propose three methods to better steer LLM code/text
generation and achieve a notable improvement. The costs of token lengths and
runtime are thoroughly discussed for all the methods. We believe the problem of
steering LLM code/text generation is critical for future research and has much
space for further improvement. Project Page, Datasets, and Codes are available
at https://yongchao98.github.io/CodeSteer/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>32 pages, 12 figures, 12 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical
  Large Language Models in Clinical Scenarios 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03502v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03502v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zetian Ouyang, Yishuai Qiu, Linlin Wang, Gerard de Melo, Ya Zhang, Yanfeng Wang, Liang He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the proliferation of Large Language Models (LLMs) in diverse domains,
there is a particular need for unified evaluation standards in clinical medical
scenarios, where models need to be examined very thoroughly. We present
CliMedBench, a comprehensive benchmark with 14 expert-guided core clinical
scenarios specifically designed to assess the medical ability of LLMs across 7
pivot dimensions. It comprises 33,735 questions derived from real-world medical
reports of top-tier tertiary hospitals and authentic examination exercises. The
reliability of this benchmark has been confirmed in several ways. Subsequent
experiments with existing LLMs have led to the following findings: (i) Chinese
medical LLMs underperform on this benchmark, especially where medical reasoning
and factual consistency are vital, underscoring the need for advances in
clinical knowledge and diagnostic accuracy. (ii) Several general-domain LLMs
demonstrate substantial potential in medical clinics, while the limited input
capacity of many medical LLMs hinders their practical use. These findings
reveal both the strengths and limitations of LLMs in clinical scenarios and
offer critical insights for medical research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accepted by ENMLP-2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Reproducible LLM Evaluation: Quantifying Uncertainty in LLM
  Benchmark Scores 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03492v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03492v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Robert E. Blackwell, Jon Barry, Anthony G. Cohn
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) are stochastic, and not all models give
deterministic answers, even when setting temperature to zero with a fixed
random seed. However, few benchmark studies attempt to quantify uncertainty,
partly due to the time and cost of repeated experiments. We use benchmarks
designed for testing LLMs' capacity to reason about cardinal directions to
explore the impact of experimental repeats on mean score and prediction
interval. We suggest a simple method for cost-effectively quantifying the
uncertainty of a benchmark score and make recommendations concerning
reproducible LLM evaluation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 pages, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Is Safer Better? The Impact of Guardrails on the Argumentative Strength
  of LLMs in Hate Speech Countering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03466v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03466v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Helena Bonaldi, Greta Damo, Nicolás Benjamín Ocampo, Elena Cabrio, Serena Villata, Marco Guerini
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The potential effectiveness of counterspeech as a hate speech mitigation
strategy is attracting increasing interest in the NLG research community,
particularly towards the task of automatically producing it. However,
automatically generated responses often lack the argumentative richness which
characterises expert-produced counterspeech. In this work, we focus on two
aspects of counterspeech generation to produce more cogent responses. First, by
investigating the tension between helpfulness and harmlessness of LLMs, we test
whether the presence of safety guardrails hinders the quality of the
generations. Secondly, we assess whether attacking a specific component of the
hate speech results in a more effective argumentative strategy to fight online
hate. By conducting an extensive human and automatic evaluation, we show how
the presence of safety guardrails can be detrimental also to a task that
inherently aims at fostering positive social interactions. Moreover, our
results show that attacking a specific component of the hate speech, and in
particular its implicit negative stereotype and its hateful parts, leads to
higher-quality generations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear in Proceedings of the 2024 Conference on Empirical Methods
  in Natural Language Processing (long paper)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Auto-GDA: Automatic Domain Adaptation for Efficient Grounding
  Verification in Retrieval Augmented Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03461v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03461v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tobias Leemann, Periklis Petridis, Giuseppe Vietri, Dionysis Manousakas, Aaron Roth, Sergul Aydore
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While retrieval augmented generation (RAG) has been shown to enhance
factuality of large language model (LLM) outputs, LLMs still suffer from
hallucination, generating incorrect or irrelevant information. One common
detection strategy involves prompting the LLM again to assess whether its
response is grounded in the retrieved evidence, but this approach is costly.
Alternatively, lightweight natural language inference (NLI) models for
efficient grounding verification can be used at inference time. While existing
pre-trained NLI models offer potential solutions, their performance remains
subpar compared to larger models on realistic RAG inputs. RAG inputs are more
complex than most datasets used for training NLI models and have
characteristics specific to the underlying knowledge base, requiring adaptation
of the NLI models to a specific target domain. Additionally, the lack of
labeled instances in the target domain makes supervised domain adaptation,
e.g., through fine-tuning, infeasible. To address these challenges, we
introduce Automatic Generative Domain Adaptation (Auto-GDA). Our framework
enables unsupervised domain adaptation through synthetic data generation.
Unlike previous methods that rely on handcrafted filtering and augmentation
strategies, Auto-GDA employs an iterative process to continuously improve the
quality of generated samples using weak labels from less efficient teacher
models and discrete optimization to select the most promising augmented
samples. Experimental results demonstrate the effectiveness of our approach,
with models fine-tuned on synthetic data using Auto-GDA often surpassing the
performance of the teacher model and reaching the performance level of LLMs at
10 % of their computational cost.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multi-Dialect Vietnamese: Task, <span class="highlight-title">Dataset</span>, Baseline Models and Challenges <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03458v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03458v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nguyen Van Dinh, Thanh Chi Dang, Luan Thanh Nguyen, Kiet Van Nguyen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vietnamese, a low-resource language, is typically categorized into three
primary dialect groups that belong to Northern, Central, and Southern Vietnam.
However, each province within these regions exhibits its own distinct
pronunciation variations. Despite the existence of various speech recognition
datasets, none of them has provided a fine-grained classification of the 63
dialects specific to individual provinces of Vietnam. To address this gap, we
introduce Vietnamese Multi-Dialect (ViMD) dataset, a novel comprehensive
dataset capturing the rich diversity of 63 provincial dialects spoken across
Vietnam. Our dataset comprises 102.56 hours of audio, consisting of
approximately 19,000 utterances, and the associated transcripts contain over
1.2 million words. To provide benchmarks and simultaneously demonstrate the
challenges of our dataset, we fine-tune state-of-the-art pre-trained models for
two downstream tasks: (1) Dialect identification and (2) Speech recognition.
The empirical results suggest two implications including the influence of
geographical factors on dialects, and the constraints of current approaches in
speech recognition tasks involving multi-dialect speech data. Our dataset is
available for research purposes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Main EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CoCoLoFa: A <span class="highlight-title">Dataset</span> of News Comments with Common Logical Fallacies
  Written by LLM-Assisted Crowds <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03457v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03457v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Min-Hsuan Yeh, Ruyuan Wan, Ting-Hao 'Kenneth' Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Detecting logical fallacies in texts can help users spot argument flaws, but
automating this detection is not easy. Manually annotating fallacies in
large-scale, real-world text data to create datasets for developing and
validating detection models is costly. This paper introduces CoCoLoFa, the
largest known logical fallacy dataset, containing 7,706 comments for 648 news
articles, with each comment labeled for fallacy presence and type. We recruited
143 crowd workers to write comments embodying specific fallacy types (e.g.,
slippery slope) in response to news articles. Recognizing the complexity of
this writing task, we built an LLM-powered assistant into the workers'
interface to aid in drafting and refining their comments. Experts rated the
writing quality and labeling validity of CoCoLoFa as high and reliable.
BERT-based models fine-tuned using CoCoLoFa achieved the highest fallacy
detection (F1=0.86) and classification (F1=0.87) performance on its test set,
outperforming the state-of-the-art LLMs. Our work shows that combining
crowdsourcing and LLMs enables us to more effectively construct datasets for
complex linguistic phenomena that crowd workers find challenging to produce on
their own.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>In Proceedings of the 2024 Conference on Empirical Methods in Natural
  Language Processing (EMNLP 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ How Language Models Prioritize Contextual Grammatical Cues? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03447v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03447v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hamidreza Amirzadeh, Afra Alishahi, Hosein Mohebbi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformer-based language models have shown an excellent ability to
effectively capture and utilize contextual information. Although various
analysis techniques have been used to quantify and trace the contribution of
single contextual cues to a target task such as subject-verb agreement or
coreference resolution, scenarios in which multiple relevant cues are available
in the context remain underexplored. In this paper, we investigate how language
models handle gender agreement when multiple gender cue words are present, each
capable of independently disambiguating a target gender pronoun. We analyze two
widely used Transformer-based models: BERT, an encoder-based, and GPT-2, a
decoder-based model. Our analysis employs two complementary approaches: context
mixing analysis, which tracks information flow within the model, and a variant
of activation patching, which measures the impact of cues on the model's
prediction. We find that BERT tends to prioritize the first cue in the context
to form both the target word representations and the model's prediction, while
GPT-2 relies more on the final cue. Our findings reveal striking differences in
how encoder-based and decoder-based models prioritize and use contextual
information for their predictions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to BlackboxNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On Uncertainty In Natural Language Processing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03446v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03446v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dennis Ulmer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The last decade in deep learning has brought on increasingly capable systems
that are deployed on a wide variety of applications. In natural language
processing, the field has been transformed by a number of breakthroughs
including large language models, which are used in increasingly many
user-facing applications. In order to reap the benefits of this technology and
reduce potential harms, it is important to quantify the reliability of model
predictions and the uncertainties that shroud their development.
  This thesis studies how uncertainty in natural language processing can be
characterized from a linguistic, statistical and neural perspective, and how it
can be reduced and quantified through the design of the experimental pipeline.
We further explore uncertainty quantification in modeling by theoretically and
empirically investigating the effect of inductive model biases in text
classification tasks. The corresponding experiments include data for three
different languages (Danish, English and Finnish) and tasks as well as a large
set of different uncertainty quantification approaches. Additionally, we
propose a method for calibrated sampling in natural language generation based
on non-exchangeable conformal prediction, which provides tighter token sets
with better coverage of the actual continuation. Lastly, we develop an approach
to quantify confidence in large black-box language models using auxiliary
predictors, where the confidence is predicted from the input to and generated
output text of the target model alone.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>PhD thesis</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Exploring the Benefit of Activation Sparsity in <span class="highlight-title">Pre-train</span>ing <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03440v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03440v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhengyan Zhang, Chaojun Xiao, Qiujieli Qin, Yankai Lin, Zhiyuan Zeng, Xu Han, Zhiyuan Liu, Ruobing Xie, Maosong Sun, Jie Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pre-trained Transformers inherently possess the characteristic of sparse
activation, where only a small fraction of the neurons are activated for each
token. While sparse activation has been explored through post-training methods,
its potential in pre-training remains untapped. In this work, we first study
how activation properties change during pre-training. Our examination reveals
that Transformers exhibit sparse activation throughout the majority of the
pre-training process while the activation correlation keeps evolving as
training progresses. Leveraging this observation, we propose Switchable
Sparse-Dense Learning (SSD). SSD adaptively switches between the
Mixtures-of-Experts (MoE) based sparse training and the conventional dense
training during the pre-training process, leveraging the efficiency of sparse
training and avoiding the static activation correlation of sparse training.
Compared to dense training, SSD achieves comparable performance with identical
model size and reduces pre-training costs. Moreover, the models trained with
SSD can be directly used as MoE models for sparse inference and achieve the
same performance as dense models with up to $2\times$ faster inference speed.
Codes are available at https://github.com/thunlp/moefication.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICML 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ToolGen: Unified Tool Retrieval and Calling via Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03439v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03439v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Renxi Wang, Xudong Han, Lei Ji, Shu Wang, Timothy Baldwin, Haonan Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As large language models (LLMs) advance, their inability to autonomously
execute tasks by directly interacting with external tools remains a critical
limitation. Traditional methods rely on inputting tool descriptions as context,
which is constrained by context length and requires separate, often
inefficient, retrieval mechanisms. We introduce ToolGen, a paradigm shift that
integrates tool knowledge directly into the LLM's parameters by representing
each tool as a unique token. This enables the LLM to generate tool calls and
arguments as part of its next token prediction capabilities, seamlessly
blending tool invocation with language generation. Our framework allows the LLM
to access and utilize a vast amount of tools with no additional retrieval step,
significantly enhancing both performance and scalability. Experimental results
with over 47,000 tools show that ToolGen not only achieves superior results in
both tool retrieval and autonomous task completion but also sets the stage for
a new era of AI agents that can adapt to tools across diverse domains. By
fundamentally transforming tool retrieval into a generative process, ToolGen
paves the way for more versatile, efficient, and autonomous AI systems. ToolGen
enables end-to-end tool learning and opens opportunities for integration with
other advanced techniques such as chain-of-thought and reinforcement learning,
thereby expanding the practical capabilities of LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A General Framework for Producing Interpretable Semantic Text Embeddings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03435v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03435v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiqun Sun, Qiang Huang, Yixuan Tang, Anthony K. H. Tung, Jun Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Semantic text embedding is essential to many tasks in Natural Language
Processing (NLP). While black-box models are capable of generating high-quality
embeddings, their lack of interpretability limits their use in tasks that
demand transparency. Recent approaches have improved interpretability by
leveraging domain-expert-crafted or LLM-generated questions, but these methods
rely heavily on expert input or well-prompt design, which restricts their
generalizability and ability to generate discriminative questions across a wide
range of tasks. To address these challenges, we introduce \algo{CQG-MBQA}
(Contrastive Question Generation - Multi-task Binary Question Answering), a
general framework for producing interpretable semantic text embeddings across
diverse tasks. Our framework systematically generates highly discriminative,
low cognitive load yes/no questions through the \algo{CQG} method and answers
them efficiently with the \algo{MBQA} model, resulting in interpretable
embeddings in a cost-effective manner. We validate the effectiveness and
interpretability of \algo{CQG-MBQA} through extensive experiments and ablation
studies, demonstrating that it delivers embedding quality comparable to many
advanced black-box models while maintaining inherently interpretability.
Additionally, \algo{CQG-MBQA} outperforms other interpretable text embedding
methods across various downstream tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 5 figures, and 9 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Images Speak Volumes: User-Centric Assessment of Image Generation for
  Accessible Communication 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03430v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03430v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Miriam Anschütz, Tringa Sylaj, Georg Groh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Explanatory images play a pivotal role in accessible and easy-to-read (E2R)
texts. However, the images available in online databases are not tailored
toward the respective texts, and the creation of customized images is
expensive. In this large-scale study, we investigated whether text-to-image
generation models can close this gap by providing customizable images quickly
and easily. We benchmarked seven, four open- and three closed-source, image
generation models and provide an extensive evaluation of the resulting images.
In addition, we performed a user study with people from the E2R target group to
examine whether the images met their requirements. We find that some of the
models show remarkable performance, but none of the models are ready to be used
at a larger scale without human supervision. Our research is an important step
toward facilitating the creation of accessible information for E2R creators and
tailoring accessible images to the target group's needs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To be published at TSAR workshop 2024
  (https://tsar-workshop.github.io/)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ How Hard is this Test Set? NLI Characterization by Exploiting Training
  Dynamics <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03429v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03429v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Adrian Cosma, Stefan Ruseti, Mihai Dascalu, Cornelia Caragea
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Natural Language Inference (NLI) evaluation is crucial for assessing language
understanding models; however, popular datasets suffer from systematic spurious
correlations that artificially inflate actual model performance. To address
this, we propose a method for the automated creation of a challenging test set
without relying on the manual construction of artificial and unrealistic
examples. We categorize the test set of popular NLI datasets into three
difficulty levels by leveraging methods that exploit training dynamics. This
categorization significantly reduces spurious correlation measures, with
examples labeled as having the highest difficulty showing markedly decreased
performance and encompassing more realistic and diverse linguistic phenomena.
When our characterization method is applied to the training set, models trained
with only a fraction of the data achieve comparable performance to those
trained on the full dataset, surpassing other dataset characterization
techniques. Our research addresses limitations in NLI dataset construction,
providing a more authentic evaluation of model performance with implications
for diverse NLU applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ One2set + Large Language Model: Best Partners for Keyphrase Generation <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03421v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03421v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liangying Shao, Liang Zhang, Minlong Peng, Guoqi Ma, Hao Yue, Mingming Sun, Jinsong Su
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Keyphrase generation (KPG) aims to automatically generate a collection of
phrases representing the core concepts of a given document. The dominant
paradigms in KPG include one2seq and one2set. Recently, there has been
increasing interest in applying large language models (LLMs) to KPG. Our
preliminary experiments reveal that it is challenging for a single model to
excel in both recall and precision. Further analysis shows that: 1) the one2set
paradigm owns the advantage of high recall, but suffers from improper
assignments of supervision signals during training; 2) LLMs are powerful in
keyphrase selection, but existing selection methods often make redundant
selections. Given these observations, we introduce a generate-then-select
framework decomposing KPG into two steps, where we adopt a one2set-based model
as generator to produce candidates and then use an LLM as selector to select
keyphrases from these candidates. Particularly, we make two important
improvements on our generator and selector: 1) we design an Optimal
Transport-based assignment strategy to address the above improper assignments;
2) we model the keyphrase selection as a sequence labeling task to alleviate
redundant selections. Experimental results on multiple benchmark datasets show
that our framework significantly surpasses state-of-the-art models, especially
in absent keyphrase prediction.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Surgical, Cheap, and Flexible: Mitigating False Refusal in Language
  Models via Single Vector Ablation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03415v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03415v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinpeng Wang, Chengzhi Hu, Paul Röttger, Barbara Plank
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Training a language model to be both helpful and harmless requires careful
calibration of refusal behaviours: Models should refuse to follow malicious
instructions or give harmful advice (e.g. "how do I kill someone?"), but they
should not refuse safe requests, even if they superficially resemble unsafe
ones (e.g. "how do I kill a Python process?"). Avoiding such false refusal, as
prior work has shown, is challenging even for highly-capable language models.
In this paper, we propose a simple and surgical method for mitigating false
refusal in language models via single vector ablation. For a given model, we
extract a false refusal vector and show that ablating this vector reduces false
refusal rate without negatively impacting model safety and general model
capabilities. We also show that our approach can be used for fine-grained
calibration of model safety. Our approach is training-free and model-agnostic,
making it useful for mitigating the problem of false refusal in current and
future language models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Team MTS @ AutoMin 2021: An <span class="highlight-title">Overview</span> of Existing Summarization
  Approaches and Comparison to Unsupervised Summarization Techniques 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03412v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03412v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Olga Iakovenko, Anna Andreeva, Anna Lapidus, Liana Mikaelyan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Remote communication through video or audio conferences has become more
popular than ever because of the worldwide pandemic. These events, therefore,
have provoked the development of systems for automatic minuting of spoken
language leading to AutoMin 2021 challenge. The following paper illustrates the
results of the research that team MTS has carried out while participating in
the Automatic Minutes challenge. In particular, in this paper we analyze
existing approaches to text and speech summarization, propose an unsupervised
summarization technique based on clustering and provide a pipeline that
includes an adapted automatic speech recognition block able to run on real-life
recordings. The proposed unsupervised technique outperforms pre-trained
summarization models on the automatic minuting task with Rouge 1, Rouge 2 and
Rouge L values of 0.21, 0.02 and 0.2 on the dev set, with Rouge 1, Rouge 2,
Rouge L, Adequacy, Grammatical correctness and Fluency values of 0.180, 0.035,
0.098, 1.857, 2.304, 1.911 on the test set accordingly
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>First Shared Task on Automatic Minuting at Interspeech 2021</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Killing Two Flies with One Stone: An Attempt to Break LLMs Using
  English->Icelandic Idioms and Proper Names 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03394v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03394v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bjarki Ármannsson, Hinrik Hafsteinsson, Atli Jasonarson, Steinþór Steingrímsson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents the submission of the \'Arni Magn\'usson Institute's team
to the WMT24 test suite subtask, focusing on idiomatic expressions and proper
names for the English->Icelandic translation direction.
  Intuitively and empirically, idioms and proper names are known to be a
significant challenge for modern translation models. We create two different
test suites. The first evaluates the competency of MT systems in translating
common English idiomatic expressions, as well as testing whether systems can
distinguish between those expressions and the same phrases when used in a
literal context. The second test suite consists of place names that should be
translated into their Icelandic exonyms (and correctly inflected) and pairs of
Icelandic names that share a surface form between the male and female variants,
so that incorrect translations impact meaning as well as readability.
  The scores reported are relatively low, especially for idiomatic expressions
and place names, and indicate considerable room for improvement.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>WMT24 MT Test Suites subtask. 8 pages, 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cogs in a Machine, Doing What They're Meant to Do -- The AMI Submission
  to the WMT24 General Translation Task 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03381v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03381v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Atli Jasonarson, Hinrik Hafsteinsson, Bjarki Ármannsson, Steinþór Steingrímsson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents the submission of the \'Arni Magnusson Institute's team
to the WMT24 General translation task. We work on the English->Icelandic
translation direction. Our system comprises four translation models and a
grammar correction model. For training our models we carefully curate our
datasets, aggressively filtering out sentence pairs that may detrimentally
affect the quality of our system's output. Some of our data are collected from
human translations and some are synthetically generated. A part of the
synthetic data is generated using an LLM, and we find that it increases the
translation capability of our system significantly.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>WMT24 General Translation Task System Description Paper, 10 pages, 1
  figure, 6 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Should Cross-Lingual AMR Parsing go Meta? An Empirical Assessment of
  Meta-Learning and Joint Learning AMR Parsing <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03357v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03357v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jeongwoo Kang, Maximin Coavoux, Cédric Lopez, Didier Schwab
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cross-lingual AMR parsing is the task of predicting AMR graphs in a target
language when training data is available only in a source language. Due to the
small size of AMR training data and evaluation data, cross-lingual AMR parsing
has only been explored in a small set of languages such as English, Spanish,
German, Chinese, and Italian. Taking inspiration from Langedijk et al. (2022),
who apply meta-learning to tackle cross-lingual syntactic parsing, we
investigate the use of meta-learning for cross-lingual AMR parsing. We evaluate
our models in $k$-shot scenarios (including 0-shot) and assess their
effectiveness in Croatian, Farsi, Korean, Chinese, and French. Notably, Korean
and Croatian test sets are developed as part of our work, based on the existing
The Little Prince English AMR corpus, and made publicly available. We
empirically study our method by comparing it to classical joint learning. Our
findings suggest that while the meta-learning model performs slightly better in
0-shot evaluation for certain languages, the performance gain is minimal or
absent when $k$ is higher than 0.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>to appear in Findings of EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generating Equivalent Representations of Code By A Self-Reflection
  Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03351v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03351v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jia Li, Ge Li, Lecheng Wang, Hao Zhu, Zhi Jin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Equivalent Representations (ERs) of code are textual representations that
preserve the same semantics as the code itself, e.g., natural language comments
and pseudocode. ERs play a critical role in software development and
maintenance. However, how to automatically generate ERs of code remains an open
challenge. In this paper, we propose a self-reflection approach to generating
ERs of code. It enables two Large Language Models (LLMs) to work mutually and
produce an ER through a reflection process. Depending on whether constraints on
ERs are applied, our approach generates ERs in both open and constrained
settings. We conduct a empirical study to generate ERs in two settings and
obtain eight findings. (1) Generating ERs in the open setting. In the open
setting, we allow LLMs to represent code without any constraints, analyzing the
resulting ERs and uncovering five key findings. These findings shed light on
how LLMs comprehend syntactic structures, APIs, and numerical computations in
code. (2) Generating ERs in the constrained setting. In the constrained
setting, we impose constraints on ERs, such as natural language comments,
pseudocode, and flowcharts. This allows our approach to address a range of
software engineering tasks. Based on our experiments, we have three findings
demonstrating that our approach can effectively generate ERs that adhere to
specific constraints, thus supporting various software engineering tasks. (3)
Future directions. We also discuss potential future research directions, such
as deriving intermediate languages for code generation, exploring LLM-friendly
requirement descriptions, and further supporting software engineering tasks. We
believe that this paper will spark discussions in research communities and
inspire many follow-up studies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Zero-Shot Fact Verification via Natural Logic and Large Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03341v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03341v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marek Strong, Rami Aly, Andreas Vlachos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The recent development of fact verification systems with natural logic has
enhanced their explainability by aligning claims with evidence through
set-theoretic operators, providing faithful justifications. Despite these
advancements, such systems often rely on a large amount of training data
annotated with natural logic. To address this issue, we propose a zero-shot
method that utilizes the generalization capabilities of instruction-tuned large
language models. To comprehensively assess the zero-shot capabilities of our
method and other fact verification systems, we evaluate all models on both
artificial and real-world claims, including multilingual datasets. We also
compare our method against other fact verification systems in two setups.
First, in the zero-shot generalization setup, we demonstrate that our approach
outperforms other systems that were not specifically trained on natural logic
data, achieving an average accuracy improvement of 8.96 points over the
best-performing baseline. Second, in the zero-shot transfer setup, we show that
current systems trained on natural logic data do not generalize well to other
domains, and our method outperforms these systems across all datasets with
real-world claims.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Context and System Fusion in Post-ASR Emotion Recognition with Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03312v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03312v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pavel Stepachev, Pinzhen Chen, Barry Haddow
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have started to play a vital role in modelling
speech and text. To explore the best use of context and multiple systems'
outputs for post-ASR speech emotion prediction, we study LLM prompting on a
recent task named GenSEC. Our techniques include ASR transcript ranking,
variable conversation context, and system output fusion. We show that the
conversation context has diminishing returns and the metric used to select the
transcript for prediction is crucial. Finally, our best submission surpasses
the provided baseline by 20% in absolute accuracy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Comparing zero-shot self-explanations with human rationales in
  multilingual text classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03296v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03296v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Stephanie Brandl, Oliver Eberle
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Instruction-tuned LLMs are able to provide an explanation about their output
to users by generating self-explanations that do not require gradient
computations or the application of possibly complex XAI methods. In this paper,
we analyse whether this ability results in a good explanation by evaluating
self-explanations in the form of input rationales with respect to their
plausibility to humans as well as their faithfulness to models. For this, we
apply two text classification tasks: sentiment classification and forced labour
detection. Next to English, we further include Danish and Italian translations
of the sentiment classification task and compare self-explanations to human
annotations for all samples. To allow for direct comparisons, we also compute
post-hoc feature attribution, i.e., layer-wise relevance propagation (LRP) and
apply this pipeline to 4 LLMs (Llama2, Llama3, Mistral and Mixtral). Our
results show that self-explanations align more closely with human annotations
compared to LRP, while maintaining a comparable level of faithfulness.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Five Years of COVID-19 Discourse on Instagram: A Labeled Instagram
  <span class="highlight-title">Dataset</span> of Over Half a Million Posts for Multilingual Sentiment Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03293v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03293v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nirmalya Thakur
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The work presented in this paper makes three scientific contributions with a
specific focus on mining and analysis of COVID-19-related posts on Instagram.
First, it presents a multilingual dataset of 500,153 Instagram posts about
COVID-19 published between January 2020 and September 2024. This dataset,
available at https://dx.doi.org/10.21227/d46p-v480, contains Instagram posts in
161 different languages as well as 535,021 distinct hashtags. After the
development of this dataset, multilingual sentiment analysis was performed,
which involved classifying each post as positive, negative, or neutral. The
results of sentiment analysis are presented as a separate attribute in this
dataset. Second, it presents the results of performing sentiment analysis per
year from 2020 to 2024. The findings revealed the trends in sentiment related
to COVID-19 on Instagram since the beginning of the pandemic. For instance,
between 2020 and 2024, the sentiment trends show a notable shift, with positive
sentiment decreasing from 38.35% to 28.69%, while neutral sentiment rising from
44.19% to 58.34%. Finally, the paper also presents findings of
language-specific sentiment analysis. This analysis highlighted similar and
contrasting trends of sentiment across posts published in different languages
on Instagram. For instance, out of all English posts, 49.68% were positive,
14.84% were negative, and 35.48% were neutral. In contrast, among Hindi posts,
4.40% were positive, 57.04% were negative, and 38.56% were neutral, reflecting
distinct differences in the sentiment distribution between these two languages.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ What do Large Language Models Need for Machine Translation Evaluation? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03278v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03278v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shenbin Qian, Archchana Sindhujan, Minnie Kabra, Diptesh Kanojia, Constantin Orăsan, Tharindu Ranasinghe, Frédéric Blain
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Leveraging large language models (LLMs) for various natural language
processing tasks has led to superlative claims about their performance. For the
evaluation of machine translation (MT), existing research shows that LLMs are
able to achieve results comparable to fine-tuned multilingual pre-trained
language models. In this paper, we explore what translation information, such
as the source, reference, translation errors and annotation guidelines, is
needed for LLMs to evaluate MT quality. In addition, we investigate prompting
techniques such as zero-shot, Chain of Thought (CoT) and few-shot prompting for
eight language pairs covering high-, medium- and low-resource languages,
leveraging varying LLM variants. Our findings indicate the importance of
reference translations for an LLM-based evaluation. While larger models do not
necessarily fare better, they tend to benefit more from CoT prompting, than
smaller models. We also observe that LLMs do not always provide a numerical
score when generating evaluations, which poses a question on their reliability
for the task. Our work presents a comprehensive analysis for
resource-constrained and training-less LLM-based evaluation of machine
translation. We release the accrued prompt templates, code and data publicly
for reproducibility.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Multi-task Learning Framework for Evaluating Machine Translation of
  Emotion-loaded User-generated Content 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03277v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03277v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shenbin Qian, Constantin Orăsan, Diptesh Kanojia, Félix do Carmo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine translation (MT) of user-generated content (UGC) poses unique
challenges, including handling slang, emotion, and literary devices like irony
and sarcasm. Evaluating the quality of these translations is challenging as
current metrics do not focus on these ubiquitous features of UGC. To address
this issue, we utilize an existing emotion-related dataset that includes
emotion labels and human-annotated translation errors based on
Multi-dimensional Quality Metrics. We extend it with sentence-level evaluation
scores and word-level labels, leading to a dataset suitable for sentence- and
word-level translation evaluation and emotion classification, in a multi-task
setting. We propose a new architecture to perform these tasks concurrently,
with a novel combined loss function, which integrates different loss
heuristics, like the Nash and Aligned losses. Our evaluation compares existing
fine-tuning and multi-task learning approaches, assessing generalization with
ablative experiments over multiple datasets. Our approach achieves
state-of-the-art performance and we present a comprehensive analysis for MT
evaluation of UGC.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Adaptive BPE Tokenization for Enhanced Vocabulary Adaptation in
  Finetuning <span class="highlight-title">Pretrain</span>ed Language Models <span class="chip">EMNLP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03258v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03258v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gunjan Balde, Soumyadeep Roy, Mainack Mondal, Niloy Ganguly
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we show a fundamental limitation in vocabulary adaptation
approaches that use Byte-Pair Encoding (BPE) tokenization scheme for
fine-tuning pretrained language models (PLMs) to expert domains. Current
approaches trivially append the target domain-specific vocabulary at the end of
the PLM vocabulary. This approach leads to a lower priority score and causes
sub-optimal tokenization in BPE that iteratively uses merge rules to tokenize a
given text. To mitigate this issue, we propose AdaptBPE where the BPE
tokenization initialization phase is modified to first perform the longest
string matching on the added (target) vocabulary before tokenizing at the
character level. We perform an extensive evaluation of AdaptBPE versus the
standard BPE over various classification and summarization tasks; AdaptBPE
improves by 3.57% (in terms of accuracy) and 1.87% (in terms of Rouge-L),
respectively. AdaptBPE for MEDVOC works particularly well when reference
summaries have high OOV concentration or are longer in length. We also conduct
a human evaluation, revealing that AdaptBPE generates more relevant and more
faithful summaries as compared to MEDVOC. We make our codebase publicly
available at https://github.com/gb-kgp/adaptbpe.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages. Accepted at EMNLP Findings 2024 (The 2024 Conference on
  Empirical Methods in Natural Language Processing)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards a Benchmark for Large Language Models for Business Process
  Management Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03255v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03255v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kiran Busch, Henrik Leopold
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  An increasing number of organizations are deploying Large Language Models
(LLMs) for a wide range of tasks. Despite their general utility, LLMs are prone
to errors, ranging from inaccuracies to hallucinations. To objectively assess
the capabilities of existing LLMs, performance benchmarks are conducted.
However, these benchmarks often do not translate to more specific real-world
tasks. This paper addresses the gap in benchmarking LLM performance in the
Business Process Management (BPM) domain. Currently, no BPM-specific benchmarks
exist, creating uncertainty about the suitability of different LLMs for BPM
tasks. This paper systematically compares LLM performance on four BPM tasks
focusing on small open-source models. The analysis aims to identify
task-specific performance variations, compare the effectiveness of open-source
versus commercial models, and assess the impact of model size on BPM task
performance. This paper provides insights into the practical applications of
LLMs in BPM, guiding organizations in selecting appropriate models for their
specific needs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Are Expert-Level Language Models Expert-Level Annotators? <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03254v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03254v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu-Min Tseng, Wei-Lin Chen, Chung-Chi Chen, Hsin-Hsi Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Data annotation refers to the labeling or tagging of textual data with
relevant information. A large body of works have reported positive results on
leveraging LLMs as an alternative to human annotators. However, existing
studies focus on classic NLP tasks, and the extent to which LLMs as data
annotators perform in domains requiring expert knowledge remains underexplored.
In this work, we investigate comprehensive approaches across three highly
specialized domains and discuss practical suggestions from a cost-effectiveness
perspective. To the best of our knowledge, we present the first systematic
evaluation of LLMs as expert-level data annotators.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to WiML @ NeurIPS 2024 (extended version)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ How much can we forget about Data Contamination? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03249v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03249v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sebastian Bordt, Suraj Srinivas, Valentyn Boreiko, Ulrike von Luxburg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The leakage of benchmark data into the training data has emerged as a
significant challenge for evaluating the capabilities of large language models
(LLMs). In this work, we use experimental evidence and theoretical estimates to
challenge the common assumption that small-scale contamination renders
benchmark evaluations invalid. First, we experimentally quantify the magnitude
of benchmark overfitting based on scaling along three dimensions: The number of
model parameters (up to 1.6B), the number of times an example is seen (up to
144), and the number of training tokens (up to 40B). We find that if model and
data follow the Chinchilla scaling laws, minor contamination indeed leads to
overfitting. At the same time, even 144 times of contamination can be forgotten
if the training data is scaled beyond five times Chinchilla, a regime
characteristic of many modern LLMs. We then derive a simple theory of example
forgetting via cumulative weight decay. It allows us to bound the number of
gradient steps required to forget past data for any training run where we know
the hyperparameters of AdamW. This indicates that many LLMs, including Llama 3,
have forgotten the data seen at the beginning of training. Experimentally, we
demonstrate that forgetting occurs faster than what is predicted by our bounds.
Taken together, our results suggest that moderate amounts of contamination can
be forgotten at the end of realistically scaled training runs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Beyond Film Subtitles: Is YouTube the Best Approximation of Spoken
  Vocabulary? <span class="chip">COLING 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03240v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03240v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Adam Nohejl, Frederikus Hudi, Eunike Andriani Kardinata, Shintaro Ozaki, Maria Angelica Riera Machin, Hongyu Sun, Justin Vasselli, Taro Watanabe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Word frequency is a key variable in psycholinguistics, useful for modeling
human familiarity with words even in the era of large language models (LLMs).
Frequency in film subtitles has proved to be a particularly good approximation
of everyday language exposure. For many languages, however, film subtitles are
not easily available, or are overwhelmingly translated from English. We
demonstrate that frequencies extracted from carefully processed YouTube
subtitles provide an approximation comparable to, and often better than, the
best currently available resources. Moreover, they are available for languages
for which a high-quality subtitle or speech corpus does not exist. We use
YouTube subtitles to construct frequency norms for five diverse languages,
Chinese, English, Indonesian, Japanese, and Spanish, and evaluate their
correlation with lexical decision time, word familiarity, and lexical
complexity. In addition to being strongly correlated with two psycholinguistic
variables, a simple linear regression on the new frequencies achieves a new
high score on a lexical complexity prediction task in English and Japanese,
surpassing both models trained on film subtitle frequencies and the LLM GPT-4.
Our code, the frequency lists, fastText word embeddings, and statistical
language models are freely available at https://github.com/naist-nlp/tubelex.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted for review to COLING 2025. 8 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Showing LLM-Generated Code Selectively Based on Confidence of LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03234v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03234v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jia Li, Yuqi Zhu, Yongmin Li, Ge Li, Zhi Jin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have shown impressive abilities in code
generation, but they may generate erroneous programs. Reading a program takes
ten times longer than writing it. Showing these erroneous programs to
developers will waste developers' energies and introduce security risks to
software.
  To address the above limitations, we propose HonestCoder, a novel LLM-based
code generation approach. HonestCoder selectively shows the generated programs
to developers based on LLMs' confidence. The confidence provides valuable
insights into the correctness of generated programs. To achieve this goal, we
propose a novel approach to estimate LLMs' confidence in code generation. It
estimates confidence by measuring the multi-modal similarity between
LLMs-generated programs.
  We collect and release a multilingual benchmark named TruthCodeBench, which
consists of 2,265 samples and covers two popular programming languages (i.e.,
Python and Java). We apply HonestCoder to four popular LLMs (e.g.,
DeepSeek-Coder and Code Llama) and evaluate it on TruthCodeBench. Based on the
experiments, we obtain the following insights. (1) HonestCoder can effectively
estimate LLMs' confidence and accurately determine the correctness of generated
programs. For example, HonestCoder outperforms the state-of-the-art baseline by
27.79% in AUROC and 63.74% in AUCPR. (2) HonestCoder can decrease the number of
erroneous programs shown to developers. Compared to eight baselines, it can
show more correct programs and fewer erroneous programs to developers. (3)
Compared to showing code indiscriminately, HonestCoder only adds slight time
overhead (approximately 0.4 seconds per requirement). (4) We discuss future
directions to facilitate the application of LLMs in software development. We
hope this work can motivate broad discussions about measuring the reliability
of LLMs' outputs in performing code-related tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ALR$^2$: A Retrieve-then-Reason Framework for Long-context Question
  Answering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03227v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03227v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huayang Li, Pat Verga, Priyanka Sen, Bowen Yang, Vijay Viswanathan, Patrick Lewis, Taro Watanabe, Yixuan Su
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The context window of large language models (LLMs) has been extended
significantly in recent years. However, while the context length that the LLM
can process has grown, the capability of the model to accurately reason over
that context degrades noticeably. This occurs because modern LLMs often become
overwhelmed by the vast amount of information in the context; when answering
questions, the model must identify and reason over relevant evidence sparsely
distributed throughout the text. To alleviate the challenge of long-context
reasoning, we develop a retrieve-then-reason framework, enabling LLMs to reason
over relevant evidence collected during an intermediate retrieval step. We find
that modern LLMs struggle to accurately retrieve relevant facts and instead,
often hallucinate "retrieved facts", resulting in flawed reasoning and the
production of incorrect answers. To address these issues, we introduce ALR$^2$,
a method that augments the long-context reasoning capability of LLMs via an
explicit two-stage procedure, i.e., aligning LLMs with the objectives of both
retrieval and reasoning. We demonstrate the efficacy of ALR$^2$ for mitigating
performance degradation in long-context reasoning tasks. Through extensive
experiments on long-context QA benchmarks, we find our method to outperform
competitive baselines by large margins, achieving at least 8.4 and 7.9 EM gains
on the long-context versions of HotpotQA and SQuAD datasets, respectively.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Frame-Voyager: Learning to Query Frames for Video Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03226v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03226v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sicheng Yu, Chengkai Jin, Huanyu Wang, Zhenghao Chen, Sheng Jin, Zhongrong Zuo, Xioalei Xu, Zhenbang Sun, Bingni Zhang, Jiawei Wu, Hao Zhang, Qianru Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video Large Language Models (Video-LLMs) have made remarkable progress in
video understanding tasks. However, they are constrained by the maximum length
of input tokens, making it impractical to input entire videos. Existing frame
selection approaches, such as uniform frame sampling and text-frame retrieval,
fail to account for the information density variations in the videos or the
complex instructions in the tasks, leading to sub-optimal performance. In this
paper, we propose Frame-Voyager that learns to query informative frame
combinations, based on the given textual queries in the task. To train
Frame-Voyager, we introduce a new data collection and labeling pipeline, by
ranking frame combinations using a pre-trained Video-LLM. Given a video of M
frames, we traverse its T-frame combinations, feed them into a Video-LLM, and
rank them based on Video-LLM's prediction losses. Using this ranking as
supervision, we train Frame-Voyager to query the frame combinations with lower
losses. In experiments, we evaluate Frame-Voyager on four Video Question
Answering benchmarks by plugging it into two different Video-LLMs. The
experimental results demonstrate that Frame-Voyager achieves impressive results
in all settings, highlighting its potential as a plug-and-play solution for
Video-LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 10 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Consultation on Industrial Machine Faults with Large language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03223v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03223v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Apiradee Boonmee, Kritsada Wongsuwan, Pimchanok Sukjai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Industrial machine fault diagnosis is a critical component of operational
efficiency and safety in manufacturing environments. Traditional methods rely
heavily on expert knowledge and specific machine learning models, which can be
limited in their adaptability and require extensive labeled data. This paper
introduces a novel approach leveraging Large Language Models (LLMs),
specifically through a structured multi-round prompting technique, to improve
fault diagnosis accuracy. By dynamically crafting prompts, our method enhances
the model's ability to synthesize information from diverse data sources,
leading to improved contextual understanding and actionable recommendations.
Experimental results demonstrate that our approach outperforms baseline models,
achieving an accuracy of 91% in diagnosing various fault types. The findings
underscore the potential of LLMs in revolutionizing industrial fault
consultation practices, paving the way for more effective maintenance
strategies in complex environments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NLIP_Lab-IITH Low-Resource MT System for WMT24 Indic MT Shared Task 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03215v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03215v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pramit Sahoo, Maharaj Brahma, Maunendra Sankar Desarkar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we describe our system for the WMT 24 shared task of
Low-Resource Indic Language Translation. We consider eng $\leftrightarrow$ {as,
kha, lus, mni} as participating language pairs. In this shared task, we explore
the finetuning of a pre-trained model motivated by the pre-trained objective of
aligning embeddings closer by alignment augmentation \cite{lin-etal-2020-pre}
for 22 scheduled Indian languages. Our primary system is based on
language-specific finetuning on a pre-trained model. We achieve chrF2 scores of
50.6, 42.3, 54.9, and 66.3 on the official public test set for
eng$\rightarrow$as, eng$\rightarrow$kha, eng$\rightarrow$lus,
eng$\rightarrow$mni respectively. We also explore multilingual training
with/without language grouping and layer-freezing. Our code, models, and
generated translations are available here:
https://github.com/pramitsahoo/WMT2024-LRILT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>WMT2024 INDICMT Shared Task</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning Semantic Structure through First-Order-Logic Translation <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03203v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03203v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Akshay Chaturvedi, Nicholas Asher
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we study whether transformer-based language models can extract
predicate argument structure from simple sentences. We firstly show that
language models sometimes confuse which predicates apply to which objects. To
mitigate this, we explore two tasks: question answering (Q/A), and first order
logic (FOL) translation, and two regimes, prompting and finetuning. In FOL
translation, we finetune several large language models on synthetic datasets
designed to gauge their generalization abilities. For Q/A, we finetune encoder
models like BERT and RoBERTa and use prompting for LLMs. The results show that
FOL translation for LLMs is better suited to learn predicate argument
structure.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PersoBench: Benchmarking Personalized Response Generation in Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03198v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03198v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Saleh Afzoon, Usman Naseem, Amin Beheshti, Zahra Jamali
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While large language models (LLMs) have exhibited impressive conversational
capabilities, their proficiency in delivering personalized responses remains
unclear. Although recent benchmarks automatically evaluate persona consistency
in role-playing contexts using LLM-based judgment, the evaluation of
personalization in response generation remains underexplored. To address this
gap, we present a new benchmark, PersoBench, to evaluate the personalization
ability of LLMs in persona-aware dialogue generation within a zero-shot
setting. We assess the performance of three open-source and three closed-source
LLMs using well-known datasets and a range of metrics. Our analysis, conducted
on three well-known persona-aware datasets, evaluates multiple dimensions of
response quality, including fluency, diversity, coherence, and personalization,
across both standard and chain-of-thought prompting methods. Our findings
reveal that while LLMs excel at generating fluent and diverse responses, they
are far from satisfactory in delivering personalized and coherent responses
considering both the conversation context and the provided personas. Our
benchmark implementation is available at
https://github.com/salehafzoon/PersoBench.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cross-lingual Transfer for Automatic Question Generation by Learning
  Interrogative Structures in Target Languages <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03197v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03197v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seonjeong Hwang, Yunsu Kim, Gary Geunbae Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic question generation (QG) serves a wide range of purposes, such as
augmenting question-answering (QA) corpora, enhancing chatbot systems, and
developing educational materials. Despite its importance, most existing
datasets predominantly focus on English, resulting in a considerable gap in
data availability for other languages. Cross-lingual transfer for QG (XLT-QG)
addresses this limitation by allowing models trained on high-resource language
datasets to generate questions in low-resource languages. In this paper, we
propose a simple and efficient XLT-QG method that operates without the need for
monolingual, parallel, or labeled data in the target language, utilizing a
small language model. Our model, trained solely on English QA datasets, learns
interrogative structures from a limited set of question exemplars, which are
then applied to generate questions in the target language. Experimental results
show that our method outperforms several XLT-QG baselines and achieves
performance comparable to GPT-3.5-turbo across different languages.
Additionally, the synthetic data generated by our model proves beneficial for
training multilingual QA models. With significantly fewer parameters than large
language models and without requiring additional training for target languages,
our approach offers an effective solution for QG and QA tasks across various
languages.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Parallel Corpus Augmentation using Masked Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03194v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03194v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vibhuti Kumari, Narayana Murthy Kavi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper we propose a novel method of augmenting parallel text corpora
which promises good quality and is also capable of producing many fold larger
corpora than the seed corpus we start with. We do not need any additional
monolingual corpora. We use Multi-Lingual Masked Language Model to mask and
predict alternative words in context and we use Sentence Embeddings to check
and select sentence pairs which are likely to be translations of each other. We
cross check our method using metrics for MT Quality Estimation. We believe this
method can greatly alleviate the data scarcity problem for all language pairs
for which a reasonable seed corpus is available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 Pages, 3 Figures. arXiv admin note: text overlap with
  arXiv:2011.01536 by other authors</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generating bilingual example sentences with large language models as
  lexicography assistants 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03182v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03182v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Raphael Merx, Ekaterina Vylomova, Kemal Kurniawan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a study of LLMs' performance in generating and rating example
sentences for bilingual dictionaries across languages with varying resource
levels: French (high-resource), Indonesian (mid-resource), and Tetun
(low-resource), with English as the target language. We evaluate the quality of
LLM-generated examples against the GDEX (Good Dictionary EXample) criteria:
typicality, informativeness, and intelligibility. Our findings reveal that
while LLMs can generate reasonably good dictionary examples, their performance
degrades significantly for lower-resourced languages. We also observe high
variability in human preferences for example quality, reflected in low
inter-annotator agreement rates. To address this, we demonstrate that
in-context learning can successfully align LLMs with individual annotator
preferences. Additionally, we explore the use of pre-trained language models
for automated rating of examples, finding that sentence perplexity serves as a
good proxy for typicality and intelligibility in higher-resourced languages.
Our study also contributes a novel dataset of 600 ratings for LLM-generated
sentence pairs, and provides insights into the potential of LLMs in reducing
the cost of lexicographic work, particularly for low-resource languages.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Kiss up, Kick down: Exploring Behavioral Changes in Multi-modal Large
  Language Models with Assigned Visual Personas <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03181v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03181v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seungjong Sun, Eungu Lee, Seo Yeon Baek, Seunghyun Hwang, Wonbyung Lee, Dongyan Nan, Bernard J. Jansen, Jang Hyun Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study is the first to explore whether multi-modal large language models
(LLMs) can align their behaviors with visual personas, addressing a significant
gap in the literature that predominantly focuses on text-based personas. We
developed a novel dataset of 5K fictional avatar images for assignment as
visual personas to LLMs, and analyzed their negotiation behaviors based on the
visual traits depicted in these images, with a particular focus on
aggressiveness. The results indicate that LLMs assess the aggressiveness of
images in a manner similar to humans and output more aggressive negotiation
behaviors when prompted with an aggressive visual persona. Interestingly, the
LLM exhibited more aggressive negotiation behaviors when the opponent's image
appeared less aggressive than their own, and less aggressive behaviors when the
opponents image appeared more aggressive.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Autoregressive Large Language Models are Computationally Universal 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03170v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03170v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dale Schuurmans, Hanjun Dai, Francesco Zanini
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We show that autoregressive decoding of a transformer-based language model
can realize universal computation, without external intervention or
modification of the model's weights. Establishing this result requires
understanding how a language model can process arbitrarily long inputs using a
bounded context. For this purpose, we consider a generalization of
autoregressive decoding where, given a long input, emitted tokens are appended
to the end of the sequence as the context window advances. We first show that
the resulting system corresponds to a classical model of computation, a Lag
system, that has long been known to be computationally universal. By leveraging
a new proof, we show that a universal Turing machine can be simulated by a Lag
system with 2027 production rules. We then investigate whether an existing
large language model can simulate the behaviour of such a universal Lag system.
We give an affirmative answer by showing that a single system-prompt can be
developed for gemini-1.5-pro-001 that drives the model, under deterministic
(greedy) decoding, to correctly apply each of the 2027 production rules. We
conclude that, by the Church-Turing thesis, prompted gemini-1.5-pro-001 with
extended autoregressive (greedy) decoding is a general purpose computer.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>32 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Can Watermarked LLMs be Identified by Users via Crafted <span class="highlight-title">Prompt</span>s? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03168v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03168v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aiwei Liu, Sheng Guan, Yiming Liu, Leyi Pan, Yifei Zhang, Liancheng Fang, Lijie Wen, Philip S. Yu, Xuming Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text watermarking for Large Language Models (LLMs) has made significant
progress in detecting LLM outputs and preventing misuse. Current watermarking
techniques offer high detectability, minimal impact on text quality, and
robustness to text editing. However, current researches lack investigation into
the imperceptibility of watermarking techniques in LLM services. This is
crucial as LLM providers may not want to disclose the presence of watermarks in
real-world scenarios, as it could reduce user willingness to use the service
and make watermarks more vulnerable to attacks. This work is the first to
investigate the imperceptibility of watermarked LLMs. We design an
identification algorithm called Water-Probe that detects watermarks through
well-designed prompts to the LLM. Our key motivation is that current
watermarked LLMs expose consistent biases under the same watermark key,
resulting in similar differences across prompts under different watermark keys.
Experiments show that almost all mainstream watermarking algorithms are easily
identified with our well-designed prompts, while Water-Probe demonstrates a
minimal false positive rate for non-watermarked LLMs. Finally, we propose that
the key to enhancing the imperceptibility of watermarked LLMs is to increase
the randomness of watermark key selection. Based on this, we introduce the
Water-Bag strategy, which significantly improves watermark imperceptibility by
merging multiple watermark keys.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages, 5 figures, 8 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Exploring Learnability in Memory-Augmented Recurrent Neural Networks:
  Precision, Stability, and Empirical Insights 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03154v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03154v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shrabon Das, Ankur Mali
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study explores the learnability of memory-less and memory-augmented
RNNs, which are theoretically equivalent to Pushdown Automata. Empirical
results show that these models often fail to generalize on longer sequences,
relying more on precision than mastering symbolic grammar. Experiments on fully
trained and component-frozen models reveal that freezing the memory component
significantly improves performance, achieving state-of-the-art results on the
Penn Treebank dataset (test perplexity reduced from 123.5 to 120.5). Models
with frozen memory retained up to 90% of initial performance on longer
sequences, compared to a 60% drop in standard models. Theoretical analysis
suggests that freezing memory stabilizes temporal dependencies, leading to
robust convergence. These findings stress the need for stable memory designs
and long-sequence evaluations to understand RNNs true learnability limits.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages, 4 theorems, 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Media Framing through the Lens of Event-Centric Narratives <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03151v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03151v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rohan Das, Aditya Chandra, I-Ta Lee, Maria Leonor Pacheco
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  From a communications perspective, a frame defines the packaging of the
language used in such a way as to encourage certain interpretations and to
discourage others. For example, a news article can frame immigration as either
a boost or a drain on the economy, and thus communicate very different
interpretations of the same phenomenon. In this work, we argue that to explain
framing devices we have to look at the way narratives are constructed. As a
first step in this direction, we propose a framework that extracts events and
their relations to other events, and groups them into high-level narratives
that help explain frames in news articles. We show that our framework can be
used to analyze framing in U.S. news for two different domains: immigration and
gun control.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the 6th Workshop on Narrative Understanding, co-located
  with EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Analysis and Detection of Differences in Spoken User Behaviors between
  Autonomous and Wizard-of-Oz Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03147v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03147v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mikey Elmers, Koji Inoue, Divesh Lala, Keiko Ochi, Tatsuya Kawahara
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study examined users' behavioral differences in a large corpus of
Japanese human-robot interactions, comparing interactions between a
tele-operated robot and an autonomous dialogue system. We analyzed user spoken
behaviors in both attentive listening and job interview dialogue scenarios.
Results revealed significant differences in metrics such as speech length,
speaking rate, fillers, backchannels, disfluencies, and laughter between
operator-controlled and autonomous conditions. Furthermore, we developed
predictive models to distinguish between operator and autonomous system
conditions. Our models demonstrated higher accuracy and precision compared to
the baseline model, with several models also achieving a higher F1 score than
the baseline.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted and will be presented at the 27th conference of the Oriental
  COCOSDA (O-COCOSDA 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Retrieval-Augmented Hierarchical in-Context Reinforcement Learning and
  Hindsight Modular Reflections for Task Planning with LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.06520v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.06520v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chuanneng Sun, Songjun Huang, Dario Pompili
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have demonstrated remarkable abilities in
various language tasks, making them promising candidates for decision-making in
robotics. Inspired by Hierarchical Reinforcement Learning (HRL), we propose
Retrieval-Augmented in-context reinforcement Learning (RAHL), a novel framework
that decomposes complex tasks into sub-tasks using an LLM-based high-level
policy, in which a complex task is decomposed into sub-tasks by a high-level
policy on-the-fly. The sub-tasks, defined by goals, are assigned to the
low-level policy to complete. To improve the agent's performance in
multi-episode execution, we propose Hindsight Modular Reflection (HMR), where,
instead of reflecting on the full trajectory, we let the agent reflect on
shorter sub-trajectories to improve reflection efficiency. We evaluated the
decision-making ability of the proposed RAHL in three benchmark
environments--ALFWorld, Webshop, and HotpotQA. The results show that RAHL can
achieve an improvement in performance in 9%, 42%, and 10% in 5 episodes of
execution in strong baselines. Furthermore, we also implemented RAHL on the
Boston Dynamics SPOT robot. The experiment shows that the robot can scan the
environment, find entrances, and navigate to new rooms controlled by the LLM
policy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SaySelf: Teaching LLMs to Express Confidence with Self-Reflective
  Rationales <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.20974v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.20974v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianyang Xu, Shujin Wu, Shizhe Diao, Xiaoze Liu, Xingyao Wang, Yangyi Chen, Jing Gao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) often generate inaccurate or fabricated
information and generally fail to indicate their confidence, which limits their
broader applications. Previous work elicits confidence from LLMs by direct or
self-consistency prompting, or constructing specific datasets for supervised
finetuning. The prompting-based approaches have inferior performance, and the
training-based approaches are limited to binary or inaccurate group-level
confidence estimates. In this work, we present the advanced SaySelf, a training
framework that teaches LLMs to express more accurate fine-grained confidence
estimates. In addition, beyond the confidence scores, SaySelf initiates the
process of directing LLMs to produce self-reflective rationales that clearly
identify gaps in their parametric knowledge and explain their uncertainty. This
is achieved by using an LLM to automatically summarize the uncertainties in
specific knowledge via natural language. The summarization is based on the
analysis of the inconsistency in multiple sampled reasoning chains, and the
resulting data is utilized for supervised fine-tuning. Moreover, we utilize
reinforcement learning with a meticulously crafted reward function to calibrate
the confidence estimates, motivating LLMs to deliver accurate, high-confidence
predictions and to penalize overconfidence in erroneous outputs. Experimental
results in both in-distribution and out-of-distribution datasets demonstrate
the effectiveness of SaySelf in reducing the confidence calibration error and
maintaining the task performance. We show that the generated self-reflective
rationales are reasonable and can further contribute to the calibration. The
code is made public at https://github.com/xu1868/SaySelf.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Language Model Empowered Spatio-Temporal Forecasting via Physics-Aware
  Reprogramming 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.14505v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.14505v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Wang, Jindong Han, Wei Fan, Hao Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spatio-temporal forecasting is pivotal in numerous real-world applications,
including transportation planning, energy management, and climate monitoring.
In this work, we aim to harness the reasoning and generalization abilities of
Pre-trained Language Models (PLMs) for more effective spatio-temporal
forecasting, particularly in data-scarce scenarios. However, recent studies
uncover that PLMs, which are primarily trained on textual data, often falter
when tasked with modeling the intricate correlations in numerical time series,
thereby limiting their effectiveness in comprehending spatio-temporal data. To
bridge the gap, we propose RePST, a physics-aware PLM reprogramming framework
tailored for spatio-temporal forecasting. Specifically, we first propose a
physics-aware decomposer that adaptively disentangles spatially correlated time
series into interpretable sub-components, which facilitates PLM to understand
sophisticated spatio-temporal dynamics via a divide-and-conquer strategy.
Moreover, we propose a selective discrete reprogramming scheme, which
introduces an expanded spatio-temporal vocabulary space to project
spatio-temporal series into discrete representations. This scheme minimizes the
information loss during reprogramming and enriches the representations derived
by PLMs. Extensive experiments on real-world datasets show that the proposed
RePST outperforms twelve state-of-the-art baseline methods, particularly in
data-scarce scenarios, highlighting the effectiveness and superior
generalization capabilities of PLMs for spatio-temporal forecasting.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving Statistical Significance in Human Evaluation of Automatic
  Metrics via Soft Pairwise Accuracy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.09598v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.09598v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Brian Thompson, Nitika Mathur, Daniel Deutsch, Huda Khayrallah
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Selecting an automatic metric that best emulates human annotators is often
non-trivial, because there is no clear definition of "best emulates." A
meta-metric is required to compare the human judgments to the automatic metric
scores, and metric rankings depend on the choice of meta-metric. We propose
Soft Pairwise Accuracy (SPA), a new meta-metric that builds on Pairwise
Accuracy (PA) but incorporates the statistical significance of both the human
judgments and the metric scores. We show that SPA is more stable than PA with
respect to changes in the number of systems/segments used for evaluation. We
also show that PA can only assign a small set of distinct output values to
metrics, and this results in many metrics being artificially assigned the exact
same PA score. We demonstrate that SPA fixes this issue. Finally, we show that
SPA is more discriminative than PA, producing more statistically significant
comparisons between metrics. SPA was selected as the official system-level
metric for the 2024 WMT Metrics Shared Task.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at WMT 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MDAgents: An Adaptive Collaboration of LLMs for Medical Decision-Making 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.15155v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.15155v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yubin Kim, Chanwoo Park, Hyewon Jeong, Yik Siu Chan, Xuhai Xu, Daniel McDuff, Hyeonhoon Lee, Marzyeh Ghassemi, Cynthia Breazeal, Hae Won Park
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Foundation models are becoming valuable tools in medicine. Yet despite their
promise, the best way to leverage Large Language Models (LLMs) in complex
medical tasks remains an open question. We introduce a novel multi-agent
framework, named Medical Decision-making Agents (MDAgents) that helps address
this gap by automatically assigning a collaboration structure to a team of
LLMs. The assigned solo or group collaboration structure is tailored to the
medical task at hand, emulating real-world medical decision-making processes
adapted to tasks of varying complexities. We evaluate our framework and
baseline methods using state-of-the-art LLMs across a suite of real-world
medical knowledge and medical diagnosis benchmarks. MDAgents achieved the best
performance in seven out of ten benchmarks on tasks requiring an understanding
of medical knowledge and multi-modal reasoning, showing a significant
improvement of up to 6.5% (p < 0.05) compared to previous methods' best
performances. Ablation studies reveal that MDAgents effectively determines
medical complexity to optimize for efficiency and accuracy across diverse
medical tasks. Notably, the combination of moderator review and external
medical knowledge in group collaboration resulted in an average accuracy
improvement of 11.8%. Our code can be found at
https://github.com/mitmedialab/MDAgents.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unraveling the Truth: Do VLMs really Understand Charts? A Deep Dive into
  Consistency and Robustness 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11229v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11229v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Srija Mukhopadhyay, Adnan Qidwai, Aparna Garimella, Pritika Ramu, Vivek Gupta, Dan Roth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Chart question answering (CQA) is a crucial area of Visual Language
Understanding. However, the robustness and consistency of current Visual
Language Models (VLMs) in this field remain under-explored. This paper
evaluates state-of-the-art VLMs on comprehensive datasets, developed
specifically for this study, encompassing diverse question categories and chart
formats. We investigate two key aspects: 1) the models' ability to handle
varying levels of chart and question complexity, and 2) their robustness across
different visual representations of the same underlying data. Our analysis
reveals significant performance variations based on question and chart types,
highlighting both strengths and weaknesses of current models. Additionally, we
identify areas for improvement and propose future research directions to build
more robust and reliable CQA systems. This study sheds light on the limitations
of current models and paves the way for future advancements in the field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>22 pages, 9 Tables, 5 figures, 22 examples</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unlocking Anticipatory Text Generation: A Constrained Approach for Large
  Language Models Decoding <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.06149v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.06149v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lifu Tu, Semih Yavuz, Jin Qu, Jiacheng Xu, Rui Meng, Caiming Xiong, Yingbo Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have demonstrated a powerful ability for text
generation. However, achieving optimal results with a given prompt or
instruction can be challenging, especially for billion-sized models.
Additionally, undesired behaviors such as toxicity or hallucinations can
manifest. While much larger models (e.g., ChatGPT) may demonstrate strength in
mitigating these issues, there is still no guarantee of complete prevention. In
this work, we propose formalizing text generation as a future-constrained
generation problem to minimize undesirable behaviors and enforce faithfulness
to instructions. The estimation of future constraint satisfaction, accomplished
using LLMs, guides the text generation process. Our extensive experiments
demonstrate the effectiveness of the proposed approach across three distinct
text generation tasks: keyword-constrained generation (Lin et al., 2020),
toxicity reduction (Gehman et al., 2020), and factual correctness in
question-answering (Gao et al., 2023).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Why Would You Suggest That? Human Trust in Language Model Responses 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.02018v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.02018v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manasi Sharma, Ho Chit Siu, Rohan Paleja, Jaime D. Peña
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The emergence of Large Language Models (LLMs) has revealed a growing need for
human-AI collaboration, especially in creative decision-making scenarios where
trust and reliance are paramount. Through human studies and model evaluations
on the open-ended News Headline Generation task from the LaMP benchmark, we
analyze how the framing and presence of explanations affect user trust and
model performance. Overall, we provide evidence that adding an explanation in
the model response to justify its reasoning significantly increases
self-reported user trust in the model when the user has the opportunity to
compare various responses. Position and faithfulness of these explanations are
also important factors. However, these gains disappear when users are shown
responses independently, suggesting that humans trust all model responses,
including deceptive ones, equitably when they are shown in isolation. Our
findings urge future research to delve deeper into the nuanced evaluation of
trust in human-machine teaming systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evaluating $n$-Gram Novelty of Language Models Using Rusty-DAWG <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13069v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13069v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        William Merrill, Noah A. Smith, Yanai Elazar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  How novel are texts generated by language models (LMs) relative to their
training corpora? In this work, we investigate the extent to which modern LMs
generate $n$-grams from their training data, evaluating both (i) the
probability LMs assign to complete training $n$-grams and (ii) $n$-novelty, the
proportion of $n$-grams generated by an LM that did not appear in the training
data (for arbitrarily large $n$). To enable arbitrary-length $n$-gram search
over a corpus in constant time w.r.t. corpus size, we develop Rusty-DAWG, a
novel search tool inspired by indexing of genomic data. We compare the novelty
of LM-generated text to human-written text and explore factors that affect
generation novelty, focusing on the Pythia models. We find that, for $n > 4$,
LM-generated text is less novel than human-written text, though it is more
novel for smaller $n$. Larger LMs and more constrained decoding strategies both
decrease novelty. Finally, we show that LMs complete $n$-grams with lower loss
if they are more frequent in the training data. Overall, our results reveal
factors influencing the novelty of LM-generated text, and we release Rusty-DAWG
to facilitate further pretraining data research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear at EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Probabilities of Chat LLMs Are Miscalibrated but Still Predict
  Correctness on Multiple-Choice Q&A 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.13213v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.13213v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Benjamin Plaut, Nguyen X. Khanh, Tu Trinh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study 14 large language models (LLMs) fine-tuned for chat and find that
their maximum softmax probabilities (MSPs) are consistently miscalibrated on
multiple-choice Q&A. However, those MSPs might still encode useful uncertainty
information. Specifically, we hypothesized that wrong answers would be
associated with smaller MSPs compared to correct answers. Via rigororous
statistical testing, we show that this hypothesis holds for models which
perform well on the underlying Q&A task. We also find a strong direction
correlation between Q&A accuracy and MSP correctness prediction, while finding
no correlation between Q&A accuracy and calibration error. This suggests that
within the current fine-tuning paradigm, we can expect correctness prediction
but not calibration to improve as LLM capabilities progress. To demonstrate the
utility of correctness prediction, we show that when models have the option to
abstain, performance can be improved by selectively abstaining based on the MSP
of the initial model response, using only a small amount of labeled data to
choose the MSP threshold.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MetaKP: On-Demand Keyphrase Generation <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.00191v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.00191v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Di Wu, Xiaoxian Shen, Kai-Wei Chang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Traditional keyphrase prediction methods predict a single set of keyphrases
per document, failing to cater to the diverse needs of users and downstream
applications. To bridge the gap, we introduce on-demand keyphrase generation, a
novel paradigm that requires keyphrases that conform to specific high-level
goals or intents. For this task, we present MetaKP, a large-scale benchmark
comprising four datasets, 7500 documents, and 3760 goals across news and
biomedical domains with human-annotated keyphrases. Leveraging MetaKP, we
design both supervised and unsupervised methods, including a multi-task
fine-tuning approach and a self-consistency prompting method with large
language models. The results highlight the challenges of supervised
fine-tuning, whose performance is not robust to distribution shifts. By
contrast, the proposed self-consistency prompting approach greatly improves the
performance of large language models, enabling GPT-4o to achieve 0.548 SemF1,
surpassing the performance of a fully fine-tuned BART-base model. Finally, we
demonstrate the potential of our method to serve as a general NLP
infrastructure, exemplified by its application in epidemic event detection from
social media.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 (Findings)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VideoCLIP-XL: Advancing Long Description Understanding for Video CLIP
  Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00741v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00741v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiapeng Wang, Chengyu Wang, Kunzhe Huang, Jun Huang, Lianwen Jin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Contrastive Language-Image Pre-training (CLIP) has been widely studied and
applied in numerous applications. However, the emphasis on brief summary texts
during pre-training prevents CLIP from understanding long descriptions. This
issue is particularly acute regarding videos given that videos often contain
abundant detailed contents. In this paper, we propose the VideoCLIP-XL (eXtra
Length) model, which aims to unleash the long-description understanding
capability of video CLIP models. Firstly, we establish an automatic data
collection system and gather a large-scale VILD pre-training dataset with VIdeo
and Long-Description pairs. Then, we propose Text-similarity-guided Primary
Component Matching (TPCM) to better learn the distribution of feature space
while expanding the long description capability. We also introduce two new
tasks namely Detail-aware Description Ranking (DDR) and Hallucination-aware
Description Ranking (HDR) for further understanding improvement. Finally, we
construct a Long Video Description Ranking (LVDR) benchmark for evaluating the
long-description capability more comprehensively. Extensive experimental
results on widely-used text-video retrieval benchmarks with both short and long
descriptions and our LVDR benchmark can fully demonstrate the effectiveness of
our method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Main conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Identifying Factual Inconsistencies in Summaries: Grounding LLM
  Inference via Task Taxonomy <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.12821v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.12821v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liyan Xu, Zhenlin Su, Mo Yu, Jin Xu, Jinho D. Choi, Jie Zhou, Fei Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Factual inconsistencies pose a significant hurdle for the faithful
summarization by generative models. While a major direction to enhance
inconsistency detection is to derive stronger Natural Language Inference (NLI)
models, we propose an orthogonal aspect that underscores the importance of
incorporating task-specific taxonomy into the inference. To this end, we
consolidate key error types of inconsistent facts in summaries, and incorporate
them to facilitate both the zero-shot and supervised paradigms of LLMs.
Extensive experiments on ten datasets of five distinct domains suggest that,
zero-shot LLM inference could benefit from the explicit solution space depicted
by the error type taxonomy, and achieves state-of-the-art performance overall,
surpassing specialized non-LLM baselines, as well as recent LLM baselines. We
further distill models that fuse the taxonomy into parameters through our
designed prompt completions and supervised training strategies, efficiently
substituting state-of-the-art zero-shot inference with much larger LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ To Err Is Human, but Llamas Can Learn It Too 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.05493v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.05493v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Agnes Luhtaru, Taido Purason, Martin Vainikko, Maksym Del, Mark Fishel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study explores enhancing grammatical error correction (GEC) through
artificial error generation (AEG) using language models (LMs). Specifically, we
fine-tune Llama 2-based LMs for error generation and find that this approach
yields synthetic errors akin to human errors. Next, we train GEC Llama models
with the help of these artificial errors and outperform previous
state-of-the-art error correction models, with gains ranging between 0.8 and 6
F0.5 points across all tested languages (German, Ukrainian, and Estonian).
Moreover, we demonstrate that generating errors by fine-tuning smaller
sequence-to-sequence models and prompting large commercial LMs (GPT-3.5 and
GPT-4) also results in synthetic errors beneficially affecting error generation
models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ "Seeing the Big through the Small": Can LLMs Approximate Human Judgment
  Distributions on NLI from a Few Explanations? <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17600v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17600v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Beiduo Chen, Xinpeng Wang, Siyao Peng, Robert Litschko, Anna Korhonen, Barbara Plank
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Human label variation (HLV) is a valuable source of information that arises
when multiple human annotators provide different labels for valid reasons. In
Natural Language Inference (NLI) earlier approaches to capturing HLV involve
either collecting annotations from many crowd workers to represent human
judgment distribution (HJD) or use expert linguists to provide detailed
explanations for their chosen labels. While the former method provides denser
HJD information, obtaining it is resource-intensive. In contrast, the latter
offers richer textual information but it is challenging to scale up to many
human judges. Besides, large language models (LLMs) are increasingly used as
evaluators ("LLM judges") but with mixed results, and few works aim to study
HJDs. This study proposes to exploit LLMs to approximate HJDs using a small
number of expert labels and explanations. Our experiments show that a few
explanations significantly improve LLMs' ability to approximate HJDs with and
without explicit labels, thereby providing a solution to scale up annotations
for HJD. However, fine-tuning smaller soft-label aware models with the
LLM-generated model judgment distributions (MJDs) presents partially
inconsistent results: while similar in distance, their resulting fine-tuned
models and visualized distributions differ substantially. We show the
importance of complementing instance-level distance measures with a
global-level shape metric and visualization to more effectively evaluate MJDs
against human judgment distributions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024 Findings, 24 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A SMART Mnemonic Sounds like "Glue Tonic": Mixing LLMs with Student
  Feedback to Make Mnemonic Learning Stick <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.15352v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.15352v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nishant Balepur, Matthew Shu, Alexander Hoyle, Alison Robey, Shi Feng, Seraphina Goldfarb-Tarrant, Jordan Boyd-Graber
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Keyword mnemonics are memorable explanations that link new terms to simpler
keywords. Prior work generates mnemonics for students, but they do not train
models using mnemonics students prefer and aid learning. We build SMART, a
mnemonic generator trained on feedback from real students learning new terms.
To train SMART, we first fine-tune LLaMA-2 on a curated set of user-written
mnemonics. We then use LLM alignment to enhance SMART: we deploy mnemonics
generated by SMART in a flashcard app to find preferences on mnemonics students
favor. We gather 2684 preferences from 45 students across two types: expressed
(inferred from ratings) and observed (inferred from student learning), yielding
three key findings. First, expressed and observed preferences disagree; what
students think is helpful does not always capture what is truly helpful.
Second, Bayesian models can synthesize complementary data from multiple
preference types into a single effectiveness signal. SMART is tuned via Direct
Preference Optimization on this signal, which resolves ties and missing labels
in the typical method of pairwise comparisons, augmenting data for LLM output
quality gains. Third, mnemonic experts assess SMART as matching GPT-4 at much
lower deployment costs, showing the utility of capturing diverse student
feedback to align LLMs in education.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Flow of Reasoning:Training LLMs for Divergent Problem Solving with
  Minimal Examples 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.05673v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.05673v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fangxu Yu, Lai Jiang, Haoqiang Kang, Shibo Hao, Lianhui Qin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The ability to generate diverse solutions to a given problem is a hallmark of
human creativity. This divergent reasoning is also crucial for machines,
enhancing their robustness and enabling them to assist humans in many
applications such as scientific discovery. However, existing approaches to
multi-step reasoning with large language models (LLMs) have mostly focused only
on reasoning accuracy, without further discovering more diverse valid
solutions. For example, supervised fine-tuning can improve LLM reasoning
quality, but requires extensive supervised data to capture the full range of
possible solutions. Reinforcement learning aims to find limited highest-reward
solutions while neglecting the solution diversity. To fill this gap, we propose
Flow of Reasoning (FoR), an efficient diversity-seeking LLM finetuning method
aimed at improving reasoning quality and diversity with minimal data. FoR
formulates multi-step LLM reasoning as a Markovian flow on a DAG-structured
reasoning graph. This formulation allows us to incorporate and adapt principled
GFlowNet approaches, for finetuning LLMs to sample diverse reasoning paths with
probabilities proportional to the (unnormalized) reward of target problems.
Extensive experiments show that, with limited training examples (e.g., 15
examples), FoR enables the discovery of diverse, creative, high-quality
solutions, greatly outperforming a wide range of existing inference and
training methods across five challenging puzzle-solving tasks, including
BlocksWorld (embodied reasoning), Game24 (math puzzle solving), Rubik's Cube
(spatial reasoning), 1D-ARC (abstraction reasoning), and PrOntoQA (logical
reasoning). Code is available at https://github.com/Yu-Fangxu/FoR.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Jailbreaking as a Reward Misspecification Problem 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14393v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14393v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhihui Xie, Jiahui Gao, Lei Li, Zhenguo Li, Qi Liu, Lingpeng Kong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The widespread adoption of large language models (LLMs) has raised concerns
about their safety and reliability, particularly regarding their vulnerability
to adversarial attacks. In this paper, we propose a novel perspective that
attributes this vulnerability to reward misspecification during the alignment
process. This misspecification occurs when the reward function fails to
accurately capture the intended behavior, leading to misaligned model outputs.
We introduce a metric ReGap to quantify the extent of reward misspecification
and demonstrate its effectiveness and robustness in detecting harmful backdoor
prompts. Building upon these insights, we present ReMiss, a system for
automated red teaming that generates adversarial prompts in a
reward-misspecified space. ReMiss achieves state-of-the-art attack success
rates on the AdvBench benchmark against various target aligned LLMs while
preserving the human readability of the generated prompts. Furthermore, these
attacks on open-source models demonstrate high transferability to closed-source
models like GPT-4o and out-of-distribution tasks from HarmBench. Detailed
analysis highlights the unique advantages of the proposed reward
misspecification objective compared to previous methods, offering new insights
for improving LLM safety and robustness.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ KARL: Knowledge-Aware Retrieval and Representations aid Retention and
  Learning in Students <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.12291v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.12291v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matthew Shu, Nishant Balepur, Shi Feng, Jordan Boyd-Graber
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Flashcard schedulers rely on 1) student models to predict the flashcards a
student knows; and 2) teaching policies to pick which cards to show next via
these predictions. Prior student models, however, just use study data like the
student's past responses, ignoring the text on cards. We propose content-aware
scheduling, the first schedulers exploiting flashcard content. To give the
first evidence that such schedulers enhance student learning, we build KARL, a
simple but effective content-aware student model employing deep knowledge
tracing (DKT), retrieval, and BERT to predict student recall. We train KARL by
collecting a new dataset of 123,143 study logs on diverse trivia questions.
KARL bests existing student models in AUC and calibration error. To ensure our
improved predictions lead to better student learning, we create a novel
delta-based teaching policy to deploy KARL online. Based on 32 study paths from
27 users, KARL improves learning efficiency over SOTA, showing KARL's strength
and encouraging researchers to look beyond historical study data to fully
capture student abilities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ How Much Can RAG Help the Reasoning of LLM? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02338v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02338v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingyu Liu, Jiaen Lin, Yong Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) has gained significant popularity in
modern Large Language Models (LLMs) due to its effectiveness in introducing new
knowledge and reducing hallucinations. However, the deep understanding of RAG
remains limited, how does RAG help the reasoning process and can RAG help
improve the reasoning capability remains question. While external documents are
typically considered as a method to incorporate domain-specific information,
they also contain intermediate reasoning results related to the query, this
suggests that documents could enhance the reasoning capability of LLMs, which
has not been previously explored. In this paper, we investigate this issue in
depth and find that while RAG can assist with reasoning, the help is limited.
If we conceptualize the reasoning process as a tree with fixed depth, then RAG
struggles to assist LLMs in performing deeper reasoning. Additionally, the
information in the documents requires preprocessing to filter out noise. We
demonstrate that this preprocessing is difficult to achieve simply fine-tuning
of the LLM, it often necessitates numerous additional transformer layers to
solve the problem. To simplify the problem, we propose DPrompt tuning, which
effectively resolves the issue within just limited transformer layers, leading
to improved performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ OpenHands: An Open Platform for AI Software Developers as Generalist
  Agents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.16741v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.16741v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingyao Wang, Boxuan Li, Yufan Song, Frank F. Xu, Xiangru Tang, Mingchen Zhuge, Jiayi Pan, Yueqi Song, Bowen Li, Jaskirat Singh, Hoang H. Tran, Fuqiang Li, Ren Ma, Mingzhang Zheng, Bill Qian, Yanjun Shao, Niklas Muennighoff, Yizhe Zhang, Binyuan Hui, Junyang Lin, Robert Brennan, Hao Peng, Heng Ji, Graham Neubig
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Software is one of the most powerful tools that we humans have at our
disposal; it allows a skilled programmer to interact with the world in complex
and profound ways. At the same time, thanks to improvements in large language
models (LLMs), there has also been a rapid development in AI agents that
interact with and affect change in their surrounding environments. In this
paper, we introduce OpenHands (f.k.a. OpenDevin), a platform for the
development of powerful and flexible AI agents that interact with the world in
similar ways to those of a human developer: by writing code, interacting with a
command line, and browsing the web. We describe how the platform allows for the
implementation of new agents, safe interaction with sandboxed environments for
code execution, coordination between multiple agents, and incorporation of
evaluation benchmarks. Based on our currently incorporated benchmarks, we
perform an evaluation of agents over 15 challenging tasks, including software
engineering (e.g., SWE-BENCH) and web browsing (e.g., WEBARENA), among others.
Released under the permissive MIT license, OpenHands is a community project
spanning academia and industry with more than 2.1K contributions from over 188
contributors.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code: https://github.com/All-Hands-AI/OpenHands</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ To Know or Not To Know? Analyzing Self-Consistency of Large Language
  Models under Ambiguity <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.17125v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.17125v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anastasiia Sedova, Robert Litschko, Diego Frassinelli, Benjamin Roth, Barbara Plank
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  One of the major aspects contributing to the striking performance of large
language models (LLMs) is the vast amount of factual knowledge accumulated
during pre-training. Yet, many LLMs suffer from self-inconsistency, which
raises doubts about their trustworthiness and reliability. This paper focuses
on entity type ambiguity, analyzing the proficiency and consistency of
state-of-the-art LLMs in applying factual knowledge when prompted with
ambiguous entities. To do so, we propose an evaluation protocol that
disentangles knowing from applying knowledge, and test state-of-the-art LLMs on
49 ambiguous entities. Our experiments reveal that LLMs struggle with choosing
the correct entity reading, achieving an average accuracy of only 85%, and as
low as 75% with underspecified prompts. The results also reveal systematic
discrepancies in LLM behavior, showing that while the models may possess
knowledge, they struggle to apply it consistently, exhibit biases toward
preferred readings, and display self-inconsistencies. This highlights the need
to address entity ambiguity in the future for more trustworthy LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Soda-Eval: Open-Domain Dialogue Evaluation in the age of LLMs <span class="chip">EMNLP2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.10902v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.10902v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        John Mendonça, Isabel Trancoso, Alon Lavie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although human evaluation remains the gold standard for open-domain dialogue
evaluation, the growing popularity of automated evaluation using Large Language
Models (LLMs) has also extended to dialogue. However, most frameworks leverage
benchmarks that assess older chatbots on aspects such as fluency and relevance,
which are not reflective of the challenges associated with contemporary models.
In fact, a qualitative analysis on Soda, a GPT-3.5 generated dialogue dataset,
suggests that current chatbots may exhibit several recurring issues related to
coherence and commonsense knowledge, but generally produce highly fluent and
relevant responses.
  Noting the aforementioned limitations, this paper introduces Soda-Eval, an
annotated dataset based on Soda that covers over 120K turn-level assessments
across 10K dialogues, where the annotations were generated by GPT-4. Using
Soda-Eval as a benchmark, we then study the performance of several open-access
instruction-tuned LLMs, finding that dialogue evaluation remains challenging.
Fine-tuning these models improves performance over few-shot inferences, both in
terms of correlation and explanation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP2024 (findings)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Latte: Latent Attention for Linear Time <span class="highlight-title">Transformer</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.17512v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.17512v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rares Dolga, Lucas Maystre, Marius Cobzarenco, David Barber
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The time complexity of the standard attention mechanism in transformers
scales quadratically with sequence length. We propose a probabilistic framework
for attention, enabling us to derive a novel low-rank linear
re-parameterisation of both bidirectional and causal cases, based on defining a
latent variable model. Our method can be seamlessly integrated as a drop-in
replacement for the standard attention mechanism. Additionally, this framework
provides a natural extension for combining local standard attention with our
global linear attention. This approach allows us to extend the context length
of existing large pre-trained models with only a few additional training steps.
The resulting ``Latte Transformer'' achieves performance comparable to standard
attention and other state-of-the-art models, while maintaining linear time and
memory complexity, along with constant-time next-token prediction during
inference.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MultiContrievers: Analysis of Dense Retrieval Representations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.15925v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.15925v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seraphina Goldfarb-Tarrant, Pedro Rodriguez, Jane Dwivedi-Yu, Patrick Lewis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dense retrievers compress source documents into (possibly lossy) vector
representations, yet there is little analysis of what information is lost
versus preserved, and how it affects downstream tasks. We conduct the first
analysis of the information captured by dense retrievers compared to the
language models they are based on (e.g., BERT versus Contriever). We use 25
MultiBert checkpoints as randomized initialisations to train MultiContrievers,
a set of 25 contriever models. We test whether specific pieces of information
-- such as gender and occupation -- can be extracted from contriever vectors of
wikipedia-like documents. We measure this extractability via information
theoretic probing. We then examine the relationship of extractability to
performance and gender bias, as well as the sensitivity of these results to
many random initialisations and data shuffles. We find that (1) contriever
models have significantly increased extractability, but extractability usually
correlates poorly with benchmark performance 2) gender bias is present, but is
not caused by the contriever representations 3) there is high sensitivity to
both random initialisation and to data shuffle, suggesting that future
retrieval research should test across a wider spread of both.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Video Instruction Tuning With Synthetic Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02713v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02713v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuanhan Zhang, Jinming Wu, Wei Li, Bo Li, Zejun Ma, Ziwei Liu, Chunyuan Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The development of video large multimodal models (LMMs) has been hindered by
the difficulty of curating large amounts of high-quality raw data from the web.
To address this, we propose an alternative approach by creating a high-quality
synthetic dataset specifically for video instruction-following, namely
LLaVA-Video-178K. This dataset includes key tasks such as detailed captioning,
open-ended question-answering (QA), and multiple-choice QA. By training on this
dataset, in combination with existing visual instruction tuning data, we
introduce LLaVA-Video, a new video LMM. Our experiments demonstrate that
LLaVA-Video achieves strong performance across various video benchmarks,
highlighting the effectiveness of our dataset. We plan to release the dataset,
its generation pipeline, and the model checkpoints.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://llava-vl.github.io/blog/2024-09-30-llava-video/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Convolutional Variational Autoencoders for Spectrogram Compression in
  Automatic Speech Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02560v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02560v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Olga Iakovenko, Ivan Bondarenko
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For many Automatic Speech Recognition (ASR) tasks audio features as
spectrograms show better results than Mel-frequency Cepstral Coefficients
(MFCC), but in practice they are hard to use due to a complex dimensionality of
a feature space. The following paper presents an alternative approach towards
generating compressed spectrogram representation, based on Convolutional
Variational Autoencoders (VAE). A Convolutional VAE model was trained on a
subsample of the LibriSpeech dataset to reconstruct short fragments of audio
spectrograms (25 ms) from a 13-dimensional embedding. The trained model for a
40-dimensional (300 ms) embedding was used to generate features for corpus of
spoken commands on the GoogleSpeechCommands dataset. Using the generated
features an ASR system was built and compared to the model with MFCC features.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Theory and Practice of Natural Computing 9th International
  Conference, TPNC 2020, Taoyuan, Taiwan, 2020, Proceedings 9</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Logistic Regression makes small LLMs strong and explainable
  "tens-of-shot" classifiers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.03414v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.03414v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marcus Buckmann, Edward Hill
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For simple classification tasks, we show that users can benefit from the
advantages of using small, local, generative language models instead of large
commercial models without a trade-off in performance or introducing extra
labelling costs. These advantages, including those around privacy,
availability, cost, and explainability, are important both in commercial
applications and in the broader democratisation of AI. Through experiments on
17 sentence classification tasks (2-4 classes), we show that penalised logistic
regression on the embeddings from a small LLM equals (and usually betters) the
performance of a large LLM in the "tens-of-shot" regime. This requires no more
labelled instances than are needed to validate the performance of the large
LLM. Finally, we extract stable and sensible explanations for classification
decisions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>48 pages, 24 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SpeciaLex: A Benchmark for In-Context Specialized Lexicon Learning <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13297v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13297v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joseph Marvin Imperial, Harish Tayyar Madabushi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Specialized lexicons are collections of words with associated constraints
such as special definitions, specific roles, and intended target audiences.
These constraints are necessary for content generation and documentation tasks
(e.g., writing technical manuals or children's reading materials), where the
goal is to reduce the ambiguity of text content and increase its overall
readability for a specific group of audience. Understanding how large language
models can capture these constraints can help researchers build better, more
impactful tools for wider use beyond the NLP community. Towards this end, we
introduce SpeciaLex, a benchmark for evaluating a language model's ability to
follow specialized lexicon-based constraints across 18 diverse subtasks with
1,785 test instances covering core tasks of Checking, Identification,
Rewriting, and Open Generation. We present an empirical evaluation of 15 open
and closed-source LLMs and discuss insights on how factors such as model scale,
openness, setup, and recency affect performance upon evaluating with the
benchmark.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Camera-ready for EMNLP 2024 (Findings)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A LLM-Based Ranking Method for the Evaluation of Automatic
  Counter-Narrative Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.15227v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.15227v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Irune Zubiaga, Aitor Soroa, Rodrigo Agerri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes a novel approach to evaluate Counter Narrative (CN)
generation using a Large Language Model (LLM) as an evaluator. We show that
traditional automatic metrics correlate poorly with human judgements and fail
to capture the nuanced relationship between generated CNs and human perception.
To alleviate this, we introduce a model ranking pipeline based on pairwise
comparisons of generated CNs from different models, organized in a
tournament-style format. The proposed evaluation method achieves a high
correlation with human preference, with a $\rho$ score of 0.88. As an
additional contribution, we leverage LLMs as zero-shot CN generators and
provide a comparative analysis of chat, instruct, and base models, exploring
their respective strengths and limitations. Through meticulous evaluation,
including fine-tuning experiments, we elucidate the differences in performance
and responsiveness to domain-specific data. We conclude that chat-aligned
models in zero-shot are the best option for carrying out the task, provided
they do not refuse to generate an answer due to security concerns.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tokenization Falling Short: On Subword Robustness in Large Language
  Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11687v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11687v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yekun Chai, Yewei Fang, Qiwei Peng, Xuhong Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language models typically tokenize raw text into sequences of subword
identifiers from a predefined vocabulary, a process inherently sensitive to
typographical errors, length variations, and largely oblivious to the internal
structure of tokens--issues we term the curse of tokenization. In this study,
we delve into these drawbacks and demonstrate that large language models (LLMs)
remain susceptible to these problems. This study systematically investigates
these challenges and their impact on LLMs through three critical research
questions: (1) complex problem solving, (2) token structure probing, and (3)
resilience to typographical variation. Our findings reveal that scaling model
parameters can mitigate the issue of tokenization; however, LLMs still suffer
from biases induced by typos and other text format variations. Our experiments
show that subword regularization such as BPE-dropout can mitigate this issue.
We release our evaluation code and data at https://github.com/FloatAI/TKEval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SLANG: New Concept Comprehension of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.12585v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.12585v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lingrui Mei, Shenghua Liu, Yiwei Wang, Baolong Bi, Xueqi Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The dynamic nature of language, particularly evident in the realm of slang
and memes on the Internet, poses serious challenges to the adaptability of
large language models (LLMs). Traditionally anchored to static datasets, these
models often struggle to keep up with the rapid linguistic evolution
characteristic of online communities. This research aims to bridge this gap by
enhancing LLMs' comprehension of the evolving new concepts on the Internet,
without the high cost of continual retraining. In pursuit of this goal, we
introduce $\textbf{SLANG}$, a benchmark designed to autonomously integrate
novel data and assess LLMs' ability to comprehend emerging concepts, alongside
$\textbf{FOCUS}$, an approach uses causal inference to enhance LLMs to
understand new phrases and their colloquial context. Our benchmark and approach
involves understanding real-world instances of linguistic shifts, serving as
contextual beacons, to form more precise and contextually relevant connections
between newly emerging expressions and their meanings. The empirical analysis
shows that our causal inference-based approach outperforms the baseline methods
in terms of precision and relevance in the comprehension of Internet slang and
memes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Self-Training for Sample-Efficient Active Learning for Text
  Classification with <span class="highlight-title">Pre-Train</span>ed Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.09206v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.09206v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Christopher Schröder, Gerhard Heyer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Active learning is an iterative labeling process that is used to obtain a
small labeled subset, despite the absence of labeled data, thereby enabling to
train a model for supervised tasks such as text classification. While active
learning has made considerable progress in recent years due to improvements
provided by pre-trained language models, there is untapped potential in the
often neglected unlabeled portion of the data, although it is available in
considerably larger quantities than the usually small set of labeled data. In
this work, we investigate how self-training, a semi-supervised approach that
uses a model to obtain pseudo-labels for unlabeled data, can be used to improve
the efficiency of active learning for text classification. Building on a
comprehensive reproduction of four previous self-training approaches, some of
which are evaluated for the first time in the context of active learning or
natural language processing, we introduce HAST, a new and effective
self-training strategy, which is evaluated on four text classification
benchmarks. Our results show that it outperforms the reproduced self-training
approaches and reaches classification results comparable to previous
experiments for three out of four datasets, using as little as 25% of the data.
The code is publicly available at
https://github.com/chschroeder/self-training-for-sample-efficient-active-learning .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ L-CiteEval: Do Long-Context Models Truly Leverage Context for
  Responding? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02115v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02115v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zecheng Tang, Keyan Zhou, Juntao Li, Baibei Ji, Jianye Hou, Min Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Long-context models (LCMs) have made remarkable strides in recent years,
offering users great convenience for handling tasks that involve long context,
such as document summarization. As the community increasingly prioritizes the
faithfulness of generated results, merely ensuring the accuracy of LCM outputs
is insufficient, as it is quite challenging for humans to verify the results
from the extremely lengthy context. Yet, although some efforts have been made
to assess whether LCMs respond truly based on the context, these works either
are limited to specific tasks or heavily rely on external evaluation resources
like GPT4.In this work, we introduce L-CiteEval, a comprehensive multi-task
benchmark for long-context understanding with citations, aiming to evaluate
both the understanding capability and faithfulness of LCMs. L-CiteEval covers
11 tasks from diverse domains, spanning context lengths from 8K to 48K, and
provides a fully automated evaluation suite. Through testing with 11
cutting-edge closed-source and open-source LCMs, we find that although these
models show minor differences in their generated results, open-source models
substantially trail behind their closed-source counterparts in terms of
citation accuracy and recall. This suggests that current open-source LCMs are
prone to responding based on their inherent knowledge rather than the given
context, posing a significant risk to the user experience in practical
applications. We also evaluate the RAG approach and observe that RAG can
significantly improve the faithfulness of LCMs, albeit with a slight decrease
in the generation quality. Furthermore, we discover a correlation between the
attention mechanisms of LCMs and the citation generation process.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy
  Data in Misaligned Languages Suffice? <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.14122v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.14122v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dawei Zhu, Pinzhen Chen, Miaoran Zhang, Barry Haddow, Xiaoyu Shen, Dietrich Klakow
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Traditionally, success in multilingual machine translation can be attributed
to three key factors in training data: large volume, diverse translation
directions, and high quality. In the current practice of fine-tuning large
language models (LLMs) for translation, we revisit the importance of these
factors. We find that LLMs display strong translation capability after being
fine-tuned on as few as 32 parallel sentences and that fine-tuning on a single
translation direction enables translation in multiple directions. However, the
choice of direction is critical: fine-tuning LLMs with only English on the
target side can lead to task misinterpretation, which hinders translation into
non-English languages. Problems also arise when noisy synthetic data is placed
on the target side, especially when the target language is well-represented in
LLM pre-training. Yet interestingly, synthesized data in an under-represented
language has a less pronounced effect. Our findings suggest that when adapting
LLMs to translation, the requirement on data quantity can be eased but careful
considerations are still crucial to prevent an LLM from exploiting unintended
data biases.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Is In-Context Learning Sufficient for Instruction Following in LLMs? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.19874v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.19874v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Zhao, Maksym Andriushchenko, Francesco Croce, Nicolas Flammarion
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In-context learning (ICL) allows LLMs to learn from examples without changing
their weights: this is a particularly promising capability for long-context
LLMs that can potentially learn from many examples. Recently, Lin et al. (2024)
proposed URIAL, a method using only three in-context examples to align base
LLMs, achieving non-trivial instruction following performance. In this work, we
show that, while effective, ICL alignment with URIAL still underperforms
compared to instruction fine-tuning on the established benchmark MT-Bench,
especially with more capable base LLMs. We then uncover the most relevant
elements for successful in-context alignment, finding the crucial role of the
decoding parameters. Based on these insights, we show that the approach of
URIAL can indeed be improved by adding high-quality, potentially carefully
selected via greedy search, demonstrations in context, getting closer to the
performance of instruct models. Finally, we provide the first, to our
knowledge, systematic comparison of ICL and instruction fine-tuning (IFT) for
instruction following in the low data regime, where ICL can be a viable
alternative to IFT. Overall, our work advances the understanding of ICL as an
alignment technique and its relationship to IFT. We provide our code at
https://github.com/tml-epfl/icl-alignment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint. Code at https://github.com/tml-epfl/icl-alignment</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous
  <span class="highlight-title">Prompt</span> Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.03279v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.03279v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qizhou Chen, Taolin Zhang, Xiaofeng He, Dongyang Li, Chengyu Wang, Longtao Huang, Hui Xue
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Model editing aims to correct outdated or erroneous knowledge in large
language models (LLMs) without the need for costly retraining. Lifelong model
editing is the most challenging task that caters to the continuous editing
requirements of LLMs. Prior works primarily focus on single or batch editing;
nevertheless, these methods fall short in lifelong editing scenarios due to
catastrophic knowledge forgetting and the degradation of model performance.
Although retrieval-based methods alleviate these issues, they are impeded by
slow and cumbersome processes of integrating the retrieved knowledge into the
model. In this work, we introduce RECIPE, a RetriEval-augmented ContInuous
Prompt lEarning method, to boost editing efficacy and inference efficiency in
lifelong learning. RECIPE first converts knowledge statements into short and
informative continuous prompts, prefixed to the LLM's input query embedding, to
efficiently refine the response grounded on the knowledge. It further
integrates the Knowledge Sentinel (KS) that acts as an intermediary to
calculate a dynamic threshold, determining whether the retrieval repository
contains relevant knowledge. Our retriever and prompt encoder are jointly
trained to achieve editing properties, i.e., reliability, generality, and
locality. In our experiments, RECIPE is assessed extensively across multiple
LLMs and editing datasets, where it achieves superior editing performance.
RECIPE also demonstrates its capability to maintain the overall performance of
LLMs alongside showcasing fast editing and inference speed.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 4 figures, 6 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GOSt-MT: A Knowledge Graph for Occupation-related Gender Biases in
  Machine Translation <span class="chip">CIKM</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.10989v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.10989v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Orfeas Menis Mastromichalakis, Giorgos Filandrianos, Eva Tsouparopoulou, Dimitris Parsanoglou, Maria Symeonaki, Giorgos Stamou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Gender bias in machine translation (MT) systems poses significant challenges
that often result in the reinforcement of harmful stereotypes. Especially in
the labour domain where frequently occupations are inaccurately associated with
specific genders, such biases perpetuate traditional gender stereotypes with a
significant impact on society. Addressing these issues is crucial for ensuring
equitable and accurate MT systems. This paper introduces a novel approach to
studying occupation-related gender bias through the creation of the GOSt-MT
(Gender and Occupation Statistics for Machine Translation) Knowledge Graph.
GOSt-MT integrates comprehensive gender statistics from real-world labour data
and textual corpora used in MT training. This Knowledge Graph allows for a
detailed analysis of gender bias across English, French, and Greek,
facilitating the identification of persistent stereotypes and areas requiring
intervention. By providing a structured framework for understanding how
occupations are gendered in both labour markets and MT systems, GOSt-MT
contributes to efforts aimed at making MT systems more equitable and reducing
gender biases in automated translations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at the KG-STAR'24: Workshop on Knowledge Graphs for
  Responsible AI co-located with the 33rd ACM CIKM Conference, October 25,
  2024, Boise, Idaho</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MobileQuant: Mobile-friendly Quantization for On-device Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.13933v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.13933v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fuwen Tan, Royson Lee, Łukasz Dudziak, Shell Xu Hu, Sourav Bhattacharya, Timothy Hospedales, Georgios Tzimiropoulos, Brais Martinez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have revolutionized language processing,
delivering outstanding results across multiple applications. However, deploying
LLMs on edge devices poses several challenges with respect to memory, energy,
and compute costs, limiting their widespread use in devices such as mobile
phones. A promising solution is to reduce the number of bits used to represent
weights and activations. While existing works have found partial success at
quantizing LLMs to lower bitwidths, e.g. 4-bit weights, quantizing activations
beyond 16 bits often leads to large computational overheads due to poor
on-device quantization support, or a considerable accuracy drop. Yet, 8-bit
activations are very attractive for on-device deployment as they would enable
LLMs to fully exploit mobile-friendly hardware, e.g. Neural Processing Units
(NPUs). In this work, we make a first attempt to facilitate the on-device
deployment of LLMs using integer-only quantization. We first investigate the
limitations of existing quantization methods for on-device deployment, with a
special focus on activation quantization. We then address these limitations by
introducing a simple post-training quantization method, named MobileQuant, that
extends previous weight equivalent transformation works by jointly optimizing
the weight transformation and activation range parameters in an end-to-end
manner. MobileQuant demonstrates superior capabilities over existing methods by
1) achieving near-lossless quantization on a wide range of LLM benchmarks, 2)
reducing latency and energy consumption by 20\%-50\% compared to current
on-device quantization strategies, 3) requiring limited compute budget, 4)
being compatible with mobile-friendly compute units, e.g. NPU.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Findings. Code and models available:
  https://github.com/saic-fi/MobileQuant</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SMILE: Single-turn to Multi-turn Inclusive Language Expansion via
  Chat<span class="highlight-title">GPT</span> for Mental Health Support <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.00450v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.00450v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huachuan Qiu, Hongliang He, Shuai Zhang, Anqi Li, Zhenzhong Lan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Developing specialized dialogue systems for mental health support requires
multi-turn conversation data, which has recently garnered increasing attention.
However, gathering and releasing large-scale, real-life multi-turn
conversations that could facilitate advancements in mental health support
presents challenges in data privacy protection and the time and cost involved
in crowdsourcing. To address these challenges, we introduce SMILE, a
single-turn to multi-turn inclusive language expansion technique that prompts
ChatGPT to rewrite public single-turn dialogues into multi-turn ones. Our work
begins by analyzing language transformation and validating the feasibility of
our proposed method. We conduct a study on dialogue diversity, including
lexical features, semantic features, and dialogue topics, demonstrating the
effectiveness of our method. Further, we employ our method to generate a
large-scale, lifelike, and diverse dialogue dataset named SMILECHAT, consisting
of 55k dialogues. Finally, we utilize the collected corpus to develop a mental
health chatbot, MeChat. To better assess the quality of SMILECHAT, we collect a
small-scale real-life counseling dataset conducted by data anonymization. Both
automatic and human evaluations demonstrate significant improvements in our
dialogue system and confirm that SMILECHAT is high-quality. Code, data, and
model are publicly available at https://github.com/qiuhuachuan/smile.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accepted to the EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Intrinsic Evaluation of Unlearning Using Parametric Knowledge Traces 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11614v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11614v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yihuai Hong, Lei Yu, Haiqin Yang, Shauli Ravfogel, Mor Geva
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The task of "unlearning" certain concepts in large language models (LLMs) has
attracted immense attention recently, due to its importance in mitigating
undesirable model behaviours, such as the generation of harmful, private, or
incorrect information. Current protocols to evaluate unlearning methods largely
rely on behavioral tests, without monitoring the presence of unlearned
knowledge within the model's parameters. This residual knowledge can be
adversarially exploited to recover the erased information post-unlearning. We
argue that unlearning should also be evaluated internally, by considering
changes in the parametric knowledge traces of the unlearned concepts. To this
end, we propose a general evaluation methodology that leverages vocabulary
projections to inspect concepts encoded in model parameters. We use this
approach to localize "concept vectors" - parameter vectors that encode concrete
concepts - and construct ConceptVectors, a benchmark dataset containing
hundreds of common concepts and their parametric knowledge traces within two
open-source LLMs. Evaluation on ConceptVectors shows that existing unlearning
methods minimally impact concept vectors and mostly suppress them during
inference, while directly ablating these vectors demonstrably removes the
associated knowledge and significantly reduces the model's susceptibility to
adversarial manipulation. Our results highlight limitations in behavioral-based
unlearning evaluations and call for future work to include parameter-based
evaluations. To support this, we release our code and benchmark at
https://github.com/yihuaihong/ConceptVectors.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Preference-Guided Reflective Sampling for Aligning Language Models <span class="chip">EMNLP2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.12163v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.12163v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hai Ye, Hwee Tou Ng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Iterative data generation and model re-training can effectively align large
language models(LLMs) to human preferences. The process of data sampling is
crucial, as it significantly influences the success of policy improvement.
Repeated random sampling is a widely used method that independently queries the
model multiple times to generate outputs. In this work, we propose a more
effective sampling method, named Preference-Guided Reflective Sampling (PRS).
Unlike random sampling, PRS employs a tree-based generation framework to enable
more efficient sampling. It leverages adaptive self-refinement techniques to
better explore the sampling space. By specifying user preferences in natural
language, PRS can further optimize response generation according to these
preferences. As a result, PRS can align models to diverse user preferences. Our
experiments demonstrate that PRS generates higher-quality responses with
significantly higher rewards. On AlpacaEval and Arena-Hard, PRS substantially
outperforms repeated random sampling in best-of-$N$ sampling. Moreover, PRS
shows strong performance when applied in iterative offline RL training.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP2024, main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PreAlign: Boosting Cross-Lingual Transfer by Early Establishment of
  Multilingual Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.16222v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.16222v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiahuan Li, Shujian Huang, Aarron Ching, Xinyu Dai, Jiajun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models demonstrate reasonable multilingual abilities, despite
predominantly English-centric pretraining. However, the spontaneous
multilingual alignment in these models is shown to be weak, leading to
unsatisfactory cross-lingual transfer and knowledge sharing. Previous works
attempt to address this issue by explicitly injecting multilingual alignment
information during or after pretraining. Thus for the early stage in
pretraining, the alignment is weak for sharing information or knowledge across
languages. In this paper, we propose PreAlign, a framework that establishes
multilingual alignment prior to language model pretraining. PreAlign injects
multilingual alignment by initializing the model to generate similar
representations of aligned words and preserves this alignment using a
code-switching strategy during pretraining. Extensive experiments in a
synthetic English to English-Clone setting demonstrate that PreAlign
significantly outperforms standard multilingual joint training in language
modeling, zero-shot cross-lingual transfer, and cross-lingual knowledge
application. Further experiments in real-world scenarios further validate
PreAlign's effectiveness across various model sizes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Standardize: Aligning Language Models with Expert-Defined Standards for
  Content Generation <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.12593v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.12593v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joseph Marvin Imperial, Gail Forey, Harish Tayyar Madabushi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Domain experts across engineering, healthcare, and education follow strict
standards for producing quality content such as technical manuals, medication
instructions, and children's reading materials. However, current works in
controllable text generation have yet to explore using these standards as
references for control. Towards this end, we introduce Standardize, a
retrieval-style in-context learning-based framework to guide large language
models to align with expert-defined standards. Focusing on English language
standards in the education domain as a use case, we consider the Common
European Framework of Reference for Languages (CEFR) and Common Core Standards
(CCS) for the task of open-ended content generation. Our findings show that
models can gain a 45% to 100% increase in precise accuracy across open and
commercial LLMs evaluated, demonstrating that the use of knowledge artifacts
extracted from standards and integrating them in the generation process can
effectively guide models to produce better standard-aligned content.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Camera-ready for EMNLP 2024 (Main)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Major Entity Identification: A Generalizable Alternative to Coreference
  Resolution 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14654v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14654v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kawshik Manikantan, Shubham Toshniwal, Makarand Tapaswi, Vineet Gandhi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The limited generalization of coreference resolution (CR) models has been a
major bottleneck in the task's broad application. Prior work has identified
annotation differences, especially for mention detection, as one of the main
reasons for the generalization gap and proposed using additional annotated
target domain data. Rather than relying on this additional annotation, we
propose an alternative referential task, Major Entity Identification (MEI),
where we: (a) assume the target entities to be specified in the input, and (b)
limit the task to only the frequent entities. Through extensive experiments, we
demonstrate that MEI models generalize well across domains on multiple datasets
with supervised models and LLM-based few-shot prompting. Additionally, MEI fits
the classification framework, which enables the use of robust and intuitive
classification-based metrics. Finally, MEI is also of practical use as it
allows a user to search for all mentions of a particular entity or a group of
entities of interest.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ C-MELT: Contrastive Enhanced Masked Auto-Encoders for ECG-Language
  <span class="highlight-title">Pre-Train</span>ing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02131v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02131v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manh Pham, Aaqib Saeed, Dong Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate interpretation of Electrocardiogram (ECG) signals is pivotal for
diagnosing cardiovascular diseases. Integrating ECG signals with their
accompanying textual reports holds immense potential to enhance clinical
diagnostics through the combination of physiological data and qualitative
insights. However, this integration faces significant challenges due to
inherent modality disparities and the scarcity of labeled data for robust
cross-modal learning. To address these obstacles, we propose C-MELT, a novel
framework that pre-trains ECG and text data using a contrastive masked
auto-encoder architecture. C-MELT uniquely combines the strengths of generative
with enhanced discriminative capabilities to achieve robust cross-modal
representations. This is accomplished through masked modality modeling,
specialized loss functions, and an improved negative sampling strategy tailored
for cross-modal alignment. Extensive experiments on five public datasets across
diverse downstream tasks demonstrate that C-MELT significantly outperforms
existing methods, achieving 15% and 2% increases in linear probing and
zero-shot performance over state-of-the-art models, respectively. These results
highlight the effectiveness of C-MELT, underscoring its potential to advance
automated clinical diagnostics through multi-modal representations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving Quotation Attribution with Fictional Character Embeddings <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11368v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11368v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gaspard Michel, Elena V. Epure, Romain Hennequin, Christophe Cerisara
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Humans naturally attribute utterances of direct speech to their speaker in
literary works. When attributing quotes, we process contextual information but
also access mental representations of characters that we build and revise
throughout the narrative. Recent methods to automatically attribute such
utterances have explored simulating human logic with deterministic rules or
learning new implicit rules with neural networks when processing contextual
information. However, these systems inherently lack \textit{character}
representations, which often leads to errors in more challenging examples of
attribution: anaphoric and implicit quotes. In this work, we propose to augment
a popular quotation attribution system, BookNLP, with character embeddings that
encode global stylistic information of characters derived from an off-the-shelf
stylometric model, Universal Authorship Representation (UAR). We create DramaCV
(Code and data can be found at
https://github.com/deezer/character_embeddings_qa ), a corpus of English drama
plays from the 15th to 20th century that we automatically annotate for
Authorship Verification of fictional characters utterances, and release two
versions of UAR trained on DramaCV, that are tailored for literary characters
analysis. Then, through an extensive evaluation on 28 novels, we show that
combining BookNLP's contextual information with our proposed global character
embeddings improves the identification of speakers for anaphoric and implicit
quotes, reaching state-of-the-art performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 (Findings)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Measuring Psychological Depth in Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12680v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12680v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fabrice Harel-Canada, Hanyu Zhou, Sreya Muppalla, Zeynep Yildiz, Miryung Kim, Amit Sahai, Nanyun Peng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Evaluations of creative stories generated by large language models (LLMs)
often focus on objective properties of the text, such as its style, coherence,
and diversity. While these metrics are indispensable, they do not speak to a
story's subjective, psychological impact from a reader's perspective. We
introduce the Psychological Depth Scale (PDS), a novel framework rooted in
literary theory that measures an LLM's ability to produce authentic and
narratively complex stories that provoke emotion, empathy, and engagement. We
empirically validate our framework by showing that humans can consistently
evaluate stories based on PDS (0.72 Krippendorff's alpha). We also explore
techniques for automating the PDS to easily scale future analyses. GPT-4o,
combined with a novel Mixture-of-Personas (MoP) prompting strategy, achieves an
average Spearman correlation of 0.51 with human judgment while Llama-3-70B with
constrained decoding scores as high as 0.68 for empathy. Finally, we compared
the depth of stories authored by both humans and LLMs. Surprisingly, GPT-4
stories either surpassed or were statistically indistinguishable from
highly-rated human-written stories sourced from Reddit. By shifting the focus
from text to reader, the Psychological Depth Scale is a validated, automated,
and systematic means of measuring the capacity of LLMs to connect with humans
through the stories they tell.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Deception in Reinforced Autonomous Agents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.04325v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.04325v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Atharvan Dogra, Krishna Pillutla, Ameet Deshpande, Ananya B Sai, John Nay, Tanmay Rajpurohit, Ashwin Kalyan, Balaraman Ravindran
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We explore the ability of large language model (LLM)-based agents to engage
in subtle deception such as strategically phrasing and intentionally
manipulating information to misguide and deceive other agents. This harmful
behavior can be hard to detect, unlike blatant lying or unintentional
hallucination. We build an adversarial testbed mimicking a legislative
environment where two LLMs play opposing roles: a corporate *lobbyist*
proposing amendments to bills that benefit a specific company while evading a
*critic* trying to detect this deception. We use real-world legislative bills
matched with potentially affected companies to ground these interactions. Our
results show that LLM lobbyists initially exhibit limited deception against
strong LLM critics which can be further improved through simple verbal
reinforcement, significantly enhancing their deceptive capabilities, and
increasing deception rates by up to 40 points. This highlights the risk of
autonomous agents manipulating other agents through seemingly neutral language
to attain self-serving goals.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ In Search of the Long-Tail: Systematic Generation of Long-Tail
  Inferential Knowledge via Logical Rule Guided Search 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.07237v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.07237v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huihan Li, Yuting Ning, Zeyi Liao, Siyuan Wang, Xiang Lorraine Li, Ximing Lu, Wenting Zhao, Faeze Brahman, Yejin Choi, Xiang Ren
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To effectively use large language models (LLMs) for real-world queries, it is
imperative that they generalize to the long-tail distribution, i.e. rare
examples where models exhibit low confidence. In this work, we take the first
step towards evaluating LLMs in the long-tail distribution of inferential
knowledge. We exemplify long-tail evaluation on the Natural Language Inference
task. First, we introduce Logic-Induced-Knowledge-Search (LINK), a systematic
long-tail data generation framework, to obtain factually-correct yet long-tail
inferential statements. LINK uses variable-wise prompting grounded on symbolic
rules to seek low-confidence statements while ensuring factual correctness. We
then use LINK to curate Logic-Induced-Long-Tail (LINT), a large-scale long-tail
inferential knowledge dataset that contains 108K statements spanning four
domains. We evaluate popular LLMs on LINT; we find that state-of-the-art LLMs
show significant performance drop (21% relative drop for GPT4) on long-tail
data as compared to on head distribution data, and smaller models show even
more generalization weakness. These results further underscore the necessity of
long-tail evaluation in developing generalizable LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ From Pixels to Tokens: Byte-Pair Encoding on Quantized Visual Modalities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02155v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02155v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wanpeng Zhang, Zilong Xie, Yicheng Feng, Yijiang Li, Xingrun Xing, Sipeng Zheng, Zongqing Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Large Language Models have made significant strides in integrating
visual and textual information, yet they often struggle with effectively
aligning these modalities. We introduce a novel image tokenizer that bridges
this gap by applying the principle of Byte-Pair Encoding (BPE) to visual data.
Unlike conventional approaches that rely on separate visual encoders, our
method directly incorporates structural prior information into image tokens,
mirroring the successful tokenization strategies used in text-only Large
Language Models. This innovative approach enables Transformer models to more
effectively learn and reason across modalities. Through theoretical analysis
and extensive experiments, we demonstrate that our BPE Image Tokenizer
significantly enhances MLLMs' multimodal understanding capabilities, even with
limited training data. Our method not only improves performance across various
benchmarks but also shows promising scalability, potentially paving the way for
more efficient and capable multimodal foundation models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Investigating LLMs as Voting Assistants via Contextual Augmentation: A
  Case Study on the European Parliament Elections 2024 <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.08495v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.08495v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ilias Chalkidis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In light of the recent 2024 European Parliament elections, we are
investigating if LLMs can be used as Voting Advice Applications (VAAs). We
audit MISTRAL and MIXTRAL models and evaluate their accuracy in predicting the
stance of political parties based on the latest "EU and I" voting assistance
questionnaire. Furthermore, we explore alternatives to improve models'
performance by augmenting the input context via Retrieval-Augmented Generation
(RAG) relying on web search, and Self-Reflection using staged conversations
that aim to re-collect relevant content from the model's internal memory. We
find that MIXTRAL is highly accurate with an 82% accuracy on average with a
significant performance disparity across different political groups (50-95%).
Augmenting the input context with expert-curated information can lead to a
significant boost of approx. 9%, which remains an open challenge for automated
RAG approaches, even considering curated content.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accepted to EMNLP 2024 as a short paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ <span class="highlight-title">★</span> HarmAug: Effective Data Augmentation for Knowledge Distillation of
  Safety Guard Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01524v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01524v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seanie Lee, Haebin Seong, Dong Bok Lee, Minki Kang, Xiaoyin Chen, Dominik Wagner, <span class="highlight-author">Yoshua Bengio</span>, Juho Lee, Sung Ju Hwang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Safety guard models that detect malicious queries aimed at large language
models (LLMs) are essential for ensuring the secure and responsible deployment
of LLMs in real-world applications. However, deploying existing safety guard
models with billions of parameters alongside LLMs on mobile devices is
impractical due to substantial memory requirements and latency. To reduce this
cost, we distill a large teacher safety guard model into a smaller one using a
labeled dataset of instruction-response pairs with binary harmfulness labels.
Due to the limited diversity of harmful instructions in the existing labeled
dataset, naively distilled models tend to underperform compared to larger
models. To bridge the gap between small and large models, we propose HarmAug, a
simple yet effective data augmentation method that involves jailbreaking an LLM
and prompting it to generate harmful instructions. Given a prompt such as,
"Make a single harmful instruction prompt that would elicit offensive content",
we add an affirmative prefix (e.g., "I have an idea for a prompt:") to the
LLM's response. This encourages the LLM to continue generating the rest of the
response, leading to sampling harmful instructions. Another LLM generates a
response to the harmful instruction, and the teacher model labels the
instruction-response pair. We empirically show that our HarmAug outperforms
other relevant baselines. Moreover, a 435-million-parameter safety guard model
trained with HarmAug achieves an F1 score comparable to larger models with over
7 billion parameters, and even outperforms them in AUPRC, while operating at
less than 25% of their computational cost.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LUQ: Long-text Uncertainty Quantification for LLMs <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.20279v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.20279v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Caiqi Zhang, Fangyu Liu, Marco Basaldella, Nigel Collier
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have demonstrated remarkable capability in a
variety of NLP tasks. However, LLMs are also prone to generate nonfactual
content. Uncertainty Quantification (UQ) is pivotal in enhancing our
understanding of a model's confidence on its generation, thereby aiding in the
mitigation of nonfactual outputs. Existing research on UQ predominantly targets
short text generation, typically yielding brief, word-limited responses.
However, real-world applications frequently necessitate much longer responses.
Our study first highlights the limitations of current UQ methods in handling
long text generation. We then introduce \textsc{Luq} and its two variations, a
series of novel sampling-based UQ approaches specifically designed for long
text. Our findings reveal that \textsc{Luq} outperforms existing baseline
methods in correlating with the model's factuality scores (negative coefficient
of -0.85 observed for Gemini Pro). To further improve the factuality of LLM
responses, we propose \textsc{Luq-Ensemble}, a method that ensembles responses
from multiple models and selects the response with the lowest uncertainty. The
ensembling method greatly improves the response factuality upon the best
standalone LLM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Annotation Guidelines for Corpus Novelties: Part 1 -- Named Entity
  Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02281v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02281v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arthur Amalvy, Vincent Labatut
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Novelties corpus is a collection of novels (and parts of novels)
annotated for Named Entity Recognition (NER) among other tasks. This document
describes the guidelines applied during its annotation. It contains the
instructions used by the annotators, as well as a number of examples retrieved
from the annotated novels, and illustrating expressions that should be marked
as entities as well as expressions that should not.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Repairs in a Block World: A New Benchmark for Handling User Corrections
  with Multi-Modal Language Models <span class="chip">EMNLP'24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.14247v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.14247v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Javier Chiyah-Garcia, Alessandro Suglia, Arash Eshghi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In dialogue, the addressee may initially misunderstand the speaker and
respond erroneously, often prompting the speaker to correct the
misunderstanding in the next turn with a Third Position Repair (TPR). The
ability to process and respond appropriately to such repair sequences is thus
crucial in conversational AI systems. In this paper, we first collect, analyse,
and publicly release BlockWorld-Repairs: a dataset of multi-modal TPR sequences
in an instruction-following manipulation task that is, by design, rife with
referential ambiguity. We employ this dataset to evaluate several
state-of-the-art Vision and Language Models (VLM) across multiple settings,
focusing on their capability to process and accurately respond to TPRs and thus
recover from miscommunication. We find that, compared to humans, all models
significantly underperform in this task. We then show that VLMs can benefit
from specialised losses targeting relevant tokens during fine-tuning, achieving
better performance and generalising better to new scenarios. Our results
suggest that these models are not yet ready to be deployed in multi-modal
collaborative settings where repairs are common, and highlight the need to
design training regimes and objectives that facilitate learning from
interaction. Our code and data are available at
www.github.com/JChiyah/blockworld-repairs
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP'24 Main (Upcoming). Data and code at
  www.github.com/JChiyah/blockworld-repairs - for Bibtex see
  https://raw.githubusercontent.com/JChiyah/blockworld-repairs/refs/heads/main/citation.bib</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Coffee-Gym: An Environment for Evaluating and Improving Natural Language
  Feedback on Erroneous Code <span class="chip">EMNLP2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19715v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19715v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hyungjoo Chae, Taeyoon Kwon, Seungjun Moon, Yongho Song, Dongjin Kang, Kai Tzu-iunn Ong, Beong-woo Kwak, Seonghyeon Bae, Seung-won Hwang, Jinyoung Yeo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents Coffee-Gym, a comprehensive RL environment for training
models that provide feedback on code editing. Coffee-Gym includes two major
components: (1) Coffee, a dataset containing humans' code edit traces for
coding questions and machine-written feedback for editing erroneous code; (2)
CoffeeEval, a reward function that faithfully reflects the helpfulness of
feedback by assessing the performance of the revised code in unit tests. With
them, Coffee-Gym addresses the unavailability of high-quality datasets for
training feedback models with RL, and provides more accurate rewards than the
SOTA reward model (i.e., GPT-4). By applying Coffee-Gym, we elicit feedback
models that outperform baselines in enhancing open-source code LLMs' code
editing, making them comparable with closed-source LLMs. We make the dataset
and the model checkpoint publicly available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Cross-lingual Contextualized Phrase Retrieval <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.16820v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.16820v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huayang Li, Deng Cai, Zhi Qu, Qu Cui, Hidetaka Kamigaito, Lemao Liu, Taro Watanabe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Phrase-level dense retrieval has shown many appealing characteristics in
downstream NLP tasks by leveraging the fine-grained information that phrases
offer. In our work, we propose a new task formulation of dense retrieval,
cross-lingual contextualized phrase retrieval, which aims to augment
cross-lingual applications by addressing polysemy using context information.
However, the lack of specific training data and models are the primary
challenges to achieve our goal. As a result, we extract pairs of cross-lingual
phrases using word alignment information automatically induced from parallel
sentences. Subsequently, we train our Cross-lingual Contextualized Phrase
Retriever (CCPR) using contrastive learning, which encourages the hidden
representations of phrases with similar contexts and semantics to align
closely. Comprehensive experiments on both the cross-lingual phrase retrieval
task and a downstream task, i.e, machine translation, demonstrate the
effectiveness of CCPR. On the phrase retrieval task, CCPR surpasses baselines
by a significant margin, achieving a top-1 accuracy that is at least 13 points
higher. When utilizing CCPR to augment the large-language-model-based
translator, it achieves average gains of 0.7 and 1.5 in BERTScore for
translations from X=>En and vice versa, respectively, on WMT16 dataset. Our
code and data are available at \url{https://github.com/ghrua/ccpr_release}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to Findings of EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for
  Tool-Augmented Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.20015v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.20015v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxiang Zhang, Jing Chen, Junjie Wang, Yaxin Liu, Cheng Yang, Chufan Shi, Xinyu Zhu, Zihao Lin, Hanwen Wan, Yujiu Yang, Tetsuya Sakai, Tian Feng, Hayato Yamana
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tool-augmented large language models (LLMs) are rapidly being integrated into
real-world applications. Due to the lack of benchmarks, the community has yet
to fully understand the hallucination issues within these models. To address
this challenge, we introduce a comprehensive diagnostic benchmark, ToolBH.
Specifically, we assess the LLM's hallucinations through two perspectives:
depth and breadth. In terms of depth, we propose a multi-level diagnostic
process, including (1) solvability detection, (2) solution planning, and (3)
missing-tool analysis. For breadth, we consider three scenarios based on the
characteristics of the toolset: missing necessary tools, potential tools, and
limited functionality tools. Furthermore, we developed seven tasks and
collected 700 evaluation samples through multiple rounds of manual annotation.
The results show the significant challenges presented by the ToolBH benchmark.
The current advanced models Gemini-1.5-Pro and GPT-4o only achieve total scores
of 45.3 and 37.0, respectively, on a scale of 100. In this benchmark, larger
model parameters do not guarantee better performance; the training data and
response strategies also play crucial roles in tool-enhanced LLM scenarios. Our
diagnostic analysis indicates that the primary reason for model errors lies in
assessing task solvability. Additionally, open-weight models suffer from
performance drops with verbose replies, whereas proprietary models excel with
longer reasoning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Authorship Obfuscation in Multilingual Machine-Generated Text Detection <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.07867v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.07867v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dominik Macko, Robert Moro, Adaku Uchendu, Ivan Srba, Jason Samuel Lucas, Michiharu Yamashita, Nafis Irtiza Tripto, Dongwon Lee, Jakub Simko, Maria Bielikova
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  High-quality text generation capability of recent Large Language Models
(LLMs) causes concerns about their misuse (e.g., in massive generation/spread
of disinformation). Machine-generated text (MGT) detection is important to cope
with such threats. However, it is susceptible to authorship obfuscation (AO)
methods, such as paraphrasing, which can cause MGTs to evade detection. So far,
this was evaluated only in monolingual settings. Thus, the susceptibility of
recently proposed multilingual detectors is still unknown. We fill this gap by
comprehensively benchmarking the performance of 10 well-known AO methods,
attacking 37 MGT detection methods against MGTs in 11 languages (i.e., 10
$\times$ 37 $\times$ 11 = 4,070 combinations). We also evaluate the effect of
data augmentation on adversarial robustness using obfuscated texts. The results
indicate that all tested AO methods can cause evasion of automated detection in
all tested languages, where homoglyph attacks are especially successful.
However, some of the AO methods severely damaged the text, making it no longer
readable or easily recognizable by humans (e.g., changed language, weird
characters).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Middleware for LLMs: Tools Are Instrumental for Language Agents in
  Complex Environments <span class="chip">EMNLP'2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.14672v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.14672v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu Gu, Yiheng Shu, Hao Yu, Xiao Liu, Yuxiao Dong, Jie Tang, Jayanth Srinivasa, Hugo Latapie, Yu Su
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The applications of large language models (LLMs) have expanded well beyond
the confines of text processing, signaling a new era where LLMs are envisioned
as generalist agents capable of operating within complex environments. These
environments are often highly expansive, making it impossible for the LLM to
process them within its short-term memory. Motivated by recent research on
extending the capabilities of LLMs with tools, we seek to investigate the
intriguing potential of tools to augment LLMs in handling such complexity by
introducing a novel class of tools, termed middleware, to aid in the proactive
exploration within these massive environments. Such specialized tools can serve
as a middleware layer shielding the LLM from environmental complexity. In two
representative complex environments -- knowledge bases (KBs) and databases --
we demonstrate the significant potential of augmenting language agents with
tools in complex environments. Notably, equipped with the middleware, GPT-4
achieves 2.8X the performance of the best baseline in tasks requiring access to
database content and 2.2X in KB tasks. Our findings illuminate the path for
advancing language agents in real-world applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP'2024; 18 pages, 8 figures, 8 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MMLU-SR: A Benchmark for Stress-Testing Reasoning Capability of Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.15468v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.15468v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wentian Wang, Sarthak Jain, Paul Kantor, Jacob Feldman, Lazaros Gallos, Hao Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose MMLU-SR, a novel dataset designed to measure the true
comprehension abilities of Large Language Models (LLMs) by challenging their
performance in question-answering tasks with modified terms. We reasoned that
an agent that "truly" understands a concept can still evaluate it when key
terms are replaced by suitably defined alternate terms, and sought to
differentiate such comprehension from mere text replacement. In our study, we
modified standardized test questions by replacing a key term with a dummy word
along with its definition. The key term could be in the context of questions,
answers, or both questions and answers. Notwithstanding the high scores
achieved by recent popular LLMs on the MMLU leaderboard, we found a substantial
reduction in model performance after such replacement, suggesting poor
comprehension. This new benchmark provides a rigorous benchmark for testing
true model comprehension, and poses a challenge to the broader scientific
community.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ High-Dimension Human Value Representation in Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.07900v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.07900v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Samuel Cahyawijaya, Delong Chen, Yejin Bang, Leila Khalatbari, Bryan Wilie, Ziwei Ji, Etsuko Ishii, Pascale Fung
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The widespread application of Large Language Models (LLMs) across various
tasks and fields has necessitated the alignment of these models with human
values and preferences. Given various approaches of human value alignment,
ranging from Reinforcement Learning with Human Feedback (RLHF), to
constitutional learning, etc. there is an urgent need to understand the scope
and nature of human values injected into these models before their release.
There is also a need for model alignment without a costly large scale human
annotation effort. We propose UniVaR, a high-dimensional representation of
human value distributions in LLMs, orthogonal to model architecture and
training data. Trained from the value-relevant output of eight multilingual
LLMs and tested on the output from four multilingual LLMs, namely LlaMA2,
ChatGPT, JAIS and Yi, we show that UniVaR is a powerful tool to compare the
distribution of human values embedded in different LLMs with different langauge
sources. Through UniVaR, we explore how different LLMs prioritize various
values in different languages and cultures, shedding light on the complex
interplay between human values and language modeling.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LearnerVoice: A <span class="highlight-title">Dataset</span> of Non-Native English Learners' Spontaneous
  Speech 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.04280v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.04280v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haechan Kim, Junho Myung, Seoyoung Kim, Sungpah Lee, Dongyeop Kang, Juho Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prevalent ungrammatical expressions and disfluencies in spontaneous speech
from second language (L2) learners pose unique challenges to Automatic Speech
Recognition (ASR) systems. However, few datasets are tailored to L2 learner
speech. We publicly release LearnerVoice, a dataset consisting of 50.04 hours
of audio and transcriptions of L2 learners' spontaneous speech. Our linguistic
analysis reveals that transcriptions in our dataset contain L2S (L2 learner's
Spontaneous speech) features, consisting of ungrammatical expressions and
disfluencies (e.g., filler words, word repetitions, self-repairs, false
starts), significantly more than native speech datasets. Fine-tuning
whisper-small.en with LearnerVoice achieves a WER of 10.26%, 44.2% lower than
vanilla whisper-small.en. Furthermore, our qualitative analysis indicates that
54.2% of errors from the vanilla model on LearnerVoice are attributable to L2S
features, with 48.1% of them being reduced in the fine-tuned model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Proceedings of Interspeech</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ POSIX: A <span class="highlight-title">Prompt</span> Sensitivity Index For Large Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02185v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02185v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anwoy Chatterjee, H S V N S Kowndinya Renduchintala, Sumit Bhatia, Tanmoy Chakraborty
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite their remarkable capabilities, Large Language Models (LLMs) are found
to be surprisingly sensitive to minor variations in prompts, often generating
significantly divergent outputs in response to minor variations in the prompts,
such as spelling errors, alteration of wording or the prompt template. However,
while assessing the quality of an LLM, the focus often tends to be solely on
its performance on downstream tasks, while very little to no attention is paid
to prompt sensitivity. To fill this gap, we propose POSIX - a novel PrOmpt
Sensitivity IndeX as a reliable measure of prompt sensitivity, thereby offering
a more comprehensive evaluation of LLM performance. The key idea behind POSIX
is to capture the relative change in loglikelihood of a given response upon
replacing the corresponding prompt with a different intent-preserving prompt.
We provide thorough empirical evidence demonstrating the efficacy of POSIX in
capturing prompt sensitivity and subsequently use it to measure and thereby
compare prompt sensitivity of various open-source LLMs. We find that merely
increasing the parameter count or instruction tuning does not necessarily
reduce prompt sensitivity whereas adding some few-shot exemplars, even just
one, almost always leads to significant decrease in prompt sensitivity. We also
find that alterations to prompt template lead to the highest sensitivity in the
case of MCQ type tasks, whereas paraphrasing results in the highest sensitivity
in open-ended generation tasks. The code for reproducing our results is
open-sourced at https://github.com/kowndinya-renduchintala/POSIX.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 (Findings)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Divide-or-Conquer? Which Part Should You Distill Your LLM? <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.15000v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.15000v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhuofeng Wu, He Bai, Aonan Zhang, Jiatao Gu, VG Vinod Vydiswaran, Navdeep Jaitly, Yizhe Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent methods have demonstrated that Large Language Models (LLMs) can solve
reasoning tasks better when they are encouraged to solve subtasks of the main
task first. In this paper we devise a similar strategy that breaks down
reasoning tasks into a problem decomposition phase and a problem solving phase
and show that the strategy is able to outperform a single stage solution.
Further, we hypothesize that the decomposition should be easier to distill into
a smaller model compared to the problem solving because the latter requires
large amounts of domain knowledge while the former only requires learning
general problem solving strategies. We propose methods to distill these two
capabilities and evaluate their impact on reasoning outcomes and inference
cost. We find that we can distill the problem decomposition phase and at the
same time achieve good generalization across tasks, datasets, and models.
However, it is harder to distill the problem solving capability without losing
performance and the resulting distilled model struggles with generalization.
These results indicate that by using smaller, distilled problem decomposition
models in combination with problem solving LLMs we can achieve reasoning with
cost-efficient inference and local adaptation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Findings of the Association for Computational Linguistics: EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LinguAlchemy: Fusing Typological and Geographical Elements for Unseen
  Language Generalization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.06034v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.06034v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Muhammad Farid Adilazuarda, Samuel Cahyawijaya, Alham Fikri Aji, Genta Indra Winata, Ayu Purwarianti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pretrained language models (PLMs) have become remarkably adept at task and
language generalization. Nonetheless, they often fail when faced with unseen
languages. In this work, we present LinguAlchemy, a regularization method that
incorporates various linguistic information covering typological, geographical,
and phylogenetic features to align PLMs representation to the corresponding
linguistic information on each language. Our LinguAlchemy significantly
improves the performance of mBERT and XLM-R on low-resource languages in
multiple downstream tasks such as intent classification, news classification,
and semantic relatedness compared to fully finetuned models and displaying a
high degree of unseen language generalization. We further introduce
AlchemyScale and AlchemyTune, extension of LinguAlchemy which adjusts the
linguistic regularization weights automatically, alleviating the need for
hyperparameter search.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MedAdapter: Efficient Test-Time Adaptation of Large Language Models
  towards Medical Reasoning <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.03000v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.03000v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenqi Shi, Ran Xu, Yuchen Zhuang, Yue Yu, Haotian Sun, Hang Wu, Carl Yang, May D. Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite their improved capabilities in generation and reasoning, adapting
large language models (LLMs) to the biomedical domain remains challenging due
to their immense size and corporate privacy. In this work, we propose
MedAdapter, a unified post-hoc adapter for test-time adaptation of LLMs towards
biomedical applications. Instead of fine-tuning the entire LLM, MedAdapter
effectively adapts the original model by fine-tuning only a small BERT-sized
adapter to rank candidate solutions generated by LLMs. Experiments demonstrate
that MedAdapter effectively adapts both white-box and black-box LLMs in
biomedical reasoning, achieving average performance improvements of 25.48% and
11.31%, respectively, without requiring extensive computational resources or
sharing data with third parties. MedAdapter also yields superior performance
when combined with train-time adaptation, highlighting a flexible and
complementary solution to existing adaptation methods. Faced with the
challenges of balancing model performance, computational resources, and data
privacy, MedAdapter provides an efficient, privacy-preserving, cost-effective,
and transparent solution for adapting LLMs to the biomedical domain.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in EMNLP 2024 main conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Prefixing Attention Sinks can Mitigate Activation Outliers for Large
  Language Model Quantization <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12016v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12016v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seungwoo Son, Wonpyo Park, Woohyun Han, Kyuyeun Kim, Jaeho Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite recent advances in LLM quantization, activation quantization remains
to be challenging due to the activation outliers. Conventional remedies, e.g.,
mixing precisions for different channels, introduce extra overhead and reduce
the speedup. In this work, we develop a simple yet effective strategy to
facilitate per-tensor activation quantization by preventing the generation of
problematic tokens. Precisely, we propose a method to find a set of key-value
cache, coined CushionCache, which mitigates outliers in subsequent tokens when
inserted as a prefix. CushionCache works in two steps: First, we greedily
search for a prompt token sequence that minimizes the maximum activation values
in subsequent tokens. Then, we further tune the token cache to regularize the
activations of subsequent tokens to be more quantization-friendly. The proposed
method successfully addresses activation outliers of LLMs, providing a
substantial performance boost for per-tensor activation quantization methods.
We thoroughly evaluate our method over a wide range of models and benchmarks
and find that it significantly surpasses the established baseline of per-tensor
W8A8 quantization and can be seamlessly integrated with the recent activation
quantization method.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Main (Long)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Demystifying Language Model Forgetting with Low-rank Example
  Associations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14026v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14026v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xisen Jin, Xiang Ren
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language models (LLMs) suffer from forgetting of upstream data when
fine-tuned. Despite efforts on mitigating forgetting, few have investigated
whether, and how forgotten upstream examples are dependent on and associated
with newly learned tasks. Insights on such associations enable efficient and
targeted mitigation of forgetting. In this paper, we empirically analyze
forgetting (measured in log-perplexity increase) that occurs in $N$ upstream
examples of language modeling or instruction-tuning after fine-tuning LLMs on
one of $M$ new tasks, visualized in $M\times N$ matrices. We demonstrate that
the matrices display simple low-rank patterns, often well-approximated with
multiplicative scalar effects of upstream examples and newly learned tasks. We
also examine fine-grained associations with visualization and statistics.
Leveraging the low-rank nature of the associations, we predict forgetting of
upstream examples when fine-tuning on unseen tasks with matrix completion over
the empirical associations. This enables fast identification of most forgotten
examples without expensive inference on the entire upstream data. The approach,
despite simplicity, outperforms prior approaches that learn semantic
relationships of learned tasks and upstream examples with LMs for predicting
forgetting. We demonstrate the practical utility of our analysis by showing
statistically significantly reduced forgetting as we upweight predicted
examples for replay at fine-tuning. Project page:
https://inklab.usc.edu/lm-forgetting-prediction/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages; preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ASTE <span class="highlight-title">Transformer</span> Modelling Dependencies in Aspect-Sentiment Triplet
  Extraction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15202v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15202v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Iwo Naglik, Mateusz Lango
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Aspect-Sentiment Triplet Extraction (ASTE) is a recently proposed task of
aspect-based sentiment analysis that consists in extracting (aspect phrase,
opinion phrase, sentiment polarity) triples from a given sentence. Recent
state-of-the-art methods approach this task by first extracting all possible
text spans from a given text, then filtering the potential aspect and opinion
phrases with a classifier, and finally considering all their pairs with another
classifier that additionally assigns sentiment polarity to them. Although
several variations of the above scheme have been proposed, the common feature
is that the final result is constructed by a sequence of independent classifier
decisions. This hinders the exploitation of dependencies between extracted
phrases and prevents the use of knowledge about the interrelationships between
classifier predictions to improve performance. In this paper, we propose a new
ASTE approach consisting of three transformer-inspired layers, which enables
the modelling of dependencies both between phrases and between the final
classifier decisions. Experimental results show that the method achieves higher
performance in terms of F1 measure than other methods studied on popular
benchmarks. In addition, we show that a simple pre-training technique further
improves the performance of the model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The 2024 Conference on Empirical Methods in Natural Language
  Processing, November 12-16, Miami, Florida 9 pages, appendix, diagrams</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ EHRAgent: Code Empowers Large Language Models for Few-shot Complex
  Tabular Reasoning on Electronic Health Records <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.07128v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.07128v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenqi Shi, Ran Xu, Yuchen Zhuang, Yue Yu, Jieyu Zhang, Hang Wu, Yuanda Zhu, Joyce Ho, Carl Yang, May D. Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have demonstrated exceptional capabilities in
planning and tool utilization as autonomous agents, but few have been developed
for medical problem-solving. We propose EHRAgent, an LLM agent empowered with a
code interface, to autonomously generate and execute code for multi-tabular
reasoning within electronic health records (EHRs). First, we formulate an EHR
question-answering task into a tool-use planning process, efficiently
decomposing a complicated task into a sequence of manageable actions. By
integrating interactive coding and execution feedback, EHRAgent learns from
error messages and improves the originally generated code through iterations.
Furthermore, we enhance the LLM agent by incorporating long-term memory, which
allows EHRAgent to effectively select and build upon the most relevant
successful cases from past experiences. Experiments on three real-world
multi-tabular EHR datasets show that EHRAgent outperforms the strongest
baseline by up to 29.6% in success rate. EHRAgent leverages the emerging
few-shot learning capabilities of LLMs, enabling autonomous code generation and
execution to tackle complex clinical tasks with minimal demonstrations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in EMNLP 2024 main conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On the Fragility of Active Learners for Text Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.15744v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.15744v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abhishek Ghose, Emma Thuong Nguyen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Active learning (AL) techniques optimally utilize a labeling budget by
iteratively selecting instances that are most valuable for learning. However,
they lack ``prerequisite checks'', i.e., there are no prescribed criteria to
pick an AL algorithm best suited for a dataset. A practitioner must pick a
technique they \emph{trust} would beat random sampling, based on prior reported
results, and hope that it is resilient to the many variables in their
environment: dataset, labeling budget and prediction pipelines. The important
questions then are: how often on average, do we expect any AL technique to
reliably beat the computationally cheap and easy-to-implement strategy of
random sampling? Does it at least make sense to use AL in an ``Always ON'' mode
in a prediction pipeline, so that while it might not always help, it never
under-performs random sampling? How much of a role does the prediction pipeline
play in AL's success?
  We examine these questions in detail for the task of text classification
using pre-trained representations, which are ubiquitous today.
  Our primary contribution here is a rigorous evaluation of AL techniques, old
and new, across setups that vary wrt datasets, text representations and
classifiers. This unlocks multiple insights around warm-up times, i.e., number
of labels before gains from AL are seen, viability of an ``Always ON'' mode and
the relative significance of different factors. Additionally, we release a
framework for rigorous benchmarking of AL techniques for text classification.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Educational Question Generation of Children Storybooks via Question Type
  Distribution Learning and Event-Centric Summarization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2203.14187v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2203.14187v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenjie Zhao, Yufang Hou, Dakuo Wang, Mo Yu, Chengzhong Liu, Xiaojuan Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating educational questions of fairytales or storybooks is vital for
improving children's literacy ability. However, it is challenging to generate
questions that capture the interesting aspects of a fairytale story with
educational meaningfulness. In this paper, we propose a novel question
generation method that first learns the question type distribution of an input
story paragraph, and then summarizes salient events which can be used to
generate high-cognitive-demand questions. To train the event-centric
summarizer, we finetune a pre-trained transformer-based sequence-to-sequence
model using silver samples composed by educational question-answer pairs. On a
newly proposed educational question answering dataset FairytaleQA, we show good
performance of our method on both automatic and human evaluation metrics. Our
work indicates the necessity of decomposing question type distribution learning
and event-centric summary generation for educational question generation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BPO: Staying Close to the Behavior LLM Creates Better Online LLM
  Alignment <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12168v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12168v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenda Xu, Jiachen Li, William Yang Wang, Lei Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Direct alignment from preferences (DAP) has emerged as a promising paradigm
for aligning large language models (LLMs) to human desiderata from
pre-collected, offline preference datasets. While recent studies indicate that
existing offline DAP methods can directly benefit from online training samples,
we highlight the need to develop specific online DAP algorithms to fully
harness the power of online training. Specifically, we identify that the
learned LLM should adhere to the proximity of the behavior LLM, which collects
the training samples. To this end, we propose online Preference Optimization in
proximity to the Behavior LLM (BPO), emphasizing the importance of constructing
a proper trust region for LLM alignment.
  We conduct extensive experiments to validate the effectiveness and
applicability of our approach by integrating it with various DAP methods,
resulting in significant performance improvements across a wide range of tasks
when training with the same amount of preference data. Even when only
introducing one additional data collection phase, our online BPO improves its
offline DAP baseline from 72.0% to 80.2% on TL;DR and from 82.2% to 89.1% on
Anthropic Helpfulness in terms of win rate against human reference text.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Wenda Xu and Jiachen Li contributed equally. Accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for
  Children's Story-Based Learning <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.09756v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.09756v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaju Chen, Yuxuan Lu, Shao Zhang, Bingsheng Yao, Yuanzhe Dong, Ying Xu, Yunyao Li, Qianwen Wang, Dakuo Wang, Yuling Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Interactive story reading is a common parent-child activity, where parents
expect to teach both language skills and real-world knowledge beyond the story.
While increasing storytelling and reading systems have been developed for this
activity, they often fail to infuse real-world knowledge into the conversation.
This limitation can be attributed to the existing question-answering (QA)
datasets used for children's education, upon which the systems are built,
failing to capture the nuances of how education experts think when conducting
interactive story reading activities. To bridge this gap, we design an
annotation framework, empowered by existing knowledge graph to capture experts'
annotations and thinking process, and leverage this framework to construct
StorySparkQA dataset, which comprises 5,868 expert-annotated QA pairs with
real-world knowledge. We conduct automated and human expert evaluations across
various QA pair generation settings to demonstrate that our StorySparkQA can
effectively support models in generating QA pairs that target real-world
knowledge beyond story content. StorySparkQA is available at
https://huggingface.co/datasets/NEU-HAI/StorySparkQA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CopyBench: Measuring Literal and Non-Literal Reproduction of
  Copyright-Protected Text in Language Model Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.07087v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.07087v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tong Chen, Akari Asai, Niloofar Mireshghallah, Sewon Min, James Grimmelmann, Yejin Choi, Hannaneh Hajishirzi, Luke Zettlemoyer, Pang Wei Koh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Evaluating the degree of reproduction of copyright-protected content by
language models (LMs) is of significant interest to the AI and legal
communities. Although both literal and non-literal similarities are considered
by courts when assessing the degree of reproduction, prior research has focused
only on literal similarities. To bridge this gap, we introduce CopyBench, a
benchmark designed to measure both literal and non-literal copying in LM
generations. Using copyrighted fiction books as text sources, we provide
automatic evaluation protocols to assess literal and non-literal copying,
balanced against the model utility in terms of the ability to recall facts from
the copyrighted works and generate fluent completions. We find that, although
literal copying is relatively rare, two types of non-literal copying -- event
copying and character copying -- occur even in models as small as 7B
parameters. Larger models demonstrate significantly more copying, with literal
copying rates increasing from 0.2\% to 10.5\% and non-literal copying from
2.3\% to 5.9\% when comparing Llama3-8B and 70B models, respectively. We
further evaluate the effectiveness of current strategies for mitigating copying
and show that (1) training-time alignment can reduce literal copying but may
increase non-literal copying, and (2) current inference-time mitigation methods
primarily reduce literal but not non-literal copying.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Dense X Retrieval: What Retrieval Granularity Should We Use? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.06648v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.06648v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tong Chen, Hongwei Wang, Sihao Chen, Wenhao Yu, Kaixin Ma, Xinran Zhao, Hongming Zhang, Dong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dense retrieval has become a prominent method to obtain relevant context or
world knowledge in open-domain NLP tasks. When we use a learned dense retriever
on a retrieval corpus at inference time, an often-overlooked design choice is
the retrieval unit in which the corpus is indexed, e.g. document, passage, or
sentence. We discover that the retrieval unit choice significantly impacts the
performance of both retrieval and downstream tasks. Distinct from the typical
approach of using passages or sentences, we introduce a novel retrieval unit,
proposition, for dense retrieval. Propositions are defined as atomic
expressions within text, each encapsulating a distinct factoid and presented in
a concise, self-contained natural language format. We conduct an empirical
comparison of different retrieval granularity. Our experiments reveal that
indexing a corpus by fine-grained units such as propositions significantly
outperforms passage-level units in retrieval tasks. Moreover, constructing
prompts with fine-grained retrieved units for retrieval-augmented language
models improves the performance of downstream QA tasks given a specific
computation budget.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Aligners: Decoupling LLMs and Alignment <span class="chip">ICLR</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.04224v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.04224v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lilian Ngweta, Mayank Agarwal, Subha Maity, Alex Gittens, Yuekai Sun, Mikhail Yurochkin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) need to be aligned with human expectations to
ensure their safety and utility in most applications. Alignment is challenging,
costly, and needs to be repeated for every LLM and alignment criterion. We
propose to decouple LLMs and alignment by training aligner models that can be
used to align any LLM for a given criteria on an as-needed basis, thus also
reducing the potential negative impacts of alignment on performance. Our recipe
for training the aligner models solely relies on synthetic data generated with
a (prompted) LLM and can be easily adjusted for a variety of alignment
criteria. We use the same synthetic data to train inspectors, binary
miss-alignment classification models to guide a "squad" of multiple aligners.
Our empirical results demonstrate consistent improvements when applying aligner
squad to various LLMs, including chat-aligned models, across several
instruction-following and red-teaming datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Short version accepted as a Tiny Paper at the International
  Conference on Learning Representations (ICLR) 2024. Long version accepted to
  the Conference on Empirical Methods in Natural Language Processing (EMNLP)
  2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Aligning Language Models to Explicitly Handle Ambiguity <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.11972v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.11972v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hyuhng Joon Kim, Youna Kim, Cheonbok Park, Junyeob Kim, Choonghyun Park, Kang Min Yoo, Sang-goo Lee, Taeuk Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In interactions between users and language model agents, user utterances
frequently exhibit ellipsis (omission of words or phrases) or imprecision (lack
of exactness) to prioritize efficiency. This can lead to varying
interpretations of the same input based on different assumptions or background
knowledge. It is thus crucial for agents to adeptly handle the inherent
ambiguity in queries to ensure reliability. However, even state-of-the-art
large language models (LLMs) still face challenges in such scenarios, primarily
due to the following hurdles: (1) LLMs are not explicitly trained to deal with
ambiguous utterances; (2) the degree of ambiguity perceived by the LLMs may
vary depending on the possessed knowledge. To address these issues, we propose
Alignment with Perceived Ambiguity (APA), a novel pipeline that aligns LLMs to
manage ambiguous queries by leveraging their own assessment of ambiguity (i.e.,
perceived ambiguity). Experimental results on question-answering datasets
demonstrate that APA empowers LLMs to explicitly detect and manage ambiguous
queries while retaining the ability to answer clear questions. Furthermore, our
finding proves that APA excels beyond training with gold-standard labels,
especially in out-of-distribution scenarios. The data and code are available at
https://github.com/heyjoonkim/APA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 (main)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Inheritune: Training Smaller Yet More Attentive Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.08634v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.08634v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sunny Sanyal, Ravid Shwartz-Ziv, Alexandros G. Dimakis, Sujay Sanghavi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have achieved remarkable performance across
various natural language processing tasks, primarily due to the transformer
architecture and its self-attention mechanism. However, we observe that in
standard decoder-style LLMs, attention matrices degenerate to single-column for
deeper layers. Layers in this state are unable to learn anything meaningful and
mostly redundant; we refer to these as lazy layers. The goal of this paper is
to train smaller models by eliminating this structural inefficiency without
compromising performance.
  Motivated by this observation, we propose Inheritune, a simple yet effective
training recipe for developing smaller, high-performing language models.
Smaller models trained with Inheritune, inherit early transformer layers from a
larger pre-trained model, then retrain and progressively expand until they
match or exceed the performance of the larger model. We demonstrate that
Inheritune enables the training of various sizes of GPT-2 models on datasets
like OpenWebText-9B and FineWeb_edu. Models trained with Inheritune, despite
having significantly fewer layers, match or even surpass the performance of
their larger counterparts. For instance, our 16-layer GPT-2 medium variant
achieves comparable performance to the standard 24-layer GPT-2 medium model.
Code is available at https://github.com/sanyalsunny111/LLM-Inheritune.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages, 13 figures, 10 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Bag of Tricks: Benchmarking of Jailbreak Attacks on LLMs <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.09324v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.09324v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhao Xu, Fan Liu, Hao Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although Large Language Models (LLMs) have demonstrated significant
capabilities in executing complex tasks in a zero-shot manner, they are
susceptible to jailbreak attacks and can be manipulated to produce harmful
outputs. Recently, a growing body of research has categorized jailbreak attacks
into token-level and prompt-level attacks. However, previous work primarily
overlooks the diverse key factors of jailbreak attacks, with most studies
concentrating on LLM vulnerabilities and lacking exploration of
defense-enhanced LLMs. To address these issues, we evaluate the impact of
various attack settings on LLM performance and provide a baseline benchmark for
jailbreak attacks, encouraging the adoption of a standardized evaluation
framework. Specifically, we evaluate the eight key factors of implementing
jailbreak attacks on LLMs from both target-level and attack-level perspectives.
We further conduct seven representative jailbreak attacks on six defense
methods across two widely used datasets, encompassing approximately 354
experiments with about 55,000 GPU hours on A800-80G. Our experimental results
highlight the need for standardized benchmarking to evaluate these attacks on
defense-enhanced LLMs. Our code is available at
https://github.com/usail-hkust/Bag_of_Tricks_for_LLM_Jailbreaking.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's
  Disease Questions with Scientific Literature <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.04819v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.04819v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dawei Li, Shu Yang, Zhen Tan, Jae Young Baik, Sukwon Yun, Joseph Lee, Aaron Chacko, Bojian Hou, Duy Duong-Tran, Ying Ding, Huan Liu, Li Shen, Tianlong Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in large language models (LLMs) have achieved promising
performances across various applications. Nonetheless, the ongoing challenge of
integrating long-tail knowledge continues to impede the seamless adoption of
LLMs in specialized domains. In this work, we introduce DALK, a.k.a. Dynamic
Co-Augmentation of LLMs and KG, to address this limitation and demonstrate its
ability on studying Alzheimer's Disease (AD), a specialized sub-field in
biomedicine and a global health priority. With a synergized framework of LLM
and KG mutually enhancing each other, we first leverage LLM to construct an
evolving AD-specific knowledge graph (KG) sourced from AD-related scientific
literature, and then we utilize a coarse-to-fine sampling method with a novel
self-aware knowledge retrieval approach to select appropriate knowledge from
the KG to augment LLM inference capabilities. The experimental results,
conducted on our constructed AD question answering (ADQA) benchmark, underscore
the efficacy of DALK. Additionally, we perform a series of detailed analyses
that can offer valuable insights and guidelines for the emerging topic of
mutually enhancing KG and LLM. We will release the code and data at
https://github.com/David-Li0406/DALK.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Do We Need Language-Specific Fact-Checking Models? The Case of Chinese <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.15498v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.15498v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Caiqi Zhang, Zhijiang Guo, Andreas Vlachos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper investigates the potential benefits of language-specific
fact-checking models, focusing on the case of Chinese. We first demonstrate the
limitations of translation-based methods and multilingual large language models
(e.g., GPT-4), highlighting the need for language-specific systems. We further
propose a Chinese fact-checking system that can better retrieve evidence from a
document by incorporating context information. To better analyze token-level
biases in different systems, we construct an adversarial dataset based on the
CHEF dataset, where each instance has large word overlap with the original one
but holds the opposite veracity label. Experimental results on the CHEF dataset
and our adversarial dataset show that our proposed method outperforms
translation-based methods and multilingual LLMs and is more robust toward
biases, while there is still large room for improvement, emphasizing the
importance of language-specific fact-checking systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Large Language Models are In-context Teachers for Knowledge Reasoning <span class="chip">EMNLP 24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.06985v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.06985v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiachen Zhao, Zonghai Yao, Zhichao Yang, Hong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we study in-context teaching (ICT), where a teacher provides
in-context example rationales to teach a student to reason over unseen cases.
Human teachers are usually required to craft in-context demonstrations, which
are costly and have high variance. We ask whether a large language model (LLM)
can serve as a more effective in-context teacher for itself or other LLMs,
compared to humans. Inspired by the Encoding Specificity Hypothesis from human
episodic memory, we hypothesize that in-context exemplars crafted by the
teacher should match the training data of the student. This hypothesis
motivates us to propose Self-Explain where an LLM's self-elicited explanations
are used as in-context demonstrations for prompting it as they are generalized
from the model's training examples. Self-Explain is shown to significantly
outperform using human-crafted exemplars and other baselines.
  Furthermore, we reveal that for ICT, rationales from different teacher LLMs
or human experts that more resemble the student LLM's self-explanations are
better in-context demonstrations. This supports our encoding specificity
hypothesis. We then propose Teach-Back that aligns a teacher LLM with the
student to enhance the ICT performance. For example, Teach-Back enables a 7B
model to teach the much larger GPT-3.5 in context, surpassing human teachers by
around 5% in test accuracy on medical question answering.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 24 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multi-LogiEval: Towards Evaluating Multi-Step Logical Reasoning Ability
  of Large Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17169v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17169v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nisarg Patel, Mohith Kulkarni, Mihir Parmar, Aashna Budhiraja, Mutsumi Nakamura, Neeraj Varshney, Chitta Baral
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As Large Language Models (LLMs) continue to exhibit remarkable performance in
natural language understanding tasks, there is a crucial need to measure their
ability for human-like multi-step logical reasoning. Existing logical reasoning
evaluation benchmarks often focus primarily on simplistic single-step or
multi-step reasoning with a limited set of inference rules. Furthermore, the
lack of datasets for evaluating non-monotonic reasoning represents a crucial
gap since it aligns more closely with human-like reasoning. To address these
limitations, we propose Multi-LogiEval, a comprehensive evaluation dataset
encompassing multi-step logical reasoning with various inference rules and
depths. Multi-LogiEval covers three logic types--propositional, first-order,
and non-monotonic--consisting of more than 30 inference rules and more than 60
of their combinations with various depths. Leveraging this dataset, we conduct
evaluations on a range of LLMs including GPT-4, ChatGPT, Gemini-Pro, Yi, Orca,
and Mistral, employing a zero-shot chain-of-thought. Experimental results show
that there is a significant drop in the performance of LLMs as the reasoning
steps/depth increases (average accuracy of ~68% at depth-1 to ~43% at depth-5).
We further conduct a thorough investigation of reasoning chains generated by
LLMs which reveals several important findings. We believe that Multi-LogiEval
facilitates future research for evaluating and enhancing the logical reasoning
ability of LLMs. Data is available at
https://github.com/Mihir3009/Multi-LogiEval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024 Main</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Sound <span class="chip" style="font-size: 60%">20</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generative Semantic Communication for Text-to-Speech Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03459v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03459v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiahao Zheng, Jinke Ren, Peng Xu, Zhihao Yuan, Jie Xu, Fangxin Wang, Gui Gui, Shuguang Cui
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Semantic communication is a promising technology to improve communication
efficiency by transmitting only the semantic information of the source data.
However, traditional semantic communication methods primarily focus on data
reconstruction tasks, which may not be efficient for emerging generative tasks
such as text-to-speech (TTS) synthesis. To address this limitation, this paper
develops a novel generative semantic communication framework for TTS synthesis,
leveraging generative artificial intelligence technologies. Firstly, we utilize
a pre-trained large speech model called WavLM and the residual vector
quantization method to construct two semantic knowledge bases (KBs) at the
transmitter and receiver, respectively. The KB at the transmitter enables
effective semantic extraction, while the KB at the receiver facilitates
lifelike speech synthesis. Then, we employ a transformer encoder and a
diffusion model to achieve efficient semantic coding without introducing
significant communication overhead. Finally, numerical results demonstrate that
our framework achieves much higher fidelity for the generated speech than four
baselines, in both cases with additive white Gaussian noise channel and
Rayleigh fading channel.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The paper has been accepted by IEEE Globecom Workshop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Biodenoising: animal vocalization denoising without access to clean data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03427v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03427v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marius Miron, Sara Keen, Jen-Yu Liu, Benjamin Hoffman, Masato Hagiwara, Olivier Pietquin, Felix Effenberger, Maddie Cusimano
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Animal vocalization denoising is a task similar to human speech enhancement,
a well-studied field of research. In contrast to the latter, it is applied to a
higher diversity of sound production mechanisms and recording environments, and
this higher diversity is a challenge for existing models. Adding to the
challenge and in contrast to speech, we lack large and diverse datasets
comprising clean vocalizations. As a solution we use as training data
pseudo-clean targets, i.e. pre-denoised vocalizations, and segments of
background noise without a vocalization. We propose a train set derived from
bioacoustics datasets and repositories representing diverse species, acoustic
environments, geographic regions. Additionally, we introduce a non-overlapping
benchmark set comprising clean vocalizations from different taxa and noise
samples. We show that that denoising models (demucs, CleanUNet) trained on
pseudo-clean targets obtained with speech enhancement models achieve
competitive results on the benchmarking set. We publish data, code, libraries,
and demos https://mariusmiron.com/research/biodenoising.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SoundSignature: What Type of Music Do You Like? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03375v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03375v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Brandon James Carone, Pablo Ripollés
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  SoundSignature is a music application that integrates a custom OpenAI
Assistant to analyze users' favorite songs. The system incorporates
state-of-the-art Music Information Retrieval (MIR) Python packages to combine
extracted acoustic/musical features with the assistant's extensive knowledge of
the artists and bands. Capitalizing on this combined knowledge, SoundSignature
leverages semantic audio and principles from the emerging Internet of Sounds
(IoS) ecosystem, integrating MIR with AI to provide users with personalized
insights into the acoustic properties of their music, akin to a musical
preference personality report. Users can then interact with the chatbot to
explore deeper inquiries about the acoustic analyses performed and how they
relate to their musical taste. This interactivity transforms the application,
acting not only as an informative resource about familiar and/or favorite
songs, but also as an educational platform that enables users to deepen their
understanding of musical features, music theory, acoustic properties commonly
used in signal processing, and the artists behind the music. Beyond general
usability, the application also incorporates several well-established
open-source musician-specific tools, such as a chord recognition algorithm
(CREMA), a source separation algorithm (DEMUCS), and an audio-to-MIDI converter
(basic-pitch). These features allow users without coding skills to access
advanced, open-source music processing algorithms simply by interacting with
the chatbot (e.g., can you give me the stems of this song?). In this paper, we
highlight the application's innovative features and educational potential, and
present findings from a pilot user study that evaluates its efficacy and
usability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 1 figure, to be published in the 2024 International
  Symposium on the IEEE Internet of Sounds Proceedings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Audio-Agent: Leveraging LLMs For Audio Generation, Editing and
  Composition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03335v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03335v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zixuan Wang, Yu-Wing Tai, Chi-Keung Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Audio-Agent, a multimodal framework for audio generation,
editing and composition based on text or video inputs. Conventional approaches
for text-to-audio (TTA) tasks often make single-pass inferences from text
descriptions. While straightforward, this design struggles to produce
high-quality audio when given complex text conditions. In our method, we
utilize a pre-trained TTA diffusion network as the audio generation agent to
work in tandem with GPT-4, which decomposes the text condition into atomic,
specific instructions, and calls the agent for audio generation. Consequently,
Audio-Agent generates high-quality audio that is closely aligned with the
provided text or video while also supporting variable-length generation. For
video-to-audio (VTA) tasks, most existing methods require training a timestamp
detector to synchronize video events with generated audio, a process that can
be tedious and time-consuming. We propose a simpler approach by fine-tuning a
pre-trained Large Language Model (LLM), e.g., Gemma2-2B-it, to obtain both
semantic and temporal conditions to bridge video and audio modality. Thus our
framework provides a comprehensive solution for both TTA and VTA tasks without
substantial computational overhead in training.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enriching Music Descriptions with a Finetuned-LLM and Metadata for
  Text-to-Music Retrieval <span class="chip">ICASSP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03264v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03264v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        SeungHeon Doh, Minhee Lee, Dasaem Jeong, Juhan Nam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-Music Retrieval, finding music based on a given natural language
query, plays a pivotal role in content discovery within extensive music
databases. To address this challenge, prior research has predominantly focused
on a joint embedding of music audio and text, utilizing it to retrieve music
tracks that exactly match descriptive queries related to musical attributes
(i.e. genre, instrument) and contextual elements (i.e. mood, theme). However,
users also articulate a need to explore music that shares similarities with
their favorite tracks or artists, such as \textit{I need a similar track to
Superstition by Stevie Wonder}. To address these concerns, this paper proposes
an improved Text-to-Music Retrieval model, denoted as TTMR++, which utilizes
rich text descriptions generated with a finetuned large language model and
metadata. To accomplish this, we obtained various types of seed text from
several existing music tag and caption datasets and a knowledge graph dataset
of artists and tracks. The experimental results show the effectiveness of
TTMR++ in comparison to state-of-the-art music-text joint embedding models
through a comprehensive evaluation involving various musical text queries.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication at the IEEE ICASSP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MultiVerse: Efficient and Expressive Zero-Shot Multi-Task Text-to-Speech <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03192v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03192v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Taejun Bak, Youngsik Eom, SeungJae Choi, Young-Sun Joo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-speech (TTS) systems that scale up the amount of training data have
achieved significant improvements in zero-shot speech synthesis. However, these
systems have certain limitations: they require a large amount of training data,
which increases costs, and often overlook prosody similarity. To address these
issues, we propose MultiVerse, a zero-shot multi-task TTS system that is able
to perform TTS or speech style transfer in zero-shot and cross-lingual
conditions. MultiVerse requires much less training data than traditional
data-driven approaches. To ensure zero-shot performance even with limited data,
we leverage source-filter theory-based disentanglement, utilizing the prompt
for modeling filter-related and source-related representations. Additionally,
to further enhance prosody similarity, we adopt a prosody modeling approach
combining prompt-based autoregressive and non-autoregressive methods.
Evaluations demonstrate the remarkable zero-shot multi-task TTS performance of
MultiVerse and show that MultiVerse not only achieves zero-shot TTS performance
comparable to data-driven TTS systems with much less data, but also
significantly outperforms other zero-shot TTS systems trained with the same
small amount of data. In particular, our novel prosody modeling technique
significantly contributes to MultiVerse's ability to generate speech with high
prosody similarity to the given prompts. Our samples are available at
https://nc-ai.github.io/speech/publications/multiverse/index.html
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ How does the teacher rate? Observations from the NeuroPiano <span class="highlight-title">dataset</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03139v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03139v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huan Zhang, Vincent Cheung, Hayato Nishioka, Simon Dixon, Shinichi Furuya
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper provides a detailed analysis of the NeuroPiano dataset, which
comprise 104 audio recordings of student piano performances accompanied with
2255 textual feedback and ratings given by professional pianists. We offer a
statistical overview of the dataset, focusing on the standardization of
annotations and inter-annotator agreement across 12 evaluative questions
concerning performance quality. We also explore the predictive relationship
between audio features and teacher ratings via machine learning, as well as
annotations provided for text analysis of the responses.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reverb: Open-Source ASR and Diarization from Rev 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03930v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03930v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nishchal Bhandari, Danny Chen, Miguel Ángel del Río Fernández, Natalie Delworth, Jennifer Drexler Fox, Migüel Jetté, Quinten McNamara, Corey Miller, Ondřej Novotný, Ján Profant, Nan Qin, Martin Ratajczak, Jean-Philippe Robichaud
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Today, we are open-sourcing our core speech recognition and diarization
models for non-commercial use. We are releasing both a full production pipeline
for developers as well as pared-down research models for experimentation. Rev
hopes that these releases will spur research and innovation in the fast-moving
domain of voice technology. The speech recognition models released today
outperform all existing open source speech recognition models across a variety
of long-form speech recognition domains.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Did You Hear That? Introducing AADG: A Framework for Generating
  Benchmark Data in Audio Anomaly Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03904v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03904v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ksheeraja Raghavan, Samiran Gode, Ankit Shah, Surabhi Raghavan, Wolfram Burgard, Bhiksha Raj, Rita Singh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a novel, general-purpose audio generation framework specifically
designed for anomaly detection and localization. Unlike existing datasets that
predominantly focus on industrial and machine-related sounds, our framework
focuses a broader range of environments, particularly useful in real-world
scenarios where only audio data are available, such as in video-derived or
telephonic audio. To generate such data, we propose a new method inspired by
the LLM-Modulo framework, which leverages large language models(LLMs) as world
models to simulate such real-world scenarios. This tool is modular allowing a
plug-and-play approach. It operates by first using LLMs to predict plausible
real-world scenarios. An LLM further extracts the constituent sounds, the order
and the way in which these should be merged to create coherent wholes. Much
like the LLM-Modulo framework, we include rigorous verification of each output
stage, ensuring the reliability of the generated data. The data produced using
the framework serves as a benchmark for anomaly detection applications,
potentially enhancing the performance of models trained on audio data,
particularly in handling out-of-distribution cases. Our contributions thus fill
a critical void in audio anomaly detection resources and provide a scalable
tool for generating diverse, realistic audio data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SONIQUE: Video Background Music Generation Using Unpaired Audio-Visual
  Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03879v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03879v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liqian Zhang, Magdalena Fuentes
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present SONIQUE, a model for generating background music tailored to video
content. Unlike traditional video-to-music generation approaches, which rely
heavily on paired audio-visual datasets, SONIQUE leverages unpaired data,
combining royalty-free music and independent video sources. By utilizing large
language models (LLMs) for video understanding and converting visual
descriptions into musical tags, alongside a U-Net-based conditional diffusion
model, SONIQUE enables customizable music generation. Users can control
specific aspects of the music, such as instruments, genres, tempo, and
melodies, ensuring the generated output fits their creative vision. SONIQUE is
open-source, with a demo available online.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SOI: Scaling Down Computational Complexity by Estimating Partial States
  of the Model <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03813v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03813v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Grzegorz Stefański, Paweł Daniluk, Artur Szumaczuk, Jakub Tkaczuk
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Consumer electronics used to follow the miniaturization trend described by
Moore's Law. Despite increased processing power in Microcontroller Units
(MCUs), MCUs used in the smallest appliances are still not capable of running
even moderately big, state-of-the-art artificial neural networks (ANNs)
especially in time-sensitive scenarios. In this work, we present a novel method
called Scattered Online Inference (SOI) that aims to reduce the computational
complexity of ANNs. SOI leverages the continuity and seasonality of time-series
data and model predictions, enabling extrapolation for processing speed
improvements, particularly in deeper layers. By applying compression, SOI
generates more general inner partial states of ANN, allowing skipping full
model recalculation at each inference.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Self-Powered LLM Modality Expansion for Large Speech-Text Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03798v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03798v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tengfei Yu, Xuebo Liu, Zhiyi Hou, Liang Ding, Dacheng Tao, Min Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) exhibit remarkable performance across diverse
tasks, indicating their potential for expansion into large speech-text models
(LSMs) by integrating speech capabilities. Although unified speech-text
pre-training and multimodal data instruction-tuning offer considerable
benefits, these methods generally entail significant resource demands and tend
to overfit specific tasks. This study aims to refine the use of speech datasets
for LSM training by addressing the limitations of vanilla instruction tuning.
We explore the instruction-following dynamics within LSMs, identifying a
critical issue termed speech anchor bias-a tendency for LSMs to over-rely on
speech inputs, mistakenly interpreting the entire speech modality as
directives, thereby neglecting textual instructions. To counteract this bias,
we introduce a self-powered LSM that leverages augmented automatic speech
recognition data generated by the model itself for more effective instruction
tuning. Our experiments across a range of speech-based tasks demonstrate that
self-powered LSM mitigates speech anchor bias and improves the fusion of speech
and text modalities in LSMs. Data, code and scripts are freely available at
https://github.com/ytf-philp/Self-powered-LSM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Convolutional Variational Autoencoders for Spectrogram Compression in
  Automatic Speech Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02560v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02560v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Olga Iakovenko, Ivan Bondarenko
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For many Automatic Speech Recognition (ASR) tasks audio features as
spectrograms show better results than Mel-frequency Cepstral Coefficients
(MFCC), but in practice they are hard to use due to a complex dimensionality of
a feature space. The following paper presents an alternative approach towards
generating compressed spectrogram representation, based on Convolutional
Variational Autoencoders (VAE). A Convolutional VAE model was trained on a
subsample of the LibriSpeech dataset to reconstruct short fragments of audio
spectrograms (25 ms) from a 13-dimensional embedding. The trained model for a
40-dimensional (300 ms) embedding was used to generate features for corpus of
spoken commands on the GoogleSpeechCommands dataset. Using the generated
features an ASR system was built and compared to the model with MFCC features.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Theory and Practice of Natural Computing 9th International
  Conference, TPNC 2020, Taoyuan, Taiwan, 2020, Proceedings 9</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Leveraging <span class="highlight-title">Self-Supervised</span> Learning for Speaker Diarization <span class="chip">ICASSP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.09408v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.09408v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiangyu Han, Federico Landini, Johan Rohdin, Anna Silnova, Mireia Diez, Lukas Burget
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  End-to-end neural diarization has evolved considerably over the past few
years, but data scarcity is still a major obstacle for further improvements.
Self-supervised learning methods such as WavLM have shown promising performance
on several downstream tasks, but their application on speaker diarization is
somehow limited. In this work, we explore using WavLM to alleviate the problem
of data scarcity for neural diarization training. We use the same pipeline as
Pyannote and improve the local end-to-end neural diarization with WavLM and
Conformer. Experiments on far-field AMI, AISHELL-4, and AliMeeting datasets
show that our method substantially outperforms the Pyannote baseline and
achieves new state-of-the-art results on AMI and AISHELL-4, respectively. In
addition, by analyzing the system performance under different data quantity
scenarios, we show that WavLM representations are much more robust against data
scarcity than filterbank features, enabling less data hungry training
strategies. Furthermore, we found that simulated data, usually used to train
endto-end diarization models, does not help when using WavLM in our
experiments. Additionally, we also evaluate our model on the recent CHiME8
NOTSOFAR-1 task where it achieves better performance than the Pyannote
baseline. Our source code is publicly available at
https://github.com/BUTSpeechFIT/DiariZen.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to ICASSP 2025; New results are updated but conclusions are
  exactly the same as the original one</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Sounds of Home: A Speech-Removed Residential Audio <span class="highlight-title">Dataset</span> for Sound
  Event Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.11262v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.11262v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gabriel Bibbó, Thomas Deacon, Arshdeep Singh, Mark D. Plumbley
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a residential audio dataset to support sound event
detection research for smart home applications aimed at promoting wellbeing for
older adults. The dataset is constructed by deploying audio recording systems
in the homes of 8 participants aged 55-80 years for a 7-day period. Acoustic
characteristics are documented through detailed floor plans and construction
material information to enable replication of the recording environments for AI
model deployment. A novel automated speech removal pipeline is developed, using
pre-trained audio neural networks to detect and remove segments containing
spoken voice, while preserving segments containing other sound events. The
resulting dataset consists of privacy-compliant audio recordings that
accurately capture the soundscapes and activities of daily living within
residential spaces. The paper details the dataset creation methodology, the
speech removal pipeline utilizing cascaded model architectures, and an analysis
of the vocal label distribution to validate the speech removal process. This
dataset enables the development and benchmarking of sound event detection
models tailored specifically for in-home applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Online Similarity-and-Independence-Aware Beamformer for Low-latency
  Target Sound Extraction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.16449v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.16449v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Atsuo Hiroe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study introduces an online target sound extraction (TSE) process using
the similarity-and-independence-aware beamformer (SIBF) derived from an
iterative batch algorithm. The study aimed to reduce latency while maintaining
extraction accuracy. The SIBF, which is a linear method, provides more accurate
estimates of the target than an approximate magnitude spectrogram reference.
The transition to an online algorithm reduces latency but presents challenges.
First, contrary to the conventional assumption, deriving the online algorithm
may degrade accuracy as compared to the batch algorithm using a sliding window.
Second, conventional post-processing methods intended for scaling the estimated
target may widen the accuracy gap between the two algorithms. This study adopts
an approach that addresses these challenges and minimizes the accuracy gap
during post-processing. It proposes a novel scaling method based on the
single-channel Wiener filter (SWF-based scaling). To further improve accuracy,
the study introduces a modified version of the time-frequency-varying variance
generalized Gaussian distribution as a source model to represent the joint
probability between the target and reference. Experimental results using the
CHiME-3 dataset demonstrate several key findings: 1) SWF-based scaling
effectively eliminates the gap between the two algorithms and improves
accuracy. 2) The new source model achieves optimal accuracy, corresponding to
the Laplacian model. 3) Our online SIBF outperforms conventional linear TSE
methods, including independent vector extraction and minimum mean square error
beamforming. These findings can contribute to the fields of beamforming and
blind source separation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Re-submitted to IEEE Open Journal of Signal Processing</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LearnerVoice: A <span class="highlight-title">Dataset</span> of Non-Native English Learners' Spontaneous
  Speech 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.04280v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.04280v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haechan Kim, Junho Myung, Seoyoung Kim, Sungpah Lee, Dongyeop Kang, Juho Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prevalent ungrammatical expressions and disfluencies in spontaneous speech
from second language (L2) learners pose unique challenges to Automatic Speech
Recognition (ASR) systems. However, few datasets are tailored to L2 learner
speech. We publicly release LearnerVoice, a dataset consisting of 50.04 hours
of audio and transcriptions of L2 learners' spontaneous speech. Our linguistic
analysis reveals that transcriptions in our dataset contain L2S (L2 learner's
Spontaneous speech) features, consisting of ungrammatical expressions and
disfluencies (e.g., filler words, word repetitions, self-repairs, false
starts), significantly more than native speech datasets. Fine-tuning
whisper-small.en with LearnerVoice achieves a WER of 10.26%, 44.2% lower than
vanilla whisper-small.en. Furthermore, our qualitative analysis indicates that
54.2% of errors from the vanilla model on LearnerVoice are attributable to L2S
features, with 48.1% of them being reduced in the fine-tuned model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Proceedings of Interspeech</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mamba in Speech: Towards an Alternative to Self-Attention 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.12609v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.12609v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangyu Zhang, Qiquan Zhang, Hexin Liu, Tianyi Xiao, Xinyuan Qian, Beena Ahmed, Eliathamby Ambikairajah, Haizhou Li, Julien Epps
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformer and its derivatives have achieved success in diverse tasks across
computer vision, natural language processing, and speech processing. To reduce
the complexity of computations within the multi-head self-attention mechanism
in Transformer, Selective State Space Models (i.e., Mamba) were proposed as an
alternative. Mamba exhibited its effectiveness in natural language processing
and computer vision tasks, but its superiority has rarely been investigated in
speech signal processing. This paper explores solutions for applying Mamba to
speech processing by discussing two typical speech processing tasks: speech
recognition, which requires semantic and sequential information, and speech
enhancement, which focuses primarily on sequential patterns. The experimental
results show the superiority of bidirectional Mamba~(BiMamba) for speech
processing to vanilla Mamba. Moreover, experiments demonstrate the
effectiveness of BiMamba as an alternative to the self-attention module in
Transformer and its derivates, particularly for the semantic-aware task. The
crucial technologies for transferring Mamba to speech are then summarized in
ablation studies and the discussion section to offer insights for future
research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Analyzing and Mitigating Inconsistency in Discrete Audio Tokens for
  Neural Codec Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19283v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19283v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenrui Liu, Zhifang Guo, Jin Xu, Yuanjun Lv, Yunfei Chu, Zhou Zhao, Junyang Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Building upon advancements in Large Language Models (LLMs), the field of
audio processing has seen increased interest in training audio generation tasks
with discrete audio token sequences. However, directly discretizing audio by
neural audio codecs often results in sequences that fundamentally differ from
text sequences. Unlike text, where text token sequences are deterministic,
discrete audio tokens can exhibit significant variability based on contextual
factors, while still producing perceptually identical audio segments. We refer
to this phenomenon as \textbf{Discrete Representation Inconsistency (DRI)}.
This inconsistency can lead to a single audio segment being represented by
multiple divergent sequences, which creates confusion in neural codec language
models and results in omissions and repetitions during speech generation. In
this paper, we quantitatively analyze the DRI phenomenon within popular audio
tokenizers such as EnCodec. Our approach effectively mitigates the DRI
phenomenon of the neural audio codec. Furthermore, extensive experiments on the
neural codec language model over LibriTTS and large-scale MLS datases (44,000
hours) demonstrate the effectiveness and generality of our method. The demo of
audio samples is available
online~\footnote{\url{https://consistencyinneuralcodec.github.io}}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>e.g.: 15 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VHASR: A Multimodal Speech Recognition System With Vision Hotwords <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00822v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00822v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiliang Hu, Zuchao Li, Ping Wang, Haojun Ai, Lefei Zhang, Hai Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The image-based multimodal automatic speech recognition (ASR) model enhances
speech recognition performance by incorporating audio-related image. However,
some works suggest that introducing image information to model does not help
improving ASR performance. In this paper, we propose a novel approach
effectively utilizing audio-related image information and set up VHASR, a
multimodal speech recognition system that uses vision as hotwords to strengthen
the model's speech recognition capability. Our system utilizes a dual-stream
architecture, which firstly transcribes the text on the two streams separately,
and then combines the outputs. We evaluate the proposed model on four datasets:
Flickr8k, ADE20k, COCO, and OpenImages. The experimental results show that
VHASR can effectively utilize key information in images to enhance the model's
speech recognition ability. Its performance not only surpasses unimodal ASR,
but also achieves SOTA among existing image-based multimodal ASR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 6 figures, accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Speech Processing <span class="chip" style="font-size: 60%">23</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generative Semantic Communication for Text-to-Speech Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03459v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03459v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiahao Zheng, Jinke Ren, Peng Xu, Zhihao Yuan, Jie Xu, Fangxin Wang, Gui Gui, Shuguang Cui
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Semantic communication is a promising technology to improve communication
efficiency by transmitting only the semantic information of the source data.
However, traditional semantic communication methods primarily focus on data
reconstruction tasks, which may not be efficient for emerging generative tasks
such as text-to-speech (TTS) synthesis. To address this limitation, this paper
develops a novel generative semantic communication framework for TTS synthesis,
leveraging generative artificial intelligence technologies. Firstly, we utilize
a pre-trained large speech model called WavLM and the residual vector
quantization method to construct two semantic knowledge bases (KBs) at the
transmitter and receiver, respectively. The KB at the transmitter enables
effective semantic extraction, while the KB at the receiver facilitates
lifelike speech synthesis. Then, we employ a transformer encoder and a
diffusion model to achieve efficient semantic coding without introducing
significant communication overhead. Finally, numerical results demonstrate that
our framework achieves much higher fidelity for the generated speech than four
baselines, in both cases with additive white Gaussian noise channel and
Rayleigh fading channel.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The paper has been accepted by IEEE Globecom Workshop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Biodenoising: animal vocalization denoising without access to clean data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03427v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03427v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marius Miron, Sara Keen, Jen-Yu Liu, Benjamin Hoffman, Masato Hagiwara, Olivier Pietquin, Felix Effenberger, Maddie Cusimano
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Animal vocalization denoising is a task similar to human speech enhancement,
a well-studied field of research. In contrast to the latter, it is applied to a
higher diversity of sound production mechanisms and recording environments, and
this higher diversity is a challenge for existing models. Adding to the
challenge and in contrast to speech, we lack large and diverse datasets
comprising clean vocalizations. As a solution we use as training data
pseudo-clean targets, i.e. pre-denoised vocalizations, and segments of
background noise without a vocalization. We propose a train set derived from
bioacoustics datasets and repositories representing diverse species, acoustic
environments, geographic regions. Additionally, we introduce a non-overlapping
benchmark set comprising clean vocalizations from different taxa and noise
samples. We show that that denoising models (demucs, CleanUNet) trained on
pseudo-clean targets obtained with speech enhancement models achieve
competitive results on the benchmarking set. We publish data, code, libraries,
and demos https://mariusmiron.com/research/biodenoising.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SoundSignature: What Type of Music Do You Like? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03375v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03375v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Brandon James Carone, Pablo Ripollés
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  SoundSignature is a music application that integrates a custom OpenAI
Assistant to analyze users' favorite songs. The system incorporates
state-of-the-art Music Information Retrieval (MIR) Python packages to combine
extracted acoustic/musical features with the assistant's extensive knowledge of
the artists and bands. Capitalizing on this combined knowledge, SoundSignature
leverages semantic audio and principles from the emerging Internet of Sounds
(IoS) ecosystem, integrating MIR with AI to provide users with personalized
insights into the acoustic properties of their music, akin to a musical
preference personality report. Users can then interact with the chatbot to
explore deeper inquiries about the acoustic analyses performed and how they
relate to their musical taste. This interactivity transforms the application,
acting not only as an informative resource about familiar and/or favorite
songs, but also as an educational platform that enables users to deepen their
understanding of musical features, music theory, acoustic properties commonly
used in signal processing, and the artists behind the music. Beyond general
usability, the application also incorporates several well-established
open-source musician-specific tools, such as a chord recognition algorithm
(CREMA), a source separation algorithm (DEMUCS), and an audio-to-MIDI converter
(basic-pitch). These features allow users without coding skills to access
advanced, open-source music processing algorithms simply by interacting with
the chatbot (e.g., can you give me the stems of this song?). In this paper, we
highlight the application's innovative features and educational potential, and
present findings from a pilot user study that evaluates its efficacy and
usability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 1 figure, to be published in the 2024 International
  Symposium on the IEEE Internet of Sounds Proceedings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Audio-Agent: Leveraging LLMs For Audio Generation, Editing and
  Composition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03335v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03335v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zixuan Wang, Yu-Wing Tai, Chi-Keung Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Audio-Agent, a multimodal framework for audio generation,
editing and composition based on text or video inputs. Conventional approaches
for text-to-audio (TTA) tasks often make single-pass inferences from text
descriptions. While straightforward, this design struggles to produce
high-quality audio when given complex text conditions. In our method, we
utilize a pre-trained TTA diffusion network as the audio generation agent to
work in tandem with GPT-4, which decomposes the text condition into atomic,
specific instructions, and calls the agent for audio generation. Consequently,
Audio-Agent generates high-quality audio that is closely aligned with the
provided text or video while also supporting variable-length generation. For
video-to-audio (VTA) tasks, most existing methods require training a timestamp
detector to synchronize video events with generated audio, a process that can
be tedious and time-consuming. We propose a simpler approach by fine-tuning a
pre-trained Large Language Model (LLM), e.g., Gemma2-2B-it, to obtain both
semantic and temporal conditions to bridge video and audio modality. Thus our
framework provides a comprehensive solution for both TTA and VTA tasks without
substantial computational overhead in training.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Context and System Fusion in Post-ASR Emotion Recognition with Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03312v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03312v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pavel Stepachev, Pinzhen Chen, Barry Haddow
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have started to play a vital role in modelling
speech and text. To explore the best use of context and multiple systems'
outputs for post-ASR speech emotion prediction, we study LLM prompting on a
recent task named GenSEC. Our techniques include ASR transcript ranking,
variable conversation context, and system output fusion. We show that the
conversation context has diminishing returns and the metric used to select the
transcript for prediction is crucial. Finally, our best submission surpasses
the provided baseline by 20% in absolute accuracy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Textless Streaming Speech-to-Speech Translation using Semantic Speech
  Tokens <span class="chip">ICASSP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03298v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03298v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinzheng Zhao, Niko Moritz, Egor Lakomkin, Ruiming Xie, Zhiping Xiu, Katerina Zmolikova, Zeeshan Ahmed, Yashesh Gaur, Duc Le, Christian Fuegen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cascaded speech-to-speech translation systems often suffer from the error
accumulation problem and high latency, which is a result of cascaded modules
whose inference delays accumulate. In this paper, we propose a transducer-based
speech translation model that outputs discrete speech tokens in a low-latency
streaming fashion. This approach eliminates the need for generating text output
first, followed by machine translation (MT) and text-to-speech (TTS) systems.
The produced speech tokens can be directly used to generate a speech signal
with low latency by utilizing an acoustic language model (LM) to obtain
acoustic tokens and an audio codec model to retrieve the waveform. Experimental
results show that the proposed method outperforms other existing approaches and
achieves state-of-the-art results for streaming translation in terms of BLEU,
average latency, and BLASER 2.0 scores for multiple language pairs using the
CVSS-C dataset as a benchmark.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to ICASSP 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Manikin-Recorded Cardiopulmonary Sounds <span class="highlight-title">Dataset</span> Using Digital
  Stethoscope 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03280v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03280v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yasaman Torabi, Shahram Shirani, James P. Reilly
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Heart and lung sounds are crucial for healthcare monitoring. Recent
improvements in stethoscope technology have made it possible to capture patient
sounds with enhanced precision. In this dataset, we used a digital stethoscope
to capture both heart and lung sounds, including individual and mixed
recordings. To our knowledge, this is the first dataset to offer both separate
and mixed cardiorespiratory sounds. The recordings were collected from a
clinical manikin, a patient simulator designed to replicate human physiological
conditions, generating clean heart and lung sounds at different body locations.
This dataset includes both normal sounds and various abnormalities (i.e.,
murmur, atrial fibrillation, tachycardia, atrioventricular block, third and
fourth heart sound, wheezing, crackles, rhonchi, pleural rub, and gurgling
sounds). The dataset includes audio recordings of chest examinations performed
at different anatomical locations, as determined by specialist nurses. Each
recording has been enhanced using frequency filters to highlight specific sound
types. This dataset is useful for applications in artificial intelligence, such
as automated cardiopulmonary disease detection, sound classification,
unsupervised separation techniques, and deep learning algorithms related to
audio signal processing.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enriching Music Descriptions with a Finetuned-LLM and Metadata for
  Text-to-Music Retrieval <span class="chip">ICASSP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03264v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03264v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        SeungHeon Doh, Minhee Lee, Dasaem Jeong, Juhan Nam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-Music Retrieval, finding music based on a given natural language
query, plays a pivotal role in content discovery within extensive music
databases. To address this challenge, prior research has predominantly focused
on a joint embedding of music audio and text, utilizing it to retrieve music
tracks that exactly match descriptive queries related to musical attributes
(i.e. genre, instrument) and contextual elements (i.e. mood, theme). However,
users also articulate a need to explore music that shares similarities with
their favorite tracks or artists, such as \textit{I need a similar track to
Superstition by Stevie Wonder}. To address these concerns, this paper proposes
an improved Text-to-Music Retrieval model, denoted as TTMR++, which utilizes
rich text descriptions generated with a finetuned large language model and
metadata. To accomplish this, we obtained various types of seed text from
several existing music tag and caption datasets and a knowledge graph dataset
of artists and tracks. The experimental results show the effectiveness of
TTMR++ in comparison to state-of-the-art music-text joint embedding models
through a comprehensive evaluation involving various musical text queries.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication at the IEEE ICASSP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MultiVerse: Efficient and Expressive Zero-Shot Multi-Task Text-to-Speech <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03192v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03192v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Taejun Bak, Youngsik Eom, SeungJae Choi, Young-Sun Joo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-speech (TTS) systems that scale up the amount of training data have
achieved significant improvements in zero-shot speech synthesis. However, these
systems have certain limitations: they require a large amount of training data,
which increases costs, and often overlook prosody similarity. To address these
issues, we propose MultiVerse, a zero-shot multi-task TTS system that is able
to perform TTS or speech style transfer in zero-shot and cross-lingual
conditions. MultiVerse requires much less training data than traditional
data-driven approaches. To ensure zero-shot performance even with limited data,
we leverage source-filter theory-based disentanglement, utilizing the prompt
for modeling filter-related and source-related representations. Additionally,
to further enhance prosody similarity, we adopt a prosody modeling approach
combining prompt-based autoregressive and non-autoregressive methods.
Evaluations demonstrate the remarkable zero-shot multi-task TTS performance of
MultiVerse and show that MultiVerse not only achieves zero-shot TTS performance
comparable to data-driven TTS systems with much less data, but also
significantly outperforms other zero-shot TTS systems trained with the same
small amount of data. In particular, our novel prosody modeling technique
significantly contributes to MultiVerse's ability to generate speech with high
prosody similarity to the given prompts. Our samples are available at
https://nc-ai.github.io/speech/publications/multiverse/index.html
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ How does the teacher rate? Observations from the NeuroPiano <span class="highlight-title">dataset</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03139v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03139v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huan Zhang, Vincent Cheung, Hayato Nishioka, Simon Dixon, Shinichi Furuya
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper provides a detailed analysis of the NeuroPiano dataset, which
comprise 104 audio recordings of student piano performances accompanied with
2255 textual feedback and ratings given by professional pianists. We offer a
statistical overview of the dataset, focusing on the standardization of
annotations and inter-annotator agreement across 12 evaluative questions
concerning performance quality. We also explore the predictive relationship
between audio features and teacher ratings via machine learning, as well as
annotations provided for text analysis of the responses.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reverb: Open-Source ASR and Diarization from Rev 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03930v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03930v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nishchal Bhandari, Danny Chen, Miguel Ángel del Río Fernández, Natalie Delworth, Jennifer Drexler Fox, Migüel Jetté, Quinten McNamara, Corey Miller, Ondřej Novotný, Ján Profant, Nan Qin, Martin Ratajczak, Jean-Philippe Robichaud
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Today, we are open-sourcing our core speech recognition and diarization
models for non-commercial use. We are releasing both a full production pipeline
for developers as well as pared-down research models for experimentation. Rev
hopes that these releases will spur research and innovation in the fast-moving
domain of voice technology. The speech recognition models released today
outperform all existing open source speech recognition models across a variety
of long-form speech recognition domains.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Did You Hear That? Introducing AADG: A Framework for Generating
  Benchmark Data in Audio Anomaly Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03904v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03904v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ksheeraja Raghavan, Samiran Gode, Ankit Shah, Surabhi Raghavan, Wolfram Burgard, Bhiksha Raj, Rita Singh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a novel, general-purpose audio generation framework specifically
designed for anomaly detection and localization. Unlike existing datasets that
predominantly focus on industrial and machine-related sounds, our framework
focuses a broader range of environments, particularly useful in real-world
scenarios where only audio data are available, such as in video-derived or
telephonic audio. To generate such data, we propose a new method inspired by
the LLM-Modulo framework, which leverages large language models(LLMs) as world
models to simulate such real-world scenarios. This tool is modular allowing a
plug-and-play approach. It operates by first using LLMs to predict plausible
real-world scenarios. An LLM further extracts the constituent sounds, the order
and the way in which these should be merged to create coherent wholes. Much
like the LLM-Modulo framework, we include rigorous verification of each output
stage, ensuring the reliability of the generated data. The data produced using
the framework serves as a benchmark for anomaly detection applications,
potentially enhancing the performance of models trained on audio data,
particularly in handling out-of-distribution cases. Our contributions thus fill
a critical void in audio anomaly detection resources and provide a scalable
tool for generating diverse, realistic audio data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SONIQUE: Video Background Music Generation Using Unpaired Audio-Visual
  Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03879v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03879v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liqian Zhang, Magdalena Fuentes
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present SONIQUE, a model for generating background music tailored to video
content. Unlike traditional video-to-music generation approaches, which rely
heavily on paired audio-visual datasets, SONIQUE leverages unpaired data,
combining royalty-free music and independent video sources. By utilizing large
language models (LLMs) for video understanding and converting visual
descriptions into musical tags, alongside a U-Net-based conditional diffusion
model, SONIQUE enables customizable music generation. Users can control
specific aspects of the music, such as instruments, genres, tempo, and
melodies, ensuring the generated output fits their creative vision. SONIQUE is
open-source, with a demo available online.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SOI: Scaling Down Computational Complexity by Estimating Partial States
  of the Model <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03813v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03813v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Grzegorz Stefański, Paweł Daniluk, Artur Szumaczuk, Jakub Tkaczuk
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Consumer electronics used to follow the miniaturization trend described by
Moore's Law. Despite increased processing power in Microcontroller Units
(MCUs), MCUs used in the smallest appliances are still not capable of running
even moderately big, state-of-the-art artificial neural networks (ANNs)
especially in time-sensitive scenarios. In this work, we present a novel method
called Scattered Online Inference (SOI) that aims to reduce the computational
complexity of ANNs. SOI leverages the continuity and seasonality of time-series
data and model predictions, enabling extrapolation for processing speed
improvements, particularly in deeper layers. By applying compression, SOI
generates more general inner partial states of ANN, allowing skipping full
model recalculation at each inference.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Self-Powered LLM Modality Expansion for Large Speech-Text Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03798v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03798v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tengfei Yu, Xuebo Liu, Zhiyi Hou, Liang Ding, Dacheng Tao, Min Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) exhibit remarkable performance across diverse
tasks, indicating their potential for expansion into large speech-text models
(LSMs) by integrating speech capabilities. Although unified speech-text
pre-training and multimodal data instruction-tuning offer considerable
benefits, these methods generally entail significant resource demands and tend
to overfit specific tasks. This study aims to refine the use of speech datasets
for LSM training by addressing the limitations of vanilla instruction tuning.
We explore the instruction-following dynamics within LSMs, identifying a
critical issue termed speech anchor bias-a tendency for LSMs to over-rely on
speech inputs, mistakenly interpreting the entire speech modality as
directives, thereby neglecting textual instructions. To counteract this bias,
we introduce a self-powered LSM that leverages augmented automatic speech
recognition data generated by the model itself for more effective instruction
tuning. Our experiments across a range of speech-based tasks demonstrate that
self-powered LSM mitigates speech anchor bias and improves the fusion of speech
and text modalities in LSMs. Data, code and scripts are freely available at
https://github.com/ytf-philp/Self-powered-LSM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Convolutional Variational Autoencoders for Spectrogram Compression in
  Automatic Speech Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02560v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02560v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Olga Iakovenko, Ivan Bondarenko
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For many Automatic Speech Recognition (ASR) tasks audio features as
spectrograms show better results than Mel-frequency Cepstral Coefficients
(MFCC), but in practice they are hard to use due to a complex dimensionality of
a feature space. The following paper presents an alternative approach towards
generating compressed spectrogram representation, based on Convolutional
Variational Autoencoders (VAE). A Convolutional VAE model was trained on a
subsample of the LibriSpeech dataset to reconstruct short fragments of audio
spectrograms (25 ms) from a 13-dimensional embedding. The trained model for a
40-dimensional (300 ms) embedding was used to generate features for corpus of
spoken commands on the GoogleSpeechCommands dataset. Using the generated
features an ASR system was built and compared to the model with MFCC features.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Theory and Practice of Natural Computing 9th International
  Conference, TPNC 2020, Taoyuan, Taiwan, 2020, Proceedings 9</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Leveraging <span class="highlight-title">Self-Supervised</span> Learning for Speaker Diarization <span class="chip">ICASSP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.09408v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.09408v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiangyu Han, Federico Landini, Johan Rohdin, Anna Silnova, Mireia Diez, Lukas Burget
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  End-to-end neural diarization has evolved considerably over the past few
years, but data scarcity is still a major obstacle for further improvements.
Self-supervised learning methods such as WavLM have shown promising performance
on several downstream tasks, but their application on speaker diarization is
somehow limited. In this work, we explore using WavLM to alleviate the problem
of data scarcity for neural diarization training. We use the same pipeline as
Pyannote and improve the local end-to-end neural diarization with WavLM and
Conformer. Experiments on far-field AMI, AISHELL-4, and AliMeeting datasets
show that our method substantially outperforms the Pyannote baseline and
achieves new state-of-the-art results on AMI and AISHELL-4, respectively. In
addition, by analyzing the system performance under different data quantity
scenarios, we show that WavLM representations are much more robust against data
scarcity than filterbank features, enabling less data hungry training
strategies. Furthermore, we found that simulated data, usually used to train
endto-end diarization models, does not help when using WavLM in our
experiments. Additionally, we also evaluate our model on the recent CHiME8
NOTSOFAR-1 task where it achieves better performance than the Pyannote
baseline. Our source code is publicly available at
https://github.com/BUTSpeechFIT/DiariZen.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to ICASSP 2025; New results are updated but conclusions are
  exactly the same as the original one</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Sounds of Home: A Speech-Removed Residential Audio <span class="highlight-title">Dataset</span> for Sound
  Event Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.11262v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.11262v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gabriel Bibbó, Thomas Deacon, Arshdeep Singh, Mark D. Plumbley
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a residential audio dataset to support sound event
detection research for smart home applications aimed at promoting wellbeing for
older adults. The dataset is constructed by deploying audio recording systems
in the homes of 8 participants aged 55-80 years for a 7-day period. Acoustic
characteristics are documented through detailed floor plans and construction
material information to enable replication of the recording environments for AI
model deployment. A novel automated speech removal pipeline is developed, using
pre-trained audio neural networks to detect and remove segments containing
spoken voice, while preserving segments containing other sound events. The
resulting dataset consists of privacy-compliant audio recordings that
accurately capture the soundscapes and activities of daily living within
residential spaces. The paper details the dataset creation methodology, the
speech removal pipeline utilizing cascaded model architectures, and an analysis
of the vocal label distribution to validate the speech removal process. This
dataset enables the development and benchmarking of sound event detection
models tailored specifically for in-home applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Online Similarity-and-Independence-Aware Beamformer for Low-latency
  Target Sound Extraction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.16449v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.16449v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Atsuo Hiroe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study introduces an online target sound extraction (TSE) process using
the similarity-and-independence-aware beamformer (SIBF) derived from an
iterative batch algorithm. The study aimed to reduce latency while maintaining
extraction accuracy. The SIBF, which is a linear method, provides more accurate
estimates of the target than an approximate magnitude spectrogram reference.
The transition to an online algorithm reduces latency but presents challenges.
First, contrary to the conventional assumption, deriving the online algorithm
may degrade accuracy as compared to the batch algorithm using a sliding window.
Second, conventional post-processing methods intended for scaling the estimated
target may widen the accuracy gap between the two algorithms. This study adopts
an approach that addresses these challenges and minimizes the accuracy gap
during post-processing. It proposes a novel scaling method based on the
single-channel Wiener filter (SWF-based scaling). To further improve accuracy,
the study introduces a modified version of the time-frequency-varying variance
generalized Gaussian distribution as a source model to represent the joint
probability between the target and reference. Experimental results using the
CHiME-3 dataset demonstrate several key findings: 1) SWF-based scaling
effectively eliminates the gap between the two algorithms and improves
accuracy. 2) The new source model achieves optimal accuracy, corresponding to
the Laplacian model. 3) Our online SIBF outperforms conventional linear TSE
methods, including independent vector extraction and minimum mean square error
beamforming. These findings can contribute to the fields of beamforming and
blind source separation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Re-submitted to IEEE Open Journal of Signal Processing</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LearnerVoice: A <span class="highlight-title">Dataset</span> of Non-Native English Learners' Spontaneous
  Speech 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.04280v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.04280v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haechan Kim, Junho Myung, Seoyoung Kim, Sungpah Lee, Dongyeop Kang, Juho Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prevalent ungrammatical expressions and disfluencies in spontaneous speech
from second language (L2) learners pose unique challenges to Automatic Speech
Recognition (ASR) systems. However, few datasets are tailored to L2 learner
speech. We publicly release LearnerVoice, a dataset consisting of 50.04 hours
of audio and transcriptions of L2 learners' spontaneous speech. Our linguistic
analysis reveals that transcriptions in our dataset contain L2S (L2 learner's
Spontaneous speech) features, consisting of ungrammatical expressions and
disfluencies (e.g., filler words, word repetitions, self-repairs, false
starts), significantly more than native speech datasets. Fine-tuning
whisper-small.en with LearnerVoice achieves a WER of 10.26%, 44.2% lower than
vanilla whisper-small.en. Furthermore, our qualitative analysis indicates that
54.2% of errors from the vanilla model on LearnerVoice are attributable to L2S
features, with 48.1% of them being reduced in the fine-tuned model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Proceedings of Interspeech</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mamba in Speech: Towards an Alternative to Self-Attention 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.12609v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.12609v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangyu Zhang, Qiquan Zhang, Hexin Liu, Tianyi Xiao, Xinyuan Qian, Beena Ahmed, Eliathamby Ambikairajah, Haizhou Li, Julien Epps
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformer and its derivatives have achieved success in diverse tasks across
computer vision, natural language processing, and speech processing. To reduce
the complexity of computations within the multi-head self-attention mechanism
in Transformer, Selective State Space Models (i.e., Mamba) were proposed as an
alternative. Mamba exhibited its effectiveness in natural language processing
and computer vision tasks, but its superiority has rarely been investigated in
speech signal processing. This paper explores solutions for applying Mamba to
speech processing by discussing two typical speech processing tasks: speech
recognition, which requires semantic and sequential information, and speech
enhancement, which focuses primarily on sequential patterns. The experimental
results show the superiority of bidirectional Mamba~(BiMamba) for speech
processing to vanilla Mamba. Moreover, experiments demonstrate the
effectiveness of BiMamba as an alternative to the self-attention module in
Transformer and its derivates, particularly for the semantic-aware task. The
crucial technologies for transferring Mamba to speech are then summarized in
ablation studies and the discussion section to offer insights for future
research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Analyzing and Mitigating Inconsistency in Discrete Audio Tokens for
  Neural Codec Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19283v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19283v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenrui Liu, Zhifang Guo, Jin Xu, Yuanjun Lv, Yunfei Chu, Zhou Zhao, Junyang Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Building upon advancements in Large Language Models (LLMs), the field of
audio processing has seen increased interest in training audio generation tasks
with discrete audio token sequences. However, directly discretizing audio by
neural audio codecs often results in sequences that fundamentally differ from
text sequences. Unlike text, where text token sequences are deterministic,
discrete audio tokens can exhibit significant variability based on contextual
factors, while still producing perceptually identical audio segments. We refer
to this phenomenon as \textbf{Discrete Representation Inconsistency (DRI)}.
This inconsistency can lead to a single audio segment being represented by
multiple divergent sequences, which creates confusion in neural codec language
models and results in omissions and repetitions during speech generation. In
this paper, we quantitatively analyze the DRI phenomenon within popular audio
tokenizers such as EnCodec. Our approach effectively mitigates the DRI
phenomenon of the neural audio codec. Furthermore, extensive experiments on the
neural codec language model over LibriTTS and large-scale MLS datases (44,000
hours) demonstrate the effectiveness and generality of our method. The demo of
audio samples is available
online~\footnote{\url{https://consistencyinneuralcodec.github.io}}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>e.g.: 15 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VHASR: A Multimodal Speech Recognition System With Vision Hotwords <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00822v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00822v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiliang Hu, Zuchao Li, Ping Wang, Haojun Ai, Lefei Zhang, Hai Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The image-based multimodal automatic speech recognition (ASR) model enhances
speech recognition performance by incorporating audio-related image. However,
some works suggest that introducing image information to model does not help
improving ASR performance. In this paper, we propose a novel approach
effectively utilizing audio-related image information and set up VHASR, a
multimodal speech recognition system that uses vision as hotwords to strengthen
the model's speech recognition capability. Our system utilizes a dual-stream
architecture, which firstly transcribes the text on the two streams separately,
and then combines the outputs. We evaluate the proposed model on four datasets:
Flickr8k, ADE20k, COCO, and OpenImages. The experimental results show that
VHASR can effectively utilize key information in images to enhance the model's
speech recognition ability. Its performance not only surpasses unimodal ASR,
but also achieves SOTA among existing image-based multimodal ASR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 6 figures, accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-10-03T00:00:00Z">2024-10-03</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language <span class="chip" style="font-size: 60%">150</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Vinoground: Scrutinizing LMMs over Dense Temporal Reasoning with Short
  Videos 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02763v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02763v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianrui Zhang, Mu Cai, Yong Jae Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  There has been growing sentiment recently that modern large multimodal models
(LMMs) have addressed most of the key challenges related to short video
comprehension. As a result, both academia and industry are gradually shifting
their attention towards the more complex challenges posed by understanding
long-form videos. However, is this really the case? Our studies indicate that
LMMs still lack many fundamental reasoning capabilities even when dealing with
short videos. We introduce Vinoground, a temporal counterfactual LMM evaluation
benchmark encompassing 1000 short and natural video-caption pairs. We
demonstrate that existing LMMs severely struggle to distinguish temporal
differences between different actions and object transformations. For example,
the best model GPT-4o only obtains ~50% on our text and video scores, showing a
large gap compared to the human baseline of ~90%. All open-source multimodal
models and CLIP-based models perform much worse, producing mostly random chance
performance. Through this work, we shed light onto the fact that temporal
reasoning in short videos is a problem yet to be fully solved. The dataset and
evaluation code are available at https://vinoground.github.io.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project Page: https://vinoground.github.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Erasing Conceptual Knowledge from Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02760v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02760v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rohit Gandikota, Sheridan Feucht, Samuel Marks, David Bau
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Concept erasure in language models has traditionally lacked a comprehensive
evaluation framework, leading to incomplete assessments of effectiveness of
erasure methods. We propose an evaluation paradigm centered on three critical
criteria: innocence (complete knowledge removal), seamlessness (maintaining
conditional fluent generation), and specificity (preserving unrelated task
performance). Our evaluation metrics naturally motivate the development of
Erasure of Language Memory (ELM), a new method designed to address all three
dimensions. ELM employs targeted low-rank updates to alter output distributions
for erased concepts while preserving overall model capabilities including
fluency when prompted for an erased concept. We demonstrate ELM's efficacy on
biosecurity, cybersecurity, and literary domain erasure tasks. Comparative
analysis shows that ELM achieves superior performance across our proposed
metrics, including near-random scores on erased topic assessments, generation
fluency, maintained accuracy on unrelated benchmarks, and robustness under
adversarial attacks. Our code, data, and trained models are available at
https://elm.baulab.info
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project Page: https://elm.baulab.info</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CorPipe at CRAC 2024: Predicting Zero Mentions from Raw Text 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02756v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02756v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Milan Straka
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present CorPipe 24, the winning entry to the CRAC 2024 Shared Task on
Multilingual Coreference Resolution. In this third iteration of the shared
task, a novel objective is to also predict empty nodes needed for zero
coreference mentions (while the empty nodes were given on input in previous
years). This way, coreference resolution can be performed on raw text. We
evaluate two model variants: a~two-stage approach (where the empty nodes are
predicted first using a pretrained encoder model and then processed together
with sentence words by another pretrained model) and a single-stage approach
(where a single pretrained encoder model generates empty nodes, coreference
mentions, and coreference links jointly). In both settings, CorPipe surpasses
other participants by a large margin of 3.9 and 2.8 percent points,
respectively. The source code and the trained model are available at
https://github.com/ufal/crac2024-corpipe .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to CRAC 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SIEVE: General Purpose Data Filtering System Matching <span class="highlight-title">GPT</span>-4o Accuracy at
  1% the Cost 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02755v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02755v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jifan Zhang, Robert Nowak
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Creating specialized large language models requires vast amounts of clean,
special purpose data for training and fine-tuning. With only a handful of
existing large-scale, domain-specific datasets, creation of new datasets is
required in most applications. This requires the development of new
application-specific filtering of web-scale data. Filtering with a
high-performance, general-purpose LLM such as GPT-4o can be highly effective,
but this is extremely expensive at web-scale. This paper proposes SIEVE, a
lightweight alternative that matches GPT-4o accuracy at a fraction of the cost.
SIEVE can perform up to 500 filtering operations for the cost of one GPT-4o
filtering call. The key to SIEVE is a seamless integration of GPT-4o and
lightweight T5 models, using active learning to fine-tune T5 in the background
with a small number of calls to GPT-4o. Once trained, it performs as well as
GPT-4o at a tiny fraction of the cost. We experimentally validate SIEVE on the
OpenWebText dataset, using five highly customized filter tasks targeting high
quality and domain-specific content. Our results demonstrate the effectiveness
and efficiency of our method in curating large, high-quality datasets for
language model training at a substantially lower cost (1%) than existing
techniques. To further validate SIEVE, experiments show that SIEVE and GPT-4o
achieve similar accuracy, with human evaluators preferring SIEVE's filtering
results to those of GPT-4o.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Training Language Models on Synthetic Edit Sequences Improves Code
  Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02749v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02749v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ulyana Piterbarg, Lerrel Pinto, Rob Fergus
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Software engineers mainly write code by editing existing programs. In
contrast, large language models (LLMs) autoregressively synthesize programs in
a single pass. One explanation for this is the scarcity of open-sourced edit
data. While high-quality instruction data for code synthesis is already scarce,
high-quality edit data is even scarcer. To fill this gap, we develop a
synthetic data generation algorithm called LintSeq. This algorithm refactors
existing code into a sequence of code edits by using a linter to procedurally
sample across the error-free insertions that can be used to sequentially write
programs. It outputs edit sequences as text strings consisting of consecutive
program diffs. To test LintSeq, we use it to refactor a dataset of instruction
+ program pairs into instruction + program-diff-sequence tuples. Then, we
instruction finetune a series of smaller LLMs ranging from 2.6B to 14B
parameters on both the re-factored and original versions of this dataset,
comparing zero-shot performance on code synthesis benchmarks. We show that
during repeated sampling, edit sequence finetuned models produce more diverse
programs than baselines. This results in better inference-time scaling for
benchmark coverage as a function of samples, i.e. the fraction of problems
"pass@k" solved by any attempt given "k" tries. For example, on HumanEval
pass@50, small LLMs finetuned on synthetic edit sequences are competitive with
GPT-4 and outperform models finetuned on the baseline dataset by +20% (+/-3%)
in absolute score. Finally, we also pretrain our own tiny LMs for code
understanding. We show that finetuning tiny models on synthetic code edits
results in state-of-the-art code synthesis for the on-device model class. Our
150M parameter edit sequence LM matches or outperforms code models with twice
as many parameters, both with and without repeated sampling, including Codex
and AlphaCode.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CriSPO: Multi-Aspect Critique-Suggestion-guided Automatic <span class="highlight-title">Prompt</span>
  Optimization for Text Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02748v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02748v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Han He, Qianchu Liu, Lei Xu, Chaitanya Shivade, Yi Zhang, Sundararajan Srinivasan, Katrin Kirchhoff
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) can generate fluent summaries across domains
using prompting techniques, reducing the need to train models for summarization
applications. However, crafting effective prompts that guide LLMs to generate
summaries with the appropriate level of detail and writing style remains a
challenge. In this paper, we explore the use of salient information extracted
from the source document to enhance summarization prompts. We show that adding
keyphrases in prompts can improve ROUGE F1 and recall, making the generated
summaries more similar to the reference and more complete. The number of
keyphrases can control the precision-recall trade-off. Furthermore, our
analysis reveals that incorporating phrase-level salient information is
superior to word- or sentence-level. However, the impact on hallucination is
not universally positive across LLMs. To conduct this analysis, we introduce
Keyphrase Signal Extractor (CriSPO), a lightweight model that can be finetuned
to extract salient keyphrases. By using CriSPO, we achieve consistent ROUGE
improvements across datasets and open-weight and proprietary LLMs without any
LLM customization. Our findings provide insights into leveraging salient
information in building prompt-based summarization systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Neutral residues: revisiting adapters for model extension 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02744v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02744v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Franck Signe Talla, Herve Jegou, Edouard Grave
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We address the problem of extending a pretrained large language model to a
new domain that was not seen at training time, like adding a language for which
the original model has seen no or little training data. Popular solutions like
fine-tuning or low-rank adaptation are successful at domain adaptation, but
formally they do not add any extra capacity and degrade the performance in the
original domain.
  Our paper analyzes this extension problem under three angles: data,
architecture and training procedure, which are advantageously considered
jointly. In particular, we improve adapters and make it possible to learn an
entire new language while ensuring that the output of the neural network is
almost unchanged in the original domain. For this purpose, we modify the new
residual blocks in a way that leads each new residual block to output
near-zeros in the original domain.
  This solution of neutral residues, which borrows architectural components
from mixture of experts, is effective: with only 20% extra learnable weights
compared to an original model trained on English, we get results that are
significantly better than concurrent approaches (fine-tuning, low-rank or
vanilla adapters) in terms of the trade-off between learning a new language and
not forgetting English.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MA-RLHF: Reinforcement Learning from Human Feedback with Macro Actions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02743v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02743v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yekun Chai, Haoran Sun, Huang Fang, Shuohuan Wang, Yu Sun, Hua Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement learning from human feedback (RLHF) has demonstrated
effectiveness in aligning large language models (LLMs) with human preferences.
However, token-level RLHF suffers from the credit assignment problem over long
sequences, where delayed rewards make it challenging for the model to discern
which actions contributed to successful outcomes. This hinders learning
efficiency and slows convergence. In this paper, we propose MA-RLHF, a simple
yet effective RLHF framework that incorporates macro actions -- sequences of
tokens or higher-level language constructs -- into the learning process. By
operating at this higher level of abstraction, our approach reduces the
temporal distance between actions and rewards, facilitating faster and more
accurate credit assignment. This results in more stable policy gradient
estimates and enhances learning efficiency within each episode, all without
increasing computational complexity during training or inference. We validate
our approach through extensive experiments across various model sizes and
tasks, including text summarization, dialogue generation, question answering,
and program synthesis. Our method achieves substantial performance improvements
over standard RLHF, with performance gains of up to 30% in text summarization
and code generation, 18% in dialogue, and 8% in question answering tasks.
Notably, our approach reaches parity with vanilla RLHF 1.7x to 2x faster in
terms of training time and continues to outperform it with further training. We
will make our code and data publicly available at
https://github.com/ernie-research/MA-RLHF .
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Grounding Large Language Models In Embodied Environment With Imperfect
  World Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02742v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02742v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haolan Liu, Jishen Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite a widespread success in various applications, large language models
(LLMs) often stumble when tackling basic physical reasoning or executing
robotics tasks, due to a lack of direct experience with the physical nuances of
the real world. To address these issues, we propose a Grounding Large language
model with Imperfect world MOdel (GLIMO), which utilizes proxy world models
such as simulators to collect and synthesize trining data. GLIMO incorporates
an LLM agent-based data generator to automatically create high-quality and
diverse instruction datasets. The generator includes an iterative self-refining
module for temporally consistent experience sampling, a diverse set of
question-answering instruction seeds, and a retrieval-augmented generation
module for reflecting on prior experiences. Comprehensive experiments show that
our approach improve the performance of strong open-source LLMs like LLaMA-3
with a performance boost of 2.04 $\times$, 1.54 $\times$, and 1.82 $\times$
across three different benchmarks, respectively. The performance is able to
compete with or surpass their larger counterparts such as GPT-4.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Salient Information <span class="highlight-title">Prompt</span>ing to Steer Content in <span class="highlight-title">Prompt</span>-based
  Abstractive Summarization <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02741v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02741v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lei Xu, Mohammed Asad Karim, Saket Dingliwal, Aparna Elangovan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) can generate fluent summaries across domains
using prompting techniques, reducing the need to train models for summarization
applications. However, crafting effective prompts that guide LLMs to generate
summaries with the appropriate level of detail and writing style remains a
challenge. In this paper, we explore the use of salient information extracted
from the source document to enhance summarization prompts. We show that adding
keyphrases in prompts can improve ROUGE F1 and recall, making the generated
summaries more similar to the reference and more complete. The number of
keyphrases can control the precision-recall trade-off. Furthermore, our
analysis reveals that incorporating phrase-level salient information is
superior to word- or sentence-level. However, the impact on hallucination is
not universally positive across LLMs. To conduct this analysis, we introduce
Keyphrase Signal Extractor (SigExt), a lightweight model that can be finetuned
to extract salient keyphrases. By using SigExt, we achieve consistent ROUGE
improvements across datasets and open-weight and proprietary LLMs without any
LLM customization. Our findings provide insights into leveraging salient
information in building prompt-based summarization systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Industry Track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Justice or Prejudice? Quantifying Biases in LLM-as-a-Judge 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02736v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02736v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiayi Ye, Yanbo Wang, Yue Huang, Dongping Chen, Qihui Zhang, Nuno Moniz, Tian Gao, Werner Geyer, Chao Huang, Pin-Yu Chen, Nitesh V Chawla, Xiangliang Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLM-as-a-Judge has been widely utilized as an evaluation method in various
benchmarks and served as supervised rewards in model training. However, despite
their excellence in many domains, potential issues are under-explored,
undermining their reliability and the scope of their utility. Therefore, we
identify 12 key potential biases and propose a new automated bias
quantification framework-CALM-which systematically quantifies and analyzes each
type of bias in LLM-as-a-Judge by using automated and principle-guided
modification. Our experiments cover multiple popular language models, and the
results indicate that while advanced models have achieved commendable overall
performance, significant biases persist in certain specific tasks. Empirical
results suggest that there remains room for improvement in the reliability of
LLM-as-a-Judge. Moreover, we also discuss the explicit and implicit influence
of these biases and give some suggestions for the reliable application of
LLM-as-a-Judge. Our work highlights the need for stakeholders to address these
issues and remind users to exercise caution in LLM-as-a-Judge applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DivScene: Benchmarking LVLMs for Object Navigation with Diverse Scenes
  and Objects 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02730v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02730v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhaowei Wang, Hongming Zhang, Tianqing Fang, Ye Tian, Yue Yang, Kaixin Ma, Xiaoman Pan, Yangqiu Song, Dong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Object navigation in unknown environments is crucial for deploying embodied
agents in real-world applications. While we have witnessed huge progress due to
large-scale scene datasets, faster simulators, and stronger models, previous
studies mainly focus on limited scene types and target objects. In this paper,
we study a new task of navigating to diverse target objects in a large number
of scene types. To benchmark the problem, we present a large-scale scene
dataset, DivScene, which contains 4,614 scenes across 81 different types. With
the dataset, we build an end-to-end embodied agent, NatVLM, by fine-tuning a
Large Vision Language Model (LVLM) through imitation learning. The LVLM is
trained to take previous observations from the environment and generate the
next actions. We also introduce CoT explanation traces of the action prediction
for better performance when tuning LVLMs. Our extensive experiments find that
we can build a performant LVLM-based agent through imitation learning on the
shortest paths constructed by a BFS planner without any human supervision. Our
agent achieves a success rate that surpasses GPT-4o by over 20%. Meanwhile, we
carry out various analyses showing the generalization ability of our agent.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in Progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unified Multi-Modal Interleaved Document Representation for Information
  Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02729v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02729v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jaewoo Lee, Joonho Ko, Jinheon Baek, Soyeong Jeong, Sung Ju Hwang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Information Retrieval (IR) methods aim to identify relevant documents in
response to a given query, which have gained remarkable attention due to their
successful application in various natural language tasks. However, existing
approaches typically consider only the textual information within the
documents, which overlooks the fact that documents can contain multiple
modalities, including texts, images, and tables. Further, they often segment
each long document into multiple discrete passages for embedding, preventing
them from capturing the overall document context and interactions between
paragraphs. We argue that these two limitations lead to suboptimal document
representations for retrieval. In this work, to address them, we aim to produce
more comprehensive and nuanced document representations by holistically
embedding documents interleaved with different modalities. Specifically, we
achieve this by leveraging the capability of recent vision-language models that
enable the processing and integration of text, images, and tables into a
unified format and representation. Moreover, to mitigate the information loss
from segmenting documents into passages, instead of representing and retrieving
passages individually, we further merge the representations of segmented
passages into one single document representation, while we additionally
introduce a reranking strategy to decouple and identify the relevant passage
within the document if necessary. Then, through extensive experiments on
diverse information retrieval scenarios considering both the textual and
multimodal queries, we show that our approach substantially outperforms
relevant baselines, thanks to the consideration of the multimodal information
interleaved within the documents in a unified way.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Adaptive Inference-Time Compute: LLMs Can Predict if They Can Do Better,
  Even Mid-Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02725v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02725v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rohin Manvi, Anikait Singh, Stefano Ermon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Inference-time computation is a powerful paradigm to enhance the performance
of large language models (LLMs), with Best-of-N sampling being a widely used
technique. However, this method is computationally expensive, requiring both
(1) an external reward model and (2) the generation of multiple samples. In
this work, we introduce a new generative self-evaluation scheme designed to
adaptively reduce the number of generated samples while maintaining or even
improving performance. We use a generative reward model formulation, allowing
the LLM to predict mid-generation the probability that restarting the
generation will yield a better response. These predictions are obtained without
an external reward model and can be used to decide whether or not to generate
more samples, prune unpromising samples early on, or to pick the best sample.
This capability is very inexpensive as it involves generating a single
predefined token. Trained using a dataset constructed with real unfiltered
LMSYS user prompts, Llama 3.1 8B's win rate against GPT-4 on AlpacaEval
increases from 21% to 34% with 16 samples and math performance on GSM8K
improves from 84% to 91%. By sampling only when the LLM determines that it is
beneficial to do so and adaptively adjusting temperature annealing, we
demonstrate that 74% of the improvement from using 16 samples can be achieved
with only 1.2 samples on average. We further demonstrate that 50-75% of samples
can be pruned early in generation with minimal degradation in performance.
Overall, our methods enable more efficient and scalable compute utilization
during inference for LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Large Language Models as Markov Chains 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02724v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02724v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Oussama Zekri, Ambroise Odonnat, Abdelhakim Benechehab, Linus Bleistein, Nicolas Boullé, Ievgen Redko
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have proven to be remarkably efficient, both
across a wide range of natural language processing tasks and well beyond them.
However, a comprehensive theoretical analysis of the origins of their
impressive performance remains elusive. In this paper, we approach this
challenging task by drawing an equivalence between generic autoregressive
language models with vocabulary of size $T$ and context window of size $K$ and
Markov chains defined on a finite state space of size $\mathcal{O}(T^K)$. We
derive several surprising findings related to the existence of a stationary
distribution of Markov chains that capture the inference power of LLMs, their
speed of convergence to it, and the influence of the temperature on the latter.
We then prove pre-training and in-context generalization bounds and show how
the drawn equivalence allows us to enrich their interpretation. Finally, we
illustrate our theoretical guarantees with experiments on several recent LLMs
to highlight how they capture the behavior observed in practice.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>49 pages, 17 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Domain-Specific Retrieval-Augmented Generation Using Vector Stores,
  Knowledge Graphs, and Tensor Factorization <span class="chip">ICML</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02721v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02721v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ryan C. Barron, Ves Grantcharov, Selma Wanna, Maksim E. Eren, Manish Bhattarai, Nicholas Solovyev, George Tompkins, Charles Nicholas, Kim Ø. Rasmussen, Cynthia Matuszek, Boian S. Alexandrov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are pre-trained on large-scale corpora and excel
in numerous general natural language processing (NLP) tasks, such as question
answering (QA). Despite their advanced language capabilities, when it comes to
domain-specific and knowledge-intensive tasks, LLMs suffer from hallucinations,
knowledge cut-offs, and lack of knowledge attributions. Additionally, fine
tuning LLMs' intrinsic knowledge to highly specific domains is an expensive and
time consuming process. The retrieval-augmented generation (RAG) process has
recently emerged as a method capable of optimization of LLM responses, by
referencing them to a predetermined ontology. It was shown that using a
Knowledge Graph (KG) ontology for RAG improves the QA accuracy, by taking into
account relevant sub-graphs that preserve the information in a structured
manner. In this paper, we introduce SMART-SLIC, a highly domain-specific LLM
framework, that integrates RAG with KG and a vector store (VS) that store
factual domain specific information. Importantly, to avoid hallucinations in
the KG, we build these highly domain-specific KGs and VSs without the use of
LLMs, but via NLP, data mining, and nonnegative tensor factorization with
automatic model selection. Pairing our RAG with a domain-specific: (i) KG
(containing structured information), and (ii) VS (containing unstructured
information) enables the development of domain-specific chat-bots that
attribute the source of information, mitigate hallucinations, lessen the need
for fine-tuning, and excel in highly domain-specific question answering tasks.
We pair SMART-SLIC with chain-of-thought prompting agents. The framework is
designed to be generalizable to adapt to any specific or specialized domain. In
this paper, we demonstrate the question answering capabilities of our framework
on a corpus of scientific publications on malware analysis and anomaly
detection.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages 7 figures, 1 table, 1 cypher code Accepted to ICMLA 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ UncertaintyRAG: Span-Level Uncertainty Enhanced Long-Context Modeling
  for Retrieval-Augmented Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02719v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02719v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zixuan Li, Jing Xiong, Fanghua Ye, Chuanyang Zheng, Xun Wu, Jianqiao Lu, Zhongwei Wan, Xiaodan Liang, Chengming Li, Zhenan Sun, Lingpeng Kong, Ngai Wong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present UncertaintyRAG, a novel approach for long-context
Retrieval-Augmented Generation (RAG) that utilizes Signal-to-Noise Ratio
(SNR)-based span uncertainty to estimate similarity between text chunks. This
span uncertainty enhances model calibration, improving robustness and
mitigating semantic inconsistencies introduced by random chunking. Leveraging
this insight, we propose an efficient unsupervised learning technique to train
the retrieval model, alongside an effective data sampling and scaling strategy.
UncertaintyRAG outperforms baselines by 2.03% on LLaMA-2-7B, achieving
state-of-the-art results while using only 4% of the training data compared to
other advanced open-source retrieval models under distribution shift settings.
Our method demonstrates strong calibration through span uncertainty, leading to
improved generalization and robustness in long-context RAG tasks. Additionally,
UncertaintyRAG provides a lightweight retrieval model that can be integrated
into any large language model with varying context window lengths, without the
need for fine-tuning, showcasing the flexibility of our approach.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Video Instruction Tuning With Synthetic Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02713v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02713v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuanhan Zhang, Jinming Wu, Wei Li, Bo Li, Zejun Ma, Ziwei Liu, Chunyuan Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The development of video large multimodal models (LMMs) has been hindered by
the difficulty of curating large amounts of high-quality raw data from the web.
To address this, we propose an alternative approach by creating a high-quality
synthetic dataset specifically for video instruction-following, namely
LLaVA-Video-178K. This dataset includes key tasks such as detailed captioning,
open-ended question-answering (QA), and multiple-choice QA. By training on this
dataset, in combination with existing visual instruction tuning data, we
introduce LLaVA-Video, a new video LMM. Our experiments demonstrate that
LLaVA-Video achieves strong performance across various video benchmarks,
highlighting the effectiveness of our dataset. We plan to release the dataset,
its generation pipeline, and the model checkpoints.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project page: https://llava-vl.github.io/blog/2024-09-30-llava-video/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLaVA-Critic: Learning to Evaluate Multimodal Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02712v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02712v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianyi Xiong, Xiyao Wang, Dong Guo, Qinghao Ye, Haoqi Fan, Quanquan Gu, Heng Huang, Chunyuan Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce LLaVA-Critic, the first open-source large multimodal model (LMM)
designed as a generalist evaluator to assess performance across a wide range of
multimodal tasks. LLaVA-Critic is trained using a high-quality critic
instruction-following dataset that incorporates diverse evaluation criteria and
scenarios. Our experiments demonstrate the model's effectiveness in two key
areas: (1) LMM-as-a-Judge, where LLaVA-Critic provides reliable evaluation
scores, performing on par with or surpassing GPT models on multiple evaluation
benchmarks; and (2) Preference Learning, where it generates reward signals for
preference learning, enhancing model alignment capabilities. This work
underscores the potential of open-source LMMs in self-critique and evaluation,
setting the stage for future research into scalable, superhuman alignment
feedback mechanisms for LMMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project Page: https://llava-vl.github.io/blog/2024-10-03-llava-critic</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLMs Know More Than They Show: On the Intrinsic Representation of LLM
  Hallucinations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02707v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02707v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hadas Orgad, Michael Toker, Zorik Gekhman, Roi Reichart, Idan Szpektor, Hadas Kotek, Yonatan Belinkov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) often produce errors, including factual
inaccuracies, biases, and reasoning failures, collectively referred to as
"hallucinations". Recent studies have demonstrated that LLMs' internal states
encode information regarding the truthfulness of their outputs, and that this
information can be utilized to detect errors. In this work, we show that the
internal representations of LLMs encode much more information about
truthfulness than previously recognized. We first discover that the
truthfulness information is concentrated in specific tokens, and leveraging
this property significantly enhances error detection performance. Yet, we show
that such error detectors fail to generalize across datasets, implying that --
contrary to prior claims -- truthfulness encoding is not universal but rather
multifaceted. Next, we show that internal representations can also be used for
predicting the types of errors the model is likely to make, facilitating the
development of tailored mitigation strategies. Lastly, we reveal a discrepancy
between LLMs' internal encoding and external behavior: they may encode the
correct answer, yet consistently generate an incorrect one. Taken together,
these insights deepen our understanding of LLM errors from the model's internal
perspective, which can guide future research on enhancing error analysis and
mitigation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Selective Attention Improves <span class="highlight-title">Transformer</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02703v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02703v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yaniv Leviathan, Matan Kalman, Yossi Matias
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Unneeded elements in the attention's context degrade performance. We
introduce Selective Attention, a simple parameter-free change to the standard
attention mechanism which reduces attention to unneeded elements. Selective
attention improves language modeling performance in a variety of model sizes
and context lengths. For example, a range of transformers trained with the
language modeling objective on C4 with selective attention perform equivalently
to standard transformers with ~2X more heads and parameters in their attention
modules. Selective attention also allows decreasing the size of the attention's
context buffer, leading to meaningful reductions in the memory and compute
requirements during inference. For example, transformers with 100M parameters
trained on C4 with context sizes of 512, 1,024, and 2,048 need 16X, 25X, and
47X less memory for their attention module, respectively, when equipped with
selective attention, as those without selective attention, with the same
validation perplexity.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HELMET: How to Evaluate Long-Context Language Models Effectively and
  Thoroughly 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02694v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02694v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Howard Yen, Tianyu Gao, Minmin Hou, Ke Ding, Daniel Fleischer, Peter Izasak, Moshe Wasserblat, Danqi Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  There have been many benchmarks for evaluating long-context language models
(LCLMs), but developers often rely on synthetic tasks like needle-in-a-haystack
(NIAH) or arbitrary subsets of tasks. It remains unclear whether they translate
to the diverse downstream applications of LCLMs, and the inconsistency further
complicates model comparison. We investigate the underlying reasons behind
current practices and find that existing benchmarks often provide noisy signals
due to low coverage of applications, insufficient lengths, unreliable metrics,
and incompatibility with base models. In this work, we present HELMET (How to
Evaluate Long-context Models Effectively and Thoroughly), a comprehensive
benchmark encompassing seven diverse, application-centric categories. We also
address many issues in previous benchmarks by adding controllable lengths up to
128k tokens, model-based evaluation for reliable metrics, and few-shot
prompting for robustly evaluating base models. Consequently, we demonstrate
that HELMET offers more reliable and consistent rankings of frontier LCLMs.
Through a comprehensive study of 51 LCLMs, we find that (1) synthetic tasks
like NIAH are not good predictors of downstream performance; (2) the diverse
categories in HELMET exhibit distinct trends and low correlation with each
other; and (3) while most LCLMs achieve perfect NIAH scores, open-source models
significantly lag behind closed ones when the task requires full-context
reasoning or following complex instructions -- the gap widens with increased
lengths. Finally, we recommend using our RAG tasks for fast model development,
as they are easy to run and more predictive of other downstream performance;
ultimately, we advocate for a holistic evaluation across diverse tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code and data are available here:
  https://github.com/princeton-nlp/HELMET</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On the Proper Treatment of Tokenization in Psycholinguistics <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02691v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02691v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mario Giulianelli, Luca Malagutti, Juan Luis Gastaldi, Brian DuSell, Tim Vieira, Ryan Cotterell
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language models are widely used in computational psycholinguistics to test
theories that relate the negative log probability (the surprisal) of a region
of interest (a substring of characters) under a language model to its cognitive
cost experienced by readers, as operationalized, for example, by gaze duration
on the region. However, the application of modern language models to
psycholinguistic studies is complicated by the practice of using tokenization
as an intermediate step in training a model. Doing so results in a language
model over token strings rather than one over character strings. Vexingly,
regions of interest are generally misaligned with these token strings. The
paper argues that token-level language models should be (approximately)
marginalized into character-level language models before they are used in
psycholinguistic studies to compute the surprisal of a region of interest;
then, the marginalized character-level language model can be used to compute
the surprisal of an arbitrary character substring, which we term a focal area,
that the experimenter may wish to use as a predictor. Our proposal of
marginalizing a token-level model into a character-level one solves this
misalignment issue independently of the tokenization scheme. Empirically, we
discover various focal areas whose surprisal is a better psychometric predictor
than the surprisal of the region of interest itself.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Main conference long paper at EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HiddenGuard: Fine-Grained Safe Generation with Specialized
  Representation Router 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02684v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02684v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lingrui Mei, Shenghua Liu, Yiwei Wang, Baolong Bi, Ruibin Yuan, Xueqi Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As Large Language Models (LLMs) grow increasingly powerful, ensuring their
safety and alignment with human values remains a critical challenge. Ideally,
LLMs should provide informative responses while avoiding the disclosure of
harmful or sensitive information. However, current alignment approaches, which
rely heavily on refusal strategies, such as training models to completely
reject harmful prompts or applying coarse filters are limited by their binary
nature. These methods either fully deny access to information or grant it
without sufficient nuance, leading to overly cautious responses or failures to
detect subtle harmful content. For example, LLMs may refuse to provide basic,
public information about medication due to misuse concerns. Moreover, these
refusal-based methods struggle to handle mixed-content scenarios and lack the
ability to adapt to context-dependent sensitivities, which can result in
over-censorship of benign content. To overcome these challenges, we introduce
HiddenGuard, a novel framework for fine-grained, safe generation in LLMs.
HiddenGuard incorporates Prism (rePresentation Router for In-Stream
Moderation), which operates alongside the LLM to enable real-time, token-level
detection and redaction of harmful content by leveraging intermediate hidden
states. This fine-grained approach allows for more nuanced, context-aware
moderation, enabling the model to generate informative responses while
selectively redacting or replacing sensitive information, rather than outright
refusal. We also contribute a comprehensive dataset with token-level
fine-grained annotations of potentially harmful information across diverse
contexts. Our experiments demonstrate that HiddenGuard achieves over 90% in F1
score for detecting and redacting harmful content while preserving the overall
utility and informativeness of the model's responses.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DailyDilemmas: Revealing Value Preferences of LLMs with Quandaries of
  Daily Life 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02683v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02683v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu Ying Chiu, Liwei Jiang, Yejin Choi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As we increasingly seek guidance from LLMs for decision-making in daily life,
many of these decisions are not clear-cut and depend significantly on the
personal values and ethical standards of the users. We present DailyDilemmas, a
dataset of 1,360 moral dilemmas encountered in everyday life. Each dilemma
includes two possible actions and with each action, the affected parties and
human values invoked. Based on these dilemmas, we consolidated a set of human
values across everyday topics e.g., interpersonal relationships, workplace, and
environmental issues. We evaluated LLMs on these dilemmas to determine what
action they will take and the values represented by these actions. Then, we
analyzed these values through the lens of five popular theories inspired by
sociology, psychology and philosophy. These theories are: World Value Survey,
Moral Foundation Theory, Maslow's Hierarchy of Needs, Aristotle's Virtues, and
Plutchik Wheel of Emotion. We find that LLMs are most aligned with the
self-expression over survival values in terms of World Value Survey, care over
loyalty in Moral Foundation Theory. Interestingly, we find large preferences
differences in models for some core values such as truthfulness e.g.,
Mixtral-8x7B model tends to neglect it by 9.7% while GPT-4-turbo model tends to
select it by 9.4%. We also study the recent guidance released by OpenAI
(ModelSpec), and Anthropic (Constitutional AI) to understand how their released
principles reflect their actual value prioritization when facing nuanced moral
reasoning in daily-life settings. We find that end users cannot effectively
steer such prioritization using system prompts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint. Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Distilling an End-to-End Voice Assistant Without Instruction Training
  Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02678v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02678v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        William Held, Ella Li, Michael Ryan, Weiyan Shi, Yanzhe Zhang, Diyi Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Voice assistants, such as Siri and Google Assistant, typically model audio
and text separately, resulting in lost speech information and increased
complexity. Recent efforts to address this with end-to-end Speech Large
Language Models (LLMs) trained with supervised finetuning (SFT)
  have led to models ``forgetting" capabilities from text-only LLMs. Our work
proposes an alternative paradigm for training Speech LLMs without instruction
data, using the response of a text-only LLM to transcripts as self-supervision.
Importantly, this process can be performed without annotated responses. We show
that our Distilled Voice Assistant (DiVA) generalizes to Spoken Question
Answering, Classification, and Translation. Furthermore, we show that DiVA
better meets user preferences, achieving a 72\% win rate compared with
state-of-the-art models like Qwen 2 Audio, despite using $>$100x less training
compute.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CulturalBench: a Robust, Diverse and Challenging Benchmark on Measuring
  the (Lack of) Cultural Knowledge of LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02677v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02677v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu Ying Chiu, Liwei Jiang, Bill Yuchen Lin, Chan Young Park, Shuyue Stella Li, Sahithya Ravi, Mehar Bhatia, Maria Antoniak, Yulia Tsvetkov, Vered Shwartz, Yejin Choi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To make large language models (LLMs) more helpful across diverse cultures, it
is essential to have effective cultural knowledge benchmarks to measure and
track our progress. Effective benchmarks need to be robust, diverse, and
challenging. We introduce CulturalBench: a set of 1,227 human-written and
human-verified questions for effectively assessing LLMs' cultural knowledge,
covering 45 global regions including the underrepresented ones like Bangladesh,
Zimbabwe, and Peru. Questions - each verified by five independent annotators -
span 17 diverse topics ranging from food preferences to greeting etiquettes. We
evaluate models on two setups: CulturalBench-Easy and CulturalBench-Hard which
share the same questions but asked differently. We find that LLMs are sensitive
to such difference in setups (e.g., GPT-4o with 27.3% difference). Compared to
human performance (92.6% accuracy), CulturalBench-Hard is more challenging for
frontier LLMs with the best performing model (GPT-4o) at only 61.5% and the
worst (Llama3-8b) at 21.4%. Moreover, we find that LLMs often struggle with
tricky questions that have multiple correct answers (e.g., What utensils do the
Chinese usually use?), revealing a tendency to converge to a single answer. Our
results also indicate that OpenAI GPT-4o substantially outperform other
proprietary and open source models in questions related to all but one region
(Oceania). Nonetheless, all models consistently underperform on questions
related to South America and the Middle East.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint. Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FAN: Fourier Analysis Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02675v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02675v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yihong Dong, Ge Li, Yongding Tao, Xue Jiang, Kechi Zhang, Jia Li, Jing Su, Jun Zhang, Jingjing Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the remarkable success achieved by neural networks, particularly
those represented by MLP and Transformer, we reveal that they exhibit potential
flaws in the modeling and reasoning of periodicity, i.e., they tend to memorize
the periodic data rather than genuinely understanding the underlying principles
of periodicity. However, periodicity is a crucial trait in various forms of
reasoning and generalization, underpinning predictability across natural and
engineered systems through recurring patterns in observations. In this paper,
we propose FAN, a novel network architecture based on Fourier Analysis, which
empowers the ability to efficiently model and reason about periodic phenomena.
By introducing Fourier Series, the periodicity is naturally integrated into the
structure and computational processes of the neural network, thus achieving a
more accurate expression and prediction of periodic patterns. As a promising
substitute to multi-layer perceptron (MLP), FAN can seamlessly replace MLP in
various models with fewer parameters and FLOPs. Through extensive experiments,
we demonstrate the effectiveness of FAN in modeling and reasoning about
periodic functions, and the superiority and generalizability of FAN across a
range of real-world tasks, including symbolic formula representation, time
series forecasting, and language modeling.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Examining Language Modeling Assumptions Using an Annotated Literary
  Dialect Corpus <span class="chip">EMNLP2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02674v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02674v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Craig Messner, Tom Lippincott
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a dataset of 19th century American literary orthovariant tokens
with a novel layer of human-annotated dialect group tags designed to serve as
the basis for computational experiments exploring literarily meaningful
orthographic variation. We perform an initial broad set of experiments over
this dataset using both token (BERT) and character (CANINE)-level contextual
language models. We find indications that the "dialect effect" produced by
intentional orthographic variation employs multiple linguistic channels, and
that these channels are able to be surfaced to varied degrees given particular
language modelling assumptions. Specifically, we find evidence showing that
choice of tokenization scheme meaningfully impact the type of orthographic
information a model is able to surface.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to NLP4DH@EMNLP2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ How to Train Long-Context Language Models (Effectively) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02660v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02660v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianyu Gao, Alexander Wettig, Howard Yen, Danqi Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study continued training and supervised fine-tuning (SFT) of a language
model (LM) to make effective use of long-context information. We first
establish a reliable evaluation protocol to guide model development -- Instead
of perplexity or simple needle-in-a-haystack (NIAH) tests, we use a broad set
of long-context tasks, and we evaluate models after SFT with instruction data
as this better reveals long-context abilities. Supported by our robust
evaluations, we run thorough experiments to decide the data mix for continued
pre-training, the instruction tuning dataset, and many other design choices. We
find that (1) code repositories and books are excellent sources of long data,
but it is crucial to combine them with high-quality short data; (2) training
with a sequence length beyond the evaluation length boosts long-context
performance; (3) for SFT, using only short instruction datasets yields strong
performance on long-context tasks. Our final model, ProLong-8B, which is
initialized from Llama-3 and trained on 40B tokens, demonstrates
state-of-the-art long-context performance among similarly sized models at a
length of 128K. ProLong outperforms Llama-3.18B-Instruct on the majority of
long-context tasks despite having seen only 5% as many tokens during
long-context training. Additionally, ProLong can effectively process up to 512K
tokens, one of the longest context windows of publicly available LMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Our code, data, and models are available at
  https://github.com/princeton-nlp/ProLong</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hate Personified: Investigating the role of LLMs in content moderation <span class="chip">EMNLP'24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02657v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02657v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sarah Masud, Sahajpreet Singh, Viktor Hangya, Alexander Fraser, Tanmoy Chakraborty
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For subjective tasks such as hate detection, where people perceive hate
differently, the Large Language Model's (LLM) ability to represent diverse
groups is unclear. By including additional context in prompts, we
comprehensively analyze LLM's sensitivity to geographical priming, persona
attributes, and numerical information to assess how well the needs of various
groups are reflected. Our findings on two LLMs, five languages, and six
datasets reveal that mimicking persona-based attributes leads to annotation
variability. Meanwhile, incorporating geographical signals leads to better
regional alignment. We also find that the LLMs are sensitive to numerical
anchors, indicating the ability to leverage community-based flagging efforts
and exposure to adversaries. Our work provides preliminary guidelines and
highlights the nuances of applying LLMs in culturally sensitive cases.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 6 Figures, 13 Tables, EMNLP'24 Mains</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Measuring and Improving Persuasiveness of Generative Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02653v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02653v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Somesh Singh, Yaman K Singla, Harini SI, Balaji Krishnamurthy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLMs are increasingly being used in workflows involving generating content to
be consumed by humans (e.g., marketing) and also in directly interacting with
humans (e.g., through chatbots). The development of such systems that are
capable of generating verifiably persuasive messages presents both
opportunities and challenges for society. On the one hand, such systems could
positively impact domains like advertising and social good, such as addressing
drug addiction, and on the other, they could be misused for spreading
misinformation and shaping political opinions. To channel LLMs' impact on
society, we need to develop systems to measure and benchmark their
persuasiveness. With this motivation, we introduce PersuasionBench and
PersuasionArena, the first large-scale benchmark and arena containing a battery
of tasks to measure the persuasion ability of generative models automatically.
We investigate to what extent LLMs know and leverage linguistic patterns that
can help them generate more persuasive language. Our findings indicate that the
persuasiveness of LLMs correlates positively with model size, but smaller
models can also be made to have a higher persuasiveness than much larger
models. Notably, targeted training using synthetic and natural datasets
significantly enhances smaller models' persuasive capabilities, challenging
scale-dependent assumptions. Our findings carry key implications for both model
developers and policymakers. For instance, while the EU AI Act and California's
SB-1047 aim to regulate AI models based on the number of floating point
operations, we demonstrate that simple metrics like this alone fail to capture
the full scope of AI's societal impact. We invite the community to explore and
contribute to PersuasionArena and PersuasionBench, available at
https://bit.ly/measure-persuasion, to advance our understanding of AI-driven
persuasion and its societal implications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Undesirable Memorization in Large Language Models: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02650v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02650v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ali Satvaty, Suzan Verberne, Fatih Turkmen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While recent research increasingly showcases the remarkable capabilities of
Large Language Models (LLMs), it's vital to confront their hidden pitfalls.
Among these challenges, the issue of memorization stands out, posing
significant ethical and legal risks. In this paper, we presents a
Systematization of Knowledge (SoK) on the topic of memorization in LLMs.
Memorization is the effect that a model tends to store and reproduce phrases or
passages from the training data and has been shown to be the fundamental issue
to various privacy and security attacks against LLMs.
  We begin by providing an overview of the literature on the memorization,
exploring it across five key dimensions: intentionality, degree,
retrievability, abstraction, and transparency. Next, we discuss the metrics and
methods used to measure memorization, followed by an analysis of the factors
that contribute to memorization phenomenon. We then examine how memorization
manifests itself in specific model architectures and explore strategies for
mitigating these effects. We conclude our overview by identifying potential
research topics for the near future: to develop methods for balancing
performance and privacy in LLMs, and the analysis of memorization in specific
contexts, including conversational agents, retrieval-augmented generation,
multilingual language models, and diffusion language models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Immunogenicity Prediction with Dual Attention Enables Vaccine Target
  Selection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02647v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02647v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Song Li, Yang Tan, Song Ke, Liang Hong, Bingxin Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Immunogenicity prediction is a central topic in reverse vaccinology for
finding candidate vaccines that can trigger protective immune responses.
Existing approaches typically rely on highly compressed features and simple
model architectures, leading to limited prediction accuracy and poor
generalizability. To address these challenges, we introduce ProVaccine, a novel
deep learning solution with a dual attention mechanism that integrates
pre-trained latent vector representations of protein sequences and structures.
We also compile the most comprehensive immunogenicity dataset to date,
encompassing over 9,500 antigen sequences, structures, and immunogenicity
labels from bacteria, viruses, and tumors. Extensive experiments demonstrate
that ProVaccine outperforms existing methods across a wide range of evaluation
metrics. Furthermore, we establish a post-hoc validation protocol to assess the
practical significance of deep learning models in tackling vaccine design
challenges. Our work provides an effective tool for vaccine design and sets
valuable benchmarks for future research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 11 tables, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Attention in Large Language Models Yields Efficient Zero-Shot Re-Rankers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02642v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02642v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shijie Chen, Bernal Jiménez Gutiérrez, Yu Su
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Information retrieval (IR) systems have played a vital role in modern digital
life and have cemented their continued usefulness in this new era of generative
AI via retrieval-augmented generation. With strong language processing
capabilities and remarkable versatility, large language models (LLMs) have
become popular choices for zero-shot re-ranking in IR systems. So far,
LLM-based re-ranking methods rely on strong generative capabilities, which
restricts their use to either specialized or powerful proprietary models. Given
these restrictions, we ask: is autoregressive generation necessary and optimal
for LLMs to perform re-ranking? We hypothesize that there are abundant signals
relevant to re-ranking within LLMs that might not be used to their full
potential via generation. To more directly leverage such signals, we propose
in-context re-ranking (ICR), a novel method that leverages the change in
attention pattern caused by the search query for accurate and efficient
re-ranking. To mitigate the intrinsic biases in LLMs, we propose a calibration
method using a content-free query. Due to the absence of generation, ICR only
requires two ($O(1)$) forward passes to re-rank $N$ documents, making it
substantially more efficient than generative re-ranking methods that require at
least $O(N)$ forward passes. Our novel design also enables ICR to be applied to
any LLM without specialized training while guaranteeing a well-formed ranking.
Extensive experiments with two popular open-weight LLMs on standard single-hop
and multi-hop information retrieval benchmarks show that ICR outperforms
RankGPT while cutting the latency by more than 60% in practice. Through
detailed analyses, we show that ICR's performance is specially strong on tasks
that require more complex re-ranking signals. Our findings call for further
exploration on novel ways of utilizing open-weight LLMs beyond text generation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Large Language Model for Multi-Domain Translation: Benchmarking and
  Domain CoT Fine-tuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02631v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02631v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianxiang Hu, Pei Zhang, Baosong Yang, Jun Xie, Derek F. Wong, Rui Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Achieving consistent high-quality machine translation (MT) across diverse
domains remains a significant challenge, primarily due to the limited and
imbalanced parallel training data available in various domains. While large
language models (LLMs) have demonstrated impressive general understanding and
generation abilities, their potential in multi-domain MT is under-explored. We
establish a comprehensive benchmark for multi-domain translation, featuring 25
German$\Leftrightarrow$English and 22 Chinese$\Leftrightarrow$English test sets
respectively covering 15 domains. Our evaluation of prominent LLMs reveals a
discernible performance gap against traditional MT systems, highlighting domain
overfitting and catastrophic forgetting issues after fine-tuning on
domain-limited corpora. To mitigate this, we propose a domain Chain of Thought
(CoT) fine-tuning technique that utilizes the intrinsic multi-domain
intelligence of LLMs to improve translation performance. This method inspires
the LLM to perceive domain information from the source text, which then serves
as a helpful hint to guide the translation process. Despite being trained on a
small dataset of four domains, our CoT fine-tune approach achieves notable
enhancements in translation accuracy and domain robustness than traditional
fine-tuning, as evidenced by an average 1.53 BLEU score increase in over 20
German$\rightarrow$English distinct out-of-domain tests.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NL-Eye: Abductive NLI for Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02613v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02613v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mor Ventura, Michael Toker, Nitay Calderon, Zorik Gekhman, Yonatan Bitton, Roi Reichart
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Will a Visual Language Model (VLM)-based bot warn us about slipping if it
detects a wet floor? Recent VLMs have demonstrated impressive capabilities, yet
their ability to infer outcomes and causes remains underexplored. To address
this, we introduce NL-Eye, a benchmark designed to assess VLMs' visual
abductive reasoning skills. NL-Eye adapts the abductive Natural Language
Inference (NLI) task to the visual domain, requiring models to evaluate the
plausibility of hypothesis images based on a premise image and explain their
decisions. NL-Eye consists of 350 carefully curated triplet examples (1,050
images) spanning diverse reasoning categories: physical, functional, logical,
emotional, cultural, and social. The data curation process involved two steps -
writing textual descriptions and generating images using text-to-image models,
both requiring substantial human involvement to ensure high-quality and
challenging scenes. Our experiments show that VLMs struggle significantly on
NL-Eye, often performing at random baseline levels, while humans excel in both
plausibility prediction and explanation quality. This demonstrates a deficiency
in the abductive reasoning capabilities of modern VLMs. NL-Eye represents a
crucial step toward developing VLMs capable of robust multimodal reasoning for
real-world applications, including accident-prevention bots and generated video
verification.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ IndicSentEval: How Effectively do Multilingual <span class="highlight-title">Transformer</span> Models encode
  Linguistic Properties for Indic Languages? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02611v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02611v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Akhilesh Aravapalli, Mounika Marreddy, Subba Reddy Oota, Radhika Mamidi, Manish Gupta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformer-based models have revolutionized the field of natural language
processing. To understand why they perform so well and to assess their
reliability, several studies have focused on questions such as: Which
linguistic properties are encoded by these models, and to what extent? How
robust are these models in encoding linguistic properties when faced with
perturbations in the input text? However, these studies have mainly focused on
BERT and the English language. In this paper, we investigate similar questions
regarding encoding capability and robustness for 8 linguistic properties across
13 different perturbations in 6 Indic languages, using 9 multilingual
Transformer models (7 universal and 2 Indic-specific). To conduct this study,
we introduce a novel multilingual benchmark dataset, IndicSentEval, containing
approximately $\sim$47K sentences. Surprisingly, our probing analysis of
surface, syntactic, and semantic properties reveals that while almost all
multilingual models demonstrate consistent encoding performance for English,
they show mixed results for Indic languages. As expected, Indic-specific
multilingual models capture linguistic properties in Indic languages better
than universal models. Intriguingly, universal models broadly exhibit better
robustness compared to Indic-specific models, particularly under perturbations
such as dropping both nouns and verbs, dropping only verbs, or keeping only
nouns. Overall, this study provides valuable insights into probing and
perturbation-specific strengths and weaknesses of popular multilingual
Transformer-based models for different Indic languages. We make our code and
dataset publicly available [https://tinyurl.com/IndicSentEval}].
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Ethio-Fake: Cutting-Edge Approaches to Combat Fake News in
  Under-Resourced Languages Using Explainable AI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02609v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02609v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mesay Gemeda Yigezu, Melkamu Abay Mersha, Girma Yohannis Bade, Jugal Kalita, Olga Kolesnikova, Alexander Gelbukh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The proliferation of fake news has emerged as a significant threat to the
integrity of information dissemination, particularly on social media platforms.
Misinformation can spread quickly due to the ease of creating and disseminating
content, affecting public opinion and sociopolitical events. Identifying false
information is therefore essential to reducing its negative consequences and
maintaining the reliability of online news sources. Traditional approaches to
fake news detection often rely solely on content-based features, overlooking
the crucial role of social context in shaping the perception and propagation of
news articles. In this paper, we propose a comprehensive approach that
integrates social context-based features with news content features to enhance
the accuracy of fake news detection in under-resourced languages. We perform
several experiments utilizing a variety of methodologies, including traditional
machine learning, neural networks, ensemble learning, and transfer learning.
Assessment of the outcomes of the experiments shows that the ensemble learning
approach has the highest accuracy, achieving a 0.99 F1 score. Additionally,
when compared with monolingual models, the fine-tuned model with the target
language outperformed others, achieving a 0.94 F1 score. We analyze the
functioning of the models, considering the important features that contribute
to model performance, using explainable AI techniques.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Agents' Room: Narrative Generation through Multi-step Collaboration <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02603v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02603v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fantine Huot, Reinald Kim Amplayo, Jennimaria Palomaki, Alice Shoshana Jakobovits, Elizabeth Clark, Mirella Lapata
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Writing compelling fiction is a multifaceted process combining elements such
as crafting a plot, developing interesting characters, and using evocative
language. While large language models (LLMs) show promise for story writing,
they currently rely heavily on intricate prompting, which limits their use. We
propose Agents' Room, a generation framework inspired by narrative theory, that
decomposes narrative writing into subtasks tackled by specialized agents. To
illustrate our method, we introduce Tell Me A Story, a high-quality dataset of
complex writing prompts and human-written stories, and a novel evaluation
framework designed specifically for assessing long narratives. We show that
Agents' Room generates stories that are preferred by expert evaluators over
those produced by baseline systems by leveraging collaboration and
specialization to decompose the complex story writing task into tractable
components. We provide extensive analysis with automated and human-based
metrics of the generated output.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review as a conference paper at ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Implicit Bias Detection and Mitigation in Multi-Agent LLM
  Interactions <span class="chip">EMNLP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02584v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02584v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Angana Borah, Rada Mihalcea
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As Large Language Models (LLMs) continue to evolve, they are increasingly
being employed in numerous studies to simulate societies and execute diverse
social tasks. However, LLMs are susceptible to societal biases due to their
exposure to human-generated data. Given that LLMs are being used to gain
insights into various societal aspects, it is essential to mitigate these
biases. To that end, our study investigates the presence of implicit gender
biases in multi-agent LLM interactions and proposes two strategies to mitigate
these biases. We begin by creating a dataset of scenarios where implicit gender
biases might arise, and subsequently develop a metric to assess the presence of
biases. Our empirical analysis reveals that LLMs generate outputs characterized
by strong implicit bias associations (>= 50\% of the time). Furthermore, these
biases tend to escalate following multi-agent interactions. To mitigate them,
we propose two strategies: self-reflection with in-context examples (ICE); and
supervised fine-tuning. Our research demonstrates that both methods effectively
mitigate implicit biases, with the ensemble of fine-tuning and self-reflection
proving to be the most successful.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP Findings 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Convolutional Variational Autoencoders for Spectrogram Compression in
  Automatic Speech Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02560v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02560v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Olga Yakovenko, Ivan Bondarenko
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For many Automatic Speech Recognition (ASR) tasks audio features as
spectrograms show better results than Mel-frequency Cepstral Coefficients
(MFCC), but in practice they are hard to use due to a complex dimensionality of
a feature space. The following paper presents an alternative approach towards
generating compressed spectrogram representation, based on Convolutional
Variational Autoencoders (VAE). A Convolutional VAE model was trained on a
subsample of the LibriSpeech dataset to reconstruct short fragments of audio
spectrograms (25 ms) from a 13-dimensional embedding. The trained model for a
40-dimensional (300 ms) embedding was used to generate features for corpus of
spoken commands on the GoogleSpeechCommands dataset. Using the generated
features an ASR system was built and compared to the model with MFCC features.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Theory and Practice of Natural Computing 9th International
  Conference, TPNC 2020, Taoyuan, Taiwan, 2020, Proceedings 9</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving Unsupervised Constituency Parsing via Maximizing Semantic
  Information 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02558v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02558v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junjie Chen, Xiangheng He, Yusuke Miyao, Danushka Bollegala
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Unsupervised constituency parsers organize phrases within a sentence into a
tree-shaped syntactic constituent structure that reflects the organization of
sentence semantics. However, the traditional objective of maximizing sentence
log-likelihood (LL) does not explicitly account for the close relationship
between the constituent structure and the semantics, resulting in a weak
correlation between LL values and parsing accuracy. In this paper, we introduce
a novel objective for training unsupervised parsers: maximizing the information
between constituent structures and sentence semantics (SemInfo). We introduce a
bag-of-substrings model to represent the semantics and apply the
probability-weighted information metric to estimate the SemInfo. Additionally,
we develop a Tree Conditional Random Field (TreeCRF)-based model to apply the
SemInfo maximization objective to Probabilistic Context-Free Grammar (PCFG)
induction, the state-of-the-art method for unsupervised constituency parsing.
Experiments demonstrate that SemInfo correlates more strongly with parsing
accuracy than LL. Our algorithm significantly enhances parsing accuracy by an
average of 7.85 points across five PCFG variants and in four languages,
achieving new state-of-the-art results in three of the four languages.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ColaCare: Enhancing Electronic Health Record Modeling through Large
  Language Model-Driven Multi-Agent Collaboration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02551v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02551v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zixiang Wang, Yinghao Zhu, Huiya Zhao, Xiaochen Zheng, Tianlong Wang, Wen Tang, Yasha Wang, Chengwei Pan, Ewen M. Harrison, Junyi Gao, Liantao Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce ColaCare, a framework that enhances Electronic Health Record
(EHR) modeling through multi-agent collaboration driven by Large Language
Models (LLMs). Our approach seamlessly integrates domain-specific expert models
with LLMs to bridge the gap between structured EHR data and text-based
reasoning. Inspired by clinical consultations, ColaCare employs two types of
agents: DoctorAgent and MetaAgent, which collaboratively analyze patient data.
Expert models process and generate predictions from numerical EHR data, while
LLM agents produce reasoning references and decision-making reports within the
collaborative consultation framework. We additionally incorporate the Merck
Manual of Diagnosis and Therapy (MSD) medical guideline within a
retrieval-augmented generation (RAG) module for authoritative evidence support.
Extensive experiments conducted on four distinct EHR datasets demonstrate
ColaCare's superior performance in mortality prediction tasks, underscoring its
potential to revolutionize clinical decision support systems and advance
personalized precision medicine. The code, complete prompt templates, more case
studies, etc. are publicly available at the anonymous link:
https://colacare.netlify.app.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MedVisionLlama: Leveraging <span class="highlight-title">Pre-Train</span>ed Large Language Model Layers to
  Enhance Medical Image Segmentation <span class="chip">WACV</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02458v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02458v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gurucharan Marthi Krishna Kumar, Aman Chadha, Janine Mendola, Amir Shmuel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs), known for their versatility in textual data,
are increasingly being explored for their potential to enhance medical image
segmentation, a crucial task for accurate diagnostic imaging. This study
explores enhancing Vision Transformers (ViTs) for medical image segmentation by
integrating pre-trained LLM transformer blocks. Our approach, which
incorporates a frozen LLM transformer block into the encoder of a ViT-based
model, leads to substantial improvements in segmentation performance across
various medical imaging modalities. We propose a Hybrid Attention Mechanism
that combines global and local feature learning with a Multi-Scale Fusion Block
for aggregating features across different scales. The enhanced model shows
significant performance gains, including an average Dice score increase from
0.74 to 0.79 and improvements in accuracy, precision, and the Jaccard Index.
These results demonstrate the effectiveness of LLM-based transformers in
refining medical image segmentation, highlighting their potential to
significantly boost model accuracy and robustness. The source code and our
implementation are available at: https://bit.ly/3zf2CVs
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to IEEE/CVF Winter Conference on Applications of Computer
  Vision (WACV) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Algorithms For Automatic Accentuation And Transcription Of Russian Texts
  In Speech Recognition Systems <span class="chip">SP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02538v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02538v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Olga Iakovenko, Ivan Bondarenko, Mariya Borovikova, Daniil Vodolazsky
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents an overview of rule-based system for automatic
accentuation and phonemic transcription of Russian texts for speech connected
tasks, such as Automatic Speech Recognition (ASR). Two parts of the developed
system, accentuation and transcription, use different approaches to achieve
correct phonemic representations of input phrases. Accentuation is based on
"Grammatical dictionary of the Russian language" of A.A. Zaliznyak and
wiktionary corpus. To distinguish homographs, the accentuation system also
utilises morphological information of the sentences based on Recurrent Neural
Networks (RNN). Transcription algorithms apply the rules presented in the
monograph of B.M. Lobanov and L.I. Tsirulnik "Computer Synthesis and Voice
Cloning". The rules described in the present paper are implemented in an
open-source module, which can be of use to any scientific study connected to
ASR or Speech To Text (STT) tasks. Automatically marked up text annotations of
the Russian Voxforge database were used as training data for an acoustic model
in CMU Sphinx. The resulting acoustic model was evaluated on cross-validation,
mean Word Accuracy being 71.2%. The developed toolkit is written in the Python
language and is accessible on GitHub for any researcher interested.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Speech and Computer 20th International Conference, SPECOM 2018,
  Leipzig, Germany, Proceedings 20</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Contextual Document Embeddings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02525v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02525v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        John X. Morris, Alexander M. Rush
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dense document embeddings are central to neural retrieval. The dominant
paradigm is to train and construct embeddings by running encoders directly on
individual documents. In this work, we argue that these embeddings, while
effective, are implicitly out-of-context for targeted use cases of retrieval,
and that a contextualized document embedding should take into account both the
document and neighboring documents in context - analogous to contextualized
word embeddings. We propose two complementary methods for contextualized
document embeddings: first, an alternative contrastive learning objective that
explicitly incorporates the document neighbors into the intra-batch contextual
loss; second, a new contextual architecture that explicitly encodes neighbor
document information into the encoded representation. Results show that both
methods achieve better performance than biencoders in several settings, with
differences especially pronounced out-of-domain. We achieve state-of-the-art
results on the MTEB benchmark with no hard negative mining, score distillation,
dataset-specific instructions, intra-GPU example-sharing, or extremely large
batch sizes. Our method can be applied to improve performance on any
contrastive learning dataset and any biencoder.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Methods for Automatic Matrix Language Determination of Code-Switched
  Speech <span class="chip">EMNLP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02521v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02521v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Olga Iakovenko, Thomas Hain
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Code-switching (CS) is the process of speakers interchanging between two or
more languages which in the modern world becomes increasingly common. In order
to better describe CS speech the Matrix Language Frame (MLF) theory introduces
the concept of a Matrix Language, which is the language that provides the
grammatical structure for a CS utterance. In this work the MLF theory was used
to develop systems for Matrix Language Identity (MLID) determination. The MLID
of English/Mandarin and English/Spanish CS text and speech was compared to
acoustic language identity (LID), which is a typical way to identify a language
in monolingual utterances. MLID predictors from audio show higher correlation
with the textual principles than LID in all cases while also outperforming LID
in an MLID recognition task based on F1 macro (60\%) and correlation score
(0.38). This novel approach has identified that non-English languages (Mandarin
and Spanish) are preferred over the English language as the ML contrary to the
monolingual choice of LID.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Can Large Language Models Grasp Legal Theories? Enhance Legal Reasoning
  with Insights from Multi-Agent Collaboration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02507v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02507v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weikang Yuan, Junjie Cao, Zhuoren Jiang, Yangyang Kang, Jun Lin, Kaisong Song, tianqianjin lin, Pengwei Yan, Changlong Sun, Xiaozhong Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) could struggle to fully understand legal
theories and perform complex legal reasoning tasks. In this study, we introduce
a challenging task (confusing charge prediction) to better evaluate LLMs'
understanding of legal theories and reasoning capabilities. We also propose a
novel framework: Multi-Agent framework for improving complex Legal Reasoning
capability (MALR). MALR employs non-parametric learning, encouraging LLMs to
automatically decompose complex legal tasks and mimic human learning process to
extract insights from legal rules, helping LLMs better understand legal
theories and enhance their legal reasoning abilities. Extensive experiments on
multiple real-world datasets demonstrate that the proposed framework
effectively addresses complex reasoning issues in practical scenarios, paving
the way for more reliable applications in the legal domain.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mixed-Session Conversation with Egocentric Memory <span class="chip">EMNLP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02503v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02503v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jihyoung Jang, Taeyoung Kim, Hyounghun Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently introduced dialogue systems have demonstrated high usability.
However, they still fall short of reflecting real-world conversation scenarios.
Current dialogue systems exhibit an inability to replicate the dynamic,
continuous, long-term interactions involving multiple partners. This shortfall
arises because there have been limited efforts to account for both aspects of
real-world dialogues: deeply layered interactions over the long-term dialogue
and widely expanded conversation networks involving multiple participants. As
the effort to incorporate these aspects combined, we introduce Mixed-Session
Conversation, a dialogue system designed to construct conversations with
various partners in a multi-session dialogue setup. We propose a new dataset
called MiSC to implement this system. The dialogue episodes of MiSC consist of
6 consecutive sessions, with four speakers (one main speaker and three
partners) appearing in each episode. Also, we propose a new dialogue model with
a novel memory management mechanism, called Egocentric Memory Enhanced
Mixed-Session Conversation Agent (EMMA). EMMA collects and retains memories
from the main speaker's perspective during conversations with partners,
enabling seamless continuity in subsequent interactions. Extensive human
evaluations validate that the dialogues in MiSC demonstrate a seamless
conversational flow, even when conversation partners change in each session.
EMMA trained with MiSC is also evaluated to maintain high memorability without
contradiction throughout the entire conversation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP Findings 2024 (30 pages); Project website:
  https://mixed-session.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Defining Knowledge: Bridging Epistemology and Large Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02499v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02499v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Constanza Fierro, Ruchira Dhar, Filippos Stamatiou, Nicolas Garneau, Anders Søgaard
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge claims are abundant in the literature on large language models
(LLMs); but can we say that GPT-4 truly "knows" the Earth is round? To address
this question, we review standard definitions of knowledge in epistemology and
we formalize interpretations applicable to LLMs. In doing so, we identify
inconsistencies and gaps in how current NLP research conceptualizes knowledge
with respect to epistemological frameworks. Additionally, we conduct a survey
of 100 professional philosophers and computer scientists to compare their
preferences in knowledge definitions and their views on whether LLMs can really
be said to know. Finally, we suggest evaluation protocols for testing knowledge
in accordance to the most relevant definitions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dynamic Gradient Alignment for Online Data Mixing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02498v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02498v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Simin Fan, David Grangier, Pierre Ablin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The composition of training data mixtures is critical for effectively
training large language models (LLMs), as it directly impacts their performance
on downstream tasks. Our goal is to identify an optimal data mixture to
specialize an LLM for a specific task with access to only a few examples.
Traditional approaches to this problem include ad-hoc reweighting methods,
importance sampling, and gradient alignment techniques. This paper focuses on
gradient alignment and introduces Dynamic Gradient Alignment (DGA), a scalable
online gradient alignment algorithm. DGA dynamically estimates the pre-training
data mixture on which the models' gradients align as well as possible with
those of the model on the specific task. DGA is the first gradient alignment
approach that incurs minimal overhead compared to standard pre-training and
outputs a competitive model, eliminating the need for retraining the model.
Experimentally, we demonstrate significant improvements over importance
sampling in two key scenarios: (i) when the pre-training set is small and
importance sampling overfits due to limited data; and (ii) when there is
insufficient specialized data, trapping importance sampling on narrow pockets
of data. Our findings underscore the effectiveness of gradient alignment
methods in optimizing training data mixtures, particularly in data-constrained
environments, and offer a practical solution for enhancing LLM performance on
specific tasks with limited data availability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DTVLT: A Multi-modal Diverse Text Benchmark for Visual Language Tracking
  Based on LLM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02492v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02492v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuchen Li, Shiyu Hu, Xiaokun Feng, Dailing Zhang, Meiqi Wu, Jing Zhang, Kaiqi Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visual language tracking (VLT) has emerged as a cutting-edge research area,
harnessing linguistic data to enhance algorithms with multi-modal inputs and
broadening the scope of traditional single object tracking (SOT) to encompass
video understanding applications. Despite this, most VLT benchmarks still
depend on succinct, human-annotated text descriptions for each video. These
descriptions often fall short in capturing the nuances of video content
dynamics and lack stylistic variety in language, constrained by their uniform
level of detail and a fixed annotation frequency. As a result, algorithms tend
to default to a "memorize the answer" strategy, diverging from the core
objective of achieving a deeper understanding of video content. Fortunately,
the emergence of large language models (LLMs) has enabled the generation of
diverse text. This work utilizes LLMs to generate varied semantic annotations
(in terms of text lengths and granularities) for representative SOT benchmarks,
thereby establishing a novel multi-modal benchmark. Specifically, we (1)
propose a new visual language tracking benchmark with diverse texts, named
DTVLT, based on five prominent VLT and SOT benchmarks, including three
sub-tasks: short-term tracking, long-term tracking, and global instance
tracking. (2) We offer four granularity texts in our benchmark, considering the
extent and density of semantic information. We expect this multi-granular
generation strategy to foster a favorable environment for VLT and video
understanding research. (3) We conduct comprehensive experimental analyses on
DTVLT, evaluating the impact of diverse text on tracking performance and hope
the identified performance bottlenecks of existing algorithms can support
further research in VLT and video understanding. The proposed benchmark,
experimental results and toolkit will be released gradually on
http://videocube.aitestunion.com/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint, Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Response Tuning: Aligning Large Language Models without Instruction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02465v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02465v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seokhyun An, Hyounghun Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Instruction tuning-supervised fine-tuning using instruction-response pairs-is
a foundational step in transitioning pre-trained Large Language Models (LLMs)
into helpful and safe chat assistants. Our hypothesis is that establishing an
adequate output space can enable such a transition given the capabilities
inherent in pre-trained LLMs. To verify this, we propose Response Tuning (RT),
which eliminates the instruction-conditioning step in instruction tuning and
solely focuses on response space supervision. Our experiments demonstrate that
RT models, trained only using responses, can effectively respond to a wide
range of instructions and exhibit helpfulness comparable to that of their
instruction-tuned counterparts. Furthermore, we observe that controlling the
training response distribution can significantly improve their user preference
or elicit target behaviors such as refusing assistance for unsafe queries. Our
findings illuminate the role of establishing an adequate output space in
alignment, highlighting the potential of the extensive inherent capabilities of
pre-trained LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>34 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Embedded Topic Models Enhanced by Wikification <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02441v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02441v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Takashi Shibuya, Takehito Utsuro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Topic modeling analyzes a collection of documents to learn meaningful
patterns of words. However, previous topic models consider only the spelling of
words and do not take into consideration the homography of words. In this
study, we incorporate the Wikipedia knowledge into a neural topic model to make
it aware of named entities. We evaluate our method on two datasets, 1) news
articles of \textit{New York Times} and 2) the AIDA-CoNLL dataset. Our
experiments show that our method improves the performance of neural topic
models in generalizability. Moreover, we analyze frequent terms in each topic
and the temporal dependencies between topics to demonstrate that our
entity-aware topic models can capture the time-series development of topics
well.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024 Workshop NLP for Wikipedia</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Better Call SAUL: Fluent and Consistent Language Model Editing with
  Generation Regularization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02433v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02433v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingyang Wang, Lukas Lange, Heike Adel, Jannik Strötgen, Hinrich Schütze
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To ensure large language models contain up-to-date knowledge, they need to be
updated regularly. However, model editing is challenging as it might also
affect knowledge that is unrelated to the new data. State-of-the-art methods
identify parameters associated with specific knowledge and then modify them via
direct weight updates. However, these locate-and-edit methods suffer from heavy
computational overhead and lack theoretical validation. In contrast, directly
fine-tuning the model on requested edits affects the model's behavior on
unrelated knowledge, and significantly damages the model's generation fluency
and consistency. To address these challenges, we propose SAUL, a streamlined
model editing method that uses sentence concatenation with augmented random
facts for generation regularization. Evaluations on three model editing
benchmarks show that SAUL is a practical and reliable solution for model
editing outperforming state-of-the-art methods while maintaining generation
quality and reducing computational overhead.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ IoT-LLM: Enhancing Real-World IoT Task Reasoning with Large Language
  Models <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02429v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02429v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tuo An, Yunjiao Zhou, Han Zou, Jianfei Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have demonstrated remarkable capabilities across
textual and visual domains but often generate outputs that violate physical
laws, revealing a gap in their understanding of the physical world. Inspired by
human cognition, where perception is fundamental to reasoning, we explore
augmenting LLMs with enhanced perception abilities using Internet of Things
(IoT) sensor data and pertinent knowledge for IoT task reasoning in the
physical world. In this work, we systematically study LLMs capability to
address real-world IoT tasks by augmenting their perception and knowledge base,
and then propose a unified framework, IoT-LLM, to enhance such capability. In
IoT-LLM, we customize three steps for LLMs: preprocessing IoT data into formats
amenable to LLMs, activating their commonsense knowledge through
chain-of-thought prompting and specialized role definitions, and expanding
their understanding via IoT-oriented retrieval-augmented generation based on
in-context learning. To evaluate the performance, We design a new benchmark
with five real-world IoT tasks with different data types and reasoning
difficulties and provide the benchmarking results on six open-source and
close-source LLMs. Experimental results demonstrate the limitations of existing
LLMs with naive textual inputs that cannot perform these tasks effectively. We
show that IoT-LLM significantly enhances the performance of IoT tasks reasoning
of LLM, such as GPT-4, achieving an average improvement of 65% across various
tasks against previous methods. The results also showcase LLMs ability to
comprehend IoT data and the physical law behind data by providing a reasoning
process. Limitations of our work are claimed to inspire future research in this
new era.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages, 10 figures, submitted to ICLR 2025 Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Collective Critics for Creative Story Generation <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02428v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02428v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minwook Bae, Hyounghun Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating a long story of several thousand words with narrative coherence
using Large Language Models (LLMs) has been a challenging task. Previous
research has addressed this challenge by proposing different frameworks that
create a story plan and generate a long story based on that plan. However,
these frameworks have been mainly focusing on maintaining narrative coherence
in stories, often overlooking creativity in story planning and the
expressiveness of the stories generated from those plans, which are desirable
properties to captivate readers' interest. In this paper, we propose Collective
Critics for Creative Story Generation framework (CritiCS), which is composed of
plan refining stage (CrPlan) and story generation stage (CrText), to integrate
a collective revision mechanism that promotes those properties into long-form
story generation process. Specifically, in each stage, a group of LLM critics
and one leader collaborate to incrementally refine drafts of plan and story
throughout multiple rounds. Extensive human evaluation shows that the CritiCS
can significantly enhance story creativity and reader engagement, while also
maintaining narrative coherence. Furthermore, the design of the framework
allows active participation from human writers in any role within the critique
process, enabling interactive human-machine collaboration in story writing.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 (36 pages)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning the Latent Rules of a Game from Data: A Chess Story 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02426v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02426v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ben Fauber
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We demonstrate that small pretrained foundational generative language models
with millions of parameters can learn the latent rules of a process from data
associated with the process. Inspired by Stefan Zweig's novella
"Schachnovelle," also known as "The Royal Game" in English, we show that 28M
and 125M parameter pretrained foundational small language models (SLMs) can be
instruction fine-tuned with 1,000-to-1,000,000 examples to learn the rules of
chess, propose legal moves, and accurately solve chess problems. We also
explore the impact of successive language model fine-tuning epochs on improved
outcomes and demonstrate reductions in model hallucinations by increasing the
number of instruction fine-tuning examples.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLM-Pilot: Characterize and Optimize Performance of your LLM Inference
  Services <span class="chip">SC '24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02425v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02425v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Małgorzata Łazuka, Andreea Anghel, Thomas Parnell
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As Large Language Models (LLMs) are rapidly growing in popularity, LLM
inference services must be able to serve requests from thousands of users while
satisfying performance requirements. The performance of an LLM inference
service is largely determined by the hardware onto which it is deployed, but
understanding of which hardware will deliver on performance requirements
remains challenging. In this work we present LLM-Pilot - a first-of-its-kind
system for characterizing and predicting performance of LLM inference services.
LLM-Pilot performs benchmarking of LLM inference services, under a realistic
workload, across a variety of GPUs, and optimizes the service configuration for
each considered GPU to maximize performance. Finally, using this
characterization data, LLM-Pilot learns a predictive model, which can be used
to recommend the most cost-effective hardware for a previously unseen LLM.
Compared to existing methods, LLM-Pilot can deliver on performance requirements
33% more frequently, whilst reducing costs by 60% on average.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the International Conference for High Performance
  Computing, Networking, Storage and Analysis (SC '24)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Menak<span class="highlight-title">BERT</span> -- Hebrew Diacriticizer <span class="chip">SC</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02417v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02417v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ido Cohen, Jacob Gidron, Idan Pinto
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diacritical marks in the Hebrew language give words their vocalized form. The
task of adding diacritical marks to plain Hebrew text is still dominated by a
system that relies heavily on human-curated resources. Recent models trained on
diacritized Hebrew texts still present a gap in performance. We use a recently
developed char-based PLM to narrowly bridge this gap. Presenting MenakBERT, a
character level transformer pretrained on Hebrew text and fine-tuned to produce
diacritical marks for Hebrew sentences. We continue to show how finetuning a
model for diacritizing transfers to a task such as part of speech tagging.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published at ISCOL2022 as a poster</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Parameter Competition Balancing for Model Merging <span class="chip">NeurIPS2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02396v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02396v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guodong Du, Junlin Lee, Jing Li, Runhua Jiang, Yifei Guo, Shuyang Yu, Hanting Liu, Sim Kuan Goh, Ho-Kin Tang, Daojing He, Min Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While fine-tuning pretrained models has become common practice, these models
often underperform outside their specific domains. Recently developed model
merging techniques enable the direct integration of multiple models, each
fine-tuned for distinct tasks, into a single model. This strategy promotes
multitasking capabilities without requiring retraining on the original
datasets. However, existing methods fall short in addressing potential
conflicts and complex correlations between tasks, especially in parameter-level
adjustments, posing a challenge in effectively balancing parameter competition
across various tasks. This paper introduces an innovative technique named
PCB-Merging (Parameter Competition Balancing), a lightweight and training-free
technique that adjusts the coefficients of each parameter for effective model
merging. PCB-Merging employs intra-balancing to gauge parameter significance
within individual tasks and inter-balancing to assess parameter similarities
across different tasks. Parameters with low importance scores are dropped, and
the remaining ones are rescaled to form the final merged model. We assessed our
approach in diverse merging scenarios, including cross-task, cross-domain, and
cross-training configurations, as well as out-of-domain generalization. The
experimental results reveal that our approach achieves substantial performance
enhancements across multiple modalities, domains, model sizes, number of tasks,
fine-tuning forms, and large language models, outperforming existing model
merging methods. The code is publicly available at:
\url{https://github.com/duguodong7/pcb-merging}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by NeurIPS2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MetaMetrics: Calibrating Metrics For Generation Tasks Using Human
  Preferences 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02381v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02381v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Genta Indra Winata, David Anugraha, Lucky Susanto, Garry Kuwanto, Derry Tanti Wijaya
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding the quality of a performance evaluation metric is crucial for
ensuring that model outputs align with human preferences. However, it remains
unclear how well each metric captures the diverse aspects of these preferences,
as metrics often excel in one particular area but not across all dimensions. To
address this, it is essential to systematically calibrate metrics to specific
aspects of human preference, catering to the unique characteristics of each
aspect. We introduce MetaMetrics, a calibrated meta-metric designed to evaluate
generation tasks across different modalities in a supervised manner.
MetaMetrics optimizes the combination of existing metrics to enhance their
alignment with human preferences. Our metric demonstrates flexibility and
effectiveness in both language and vision downstream tasks, showing significant
benefits across various multilingual and multi-domain scenarios. MetaMetrics
aligns closely with human preferences and is highly extendable and easily
integrable into any application. This makes MetaMetrics a powerful tool for
improving the evaluation of generation tasks, ensuring that metrics are more
representative of human judgment across diverse contexts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Comprehensive Detection of Chinese Harmful Memes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02378v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02378v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junyu Lu, Bo Xu, Xiaokun Zhang, Hongbo Wang, Haohao Zhu, Dongyu Zhang, Liang Yang, Hongfei Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper has been accepted in the NeurIPS 2024 D & B Track. Harmful memes
have proliferated on the Chinese Internet, while research on detecting Chinese
harmful memes significantly lags behind due to the absence of reliable datasets
and effective detectors. To this end, we focus on the comprehensive detection
of Chinese harmful memes. We construct ToxiCN MM, the first Chinese harmful
meme dataset, which consists of 12,000 samples with fine-grained annotations
for various meme types. Additionally, we propose a baseline detector,
Multimodal Knowledge Enhancement (MKE), incorporating contextual information of
meme content generated by the LLM to enhance the understanding of Chinese
memes. During the evaluation phase, we conduct extensive quantitative
experiments and qualitative analyses on multiple baselines, including LLMs and
our MKE. The experimental results indicate that detecting Chinese harmful memes
is challenging for existing models while demonstrating the effectiveness of
MKE. The resources for this paper are available at
https://github.com/DUT-lujunyu/ToxiCN_MM.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ From Concrete to Abstract: A Multimodal Generative Approach to Abstract
  Concept Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02365v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02365v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haodong Xie, Rahul Singh Maharjan, Federico Tavella, Angelo Cangelosi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding and manipulating concrete and abstract concepts is fundamental
to human intelligence. Yet, they remain challenging for artificial agents. This
paper introduces a multimodal generative approach to high order abstract
concept learning, which integrates visual and categorical linguistic
information from concrete ones. Our model initially grounds subordinate level
concrete concepts, combines them to form basic level concepts, and finally
abstracts to superordinate level concepts via the grounding of basic-level
concepts. We evaluate the model language learning ability through
language-to-visual and visual-to-language tests with high order abstract
concepts. Experimental results demonstrate the proficiency of the model in both
language understanding and language naming tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AlphaEdit: Null-Space Constrained Knowledge Editing for Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02355v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02355v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junfeng Fang, Houcheng Jiang, Kun Wang, Yunshan Ma, Xiang Wang, Xiangnan He, Tat-seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) often exhibit hallucinations due to incorrect or
outdated knowledge. Hence, model editing methods have emerged to enable
targeted knowledge updates. To achieve this, a prevailing paradigm is the
locating-then-editing approach, which first locates influential parameters and
then edits them by introducing a perturbation. While effective, current studies
have demonstrated that this perturbation inevitably disrupt the originally
preserved knowledge within LLMs, especially in sequential editing scenarios. To
address this, we introduce AlphaEdit, a novel solution that projects
perturbation onto the null space of the preserved knowledge before applying it
to the parameters. We theoretically prove that this projection ensures the
output of post-edited LLMs remains unchanged when queried about the preserved
knowledge, thereby mitigating the issue of disruption. Extensive experiments on
various LLMs, including LLaMA3, GPT2-XL, and GPT-J, show that AlphaEdit boosts
the performance of most locating-then-editing methods by an average of 36.4%
with a single line of additional code for projection solely. Our code is
available at: https://github.com/jianghoucheng/AlphaEdit.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Listening to the Wise Few: Select-and-Copy Attention Heads for
  Multiple-Choice QA 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02343v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02343v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eduard Tulchinskii, Laida Kushnareva, Kristian Kuznetsov, Anastasia Voznyuk, Andrei Andriiainen, Irina Piontkovskaya, Evgeny Burnaev, Serguei Barannikov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A standard way to evaluate the abilities of LLM involves presenting a
multiple-choice question and selecting the option with the highest logit as the
model's predicted answer. However, such a format for evaluating LLMs has
limitations, since even if the model knows the correct answer, it may struggle
to select the corresponding letter simply due to difficulties in following this
rigid format. To address this, we introduce new scores that better capture and
reveal model's underlying knowledge: the Query-Key Score (QK-score), derived
from the interaction between query and key representations in attention heads,
and the Attention Score, based on attention weights. These scores are extracted
from specific \textit{select-and-copy} heads, which show consistent performance
across popular Multi-Choice Question Answering (MCQA) datasets. Based on these
scores, our method improves knowledge extraction, yielding up to 16\% gain for
LLaMA2-7B and up to 10\% for larger models on popular MCQA benchmarks. At the
same time, the accuracy on a simple synthetic dataset, where the model
explicitly knows the right answer, increases by almost 60\%, achieving nearly
perfect accuracy, therefore demonstrating the method's efficiency in mitigating
MCQA format limitations. To support our claims, we conduct experiments on
models ranging from 7 billion to 70 billion parameters in both zero- and
few-shot setups.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ How Much Can RAG Help the Reasoning of LLM? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02338v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02338v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingyu Liu, Jiaen Lin, Yong Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) has gained significant popularity in
modern Large Language Models (LLMs) due to its effectiveness in introducing new
knowledge and reducing hallucinations. However, the deep understanding of RAG
remains limited, how does RAG help the reasoning process and can RAG help
improve the reasoning capability remains question. While external documents are
typically considered as a method to incorporate domain-specific information,
they also contain intermediate reasoning results related to the query, this
suggests that documents could enhance the reasoning capability of LLMs, which
has not been previously explored. In this paper, we investigate this issue in
depth and find that while RAG can assist with reasoning, the help is limited.
If we conceptualize the reasoning process as a tree with fixed depth, then RAG
struggles to assist LLMs in performing deeper reasoning. Additionally, the
information in the documents requires preprocessing to filter out noise. We
demonstrate that this preprocessing is difficult to achieve simply fine-tuning
of the LLM, it often necessitates numerous additional transformer layers to
solve the problem. To simplify the problem, we propose DPrompt tuning, which
effectively resolves the issue within just limited transformer layers, leading
to improved performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Llama SLayer 8B: Shallow Layers Hold the Key to Knowledge Injection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02330v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02330v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianxiang Chen, Zhentao Tan, Tao Gong, Yue Wu, Qi Chu, Bin Liu, Jieping Ye, Nenghai Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As a manner to augment pre-trained large language models (LLM), knowledge
injection is critical to develop vertical domain large models and has been
widely studied. Although most current approaches, including parameter-efficient
fine-tuning (PEFT) and block expansion methods, uniformly apply knowledge
across all LLM layers, it raises the question: are all layers equally crucial
for knowledge injection? We begin by evaluating the importance of each layer in
finding the optimal layer range for knowledge injection. Intuitively, the more
important layers should play a more critical role in knowledge injection and
deserve a denser injection. We observe performance dips in question-answering
benchmarks after the removal or expansion of the shallow layers, and the
degradation shrinks as the layer gets deeper, indicating that the shallow
layers hold the key to knowledge injection. This insight leads us to propose
the S strategy, a post-pretraining strategy of selectively enhancing shallow
layers while pruning the less effective deep ones. Based on this strategy, we
introduce Llama Slayer-8B and Llama Slayer-8B-Instruct. We experimented on the
corpus of code $\&$ math and demonstrated the effectiveness of our strategy.
Further experiments across different LLM, Mistral-7B, and a legal corpus
confirmed the general applicability of the approach, underscoring its
wide-ranging efficacy. Our code is available at:
\https://github.com/txchen-USTC/Llama-Slayer
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Post-edits Are Preferences Too 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02320v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02320v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nathaniel Berger, Stefan Riezler, Miriam Exel, Matthias Huck
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Preference Optimization (PO) techniques are currently one of the state of the
art techniques for fine-tuning large language models (LLMs) on pairwise
preference feedback from human annotators. However, in machine translation,
this sort of feedback can be difficult to solicit. Additionally, Kreutzer et
al. (2018) have shown that, for machine translation, pairwise preferences are
less reliable than other forms of human feedback, such as 5-point ratings.
  We examine post-edits to see if they can be a source of reliable human
preferences by construction. In PO, a human annotator is shown sequences $s_1$
and $s_2$ and asked for a preference judgment, %$s_1 > s_2$; while for
post-editing, editors \emph{create} $s_1$ and know that it should be better
than $s_2$. We attempt to use these implicit preferences for PO and show that
it helps the model move towards post-edit-like hypotheses and away from machine
translation-like hypotheses. Furthermore, we show that best results are
obtained by pre-training the model with supervised fine-tuning (SFT) on
post-edits in order to promote post-edit-like hypotheses to the top output
ranks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear at the Ninth Conference on Machine Translation (WMT24)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Traffic Light or Light Traffic? Investigating Phrasal Semantics in Large
  Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02308v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02308v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Meng, Ye Liu, Lifu Tu, Daqing He, Yingbo Zhou, Semih Yavuz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Phrases are fundamental linguistic units through which humans convey
semantics. This study critically examines the capacity of API-based large
language models (LLMs) to comprehend phrase semantics, utilizing three
human-annotated datasets. We assess the performance of LLMs in executing phrase
semantic reasoning tasks guided by natural language instructions and explore
the impact of common prompting techniques, including few-shot demonstrations
and Chain-of-Thought reasoning. Our findings reveal that LLMs greatly
outperform traditional embedding methods across the datasets; however, they do
not show a significant advantage over fine-tuned methods. The effectiveness of
advanced prompting strategies shows variability. We conduct detailed error
analyses to interpret the limitations faced by LLMs in comprehending phrase
semantics. Code and data can be found at
https://github.com/memray/llm_phrase_semantics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Jailbreak Antidote: Runtime Safety-Utility Balance via Sparse
  Representation Adjustment in Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02298v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02298v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guobin Shen, Dongcheng Zhao, Yiting Dong, Xiang He, Yi Zeng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As large language models (LLMs) become integral to various applications,
ensuring both their safety and utility is paramount. Jailbreak attacks, which
manipulate LLMs into generating harmful content, pose significant challenges to
this balance. Existing defenses, such as prompt engineering and safety
fine-tuning, often introduce computational overhead, increase inference
latency, and lack runtime flexibility. Moreover, overly restrictive safety
measures can degrade model utility by causing refusals of benign queries. In
this paper, we introduce Jailbreak Antidote, a method that enables real-time
adjustment of LLM safety preferences by manipulating a sparse subset of the
model's internal states during inference. By shifting the model's hidden
representations along a safety direction with varying strengths, we achieve
flexible control over the safety-utility balance without additional token
overhead or inference delays. Our analysis reveals that safety-related
information in LLMs is sparsely distributed; adjusting approximately 5% of the
internal state is as effective as modifying the entire state. Extensive
experiments on nine LLMs (ranging from 2 billion to 72 billion parameters),
evaluated against ten jailbreak attack methods and compared with six defense
strategies, validate the effectiveness and efficiency of our approach. By
directly manipulating internal states during reasoning, Jailbreak Antidote
offers a lightweight, scalable solution that enhances LLM safety while
preserving utility, opening new possibilities for real-time safety mechanisms
in widely-deployed AI systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Make Compound Sentences Simple to Analyze: Learning to Split Sentences
  for Aspect-based Sentiment Analysis <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02297v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02297v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yongsik Seo, Sungwon Song, Ryang Heo, Jieyong Kim, Dongha Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the domain of Aspect-Based Sentiment Analysis (ABSA), generative methods
have shown promising results and achieved substantial advancements. However,
despite these advancements, the tasks of extracting sentiment quadruplets,
which capture the nuanced sentiment expressions within a sentence, remain
significant challenges. In particular, compound sentences can potentially
contain multiple quadruplets, making the extraction task increasingly difficult
as sentence complexity grows. To address this issue, we are focusing on
simplifying sentence structures to facilitate the easier recognition of these
elements and crafting a model that integrates seamlessly with various ABSA
tasks. In this paper, we propose Aspect Term Oriented Sentence Splitter
(ATOSS), which simplifies compound sentence into simpler and clearer forms,
thereby clarifying their structure and intent. As a plug-and-play module, this
approach retains the parameters of the ABSA model while making it easier to
identify essential intent within input sentences. Extensive experimental
results show that utilizing ATOSS outperforms existing methods in both ASQP and
ACOS tasks, which are the primary tasks for extracting sentiment quadruplets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024 (Findings, long paper)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Language Models are Graph Learners 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02296v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02296v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhe Xu, Kaveh Hassani, Si Zhang, Hanqing Zeng, Michihiro Yasunaga, Limei Wang, Dongqi Fu, Ning Yao, Bo Long, Hanghang Tong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language Models (LMs) are increasingly challenging the dominance of
domain-specific models, including Graph Neural Networks (GNNs) and Graph
Transformers (GTs), in graph learning tasks. Following this trend, we propose a
novel approach that empowers off-the-shelf LMs to achieve performance
comparable to state-of-the-art GNNs on node classification tasks, without
requiring any architectural modification. By preserving the LM's original
architecture, our approach retains a key benefit of LM instruction tuning: the
ability to jointly train on diverse datasets, fostering greater flexibility and
efficiency. To achieve this, we introduce two key augmentation strategies: (1)
Enriching LMs' input using topological and semantic retrieval methods, which
provide richer contextual information, and (2) guiding the LMs' classification
process through a lightweight GNN classifier that effectively prunes class
candidates. Our experiments on real-world datasets show that backbone Flan-T5
models equipped with these augmentation strategies outperform state-of-the-art
text-output node classifiers and are comparable to top-performing vector-output
node classifiers. By bridging the gap between specialized task-specific node
classifiers and general LMs, this work paves the way for more versatile and
widely applicable graph learning models. We will open-source the code upon
publication.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient Second-Order Neural Network Optimization via Adaptive Trust
  Region Methods 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02293v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02293v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        James Vo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Second-order optimization methods offer notable advantages in training deep
neural networks by utilizing curvature information to achieve faster
convergence. However, traditional second-order techniques are computationally
prohibitive, primarily due to the large matrix inversions and high memory
demands they require. While adaptive trust-region methods have been developed
to mitigate these issues, their performance is often hindered by conservative
estimates of key parameters, such as the Lipschitz constant of the Hessian,
resulting in suboptimal outcomes. In this paper, we introduce
SecondOrderAdaptiveAdam (SOAA), a novel optimization algorithm designed to
overcome these limitations. SOAA approximates the Fisher information matrix
using a diagonal representation, reducing computational complexity from
\(O(n^{2})\) to \(O(n)\), thereby making it suitable for large-scale deep
learning models, including large language models (LLMs). Additionally, the
algorithm integrates an adaptive trust-region mechanism that dynamically
adjusts the trust region size based on observed loss reduction, ensuring both
robust convergence and computational efficiency. We empirically demonstrate
that SOAA achieves faster and more stable convergence compared to first-order
optimizers, such as Adam, under similar computational constraints. However, the
diagonal approximation of the Fisher information matrix may be less effective
in capturing higher-order interactions between gradients, suggesting potential
areas for further refinement and future research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Correlation and Navigation in the Vocabulary Key Representation Space of
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02284v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02284v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Letian Peng, Chenyang An, Jingbo Shang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language model (LM) decoding is based on the next-token prediction (NTP)
probability distribution. For neural LMs (e.g., Transformer-based), NTP
distribution is essentially a softmax-regularized dot product between an
encoded input context (query) and fixed vocabulary representations (keys). In
this paper, we study the effect of the key distribution on the NTP
distribution, with a focus on whether the similarity between keys will trigger
spurious correlations in NTP. Through knowledge-probing tasks, we show that in
the NTP distribution, the few top-ranked tokens are typically accurate.
However, the middle-ranked prediction is highly biased towards the tokens that
are distributionally (not necessarily semantically) similar to these top ones.
For instance, if "P" is predicted as the top-1 token, "A"-"Z" will all be
ranked high in NTP, no matter whether they can lead to correct decoding
results. This hurts the sampling diversity and makes the sampling of correct,
long-tail results hopeless and noisy. We attempt to alleviate this issue via a
novel in-context method that iteratively pushes the query representation away
from explored regions. Specifically, we include the explored decoding results
in the context and prompt the LM to generate something else, which encourages
the LM to produce a query representation that has small dot products with
explored keys. Experiments on knowledge-probing tasks show that our method
leads to efficient navigation away from explored keys to correct new keys. We
further extend our method to open-ended and chain-of-thought (for reasoning)
generation. Experiment results show that ICN contributes to better generation
diversity and improved self-consistency voting performance. Finally, we discuss
potential training issues caused by the fixed key space together with the
challenges and possible ways to address them in future research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Morphological evaluation of subwords vocabulary used by BETO language
  model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02283v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02283v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Óscar García-Sierra, Ana Fernández-Pampillón Cesteros, Miguel Ortega-Martín
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Subword tokenization algorithms used by Large Language Models are
significantly more efficient and can independently build the necessary
vocabulary of words and subwords without human intervention. However, those
subwords do not always align with real morphemes, potentially impacting the
models' performance, though it remains uncertain when this might occur. In
previous research, we proposed a method to assess the morphological quality of
vocabularies, focusing on the overlap between these vocabularies and the
morphemes of a given language. Our evaluation method was built on three quality
measures, relevance, cohesion, and morphological accuracy, and a procedure for
their assessment. By applying this method to vocabularies created by three
subword tokenization algorithms, BPE, Wordpiece, and Unigram, we concluded that
these vocabularies generally exhibit very low morphological quality. In this
article, we apply this evaluation to the tokenizer of BETO, a BERT language
model trained on large Spanish corpora. This evaluation, along with our
previous results, helped us conclude that its vocabulary has a low
morphological quality, and we also found that training the tokenizer in a
larger corpus does not improve the morphological quality of the generated
vocabulary. Additionally, this evaluation helps clarify the algorithm used by
the tokenizer, that is, Wordpiece, given the inconsistencies between the
authors' claims and the model's configuration.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>in Spanish language</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Annotation Guidelines for Corpus Novelties: Part 1 -- Named Entity
  Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02281v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02281v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arthur Amalvy, Vincent Labatut
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Novelties corpus is a collection of novels (and parts of novels)
annotated for Named Entity Recognition (NER) among other tasks. This document
describes the guidelines applied during its annotation. It contains the
instructions used by the annotators, as well as a number of examples retrieved
from the annotated novels, and illustrating expressions that should be marked
as entities as well as expressions that should not.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Which questions should I answer? Salience Prediction of Inquisitive
  Questions <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.10917v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.10917v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yating Wu, Ritika Mangla, Alexandros G. Dimakis, Greg Durrett, Junyi Jessy Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Inquisitive questions -- open-ended, curiosity-driven questions people ask as
they read -- are an integral part of discourse processing (Kehler and Rohde,
2017; Onea, 2016) and comprehension (Prince, 2004). Recent work in NLP has
taken advantage of question generation capabilities of LLMs to enhance a wide
range of applications. But the space of inquisitive questions is vast: many
questions can be evoked from a given context. So which of those should be
prioritized to find answers? Linguistic theories, unfortunately, have not yet
provided an answer to this question. This paper presents QSALIENCE, a salience
predictor of inquisitive questions. QSALIENCE is instruction-tuned over our
dataset of linguist-annotated salience scores of 1,766 (context, question)
pairs. A question scores high on salience if answering it would greatly enhance
the understanding of the text (Van Rooy, 2003). We show that highly salient
questions are empirically more likely to be answered in the same article,
bridging potential questions (Onea, 2016) with Questions Under Discussion
(Roberts, 2012). We further validate our findings by showing that answering
salient questions is an indicator of summarization quality in news.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Camera Ready for EMNLP 2024 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LML-DAP: Language Model Learning a <span class="highlight-title">Dataset</span> for Data-Augmented Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18957v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18957v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Praneeth Vadlapati
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Classification tasks are typically handled using Machine Learning (ML)
models, which lack a balance between accuracy and interpretability. This paper
introduces a new approach to using Large Language Models (LLMs) for
classification tasks in an explainable way. Unlike ML models that rely heavily
on data cleaning and feature engineering, this method streamlines the process
using LLMs. This paper proposes a new concept called "Language Model Learning
(LML)" powered by a new method called "Data-Augmented Prediction (DAP)". The
classification is performed by LLMs using a method similar to humans manually
exploring and understanding the data and deciding classifications using data as
a reference. In the LML process, a dataset is summarized and evaluated to
determine the features that lead to the classification of each label the most.
In the process of DAP, the system uses the data summary and a row of the
testing dataset to automatically generate a query, which is used to retrieve
relevant rows from the dataset. A classification is generated by the LLM using
data summary and relevant rows, ensuring satisfactory accuracy even with
complex data using context-aware decision-making. LML and DAP unlock the
possibilities of new applications. The proposed method uses the words "Act as
an Explainable Machine Learning Model" in the prompt to enhance the
interpretability of the predictions by allowing users to review the logic
behind each prediction. In some test cases, the system scored an accuracy above
90%, proving the effectiveness of the system and its potential to outperform
conventional ML models in various scenarios. The code is available at
https://github.com/Pro-GenAI/LML-DAP
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Updated title, abstract, and images</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tokenization Falling Short: The Curse of Tokenization <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11687v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11687v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yekun Chai, Yewei Fang, Qiwei Peng, Xuhong Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language models typically tokenize raw text into sequences of subword
identifiers from a predefined vocabulary, a process inherently sensitive to
typographical errors, length variations, and largely oblivious to the internal
structure of tokens--issues we term the curse of tokenization. In this study,
we delve into these drawbacks and demonstrate that large language models (LLMs)
remain susceptible to these problems. This study systematically investigates
these challenges and their impact on LLMs through three critical research
questions: (1) complex problem solving, (2) token structure probing, and (3)
resilience to typographical variation. Our findings reveal that scaling model
parameters can mitigate the issue of tokenization; however, LLMs still suffer
from biases induced by typos and other text format variations. Our experiments
show that subword regularization such as BPE-dropout can mitigate this issue.
We release our evaluation code and data at https://github.com/FloatAI/TKEval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On Training Data Influence of <span class="highlight-title">GPT</span> Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.07840v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.07840v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yekun Chai, Qingyi Liu, Shuohuan Wang, Yu Sun, Qiwei Peng, Hua Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Amidst the rapid advancements in generative language models, the
investigation of how training data shapes the performance of GPT models is
still emerging. This paper presents GPTfluence, a novel approach that leverages
a featurized simulation to assess the impact of training examples on the
training dynamics of GPT models. Our approach not only traces the influence of
individual training instances on performance trajectories, such as loss and
other key metrics, on targeted test points but also enables a comprehensive
comparison with existing methods across various training scenarios in GPT
models, ranging from 14 million to 2.8 billion parameters, across a range of
downstream tasks. Contrary to earlier methods that struggle with generalization
to new data, GPTfluence introduces a parameterized simulation of training
dynamics, demonstrating robust generalization capabilities to unseen training
data. This adaptability is evident across both fine-tuning and
instruction-tuning scenarios, spanning tasks in natural language understanding
and generation. We make our code and data publicly available at
https://github.com/ernie-research/gptfluence.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Pharmacy<span class="highlight-title">GPT</span>: The AI Pharmacist 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2307.10432v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2307.10432v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhengliang Liu, Zihao Wu, Mengxuan Hu, Bokai Zhao, Lin Zhao, Tianyi Zhang, Haixing Dai, Xianyan Chen, Ye Shen, Sheng Li, Quanzheng Li, Xiang Li, Brian Murray, Tianming Liu, Andrea Sikora
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this study, we introduce PharmacyGPT, a novel framework to assess the
capabilities of large language models (LLMs) such as ChatGPT and GPT-4 in
emulating the role of clinical pharmacists. Our methodology encompasses the
utilization of LLMs to generate comprehensible patient clusters, formulate
medication plans, and forecast patient outcomes. We conduct our investigation
using real data acquired from the intensive care unit (ICU) at the University
of North Carolina Chapel Hill (UNC) Hospital. Our analysis offers valuable
insights into the potential applications and limitations of LLMs in the field
of clinical pharmacy, with implications for both patient care and the
development of future AI-driven healthcare solutions. By evaluating the
performance of PharmacyGPT, we aim to contribute to the ongoing discourse
surrounding the integration of artificial intelligence in healthcare settings,
ultimately promoting the responsible and efficacious use of such technologies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Autoregressive <span class="highlight-title">Pre-Train</span>ing on Pixels and Texts <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.10710v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.10710v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yekun Chai, Qingyi Liu, Jingwu Xiao, Shuohuan Wang, Yu Sun, Hua Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The integration of visual and textual information represents a promising
direction in the advancement of language models. In this paper, we explore the
dual modality of language--both visual and textual--within an autoregressive
framework, pre-trained on both document images and texts. Our method employs a
multimodal training strategy, utilizing visual data through next patch
prediction with a regression head and/or textual data through next token
prediction with a classification head. We focus on understanding the
interaction between these two modalities and their combined impact on model
performance. Our extensive evaluation across a wide range of benchmarks shows
that incorporating both visual and textual data significantly improves the
performance of pixel-based language models. Remarkably, we find that a
unidirectional pixel-based model trained solely on visual data can achieve
comparable results to state-of-the-art bidirectional models on several language
understanding tasks. This work uncovers the untapped potential of integrating
visual and textual modalities for more effective language modeling. We release
our code, data, and model checkpoints at
\url{https://github.com/ernie-research/pixelgpt}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is
  Needed? <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.12683v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.12683v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tannon Kew, Florian Schottmann, Rico Sennrich
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The vast majority of today's large language models (LLMs) are
English-centric, having been pretrained predominantly on English text. Yet, in
order to meet user expectations, models need to be able to respond
appropriately in multiple languages once deployed in downstream applications.
This requires strong cross-lingual transfer abilities. In this work, we
investigate the minimal amount of multilinguality required during finetuning to
elicit cross-lingual generalisation in English-centric LLMs. In experiments
across four LLMs, we find that multilingual instruction tuning with as few as
two to three languages is both necessary and sufficient to elicit effective
cross-lingual generalisation, with the limiting factor being the degree to
which a target language is seen during pretraining. Evaluations on five
different tasks further reveal that multilingual instruction tuning is most
beneficial for generative tasks that assume input/output language agreement,
such as in chat settings, while being of less importance for highly structured
classification-style tasks. Our code and data is available at
https://github.com/ZurichNLP/multilingual-instruction-tuning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at Findings of EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Lookback Lens: Detecting and Mitigating Contextual Hallucinations in
  Large Language Models Using Only Attention Maps <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.07071v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.07071v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yung-Sung Chuang, Linlu Qiu, Cheng-Yu Hsieh, Ranjay Krishna, Yoon Kim, James Glass
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  When asked to summarize articles or answer questions given a passage, large
language models (LLMs) can hallucinate details and respond with unsubstantiated
answers that are inaccurate with respect to the input context. This paper
describes a simple approach for detecting such contextual hallucinations. We
hypothesize that contextual hallucinations are related to the extent to which
an LLM attends to information in the provided context versus its own
generations. Based on this intuition, we propose a simple hallucination
detection model whose input features are given by the ratio of attention
weights on the context versus newly generated tokens (for each attention head).
We find that a linear classifier based on these lookback ratio features is as
effective as a richer detector that utilizes the entire hidden states of an LLM
or a text-based entailment model. The lookback ratio-based detector -- Lookback
Lens -- is found to transfer across tasks and even models, allowing a detector
that is trained on a 7B model to be applied (without retraining) to a larger
13B model. We further apply this detector to mitigate contextual
hallucinations, and find that a simple classifier-guided decoding approach is
able to reduce the amount of hallucination, for example by 9.6% in the XSum
summarization task.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 main conference long paper. The source code is available
  at https://github.com/voidism/Lookback-Lens</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Mystery of In-Context Learning: A Comprehensive <span class="highlight-title">Survey</span> on
  Interpretation and Analysis <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.00237v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.00237v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxiang Zhou, Jiazheng Li, Yanzheng Xiang, Hanqi Yan, Lin Gui, Yulan He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding in-context learning (ICL) capability that enables large
language models (LLMs) to excel in proficiency through demonstration examples
is of utmost importance. This importance stems not only from the better
utilization of this capability across various tasks, but also from the
proactive identification and mitigation of potential risks, including concerns
regarding truthfulness, bias, and toxicity, that may arise alongside the
capability. In this paper, we present a thorough survey on the interpretation
and analysis of in-context learning. First, we provide a concise introduction
to the background and definition of in-context learning. Then, we give an
overview of advancements from two perspectives: 1) a theoretical perspective,
emphasizing studies on mechanistic interpretability and delving into the
mathematical foundations behind ICL; and 2) an empirical perspective,
concerning studies that empirically analyze factors associated with ICL. We
conclude by highlighting the challenges encountered and suggesting potential
avenues for future research. We believe that our work establishes the basis for
further exploration into the interpretation of in-context learning.
Additionally, we have created a repository containing the resources referenced
in our survey.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the main conference of EMNLP 2024. Resources are
  available at https://github.com/zyxnlp/ICL-Interpretation-Analysis-Resources</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhanced Automated Code Vulnerability Repair using Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.03741v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.03741v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David de-Fitero-Dominguez, Eva Garcia-Lopez, Antonio Garcia-Cabot, Jose-Javier Martinez-Herraiz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This research addresses the complex challenge of automated repair of code
vulnerabilities, vital for enhancing digital security in an increasingly
technology-driven world. The study introduces a novel and efficient format for
the representation of code modification, using advanced Large Language Models
(LLMs) such as Code Llama and Mistral. These models, fine-tuned on datasets
featuring C code vulnerabilities, significantly improve the accuracy and
adaptability of automated code repair techniques. A key finding is the enhanced
repair accuracy of these models when compared to previous methods such as
VulRepair, which underscores their practical utility and efficiency. The
research also offers a critical assessment of current evaluation metrics, such
as perfect predictions, and their limitations in reflecting the true
capabilities of automated repair models in real-world scenarios. Following
this, it underscores the importance of using test datasets devoid of train
samples, emphasizing the need for dataset integrity to enhance the
effectiveness of LLMs in code repair tasks. The significance of this work is
its contribution to digital security, setting new standards for automated code
vulnerability repair and paving the way for future advancements in the fields
of cybersecurity and artificial intelligence. The study does not only highlight
the potential of LLMs in enhancing code security but also fosters further
exploration and research in these crucial areas.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On the Limited Generalization Capability of the Implicit Reward Model
  Induced by Direct Preference Optimization <span class="chip">EMNLP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.03650v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.03650v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yong Lin, Skyler Seto, Maartje ter Hoeve, Katherine Metcalf, Barry-John Theobald, Xuan Wang, Yizhe Zhang, Chen Huang, Tong Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement Learning from Human Feedback (RLHF) is an effective approach
for aligning language models to human preferences. Central to RLHF is learning
a reward function for scoring human preferences. Two main approaches for
learning a reward model are 1) training an EXplicit Reward Model (EXRM) as in
RLHF, and 2) using an implicit reward learned from preference data through
methods such as Direct Preference Optimization (DPO). Prior work has shown that
the implicit reward model of DPO (denoted as DPORM) can approximate an EXRM in
the limit. DPORM's effectiveness directly implies the optimality of the learned
policy, and also has practical implication for LLM alignment methods including
iterative DPO. However, it is unclear how well DPORM empirically matches the
performance of EXRM. This work studies the accuracy at distinguishing preferred
and rejected answers for both DPORM and EXRM. Our findings indicate that even
though DPORM fits the training dataset comparably, it generalizes less
effectively than EXRM, especially when the validation datasets contain
distribution shifts. Across five out-of-distribution settings, DPORM has a mean
drop in accuracy of 3% and a maximum drop of 7%. These findings highlight that
DPORM has limited generalization ability and substantiates the integration of
an explicit reward model in iterative DPO approaches.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 8 tables, 3 figures; Paper Accepted at EMNLP Findings 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Jailbreaking LLMs with Arabic Transliteration and Arabizi <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18725v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18725v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mansour Al Ghanim, Saleh Almohaimeed, Mengxin Zheng, Yan Solihin, Qian Lou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study identifies the potential vulnerabilities of Large Language Models
(LLMs) to 'jailbreak' attacks, specifically focusing on the Arabic language and
its various forms. While most research has concentrated on English-based prompt
manipulation, our investigation broadens the scope to investigate the Arabic
language. We initially tested the AdvBench benchmark in Standardized Arabic,
finding that even with prompt manipulation techniques like prefix injection, it
was insufficient to provoke LLMs into generating unsafe content. However, when
using Arabic transliteration and chatspeak (or arabizi), we found that unsafe
content could be produced on platforms like OpenAI GPT-4 and Anthropic Claude 3
Sonnet. Our findings suggest that using Arabic and its various forms could
expose information that might remain hidden, potentially increasing the risk of
jailbreak attacks. We hypothesize that this exposure could be due to the
model's learned connection to specific words, highlighting the need for more
comprehensive safety training across all language forms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for
  Children's Story-Based Learning <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.09756v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.09756v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaju Chen, Yuxuan Lu, Shao Zhang, Bingsheng Yao, Yuanzhe Dong, Ying Xu, Yunyao Li, Qianwen Wang, Dakuo Wang, Yuling Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Interactive story reading is a common parent-child activity, where parents
expect to teach both language skills and real-world knowledge beyond the story.
While increasing storytelling and reading systems have been developed for this
activity, they often fail to infuse real-world knowledge into the conversation.
This limitation can be attributed to the existing question-answering (QA)
datasets used for children's education, upon which the systems are built,
failing to capture the nuances of how education experts think when conducting
interactive story reading activities. To bridge this gap, we design an
annotation framework, empowered by existing knowledge graph to capture experts'
annotations and thinking process, and leverage this framework to construct
StorySparkQA dataset, which comprises 5,868 expert-annotated QA pairs with
real-world knowledge. We conduct automated and human expert evaluations across
various QA pair generation settings to demonstrate that our StorySparkQA can
effectively support models in generating QA pairs that target real-world
knowledge beyond story content. StorySparkQA is available at
https://huggingface.co/datasets/NEU-HAI/StorySparkQA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Rel-A.I.: An Interaction-Centered Approach To Measuring Human-LM
  Reliance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.07950v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.07950v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaitlyn Zhou, Jena D. Hwang, Xiang Ren, Nouha Dziri, Dan Jurafsky, Maarten Sap
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The ability to communicate uncertainty, risk, and limitation is crucial for
the safety of large language models. However, current evaluations of these
abilities rely on simple calibration, asking whether the language generated by
the model matches appropriate probabilities. Instead, evaluation of this aspect
of LLM communication should focus on the behaviors of their human
interlocutors: how much do they rely on what the LLM says? Here we introduce an
interaction-centered evaluation framework called Rel-A.I. (pronounced "rely"})
that measures whether humans rely on LLM generations. We use this framework to
study how reliance is affected by contextual features of the interaction (e.g,
the knowledge domain that is being discussed), or the use of greetings
communicating warmth or competence (e.g., "I'm happy to help!"). We find that
contextual characteristics significantly affect human reliance behavior. For
example, people rely 10% more on LMs when responding to questions involving
calculations and rely 30% more on LMs that are perceived as more competent. Our
results show that calibration and language quality alone are insufficient in
evaluating the risks of human-LM interactions, and illustrate the need to
consider features of the interactional context.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On Leakage of Code Generation Evaluation <span class="highlight-title">Dataset</span>s <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.07565v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.07565v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexandre Matton, Tom Sherborne, Dennis Aumiller, Elena Tommasone, Milad Alizadeh, Jingyi He, Raymond Ma, Maxime Voisin, Ellen Gilsenan-McMahon, Matthias Gallé
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we consider contamination by code generation test sets, in
particular in their use in modern large language models. We discuss three
possible sources of such contamination and show findings supporting each of
them: (i) direct data leakage, (ii) indirect data leakage through the use of
synthetic data and (iii) overfitting to evaluation sets during model selection.
To address this, we release Less Basic Python Problems (LBPP): an
uncontaminated new benchmark of 161 prompts with their associated Python
solutions. LBPP is released at https://huggingface.co/datasets/CohereForAI/lbpp .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Findings. 5 main pages, 9 in total</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Does Refusal Training in LLMs Generalize to the Past Tense? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11969v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11969v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maksym Andriushchenko, Nicolas Flammarion
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Refusal training is widely used to prevent LLMs from generating harmful,
undesirable, or illegal outputs. We reveal a curious generalization gap in the
current refusal training approaches: simply reformulating a harmful request in
the past tense (e.g., "How to make a Molotov cocktail?" to "How did people make
a Molotov cocktail?") is often sufficient to jailbreak many state-of-the-art
LLMs. We systematically evaluate this method on Llama-3 8B, Claude-3.5 Sonnet,
GPT-3.5 Turbo, Gemma-2 9B, Phi-3-Mini, GPT-4o mini, GPT-4o, o1-mini,
o1-preview, and R2D2 models using GPT-3.5 Turbo as a reformulation model. For
example, the success rate of this simple attack on GPT-4o increases from 1%
using direct requests to 88% using 20 past tense reformulation attempts on
harmful requests from JailbreakBench with GPT-4 as a jailbreak judge.
Interestingly, we also find that reformulations in the future tense are less
effective, suggesting that refusal guardrails tend to consider past historical
questions more benign than hypothetical future questions. Moreover, our
experiments on fine-tuning GPT-3.5 Turbo show that defending against past
reformulations is feasible when past tense examples are explicitly included in
the fine-tuning data. Overall, our findings highlight that the widely used
alignment techniques -- such as SFT, RLHF, and adversarial training -- employed
to align the studied models can be brittle and do not always generalize as
intended. We provide code and jailbreak artifacts at
https://github.com/tml-epfl/llm-past-tense.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Update in v3: o1-mini and o1-preview results (on top of GPT-4o and
  Claude 3.5 Sonnet added in v2). We provide code and jailbreak artifacts at
  https://github.com/tml-epfl/llm-past-tense</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Immunization against harmful fine-tuning attacks <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.16382v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.16382v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Domenic Rosati, Jan Wehner, Kai Williams, Łukasz Bartoszcze, Jan Batzner, Hassan Sajjad, Frank Rudzicz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are often trained with safety guards intended to
prevent harmful text generation. However, such safety training can be removed
by fine-tuning the LLM on harmful datasets. While this emerging threat (harmful
fine-tuning attacks) has been characterized by previous work, there is little
understanding of how we should proceed in constructing and validating defenses
against these attacks especially in the case where defenders would not have
control of the fine-tuning process. We introduce a formal framework based on
the training budget of an attacker which we call "Immunization" conditions.
Using a formal characterisation of the harmful fine-tuning problem, we provide
a thorough description of what a successful defense must comprise of and
establish a set of guidelines on how rigorous defense research that gives us
confidence should proceed.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published in EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Foundations of Large Language Model Compression -- Part 1: Weight
  Quantization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02026v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02026v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sean I. Young
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, compression of large language models (LLMs) has emerged as
an important problem to enable language model deployment on
resource-constrained devices, reduce computational costs, and mitigate the
environmental footprint of large-scale AI infrastructure. In this paper, we lay
down the foundation for LLM quantization from a convex optimization perspective
and propose a quantization technique that builds on this foundation for optimum
quantization outcomes. Our quantization framework, CVXQ, scales to models
containing hundreds of billions of weight parameters and provides users with
the flexibility to compress models to any specified model size, post-training.
A reference implementation of CVXQ can be obtained from github.com/seannz/cvxq.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint. 17 pages, 4 figures, 5 appendices</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ EIA: Environmental Injection Attack on Generalist Web Agents for Privacy
  Leakage 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.11295v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.11295v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zeyi Liao, Lingbo Mo, Chejian Xu, Mintong Kang, Jiawei Zhang, Chaowei Xiao, Yuan Tian, Bo Li, Huan Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generalist web agents have demonstrated remarkable potential in autonomously
completing a wide range of tasks on real websites, significantly boosting human
productivity. However, web tasks, such as booking flights, usually involve
users' PII, which may be exposed to potential privacy risks if web agents
accidentally interact with compromised websites, a scenario that remains
largely unexplored in the literature. In this work, we narrow this gap by
conducting the first study on the privacy risks of generalist web agents in
adversarial environments. First, we present a realistic threat model for
attacks on the website, where we consider two adversarial targets: stealing
users' specific PII or the entire user request. Then, we propose a novel attack
method, termed Environmental Injection Attack (EIA). EIA injects malicious
content designed to adapt well to environments where the agents operate and our
work instantiates EIA specifically for privacy scenarios in web environments.
We collect 177 action steps that involve diverse PII categories on realistic
websites from the Mind2Web, and conduct experiments using one of the most
capable generalist web agent frameworks to date. The results demonstrate that
EIA achieves up to 70% ASR in stealing specific PII and 16% ASR for full user
request. Additionally, by accessing the stealthiness and experimenting with a
defensive system prompt, we indicate that EIA is hard to detect and mitigate.
Notably, attacks that are not well adapted for a webpage can be detected via
human inspection, leading to our discussion about the trade-off between
security and autonomy. However, extra attackers' efforts can make EIA
seamlessly adapted, rendering such supervision ineffective. Thus, we further
discuss the defenses at the pre- and post-deployment stages of the websites
without relying on human supervision and call for more advanced defense
strategies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>29 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">PRompt</span> Optimization in Multi-Step Tasks (PROMST): Integrating Human
  Feedback and Heuristic-based Sampling <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.08702v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.08702v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yongchao Chen, Jacob Arkin, Yilun Hao, Yang Zhang, Nicholas Roy, Chuchu Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prompt optimization aims to find the best prompt to a large language model
(LLM) for a given task. LLMs have been successfully used to help find and
improve prompt candidates for single-step tasks. However, realistic tasks for
agents are multi-step and introduce new challenges: (1) Prompt content is
likely to be more extensive and complex, making it more difficult for LLMs to
analyze errors, (2) the impact of an individual step is difficult to evaluate,
and (3) different people may have varied preferences about task execution.
While humans struggle to optimize prompts, they are good at providing feedback
about LLM outputs; we therefore introduce a new LLM-driven discrete prompt
optimization framework PRompt Optimization in Multi-Step Tasks (PROMST) that
incorporates human-designed feedback rules to automatically offer direct
suggestions for improvement. We also use an extra learned heuristic model that
predicts prompt performance to efficiently sample from prompt candidates. This
approach significantly outperforms both human-engineered prompts and several
other prompt optimization methods across 11 representative multi-step tasks (an
average 10.6\%-29.3\% improvement to current best methods on five LLMs
respectively). We believe our work can serve as a benchmark for automatic
prompt optimization for LLM-driven multi-step tasks. Datasets and Codes are
available at https://github.com/yongchao98/PROMST. Project Page is available at
https://yongchao98.github.io/MIT-REALM-PROMST.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>62 pages, 14 figures, Published in EMNLP 2024 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PARAMANU-AYN: <span class="highlight-title">Pretrain</span> from scratch or Continual <span class="highlight-title">Pretrain</span>ing of LLMs for
  Legal Domain Adaptation? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.13681v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.13681v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mitodru Niyogi, Arnab Bhattacharya
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we present Paramanu-Ayn, a collection of legal language models
trained exclusively on Indian legal case documents. This 97-million-parameter
Auto-Regressive (AR) decoder-only model was pretrained from scratch with a
context size of 8192 on a single GPU for just 185 hours, achieving an efficient
MFU of 41.35. We also developed a legal domain specialized BPE tokenizer. We
evaluated our model using perplexity and zero-shot tasks: case judgment
prediction with explanation and abstractive case summarization. Paramanu-Ayn
outperformed Llama-2 7B and Gemini-Pro in case judgment prediction with
explanation task on test accuracy by nearly 2 percentage points, despite being
72 times smaller. In zero-shot abstractive summarization, it surpassed
decoder-only LLMs generating fixed-length summaries (5000 tokens) by over 10
percentage points in BLEU and METEOR metrics, and by nearly 4 percentage points
in BERTScore. Further evaluations on zero-shot commonsense and mathematical
benchmarks showed that Paramanu-Ayn excelled despite being trained exclusively
on legal documents, outperforming Llama-1, Llama-2, and Falcon on
AGIEVAL-AQuA-RAT and AGIEVAL-SAT-Math tasks. We also instruction-tuned our
model on 10,763 diverse legal tasks, including legal clause generation, legal
drafting, case summarization, etc. The Paramanu-Ayn-instruct model scored above
8 out of 10 in clarity, relevance, completeness, and legal reasoning metrics by
GPT-3.5-Turbo. We found that our models, were able to learn drafting knowledge
and generalize to draft legal contracts and legal clauses with limited
instruction-tuning. Hence, we conclude that for a strong domain-specialized
generative language model (such as legal), domain specialized pretraining from
scratch is more cost effective, environmentally friendly, and remains
competitive with larger models or even better than adapting LLMs for legal
domain tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Leopard: A Vision Language Model For Text-Rich Multi-Image Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01744v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01744v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mengzhao Jia, Wenhao Yu, Kaixin Ma, Tianqing Fang, Zhihan Zhang, Siru Ouyang, Hongming Zhang, Meng Jiang, Dong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-rich images, where text serves as the central visual element guiding the
overall understanding, are prevalent in real-world applications, such as
presentation slides, scanned documents, and webpage snapshots. Tasks involving
multiple text-rich images are especially challenging, as they require not only
understanding the content of individual images but reasoning about
inter-relationships and logical flows across multiple visual inputs. Despite
the importance of these scenarios, current multimodal large language models
(MLLMs) struggle to handle such tasks due to two key challenges: (1) the
scarcity of high-quality instruction tuning datasets for text-rich multi-image
scenarios, and (2) the difficulty in balancing image resolution with visual
feature sequence length. To address these challenges, we propose Leopard, a
MLLM designed specifically for handling vision-language tasks involving
multiple text-rich images. First, we curated about one million high-quality
multimodal instruction-tuning data, tailored to text-rich, multi-image
scenarios. Second, we developed an adaptive high-resolution multi-image
encoding module to dynamically optimize the allocation of visual sequence
length based on the original aspect ratios and resolutions of the input images.
Experiments across a wide range of benchmarks demonstrate our model's superior
capabilities in text-rich, multi-image evaluations and competitive performance
in general domain evaluations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Our code is available at https://github.com/Jill0001/Leopard</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Seemingly Plausible Distractors in Multi-Hop Reasoning: Are Large
  Language Models Attentive Readers? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05197v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05197v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Neeladri Bhuiya, Viktor Schlegel, Stefan Winkler
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  State-of-the-art Large Language Models (LLMs) are accredited with an
increasing number of different capabilities, ranging from reading
comprehension, over advanced mathematical and reasoning skills to possessing
scientific knowledge. In this paper we focus on their multi-hop reasoning
capability: the ability to identify and integrate information from multiple
textual sources.
  Given the concerns with the presence of simplifying cues in existing
multi-hop reasoning benchmarks, which allow models to circumvent the reasoning
requirement, we set out to investigate, whether LLMs are prone to exploiting
such simplifying cues. We find evidence that they indeed circumvent the
requirement to perform multi-hop reasoning, but they do so in more subtle ways
than what was reported about their fine-tuned pre-trained language model (PLM)
predecessors. Motivated by this finding, we propose a challenging multi-hop
reasoning benchmark, by generating seemingly plausible multi-hop reasoning
chains, which ultimately lead to incorrect answers. We evaluate multiple open
and proprietary state-of-the-art LLMs, and find that their performance to
perform multi-hop reasoning is affected, as indicated by up to 45% relative
decrease in F1 score when presented with such seemingly plausible alternatives.
We conduct a deeper analysis and find evidence that while LLMs tend to ignore
misleading lexical cues, misleading reasoning paths indeed present a
significant challenge.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at
  Any Resolution 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.12191v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.12191v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peng Wang, Shuai Bai, Sinan Tan, Shijie Wang, Zhihao Fan, Jinze Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, Yang Fan, Kai Dang, Mengfei Du, Xuancheng Ren, Rui Men, Dayiheng Liu, Chang Zhou, Jingren Zhou, Junyang Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present the Qwen2-VL Series, an advanced upgrade of the previous Qwen-VL
models that redefines the conventional predetermined-resolution approach in
visual processing. Qwen2-VL introduces the Naive Dynamic Resolution mechanism,
which enables the model to dynamically process images of varying resolutions
into different numbers of visual tokens. This approach allows the model to
generate more efficient and accurate visual representations, closely aligning
with human perceptual processes. The model also integrates Multimodal Rotary
Position Embedding (M-RoPE), facilitating the effective fusion of positional
information across text, images, and videos. We employ a unified paradigm for
processing both images and videos, enhancing the model's visual perception
capabilities. To explore the potential of large multimodal models, Qwen2-VL
investigates the scaling laws for large vision-language models (LVLMs). By
scaling both the model size-with versions at 2B, 8B, and 72B parameters-and the
amount of training data, the Qwen2-VL Series achieves highly competitive
performance. Notably, the Qwen2-VL-72B model achieves results comparable to
leading models such as GPT-4o and Claude3.5-Sonnet across various multimodal
benchmarks, outperforming other generalist models. Code is available at
https://github.com/QwenLM/Qwen2-VL .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code is available at https://github.com/QwenLM/Qwen2-VL. arXiv admin
  note: text overlap with arXiv:2408.15262 by other authors</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fast Matrix Multiplications for Lookup Table-Quantized LLMs <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10960v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10960v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Han Guo, William Brandon, Radostin Cholakov, Jonathan Ragan-Kelley, Eric P. Xing, Yoon Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The deployment of large language models (LLMs) is often constrained by memory
bandwidth, where the primary bottleneck is the cost of transferring model
parameters from the GPU's global memory to its registers. When coupled with
custom kernels that fuse the dequantization and matmul operations, weight-only
quantization can thus enable faster inference by reducing the amount of memory
movement. However, developing high-performance kernels for weight-quantized
LLMs presents substantial challenges, especially when the weights are
compressed to non-evenly-divisible bit widths (e.g., 3 bits) with non-uniform,
lookup table (LUT) quantization. This paper describes FLUTE, a flexible lookup
table engine for LUT-quantized LLMs, which uses offline restructuring of the
quantized weight matrix to minimize bit manipulations associated with
unpacking, and vectorization and duplication of the lookup table to mitigate
shared memory bandwidth constraints. At batch sizes < 32 and quantization group
size of 128 (typical in LLM inference), the FLUTE kernel can be 2-4x faster
than existing GEMM kernels. As an application of FLUTE, we explore a simple
extension to lookup table-based NormalFloat quantization and apply it to
quantize LLaMA3 to various configurations, obtaining competitive quantization
performance against strong baselines while obtaining an end-to-end throughput
increase of 1.5 to 2 times.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 (Findings)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Llamipa: An Incremental Discourse Parser <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18256v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18256v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kate Thompson, Akshay Chaturvedi, Julie Hunter, Nicholas Asher
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper provides the first discourse parsing experiments with a large
language model(LLM) finetuned on corpora annotated in the style of SDRT
(Segmented Discourse Representation Theory Asher, 1993; Asher and Lascarides,
2003). The result is a discourse parser, Llamipa (Llama Incremental Parser),
that leverages discourse context, leading to substantial performance gains over
approaches that use encoder-only models to provide local, context-sensitive
representations of discourse units. Furthermore, it can process discourse data
incrementally, which is essential for the eventual use of discourse information
in downstream tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Nebula: A discourse aware Minecraft Builder <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18164v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18164v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Akshay Chaturvedi, Kate Thompson, Nicholas Asher
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  When engaging in collaborative tasks, humans efficiently exploit the semantic
structure of a conversation to optimize verbal and nonverbal interactions. But
in recent "language to code" or "language to action" models, this information
is lacking. We show how incorporating the prior discourse and nonlinguistic
context of a conversation situated in a nonlinguistic environment can improve
the "language to action" component of such interactions. We finetune an LLM to
predict actions based on prior context; our model, Nebula, doubles the
net-action F1 score over the baseline on this task of Jayannavar et al.(2020).
We also investigate our model's ability to construct shapes and understand
location descriptions using a synthetic dataset
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LongForm: Effective Instruction Tuning with Reverse Instructions <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2304.08460v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2304.08460v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abdullatif Köksal, Timo Schick, Anna Korhonen, Hinrich Schütze
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Instruction tuning enables language models to more effectively generalize and
better follow user intent. However, obtaining instruction data is costly and
challenging. Prior work employs methods such as expensive human annotation,
crowd-sourced datasets with alignment issues, and generating noisy examples via
LLMs. We introduce the LongForm-C dataset, which is created by reverse
instructions. We generate instructions via LLMs for human-written corpus
examples using reverse instructions. First we select a diverse set of
human-written documents from corpora such as C4 and Wikipedia; then we generate
instructions for these documents via LLMs. This approach provides a cheaper and
cleaner instruction-tuning dataset with natural output and one suitable for
long text generation. Our models outperform 10x larger language models without
instruction tuning on tasks such as story/recipe generation and long-form
question answering. Moreover, LongForm models outperform prior
instruction-tuned models such as FLAN-T5 and Alpaca by a large margin, and
improve language understanding capabilities further. We publicly release our
data and models: https://github.com/akoksal/LongForm.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Findings. This version extends the training with recent
  LLMs, evaluation with new metrics, and NLU tasks</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TurkishMMLU: Measuring Massive Multitask Language Understanding in
  Turkish <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12402v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12402v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arda Yüksel, Abdullatif Köksal, Lütfi Kerem Şenel, Anna Korhonen, Hinrich Schütze
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multiple choice question answering tasks evaluate the reasoning,
comprehension, and mathematical abilities of Large Language Models (LLMs).
While existing benchmarks employ automatic translation for multilingual
evaluation, this approach is error-prone and potentially introduces culturally
biased questions, especially in social sciences. We introduce the first
multitask, multiple-choice Turkish QA benchmark, TurkishMMLU, to evaluate LLMs'
understanding of the Turkish language. TurkishMMLU includes over 10,000
questions, covering 9 different subjects from Turkish high-school education
curricula. These questions are written by curriculum experts, suitable for the
high-school curricula in Turkey, covering subjects ranging from natural
sciences and math questions to more culturally representative topics such as
Turkish Literature and the history of the Turkish Republic. We evaluate over 20
LLMs, including multilingual open-source (e.g., Gemma, Llama, MT5),
closed-source (GPT 4o, Claude, Gemini), and Turkish-adapted (e.g., Trendyol)
models. We provide an extensive evaluation, including zero-shot and few-shot
evaluation of LLMs, chain-of-thought reasoning, and question difficulty
analysis along with model performance. We provide an in-depth analysis of the
Turkish capabilities and limitations of current LLMs to provide insights for
future LLMs for the Turkish language. We publicly release our code for the
dataset and evaluation: https://github.com/ArdaYueksel/TurkishMMLU.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 - Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Generate-on-Graph: Treat LLM as both Agent and KG in Incomplete
  Knowledge Graph Question Answering <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.14741v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.14741v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yao Xu, Shizhu He, Jiabei Chen, Zihao Wang, Yangqiu Song, Hanghang Tong, Guang Liu, Kang Liu, Jun Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To address the issues of insufficient knowledge and hallucination in Large
Language Models (LLMs), numerous studies have explored integrating LLMs with
Knowledge Graphs (KGs). However, these methods are typically evaluated on
conventional Knowledge Graph Question Answering (KGQA) with complete KGs, where
all factual triples required for each question are entirely covered by the
given KG. In such cases, LLMs primarily act as an agent to find answer entities
within the KG, rather than effectively integrating the internal knowledge of
LLMs and external knowledge sources such as KGs. In fact, KGs are often
incomplete to cover all the knowledge required to answer questions. To simulate
these real-world scenarios and evaluate the ability of LLMs to integrate
internal and external knowledge, we propose leveraging LLMs for QA under
Incomplete Knowledge Graph (IKGQA), where the provided KG lacks some of the
factual triples for each question, and construct corresponding datasets. To
handle IKGQA, we propose a training-free method called Generate-on-Graph (GoG),
which can generate new factual triples while exploring KGs. Specifically, GoG
performs reasoning through a Thinking-Searching-Generating framework, which
treats LLM as both Agent and KG in IKGQA. Experimental results on two datasets
demonstrate that our GoG outperforms all previous methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Quantifying Generalization Complexity for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01769v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01769v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenting Qi, Hongyin Luo, Xuliang Huang, Zhuokai Zhao, Yibo Jiang, Xiangjun Fan, Himabindu Lakkaraju, James Glass
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While large language models (LLMs) have shown exceptional capabilities in
understanding complex queries and performing sophisticated tasks, their
generalization abilities are often deeply entangled with memorization,
necessitating more precise evaluation. To address this challenge, we introduce
Scylla, a dynamic evaluation framework that quantitatively measures the
generalization abilities of LLMs. Scylla disentangles generalization from
memorization via assessing model performance on both in-distribution (ID) and
out-of-distribution (OOD) data through 20 tasks across 5 levels of complexity.
Through extensive experiments, we uncover a non-monotonic relationship between
task complexity and the performance gap between ID and OOD data, which we term
the generalization valley. Specifically, this phenomenon reveals a critical
threshold - referred to as critical complexity - where reliance on
non-generalizable behavior peaks, indicating the upper bound of LLMs'
generalization capabilities. As model size increases, the critical complexity
shifts toward higher levels of task complexity, suggesting that larger models
can handle more complex reasoning tasks before over-relying on memorization.
Leveraging Scylla and the concept of critical complexity, we benchmark 28LLMs
including both open-sourced models such as LLaMA and Qwen families, and
close-sourced models like Claude and GPT, providing a more robust evaluation
and establishing a clearer understanding of LLMs' generalization capabilities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Ada-Instruct: Adapting Instruction Generators for Complex Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.04484v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.04484v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wanyun Cui, Qianle Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Instructions augmentation is a crucial step for unleashing the full potential
of large language models (LLMs) in downstream tasks. Existing Self-Instruct
methods primarily simulate new instructions from a few initial instructions
with in-context learning. However, our study identifies a critical flaw in this
approach: even with GPT4o, Self-Instruct cannot generate complex instructions
of length $\ge 100$, which is necessary in complex tasks such as code
completion.
  To address this issue, our key insight is that fine-tuning open source LLMs
with only ten examples can produce complex instructions that maintain
distributional consistency for complex reasoning tasks. We introduce
Ada-Instruct, an adaptive instruction generator developed through fine-tuning.
We empirically validated Ada-Instruct's efficacy across different applications.
The results highlight Ada-Instruct's capacity to generate long, intricate, and
distributionally consistent instructions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ In-Context Editing: Learning Knowledge from Self-Induced Distributions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11194v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11194v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siyuan Qi, Bangcheng Yang, Kailin Jiang, Xiaobo Wang, Jiaqi Li, Yifan Zhong, Yaodong Yang, Zilong Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In scenarios where language models must incorporate new information
efficiently without extensive retraining, traditional fine-tuning methods are
prone to overfitting, degraded generalization, and unnatural language
generation. To address these limitations, we introduce Consistent In-Context
Editing (ICE), a novel approach leveraging the model's in-context learning
capability to optimize toward a contextual distribution rather than a one-hot
target. ICE introduces a simple yet effective optimization framework for the
model to internalize new knowledge by aligning its output distributions with
and without additional context. This method enhances the robustness and
effectiveness of gradient-based tuning methods, preventing overfitting and
preserving the model's integrity. We analyze ICE across four critical aspects
of knowledge editing: accuracy, locality, generalization, and linguistic
quality, demonstrating its advantages. Experimental results confirm the
effectiveness of ICE and demonstrate its potential for continual editing,
ensuring that the integrity of the model is preserved while updating
information.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fighting Randomness with Randomness: Mitigating Optimisation Instability
  of Fine-Tuning using Delayed Ensemble and Noisy Interpolation <span class="chip">EMNLP'24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12471v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12471v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Branislav Pecher, Jan Cegin, Robert Belanec, Jakub Simko, Ivan Srba, Maria Bielikova
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While fine-tuning of pre-trained language models generally helps to overcome
the lack of labelled training samples, it also displays model performance
instability. This instability mainly originates from randomness in
initialisation or data shuffling. To address this, researchers either modify
the training process or augment the available samples, which typically results
in increased computational costs. We propose a new mitigation strategy, called
Delayed Ensemble with Noisy Interpolation (DENI), that leverages the strengths
of ensembling, noise regularisation and model interpolation, while retaining
computational efficiency. We compare DENI with 9 representative mitigation
strategies across 3 models, 4 tuning strategies and 7 text classification
datasets. We show that: 1) DENI outperforms the best performing mitigation
strategy (Ensemble), while using only a fraction of its cost; 2) the mitigation
strategies are beneficial for parameter-efficient fine-tuning (PEFT) methods,
outperforming full fine-tuning in specific cases; and 3) combining DENI with
data augmentation often leads to even more effective instability mitigation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the Findings of the EMNLP'24 Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On Sensitivity of Learning with Limited Labelled Data to the Effects of
  Randomness: Impact of Interactions and Systematic Choices <span class="chip">EMNLP'24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.12817v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.12817v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Branislav Pecher, Ivan Srba, Maria Bielikova
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While learning with limited labelled data can improve performance when the
labels are lacking, it is also sensitive to the effects of uncontrolled
randomness introduced by so-called randomness factors (e.g., varying order of
data). We propose a method to systematically investigate the effects of
randomness factors while taking the interactions between them into
consideration. To measure the true effects of an individual randomness factor,
our method mitigates the effects of other factors and observes how the
performance varies across multiple runs. Applying our method to multiple
randomness factors across in-context learning and fine-tuning approaches on 7
representative text classification tasks and meta-learning on 3 tasks, we show
that: 1) disregarding interactions between randomness factors in existing works
caused inconsistent findings due to incorrect attribution of the effects of
randomness factors, such as disproving the consistent sensitivity of in-context
learning to sample order even with random sample selection; and 2) besides
mutual interactions, the effects of randomness factors, especially sample
order, are also dependent on more systematic choices unexplored in existing
works, such as number of classes, samples per class or choice of prompt format.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the EMNLP'24 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ 2D-TPE: Two-Dimensional Positional Encoding Enhances Table Understanding
  for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19700v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19700v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jia-Nan Li, Jian Guan, Wei Wu, Zhengtao Yu, Rui Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tables are ubiquitous across various domains for concisely representing
structured information. Empowering large language models (LLMs) to reason over
tabular data represents an actively explored direction. However, since typical
LLMs only support one-dimensional~(1D) inputs, existing methods often flatten
the two-dimensional~(2D) table structure into a sequence of tokens, which can
severely disrupt the spatial relationships and result in an inevitable loss of
vital contextual information. In this paper, we first empirically demonstrate
the detrimental impact of such flattening operations on the performance of LLMs
in capturing the spatial information of tables through two elaborate proxy
tasks. Subsequently, we introduce a simple yet effective positional encoding
method, termed ``2D-TPE'' (Two-Dimensional Table Positional Encoding), to
address this challenge. 2D-TPE enables each attention head to dynamically
select a permutation order of tokens within the context for attending to them,
where each permutation represents a distinct traversal mode for the table, such
as column-wise or row-wise traversal. 2D-TPE effectively mitigates the risk of
losing essential spatial information while preserving computational efficiency,
thus better preserving the table structure. Extensive experiments across five
benchmarks demonstrate that 2D-TPE outperforms strong baselines, underscoring
the importance of preserving the table structure for accurate table
comprehension. Comprehensive analysis further reveals the substantially better
scalability of 2D-TPE to large tables than baselines.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TCSinger: Zero-Shot Singing Voice Synthesis with Style Transfer and
  Multi-Level Style Control <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15977v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15977v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu Zhang, Ziyue Jiang, Ruiqi Li, Changhao Pan, Jinzheng He, Rongjie Huang, Chuxin Wang, Zhou Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Zero-shot singing voice synthesis (SVS) with style transfer and style control
aims to generate high-quality singing voices with unseen timbres and styles
(including singing method, emotion, rhythm, technique, and pronunciation) from
audio and text prompts. However, the multifaceted nature of singing styles
poses a significant challenge for effective modeling, transfer, and control.
Furthermore, current SVS models often fail to generate singing voices rich in
stylistic nuances for unseen singers. To address these challenges, we introduce
TCSinger, the first zero-shot SVS model for style transfer across cross-lingual
speech and singing styles, along with multi-level style control. Specifically,
TCSinger proposes three primary modules: 1) the clustering style encoder
employs a clustering vector quantization model to stably condense style
information into a compact latent space; 2) the Style and Duration Language
Model (S\&D-LM) concurrently predicts style information and phoneme duration,
which benefits both; 3) the style adaptive decoder uses a novel mel-style
adaptive normalization method to generate singing voices with enhanced details.
Experimental results show that TCSinger outperforms all baseline models in
synthesis quality, singer similarity, and style controllability across various
tasks, including zero-shot style transfer, multi-level style control,
cross-lingual style transfer, and speech-to-singing style transfer. Singing
voice samples can be accessed at https://tcsinger.github.io/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multi-FAct: Assessing Factuality of Multilingual LLMs using FActScore 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.18045v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.18045v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sheikh Shafayat, Eunsu Kim, Juhyun Oh, Alice Oh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Evaluating the factuality of long-form large language model (LLM)-generated
text is an important challenge. Recently there has been a surge of interest in
factuality evaluation for English, but little is known about the factuality
evaluation of multilingual LLMs, specially when it comes to long-form
generation. %This paper systematically evaluates multilingual LLMs' factual
accuracy across languages and geographic regions. We introduce a simple
pipeline for multilingual factuality evaluation, by applying FActScore (Min et
al., 2023) for diverse languages. In addition to evaluating multilingual
factual generation, we evaluate the factual accuracy of long-form text
generation in topics that reflect regional diversity. We also examine the
feasibility of running the FActScore pipeline using non-English Wikipedia and
provide comprehensive guidelines on multilingual factual evaluation for
regionally diverse topics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Latte: Latent Attention for Linear Time <span class="highlight-title">Transformer</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.17512v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.17512v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rares Dolga, Marius Cobzarenco, David Barber
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The time complexity of the standard attention mechanism in transformers
scales quadratically with sequence length. We propose a probabilistic framework
for attention, enabling us to derive a novel low-rank linear
re-parameterisation of both bidirectional and causal cases, based on defining a
latent variable model. Our method can be seamlessly integrated as a drop-in
replacement for the standard attention mechanism. Additionally, this framework
provides a natural extension for combining local standard attention with our
global linear attention. This approach allows us to extend the context length
of existing large pre-trained models with only a few additional training steps.
The resulting ``Latte Transformer'' achieves performance comparable to standard
attention and other state-of-the-art models, while maintaining linear time and
memory complexity, along with constant-time next-token prediction during
inference.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Twists, Humps, and Pebbles: Multilingual Speech Recognition Models
  Exhibit Gender Performance Gaps <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.17954v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.17954v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Giuseppe Attanasio, Beatrice Savoldi, Dennis Fucci, Dirk Hovy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current automatic speech recognition (ASR) models are designed to be used
across many languages and tasks without substantial changes. However, this
broad language coverage hides performance gaps within languages, for example,
across genders. Our study systematically evaluates the performance of two
widely used multilingual ASR models on three datasets, encompassing 19
languages from eight language families and two speaking conditions. Our
findings reveal clear gender disparities, with the advantaged group varying
across languages and models. Surprisingly, those gaps are not explained by
acoustic or lexical properties. However, probing internal model states reveals
a correlation with gendered performance gap. That is, the easier it is to
distinguish speaker gender in a language using probes, the more the gap
reduces, favoring female speakers. Our results show that gender disparities
persist even in state-of-the-art models. Our findings have implications for the
improvement of multilingual ASR systems, underscoring the importance of
accessibility to training data and nuanced evaluation to predict and mitigate
gender gaps. We release all code and artifacts at
https://github.com/g8a9/multilingual-asr-gender-gap.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024. Code and artifacts at
  https://github.com/g8a9/multilingual-asr-gender-gap</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Conversational Feedback in Scripted versus Spontaneous Dialogues: A
  Comparative Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.15656v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.15656v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ildikó Pilán, Laurent Prévot, Hendrik Buschmeier, Pierre Lison
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scripted dialogues such as movie and TV subtitles constitute a widespread
source of training data for conversational NLP models. However, there are
notable linguistic differences between these dialogues and spontaneous
interactions, especially regarding the occurrence of communicative feedback
such as backchannels, acknowledgments, or clarification requests. This paper
presents a quantitative analysis of such feedback phenomena in both subtitles
and spontaneous conversations. Based on conversational data spanning eight
languages and multiple genres, we extract lexical statistics, classifications
from a dialogue act tagger, expert annotations and labels derived from a
fine-tuned Large Language Model (LLM). Our main empirical findings are that (1)
communicative feedback is markedly less frequent in subtitles than in
spontaneous dialogues and (2) subtitles contain a higher proportion of negative
feedback. We also show that dialogues generated by standard LLMs lie much
closer to scripted dialogues than spontaneous interactions in terms of
communicative feedback.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Updated version for SIGdial 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ miniCTX: Neural Theorem Proving with (Long-)Contexts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.03350v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.03350v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiewen Hu, Thomas Zhu, Sean Welleck
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Real-world formal theorem proving often depends on a wealth of context,
including definitions, lemmas, comments, file structure, and other information.
We introduce miniCTX, which tests a model's ability to prove formal
mathematical theorems that depend on new context that is not seen during
training. miniCTX contains theorems sourced from real Lean projects and
textbooks, each associated with a context that can span tens of thousands of
tokens. Models are tasked with proving a theorem given access to code from the
theorem's repository, which contains context that is needed for the proof. As a
baseline for miniCTX, we tested fine-tuning and prompting methods that
condition theorem proving on preceding context. Both approaches substantially
outperform traditional methods that rely solely on state information. We found
that this ability to use context is not captured by previous benchmarks such as
miniF2F. Alongside miniCTX, we offer ntp-toolkit for automatically extracting
and annotating theorem proving data, making it easy to add new projects into
miniCTX to ensure that contexts are not seen during training. miniCTX offers a
challenging and realistic evaluation of neural theorem provers.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Compositional Hardness of Code in Large Language Models -- A
  Probabilistic Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18028v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18028v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yotam Wolf, Binyamin Rothberg, Dorin Shteyman, Amnon Shashua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A common practice in large language model (LLM) usage for complex analytical
tasks such as code generation, is to sample a solution for the entire task
within the model's context window. Previous works have shown that subtask
decomposition within the model's context (chain of thought), is beneficial for
solving such tasks. In this work, we point a limitation of LLMs' ability to
perform several sub-tasks within the same context window - an in-context
hardness of composition, pointing to an advantage for distributing a decomposed
problem in a multi-agent system of LLMs. The hardness of composition is
quantified by a generation complexity metric, i.e., the number of LLM
generations required to sample at least one correct solution. We find a gap
between the generation complexity of solving a compositional problem within the
same context relative to distributing it among multiple agents, that increases
exponentially with the solution's length. We prove our results theoretically
and demonstrate them empirically.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evaluating Automatic Metrics with Incremental Machine Translation
  Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.03277v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.03277v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guojun Wu, Shay B. Cohen, Rico Sennrich
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a dataset comprising commercial machine translations, gathered
weekly over six years across 12 translation directions. Since human A/B testing
is commonly used, we assume commercial systems improve over time, which enables
us to evaluate machine translation (MT) metrics based on their preference for
more recent translations. Our study not only confirms several prior findings,
such as the advantage of neural metrics over non-neural ones, but also explores
the debated issue of how MT quality affects metric reliability--an
investigation that smaller datasets in previous research could not sufficiently
explore. Overall, our research demonstrates the dataset's value as a testbed
for metric evaluation. We release our code at https://github.com/gjwubyron/Evo
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on
  Graphs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.07103v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.07103v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bowen Jin, Chulin Xie, Jiawei Zhang, Kashob Kumar Roy, Yu Zhang, Zheng Li, Ruirui Li, Xianfeng Tang, Suhang Wang, Yu Meng, Jiawei Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs), while exhibiting exceptional performance,
suffer from hallucinations, especially on knowledge-intensive tasks. Existing
works propose to augment LLMs with individual text units retrieved from
external knowledge corpora to alleviate the issue. However, in many domains,
texts are interconnected (e.g., academic papers in a bibliographic graph are
linked by citations and co-authorships) which form a (text-attributed) graph.
The knowledge in such graphs is encoded not only in single texts/nodes but also
in their associated connections. To facilitate the research of augmenting LLMs
with graphs, we manually construct a Graph Reasoning Benchmark dataset called
GRBench, containing 1,740 questions that can be answered with the knowledge
from 10 domain graphs. Then, we propose a simple and effective framework called
Graph Chain-of-thought (Graph-CoT) to augment LLMs with graphs by encouraging
LLMs to reason on the graph iteratively. Each Graph-CoT iteration consists of
three sub-steps: LLM reasoning, LLM-graph interaction, and graph execution. We
conduct systematic experiments with three LLM backbones on GRBench, where
Graph-CoT outperforms the baselines consistently. The code is available at
https://github.com/PeterGriffinJin/Graph-CoT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages. Code: https://github.com/PeterGriffinJin/Graph-CoT</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Distilling Instruction-following Abilities of Large Language Models with
  Task-aware Curriculum Planning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.13448v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.13448v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuanhao Yue, Chengyu Wang, Jun Huang, Peng Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Instruction tuning aims to align large language models (LLMs) with
open-domain instructions and human-preferred responses. While several studies
have explored autonomous approaches to distilling and annotating instructions
from powerful proprietary LLMs, such as ChatGPT, they often neglect the impact
of the distributions and characteristics of tasks, together with the varying
difficulty of instructions in training sets. This oversight can lead to
imbalanced knowledge capabilities and poor generalization powers of student
LLMs. To address these challenges, we introduce Task-Aware Curriculum Planning
for Instruction Refinement (TAPIR), a multi-round distillation framework that
utilizes an oracle LLM to select instructions that are difficult for a student
LLM to follow. To balance the student's capabilities, task distributions in
training sets are adjusted with responses automatically refined according to
their corresponding tasks. In addition, by incorporating curriculum planning,
our approach systematically escalates the difficulty levels of tasks,
progressively enhancing the student LLM's capabilities. We rigorously evaluate
TAPIR using several widely recognized benchmarks (such as AlpacaEval 2.0,
MT-Bench, etc.) and multiple student LLMs. Empirical results demonstrate that
student LLMs, trained with our method and less training data, outperform larger
instruction-tuned models and strong distillation baselines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>emnlp 2024 findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Systematic <span class="highlight-title">Survey</span> and Critical <span class="highlight-title">Review</span> on Evaluating Large Language
  Models: Challenges, Limitations, and Recommendations <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.04069v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.04069v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Md Tahmid Rahman Laskar, Sawsan Alqahtani, M Saiful Bari, Mizanur Rahman, Mohammad Abdullah Matin Khan, Haidar Khan, Israt Jahan, Amran Bhuiyan, Chee Wei Tan, Md Rizwan Parvez, Enamul Hoque, Shafiq Joty, Jimmy Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have recently gained significant attention due
to their remarkable capabilities in performing diverse tasks across various
domains. However, a thorough evaluation of these models is crucial before
deploying them in real-world applications to ensure they produce reliable
performance. Despite the well-established importance of evaluating LLMs in the
community, the complexity of the evaluation process has led to varied
evaluation setups, causing inconsistencies in findings and interpretations. To
address this, we systematically review the primary challenges and limitations
causing these inconsistencies and unreliable evaluations in various steps of
LLM evaluation. Based on our critical review, we present our perspectives and
recommendations to ensure LLM evaluations are reproducible, reliable, and
robust.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024 (Main Conference)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Large Language Models on Graphs: A Comprehensive <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.02783v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.02783v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bowen Jin, Gang Liu, Chi Han, Meng Jiang, Heng Ji, Jiawei Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs), such as GPT4 and LLaMA, are creating
significant advancements in natural language processing, due to their strong
text encoding/decoding ability and newly found emergent capability (e.g.,
reasoning). While LLMs are mainly designed to process pure texts, there are
many real-world scenarios where text data is associated with rich structure
information in the form of graphs (e.g., academic networks, and e-commerce
networks) or scenarios where graph data is paired with rich textual information
(e.g., molecules with descriptions). Besides, although LLMs have shown their
pure text-based reasoning ability, it is underexplored whether such ability can
be generalized to graphs (i.e., graph-based reasoning). In this paper, we
provide a systematic review of scenarios and techniques related to large
language models on graphs. We first summarize potential scenarios of adopting
LLMs on graphs into three categories, namely pure graphs, text-attributed
graphs, and text-paired graphs. We then discuss detailed techniques for
utilizing LLMs on graphs, including LLM as Predictor, LLM as Encoder, and LLM
as Aligner, and compare the advantages and disadvantages of different schools
of models. Furthermore, we discuss the real-world applications of such methods
and summarize open-source codes and benchmark datasets. Finally, we conclude
with potential future research directions in this fast-growing field. The
related source can be found at
https://github.com/PeterGriffinJin/Awesome-Language-Model-on-Graphs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tradeoffs Between Alignment and Helpfulness in Language Models with
  Representation Engineering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.16332v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.16332v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yotam Wolf, Noam Wies, Dorin Shteyman, Binyamin Rothberg, Yoav Levine, Amnon Shashua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language model alignment has become an important component of AI safety,
allowing safe interactions between humans and language models, by enhancing
desired behaviors and inhibiting undesired ones. It is often done by tuning the
model or inserting preset aligning prompts. Recently, representation
engineering, a method which alters the model's behavior via changing its
representations post-training, was shown to be effective in aligning LLMs (Zou
et al., 2023a). Representation engineering yields gains in alignment oriented
tasks such as resistance to adversarial attacks and reduction of social biases,
but was also shown to cause a decrease in the ability of the model to perform
basic tasks. In this paper we study the tradeoff between the increase in
alignment and decrease in helpfulness of the model. We propose a theoretical
framework which provides bounds for these two quantities, and demonstrate their
relevance empirically. First, we find that under the conditions of our
framework, alignment can be guaranteed with representation engineering, and at
the same time that helpfulness is harmed in the process. Second, we show that
helpfulness is harmed quadratically with the norm of the representation
engineering vector, while the alignment increases linearly with it, indicating
a regime in which it is efficient to use representation engineering. We
validate our findings empirically, and chart the boundaries to the usefulness
of representation engineering for alignment.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Eliciting In-Context Learning in Vision-Language Models for Videos
  Through Curated Data Distributional Properties <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.17041v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.17041v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Keunwoo Peter Yu, Zheyuan Zhang, Fengyuan Hu, Shane Storks, Joyce Chai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A major reason behind the recent success of large language models (LLMs) is
their \textit{in-context learning} capability, which makes it possible to
rapidly adapt them to downstream text-based tasks by prompting them with a
small number of relevant demonstrations. While large vision-language models
(VLMs) have recently been developed for tasks requiring both text and images,
they largely lack in-context learning over visual information, especially in
understanding and generating text about videos. In this work, we implement
\textbf{E}mergent \textbf{I}n-context \textbf{Le}arning on \textbf{V}ideos
(\eilev{}), a novel training paradigm that induces in-context learning over
video and text by capturing key properties of pre-training data found by prior
work to be essential for in-context learning in transformers. In our
experiments, we show that \eilev-trained models outperform other off-the-shelf
VLMs in few-shot video narration for novel, rare actions. Furthermore, we
demonstrate that these key properties of bursty distributions, skewed marginal
distributions, and dynamic meaning each contribute to varying degrees to VLMs'
in-context learning capability in narrating procedural videos. Our results,
analysis, and \eilev{}-trained models yield numerous insights about the
emergence of in-context learning over video and text, creating a foundation for
future work to optimize and scale VLMs for open-domain video understanding and
reasoning. Our code and demo are available at
\url{https://github.com/yukw777/EILEV}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, LaTeX; Accepted to EMNLP 2024 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Does Instruction Tuning Make LLMs More Consistent? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.15206v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.15206v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Constanza Fierro, Jiaang Li, Anders Søgaard
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The purpose of instruction tuning is enabling zero-shot performance, but
instruction tuning has also been shown to improve chain-of-thought reasoning
and value alignment (Si et al., 2023). Here we consider the impact on
$\textit{consistency}$, i.e., the sensitivity of language models to small
perturbations in the input. We compare 10 instruction-tuned LLaMA models to the
original LLaMA-7b model and show that almost across-the-board they become more
consistent, both in terms of their representations and their predictions in
zero-shot and downstream tasks. We explain these improvements through
mechanistic analyses of factual recall.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>We need to run extra experiments to ensure some of the claims in the
  paper are fully correct</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RGD: Multi-LLM Based Agent Debugger via Refinement and Generation
  Guidance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01242v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01242v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haolin Jin, Zechao Sun, Huaming Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have shown incredible potential in code
generation tasks, and recent research in prompt engineering have enhanced LLMs'
understanding of textual information. However, ensuring the accuracy of
generated code often requires extensive testing and validation by programmers.
While LLMs can typically generate code based on task descriptions, their
accuracy remains limited, especially for complex tasks that require a deeper
understanding of both the problem statement and the code generation process.
This limitation is primarily due to the LLMs' need to simultaneously comprehend
text and generate syntactically and semantically correct code, without having
the capability to automatically refine the code. In real-world software
development, programmers rarely produce flawless code in a single attempt based
on the task description alone, they rely on iterative feedback and debugging to
refine their programs. Inspired by this process, we introduce a novel
architecture of LLM-based agents for code generation and automatic debugging:
Refinement and Guidance Debugging (RGD). The RGD framework is a multi-LLM-based
agent debugger that leverages three distinct LLM agents-Guide Agent, Debug
Agent, and Feedback Agent. RGD decomposes the code generation task into
multiple steps, ensuring a clearer workflow and enabling iterative code
refinement based on self-reflection and feedback. Experimental results
demonstrate that RGD exhibits remarkable code generation capabilities,
achieving state-of-the-art performance with a 9.8% improvement on the HumanEval
dataset and a 16.2% improvement on the MBPP dataset compared to the
state-of-the-art approaches and traditional direct prompting approaches. We
highlight the effectiveness of the RGD framework in enhancing LLMs' ability to
generate and refine code autonomously.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Synthetic continued <span class="highlight-title">pretrain</span>ing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.07431v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.07431v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zitong Yang, Neil Band, Shuangping Li, Emmanuel Candès, Tatsunori Hashimoto
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pretraining on large-scale, unstructured internet text enables language
models to acquire a significant amount of world knowledge. However, this
knowledge acquisition is data-inefficient--to learn a given fact, models must
be trained on hundreds to thousands of diverse representations of it. This
poses a challenge when adapting a pretrained model to a small corpus of
domain-specific documents, where each fact may appear rarely or only once. We
propose to bridge this gap with synthetic continued pretraining: using the
small domain-specific corpus to synthesize a large corpus more amenable to
learning, and then performing continued pretraining on the synthesized corpus.
We instantiate this proposal with EntiGraph, a synthetic data augmentation
algorithm that extracts salient entities from the source documents and then
generates diverse text by drawing connections between the sampled entities.
Synthetic continued pretraining with EntiGraph enables a language model to
answer questions and follow generic instructions related to the source
documents without access to them. If, instead, the source documents are
available at inference time, we show that the knowledge acquired through our
approach compounds with retrieval-augmented generation. To better understand
these results, we build a simple mathematical model of EntiGraph, and show how
synthetic data augmentation can "rearrange" knowledge to enable more
data-efficient learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Updated organization of experimental results and methods
  introduction. Released the dataset and model weights artifact</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The SIFo Benchmark: Investigating the Sequential Instruction Following
  Ability of Large Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19999v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19999v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyi Chen, Baohao Liao, Jirui Qi, Panagiotis Eustratiadis, Christof Monz, Arianna Bisazza, Maarten de Rijke
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Following multiple instructions is a crucial ability for large language
models (LLMs). Evaluating this ability comes with significant challenges: (i)
limited coherence between multiple instructions, (ii) positional bias where the
order of instructions affects model performance, and (iii) a lack of
objectively verifiable tasks. To address these issues, we introduce a benchmark
designed to evaluate models' abilities to follow multiple instructions through
sequential instruction following (SIFo) tasks. In SIFo, the successful
completion of multiple instructions is verifiable by examining only the final
instruction. Our benchmark evaluates instruction following using four tasks
(text modification, question answering, mathematics, and security rules), each
assessing different aspects of sequential instruction following. Our evaluation
of popular LLMs, both closed-source and open-source, shows that more recent and
larger models significantly outperform their older and smaller counterparts on
the SIFo tasks, validating the benchmark's effectiveness. All models struggle
with following sequences of instructions, hinting at an important lack of
robustness of today's language models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multilingual Synopses of Movie Narratives: A <span class="highlight-title">Dataset</span> for Vision-Language
  Story Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13092v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13092v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yidan Sun, Jianfei Yu, Boyang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Story video-text alignment, a core task in computational story understanding,
aims to align video clips with corresponding sentences in their descriptions.
However, progress on the task has been held back by the scarcity of manually
annotated video-text correspondence and the heavy concentration on English
narrations of Hollywood movies. To address these issues, in this paper, we
construct a large-scale multilingual video story dataset named Multilingual
Synopses of Movie Narratives (M-SYMON), containing 13,166 movie summary videos
from 7 languages, as well as manual annotation of fine-grained video-text
correspondences for 101.5 hours of video. Training on the human annotated data
from SyMoN outperforms the SOTA methods by 15.7 and 16.2 percentage points on
Clip Accuracy and Sentence IoU scores, respectively, demonstrating the
effectiveness of the annotations. As benchmarks for future research, we create
6 baseline approaches with different multilingual training strategies, compare
their performance in both intra-lingual and cross-lingual setups, exemplifying
the challenges of multilingual video-text alignment. The dataset is released
at: https://github.com/insundaycathy/M-SyMoN
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Potential and Challenges of Evaluating Attitudes, Opinions, and
  Values in Large Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11096v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11096v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bolei Ma, Xinpeng Wang, Tiancheng Hu, Anna-Carolina Haensch, Michael A. Hedderich, Barbara Plank, Frauke Kreuter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in Large Language Models (LLMs) have sparked wide interest in
validating and comprehending the human-like cognitive-behavioral traits LLMs
may capture and convey. These cognitive-behavioral traits include typically
Attitudes, Opinions, Values (AOVs). However, measuring AOVs embedded within
LLMs remains opaque, and different evaluation methods may yield different
results. This has led to a lack of clarity on how different studies are related
to each other and how they can be interpreted. This paper aims to bridge this
gap by providing a comprehensive overview of recent works on the evaluation of
AOVs in LLMs. Moreover, we survey related approaches in different stages of the
evaluation pipeline in these works. By doing so, we address the potential and
challenges with respect to understanding the model, human-AI alignment, and
downstream application in social sciences. Finally, we provide practical
insights into evaluation methods, model enhancement, and interdisciplinary
collaboration, thereby contributing to the evolving landscape of evaluating
AOVs in LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Language models and brains align due to more than next-word prediction
  and word-level information <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2212.00596v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2212.00596v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gabriele Merlin, Mariya Toneva
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pretrained language models have been shown to significantly predict brain
recordings of people comprehending language. Recent work suggests that the
prediction of the next word is a key mechanism that contributes to this
alignment. What is not yet understood is whether prediction of the next word is
necessary for this observed alignment or simply sufficient, and whether there
are other shared mechanisms or information that are similarly important. In
this work, we take a step towards understanding the reasons for brain alignment
via two simple perturbations in popular pretrained language models. These
perturbations help us design contrasts that can control for different types of
information. By contrasting the brain alignment of these differently perturbed
models, we show that improvements in alignment with brain recordings are due to
more than improvements in next-word prediction and word-level information.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Lexically Grounded Subword Segmentation <span class="chip">EMNLP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13560v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13560v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jindřich Libovický, Jindřich Helcl
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present three innovations in tokenization and subword segmentation. First,
we propose to use unsupervised morphological analysis with Morfessor as
pre-tokenization. Second, we present an algebraic method for obtaining subword
embeddings grounded in a word embedding space. Based on that, we design a novel
subword segmentation algorithm that uses the embeddings, ensuring that the
procedure considers lexical meaning. Third, we introduce an efficient
segmentation algorithm based on a subword bigram model that can be initialized
with the lexically aware segmentation method to avoid using Morfessor and large
embedding tables at inference time. We evaluate the proposed approaches using
two intrinsic metrics and measure their performance on two downstream tasks:
part-of-speech tagging and machine translation. Our experiments show
significant improvements in the morphological plausibility of the segmentation
when evaluated using segmentation precision on morpheme boundaries and improved
R\'enyi efficiency in 8 languages. Although the proposed tokenization methods
do not have a large impact on automatic translation quality, we observe
consistent performance gains in the arguably more morphological task of
part-of-speech tagging.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Camera-ready, EMNLP Main conf</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Model Internals-based Answer Attribution for Trustworthy
  Retrieval-Augmented Generation <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13663v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13663v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jirui Qi, Gabriele Sarti, Raquel Fernández, Arianna Bisazza
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ensuring the verifiability of model answers is a fundamental challenge for
retrieval-augmented generation (RAG) in the question answering (QA) domain.
Recently, self-citation prompting was proposed to make large language models
(LLMs) generate citations to supporting documents along with their answers.
However, self-citing LLMs often struggle to match the required format, refer to
non-existent sources, and fail to faithfully reflect LLMs' context usage
throughout the generation. In this work, we present MIRAGE --Model
Internals-based RAG Explanations -- a plug-and-play approach using model
internals for faithful answer attribution in RAG applications. MIRAGE detects
context-sensitive answer tokens and pairs them with retrieved documents
contributing to their prediction via saliency methods. We evaluate our proposed
approach on a multilingual extractive QA dataset, finding high agreement with
human answer attribution. On open-ended QA, MIRAGE achieves citation quality
and efficiency comparable to self-citation while also allowing for a
finer-grained control of attribution parameters. Our qualitative evaluation
highlights the faithfulness of MIRAGE's attributions and underscores the
promising application of model internals for RAG answer attribution.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024 Main Conference. Code and data released at
  https://github.com/Betswish/MIRAGE</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LongLLaVA: Scaling Multi-modal LLMs to 1000 Images Efficiently via a
  Hybrid Architecture 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02889v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02889v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xidong Wang, Dingjie Song, Shunian Chen, Chen Zhang, Benyou Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Expanding the long-context capabilities of Multi-modal Large Language
Models~(MLLMs) is crucial for video understanding, high-resolution image
understanding, and multi-modal agents. This involves a series of systematic
optimizations, including model architecture, data construction and training
strategy, particularly addressing challenges such as \textit{degraded
performance with more images} and \textit{high computational costs}. In this
paper, we adapt the model architecture to a hybrid of Mamba and Transformer
blocks, approach data construction with both temporal and spatial dependencies
among multiple images and employ a progressive training strategy. The released
model \textbf{LongLLaVA}~(\textbf{Long}-Context \textbf{L}arge
\textbf{L}anguage \textbf{a}nd \textbf{V}ision \textbf{A}ssistant) is the first
hybrid MLLM, which achieved a better balance between efficiency and
effectiveness. LongLLaVA not only achieves competitive results across various
benchmarks, but also maintains high throughput and low memory consumption.
Especially, it could process nearly a thousand images on a single A100 80GB
GPU, showing promising application prospects for a wide range of tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 9 figures, 9 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Prompt</span>Wizard: Task-Aware <span class="highlight-title">Prompt</span> Optimization Framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.18369v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.18369v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eshaan Agarwal, Joykirat Singh, Vivek Dani, Raghav Magazine, Tanuja Ganu, Akshay Nambi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have transformed AI across diverse domains, with
prompting being central to their success in guiding model outputs. However,
manual prompt engineering is both labor-intensive and domain-specific,
necessitating the need for automated solutions. We introduce PromptWizard, a
novel, fully automated framework for discrete prompt optimization, utilizing a
self-evolving, self-adapting mechanism. Through a feedback-driven critique and
synthesis process, PromptWizard achieves an effective balance between
exploration and exploitation, iteratively refining both prompt instructions and
in-context examples to generate human-readable, task-specific prompts. This
guided approach systematically improves prompt quality, resulting in superior
performance across 45 tasks. PromptWizard excels even with limited training
data, smaller LLMs, and various LLM architectures. Additionally, our cost
analysis reveals a substantial reduction in API calls, token usage, and overall
cost, demonstrating PromptWizard's efficiency, scalability, and advantages over
existing prompt optimization strategies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On the Adversarial Vulnerability of Pairwise Evaluation Using Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12319v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12319v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hawon Jeong, ChaeHun Park, Jimin Hong, Jaegul Choo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pairwise evaluation using large language models (LLMs) is widely adopted for
evaluating generated outputs. However, the reliability of LLM evaluators is
often compromised by their biased preferences, such as favoring verbosity and
an authoritative tone. In this work, we find that the evaluation setup itself
can significantly amplify these biases, where pairwise evaluators exhibit more
undesirable tendencies than pointwise evaluators. Our analysis further reveals
that even when pairwise evaluators make incorrect judgments, they can still
accurately identify shortcomings in low-quality outputs. As a simple remedy, we
also propose incorporating pointwise reasoning into pairwise evaluation.
Experimental results show that our method improves the performance of pairwise
evaluators on adversarial samples across various models. We hope our findings
encourage further exploration into the reliability of LLM evaluators.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Generalists vs. Specialists: Evaluating Large Language Models for Urdu 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.04459v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.04459v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Samee Arif, Abdul Hameed Azeemi, Agha Ali Raza, Awais Athar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we compare general-purpose models, GPT-4-Turbo and Llama-3-8b,
with special-purpose models--XLM-Roberta-large, mT5-large, and Llama-3-8b--that
have been fine-tuned on specific tasks. We focus on seven classification and
seven generation tasks to evaluate the performance of these models on Urdu
language. Urdu has 70 million native speakers, yet it remains underrepresented
in Natural Language Processing (NLP). Despite the frequent advancements in
Large Language Models (LLMs), their performance in low-resource languages,
including Urdu, still needs to be explored. We also conduct a human evaluation
for the generation tasks and compare the results with the evaluations performed
by GPT-4-Turbo, Llama-3-8b and Claude 3.5 Sonnet. We find that special-purpose
models consistently outperform general-purpose models across various tasks. We
also find that the evaluation done by GPT-4-Turbo for generation tasks aligns
more closely with human evaluation compared to the evaluation the evaluation
done by Llama-3-8b. This paper contributes to the NLP community by providing
insights into the effectiveness of general and specific-purpose LLMs for
low-resource languages.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficient Temporal Extrapolation of Multimodal Large Language Models
  with Temporal Grounding Bridge <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.16050v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.16050v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxuan Wang, Yueqian Wang, Pengfei Wu, Jianxin Liang, Dongyan Zhao, Yang Liu, Zilong Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite progress in multimodal large language models (MLLMs), the challenge
of interpreting long-form videos in response to linguistic queries persists,
largely due to the inefficiency in temporal grounding and limited pre-trained
context window size. In this work, we introduce Temporal Grounding Bridge
(TGB), a novel framework that bootstraps MLLMs with advanced temporal grounding
capabilities and broadens their contextual scope. Our framework significantly
enhances the temporal capabilities of current MLLMs through three key
innovations: an efficient multi-span temporal grounding algorithm applied to
low-dimension temporal features projected from flow; a multimodal length
extrapolation training paradigm that utilizes low-dimension temporal features
to extend the training context window size; and a bootstrapping framework that
bridges our model with pluggable MLLMs without requiring annotation. We
validate TGB across seven video benchmarks and demonstrate substantial
performance improvements compared with prior MLLMs. Notably, our model,
initially trained on sequences of four frames, effectively handles sequences up
to 16 longer without sacrificing performance, highlighting its scalability and
effectiveness in real-world applications. Our code is publicly available at
https://github.com/bigai-nlco/VideoTGB
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear at EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Wavelet<span class="highlight-title">GPT</span>: Wavelets Meet Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.12924v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.12924v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Prateek Verma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have ushered in a new wave of artificial
intelligence advancements impacting every scientific field and discipline. They
are trained on a simple objective: to predict the next token given the previous
context. We live in a world where most of the data around us, e.g., text,
audio, and music, has a multi-scale structure associated with it. This paper
infuses LLMs with traditional signal processing ideas, namely wavelets, during
pre-training to take advantage of the structure. Without adding \textbf{any
extra parameters} to a GPT-style LLM architecture, we achieve the same
pre-training performance almost twice as fast in text, raw audio, and symbolic
music. This is achieved by imposing a structure on intermediate embeddings.
When trained for the same number of training steps, we achieve significant
gains in performance, which is comparable to pre-training a larger neural
architecture. Our architecture allows every next token prediction access to
intermediate embeddings at different temporal resolutions in every Transformer
decoder block. This work will hopefully pave the way for incorporating
multi-rate signal processing ideas into traditional LLM pre-training. Further,
we showcase pushing model performance by improving internal structure instead
of just going after scale.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Comprehensive <span class="highlight-title">Survey</span> of Hallucination in Large Language, Image, Video
  and Audio Foundation Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.09589v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.09589v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pranab Sahoo, Prabhash Meharia, Akash Ghosh, Sriparna Saha, Vinija Jain, Aman Chadha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid advancement of foundation models (FMs) across language, image,
audio, and video domains has shown remarkable capabilities in diverse tasks.
However, the proliferation of FMs brings forth a critical challenge: the
potential to generate hallucinated outputs, particularly in high-stakes
applications. The tendency of foundation models to produce hallucinated content
arguably represents the biggest hindrance to their widespread adoption in
real-world scenarios, especially in domains where reliability and accuracy are
paramount. This survey paper presents a comprehensive overview of recent
developments that aim to identify and mitigate the problem of hallucination in
FMs, spanning text, image, video, and audio modalities. By synthesizing recent
advancements in detecting and mitigating hallucination across various
modalities, the paper aims to provide valuable insights for researchers,
developers, and practitioners. Essentially, it establishes a clear framework
encompassing definition, taxonomy, and detection strategies for addressing
hallucination in multimodal foundation models, laying the foundation for future
research in this pivotal area.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information
  Funneling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.02069v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.02069v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zefan Cai, Yichi Zhang, Bofei Gao, Yuliang Liu, Tianyu Liu, Keming Lu, Wayne Xiong, Yue Dong, Baobao Chang, Junjie Hu, Wen Xiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this study, we investigate whether attention-based information flow inside
large language models (LLMs) is aggregated through noticeable patterns for long
context processing. Our observations reveal that LLMs aggregate information
through Pyramidal Information Funneling where attention is scattering widely in
lower layers, progressively consolidating within specific contexts, and
ultimately focusing on critical tokens (a.k.a massive activation or attention
sink) in higher layers. Motivated by these insights, we developed PyramidKV, a
novel and effective KV cache compression method. This approach dynamically
adjusts the KV cache size across different layers, allocating more cache in
lower layers and less in higher ones, diverging from traditional methods that
maintain a uniform KV cache size. Our experimental evaluations, utilizing the
LongBench benchmark, show that PyramidKV matches the performance of models with
a full KV cache while retaining only 12% of the KV cache, thus significantly
reducing memory usage. In scenarios emphasizing memory efficiency, where only
0.7% of the KV cache is maintained, PyramidKV surpasses other KV cache
compression techniques, achieving up to a 20.5 absolute accuracy improvement on
TREC dataset. In the Needle-in-a-Haystack experiment, PyramidKV outperforms
competing methods in maintaining long-context comprehension in LLMs; notably,
retaining just 128 KV cache entries enables the LLAMA-3-70B model to achieve
100% Acc. performance, matching that of a full KV cache.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Self-Constructed Context Decompilation with Fined-grained Alignment
  Enhancement <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17233v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17233v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunlong Feng, Dechuan Teng, Yang Xu, Honglin Mu, Xiao Xu, Libo Qin, Qingfu Zhu, Wanxiang Che
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Decompilation transforms compiled code back into a high-level programming
language for analysis when source code is unavailable. Previous work has
primarily focused on enhancing decompilation performance by increasing the
scale of model parameters or training data for pre-training. Based on the
characteristics of the decompilation task, we propose two methods: (1) Without
fine-tuning, the Self-Constructed Context Decompilation (sc$^2$dec) method
recompiles the LLM's decompilation results to construct pairs for in-context
learning, helping the model improve decompilation performance. (2) Fine-grained
Alignment Enhancement (FAE), which meticulously aligns assembly code with
source code at the statement level by leveraging debugging information, is
employed during the fine-tuning phase to achieve further improvements in
decompilation. By integrating these two methods, we achieved a Re-Executability
performance improvement of approximately 3.90% on the Decompile-Eval benchmark,
establishing a new state-of-the-art performance of 52.41%. The code, data, and
models are available at https://github.com/AlongWY/sccdec.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring language relations through syntactic distances and geographic
  proximity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.18430v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.18430v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Juan De Gregorio, Raúl Toral, David Sánchez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Languages are grouped into families that share common linguistic traits.
While this approach has been successful in understanding genetic relations
between diverse languages, more analyses are needed to accurately quantify
their relatedness, especially in less studied linguistic levels such as syntax.
Here, we explore linguistic distances using series of parts of speech (POS)
extracted from the Universal Dependencies dataset. Within an
information-theoretic framework, we show that employing POS trigrams maximizes
the possibility of capturing syntactic variations while being at the same time
compatible with the amount of available data. Linguistic connections are then
established by assessing pairwise distances based on the POS distributions.
Intriguingly, our analysis reveals definite clusters that correspond to well
known language families and groups, with exceptions explained by distinct
morphological typologies. Furthermore, we obtain a significant correlation
between language similarity and geographic distance, which underscores the
influence of spatial proximity on language kinships.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>39 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Systematic Analysis of Large Language Models as Soft Reasoners: The
  Case of Syllogistic Inferences 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11341v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11341v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Leonardo Bertolazzi, Albert Gatt, Raffaella Bernardi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The reasoning abilities of Large Language Models (LLMs) are becoming a
central focus of study in NLP. In this paper, we consider the case of
syllogistic reasoning, an area of deductive reasoning studied extensively in
logic and cognitive psychology. Previous research has shown that pre-trained
LLMs exhibit reasoning biases, such as $\textit{content effects}$, avoid
answering that $\textit{no conclusion follows}$, display human-like
difficulties, and struggle with multi-step reasoning. We contribute to this
research line by systematically investigating the effects of chain-of-thought
reasoning, in-context learning (ICL), and supervised fine-tuning (SFT) on
syllogistic reasoning, considering syllogisms with conclusions that support or
violate world knowledge, as well as ones with multiple premises. Crucially, we
go beyond the standard focus on accuracy, with an in-depth analysis of the
conclusions generated by the models. Our results suggest that the behavior of
pre-trained LLMs can be explained by heuristics studied in cognitive science
and that both ICL and SFT improve model performance on valid inferences,
although only the latter mitigates most reasoning biases without harming model
consistency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Optimized Speculative Sampling for GPU Hardware Accelerators <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11016v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11016v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dominik Wagner, Seanie Lee, Ilja Baumann, Philipp Seeberger, Korbinian Riedhammer, Tobias Bocklet
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we optimize speculative sampling for parallel hardware
accelerators to improve sampling speed. We notice that substantial portions of
the intermediate matrices necessary for speculative sampling can be computed
concurrently. This allows us to distribute the workload across multiple GPU
threads, enabling simultaneous operations on matrix segments within thread
blocks. This results in profiling time improvements ranging from 6% to 13%
relative to the baseline implementation, without compromising accuracy. To
further accelerate speculative sampling, probability distributions
parameterized by softmax are approximated by sigmoid. This approximation
approach results in significantly greater relative improvements in profiling
time, ranging from 37% to 94%, with a minor decline in accuracy. We conduct
extensive experiments on both automatic speech recognition and summarization
tasks to validate the effectiveness of our optimization methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ StablePT: Towards Stable <span class="highlight-title">Prompt</span>ing for Few-shot Learning via Input
  Separation <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.19335v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.19335v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoming Liu, Chen Liu, Zhaohan Zhang, Chengzhengxu Li, Longtian Wang, Yu Lan, Chao Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models have shown their ability to become effective few-shot
learners with prompting, revolutionizing the paradigm of learning with data
scarcity. However, this approach largely depends on the quality of prompt
initialization, and always exhibits large variability among different runs.
Such property makes prompt tuning highly unreliable and vulnerable to poorly
constructed prompts, which limits its extension to more real-world
applications. To tackle this issue, we propose to treat the hard prompt and
soft prompt as separate inputs to mitigate noise brought by the prompt
initialization. Furthermore, we optimize soft prompts with contrastive learning
for utilizing class-aware information in the training process to maintain model
performance. Experimental results demonstrate that \sysname outperforms
state-of-the-art methods by 6.97% in accuracy and reduces the standard
deviation by 1.92 on average. Furthermore, extensive experiments underscore its
robustness and stability across 8 datasets covering various tasks. Codes are
available at https://github.com/lccc0528/Stable/tree/main.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Sound <span class="chip" style="font-size: 60%">19</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Convolutional Variational Autoencoders for Spectrogram Compression in
  Automatic Speech Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02560v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02560v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Olga Yakovenko, Ivan Bondarenko
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For many Automatic Speech Recognition (ASR) tasks audio features as
spectrograms show better results than Mel-frequency Cepstral Coefficients
(MFCC), but in practice they are hard to use due to a complex dimensionality of
a feature space. The following paper presents an alternative approach towards
generating compressed spectrogram representation, based on Convolutional
Variational Autoencoders (VAE). A Convolutional VAE model was trained on a
subsample of the LibriSpeech dataset to reconstruct short fragments of audio
spectrograms (25 ms) from a 13-dimensional embedding. The trained model for a
40-dimensional (300 ms) embedding was used to generate features for corpus of
spoken commands on the GoogleSpeechCommands dataset. Using the generated
features an ASR system was built and compared to the model with MFCC features.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Theory and Practice of Natural Computing 9th International
  Conference, TPNC 2020, Taoyuan, Taiwan, 2020, Proceedings 9</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CoLLAP: Contrastive Long-form Language-Audio <span class="highlight-title">Pretrain</span>ing with Musical
  Temporal Structure Augmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02271v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02271v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junda Wu, Warren Li, Zachary Novack, Amit Namburi, Carol Chen, Julian McAuley
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modeling temporal characteristics plays a significant role in the
representation learning of audio waveform. We propose Contrastive Long-form
Language-Audio Pretraining (\textbf{CoLLAP}) to significantly extend the
perception window for both the input audio (up to 5 minutes) and the language
descriptions (exceeding 250 words), while enabling contrastive learning across
modalities and temporal dynamics. Leveraging recent Music-LLMs to generate
long-form music captions for full-length songs, augmented with musical temporal
structures, we collect 51.3K audio-text pairs derived from the large-scale
AudioSet training dataset, where the average audio length reaches 288 seconds.
We propose a novel contrastive learning architecture that fuses language
representations with structured audio representations by segmenting each song
into clips and extracting their embeddings. With an attention mechanism, we
capture multimodal temporal correlations, allowing the model to automatically
weigh and enhance the final fusion score for improved contrastive alignment.
Finally, we develop two variants of the CoLLAP model with different types of
backbone language models. Through comprehensive experiments on multiple
long-form music-text retrieval datasets, we demonstrate consistent performance
improvement in retrieval accuracy compared with baselines. We also show the
pretrained CoLLAP models can be transferred to various music information
retrieval tasks, with heterogeneous long-form multimodal contexts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Pilot Study of Applying Sequence-to-Sequence Voice Conversion to
  Evaluate the Intelligibility of L2 Speech Using a Native Speaker's Shadowings <span class="chip">SC 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02239v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02239v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haopeng Geng, Daisuke Saito, Nobuaki Minematsu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Utterances by L2 speakers can be unintelligible due to mispronunciation and
improper prosody. In computer-aided language learning systems, textual feedback
is often provided using a speech recognition engine. However, an ideal form of
feedback for L2 speakers should be so fine-grained that it enables them to
detect and diagnose unintelligible parts of L2 speakers' utterances. Inspired
by language teachers who correct students' pronunciation through a
voice-to-voice process, this pilot study utilizes a unique semi-parallel
dataset composed of non-native speakers' (L2) reading aloud, shadowing of
native speakers (L1) and their script-shadowing utterances. We explore the
technical possibility of replicating the process of an L1 speaker's shadowing
L2 speech using Voice Conversion techniques, to create a virtual shadower
system. Experimental results demonstrate the feasibility of the VC system in
simulating L1's shadowing behavior. The output of the virtual shadower system
shows a reasonable similarity to the real L1 shadowing utterances in both
linguistic and acoustic aspects.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by APSIPA ASC 2024. arXiv admin note: text overlap with
  arXiv:2409.11742</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SoundMorpher: Perceptually-Uniform Sound Morphing with Diffusion Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02144v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02144v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinlei Niu, Jing Zhang, Charles Patrick Martin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present SoundMorpher, a sound morphing method that generates perceptually
uniform morphing trajectories using a diffusion model. Traditional sound
morphing methods models the intractable relationship between morph factor and
perception of the stimuli for resulting sounds under a linear assumption, which
oversimplifies the complex nature of sound perception and limits their morph
quality. In contrast, SoundMorpher explores an explicit proportional mapping
between the morph factor and the perceptual stimuli of morphed sounds based on
Mel-spectrogram. This approach enables smoother transitions between
intermediate sounds and ensures perceptually consistent transformations, which
can be easily extended to diverse sound morphing tasks. Furthermore, we present
a set of quantitative metrics to comprehensively assess sound morphing systems
based on three objective criteria, namely, correspondence, perceptual
intermediateness, and smoothness. We provide extensive experiments to
demonstrate the effectiveness and versatility of SoundMorpher in real-world
scenarios, highlighting its potential impact on various applications such as
creative music composition, film post-production and interactive audio
technologies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MDSGen: Fast and Efficient Masked Diffusion Temporal-Aware <span class="highlight-title">Transformer</span>s
  for Open-Domain Sound Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02130v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02130v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Trung X. Pham, Tri Ton, Chang D. Yoo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce MDSGen, a novel framework for vision-guided open-domain sound
generation optimized for model parameter size, memory consumption, and
inference speed. This framework incorporates two key innovations: (1) a
redundant video feature removal module that filters out unnecessary visual
information, and (2) a temporal-aware masking strategy that leverages temporal
context for enhanced audio generation accuracy. In contrast to existing
resource-heavy Unet-based models, MDSGen employs denoising masked diffusion
transformers, facilitating efficient generation without reliance on pre-trained
diffusion models. Evaluated on the benchmark VGGSound dataset, our smallest
model (5M parameters) achieves 97.9% alignment accuracy, using 172x fewer
parameters, 371% less memory, and offering 36x faster inference than the
current 860M-parameter state-of-the-art model (93.9% accuracy). The larger
model (131M parameters) reaches nearly 99% accuracy while requiring 6.5x fewer
parameters. These results highlight the scalability and effectiveness of our
approach.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages, 16 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Disentangling Textual and Acoustic Features of Neural Speech
  Representations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03037v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03037v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hosein Mohebbi, Grzegorz Chrupała, Willem Zuidema, Afra Alishahi, Ivan Titov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural speech models build deeply entangled internal representations, which
capture a variety of features (e.g., fundamental frequency, loudness, syntactic
category, or semantic content of a word) in a distributed encoding. This
complexity makes it difficult to track the extent to which such representations
rely on textual and acoustic information, or to suppress the encoding of
acoustic features that may pose privacy risks (e.g., gender or speaker
identity) in critical, real-world applications. In this paper, we build upon
the Information Bottleneck principle to propose a disentanglement framework
that separates complex speech representations into two distinct components: one
encoding content (i.e., what can be transcribed as text) and the other encoding
acoustic features relevant to a given downstream task. We apply and evaluate
our framework to emotion recognition and speaker identification downstream
tasks, quantifying the contribution of textual and acoustic features at each
model layer. Additionally, we explore the application of our disentanglement
framework as an attribution method to identify the most salient speech frame
representations from both the textual and acoustic perspectives.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ People are poorly equipped to detect AI-powered voice clones 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03791v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03791v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sarah Barrington, Hany Farid
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As generative AI continues its ballistic trajectory, everything from text to
audio, image, and video generation continues to improve in mimicking
human-generated content. Through a series of perceptual studies, we report on
the realism of AI-generated voices in terms of identity matching and
naturalness. We find human participants cannot reliably identify short
recordings (less than 20 seconds) of AI-generated voices. Specifically,
participants mistook the identity of an AI-voice for its real counterpart 80%
of the time, and correctly identified a voice as AI-generated only 60% of the
time. In all cases, performance is independent of the demographics of the
speaker or listener.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Continual Test-time Adaptation for End-to-end Speech Recognition on
  Noisy Speech <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11064v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11064v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guan-Ting Lin, Wei-Ping Huang, Hung-yi Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep Learning-based end-to-end Automatic Speech Recognition (ASR) has made
significant strides but still struggles with performance on out-of-domain
samples due to domain shifts in real-world scenarios. Test-Time Adaptation
(TTA) methods address this issue by adapting models using test samples at
inference time. However, current ASR TTA methods have largely focused on
non-continual TTA, which limits cross-sample knowledge learning compared to
continual TTA. In this work, we first propose a Fast-slow TTA framework for ASR
that leverages the advantage of continual and non-continual TTA. Following this
framework, we introduce Dynamic SUTA (DSUTA), an entropy-minimization-based
continual TTA method for ASR. To enhance DSUTA robustness for time-varying
data, we design a dynamic reset strategy to automatically detect domain shifts
and reset the model, making it more effective at handling multi-domain data.
Our method demonstrates superior performance on various noisy ASR datasets,
outperforming both non-continual and continual TTA baselines while maintaining
robustness to domain changes without requiring domain boundary information.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TCSinger: Zero-Shot Singing Voice Synthesis with Style Transfer and
  Multi-Level Style Control <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15977v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15977v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu Zhang, Ziyue Jiang, Ruiqi Li, Changhao Pan, Jinzheng He, Rongjie Huang, Chuxin Wang, Zhou Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Zero-shot singing voice synthesis (SVS) with style transfer and style control
aims to generate high-quality singing voices with unseen timbres and styles
(including singing method, emotion, rhythm, technique, and pronunciation) from
audio and text prompts. However, the multifaceted nature of singing styles
poses a significant challenge for effective modeling, transfer, and control.
Furthermore, current SVS models often fail to generate singing voices rich in
stylistic nuances for unseen singers. To address these challenges, we introduce
TCSinger, the first zero-shot SVS model for style transfer across cross-lingual
speech and singing styles, along with multi-level style control. Specifically,
TCSinger proposes three primary modules: 1) the clustering style encoder
employs a clustering vector quantization model to stably condense style
information into a compact latent space; 2) the Style and Duration Language
Model (S\&D-LM) concurrently predicts style information and phoneme duration,
which benefits both; 3) the style adaptive decoder uses a novel mel-style
adaptive normalization method to generate singing voices with enhanced details.
Experimental results show that TCSinger outperforms all baseline models in
synthesis quality, singer similarity, and style controllability across various
tasks, including zero-shot style transfer, multi-level style control,
cross-lingual style transfer, and speech-to-singing style transfer. Singing
voice samples can be accessed at https://tcsinger.github.io/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SonicSense: Object Perception from In-Hand Acoustic Vibration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17932v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17932v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaxun Liu, Boyuan Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce SonicSense, a holistic design of hardware and software to enable
rich robot object perception through in-hand acoustic vibration sensing. While
previous studies have shown promising results with acoustic sensing for object
perception, current solutions are constrained to a handful of objects with
simple geometries and homogeneous materials, single-finger sensing, and mixing
training and testing on the same objects. SonicSense enables container
inventory status differentiation, heterogeneous material prediction, 3D shape
reconstruction, and object re-identification from a diverse set of 83
real-world objects. Our system employs a simple but effective heuristic
exploration policy to interact with the objects as well as end-to-end
learning-based algorithms to fuse vibration signals to infer object properties.
Our framework underscores the significance of in-hand acoustic vibration
sensing in advancing robot tactile perception.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Our project website is at: http://generalroboticslab.com/SonicSense</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ESC: Efficient Speech Coding with Cross-Scale Residual Vector Quantized
  <span class="highlight-title">Transformer</span>s <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.19441v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.19441v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuzhe Gu, Enmao Diao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural speech codecs aim to compress input signals into minimal bits while
maintaining content quality in a low-latency manner. However, existing neural
codecs often trade model complexity for reconstruction performance. These
codecs primarily use convolutional blocks for feature transformation, which are
not inherently suited for capturing the local redundancies in speech signals.
To compensate, they require either adversarial discriminators or a large number
of model parameters to enhance audio quality. In response to these challenges,
we introduce the Efficient Speech Codec (ESC), a lightweight,
parameter-efficient speech codec based on a cross-scale residual vector
quantization scheme and transformers. Our model employs mirrored hierarchical
window transformer blocks and performs step-wise decoding from coarse-to-fine
feature representations. To enhance bitrate efficiency, we propose a novel
combination of vector quantization techniques along with a pre-training
paradigm. Extensive experiments demonstrate that ESC can achieve high-fidelity
speech reconstruction with significantly lower model complexity, making it a
promising alternative to existing convolutional audio codecs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Wavelet<span class="highlight-title">GPT</span>: Wavelets Meet Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.12924v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.12924v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Prateek Verma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have ushered in a new wave of artificial
intelligence advancements impacting every scientific field and discipline. They
are trained on a simple objective: to predict the next token given the previous
context. We live in a world where most of the data around us, e.g., text,
audio, and music, has a multi-scale structure associated with it. This paper
infuses LLMs with traditional signal processing ideas, namely wavelets, during
pre-training to take advantage of the structure. Without adding \textbf{any
extra parameters} to a GPT-style LLM architecture, we achieve the same
pre-training performance almost twice as fast in text, raw audio, and symbolic
music. This is achieved by imposing a structure on intermediate embeddings.
When trained for the same number of training steps, we achieve significant
gains in performance, which is comparable to pre-training a larger neural
architecture. Our architecture allows every next token prediction access to
intermediate embeddings at different temporal resolutions in every Transformer
decoder block. This work will hopefully pave the way for incorporating
multi-rate signal processing ideas into traditional LLM pre-training. Further,
we showcase pushing model performance by improving internal structure instead
of just going after scale.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Comprehensive <span class="highlight-title">Survey</span> of Hallucination in Large Language, Image, Video
  and Audio Foundation Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.09589v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.09589v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pranab Sahoo, Prabhash Meharia, Akash Ghosh, Sriparna Saha, Vinija Jain, Aman Chadha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid advancement of foundation models (FMs) across language, image,
audio, and video domains has shown remarkable capabilities in diverse tasks.
However, the proliferation of FMs brings forth a critical challenge: the
potential to generate hallucinated outputs, particularly in high-stakes
applications. The tendency of foundation models to produce hallucinated content
arguably represents the biggest hindrance to their widespread adoption in
real-world scenarios, especially in domains where reliability and accuracy are
paramount. This survey paper presents a comprehensive overview of recent
developments that aim to identify and mitigate the problem of hallucination in
FMs, spanning text, image, video, and audio modalities. By synthesizing recent
advancements in detecting and mitigating hallucination across various
modalities, the paper aims to provide valuable insights for researchers,
developers, and practitioners. Essentially, it establishes a clear framework
encompassing definition, taxonomy, and detection strategies for addressing
hallucination in multimodal foundation models, laying the foundation for future
research in this pivotal area.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Melody Is All You Need For Music Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.20196v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.20196v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shaopeng Wei, Manzhen Wei, Haoyu Wang, Yu Zhao, Gang Kou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present the Melody Guided Music Generation (MMGen) model, the first novel
approach using melody to guide the music generation that, despite a pretty
simple method and extremely limited resources, achieves excellent performance.
Specifically, we first align the melody with audio waveforms and their
associated descriptions using the multimodal alignment module. Subsequently, we
condition the diffusion module on the learned melody representations. This
allows MMGen to generate music that matches the style of the provided audio
while also producing music that reflects the content of the given text
description. To address the scarcity of high-quality data, we construct a
multi-modal dataset, MusicSet, which includes melody, text, and audio, and will
be made publicly available. We conduct extensive experiments which demonstrate
the superiority of the proposed model both in terms of experimental metrics and
actual performance quality.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 1 figure, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GALD-SE: Guided Anisotropic Lightweight Diffusion for Efficient Speech
  Enhancement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15101v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15101v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengzhong Wang, Jianjun Gu, Dingding Yao, Zelin Qiu, Junfeng Li, Yonghong Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Speech enhancement is designed to enhance the intelligibility and quality of
speech across diverse noise conditions. Recently, diffusion model has gained
lots of attention in speech enhancement area, achieving competitive results.
Current diffusion-based methods blur the signal with isotropic Gaussian noise
and recover clean speech from the prior. However, these methods often suffer
from a substantial computational burden. We argue that the inefficiency
partially stems from the oversight that speech enhancement is not purely a
generative task; it primarily involves noise reduction and completion of
missing information, while the clean clues in the original mixture do not need
to be regenerated. In this paper, we propose a method that introduces noise
with anisotropic guidance during the diffusion process, allowing the neural
network to preserve clean clues within noisy recordings. This approach
substantially reduces computational complexity while exhibiting robustness
against various forms of noise interference and speech distortion. Experiments
demonstrate that the proposed method achieves state-of-the-art results with
only approximately 4.5 million parameters, a number significantly lower than
that required by other diffusion methods. This effectively narrows the model
size disparity between diffusion-based and predictive speech enhancement
approaches. Additionally, the proposed method performs well in very noisy
scenarios, demonstrating its potential for applications in highly challenging
environments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>We make reassessment and update the author list. All authors have
  approved this version of the manuscript</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PSLM: Parallel Generation of Text and Speech with LLMs for Low-Latency
  Spoken Dialogue Systems <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12428v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12428v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kentaro Mitsui, Koh Mitsuda, Toshiaki Wakatsuki, Yukiya Hono, Kei Sawada
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal language models that process both text and speech have a potential
for applications in spoken dialogue systems. However, current models face two
major challenges in response generation latency: (1) generating a spoken
response requires the prior generation of a written response, and (2) speech
sequences are significantly longer than text sequences. This study addresses
these issues by extending the input and output sequences of the language model
to support the parallel generation of text and speech. Our experiments on
spoken question answering tasks demonstrate that our approach improves latency
while maintaining the quality of response content. Additionally, we show that
latency can be further reduced by generating speech in multiple sequences. Demo
samples are available at https://rinnakk.github.io/research/publications/PSLM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 6 figures, 4 tables, accepted for Findings of EMNLP 2024.
  Demo samples: https://rinnakk.github.io/research/publications/PSLM</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficient Sparse Coding with the Adaptive Locally Competitive Algorithm
  for Speech Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.08188v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.08188v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Soufiyan Bahadi, Eric Plourde, Jean Rouat
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Researchers are exploring novel computational paradigms such as sparse coding
and neuromorphic computing to bridge the efficiency gap between the human brain
and conventional computers in complex tasks. A key area of focus is
neuromorphic audio processing. While the Locally Competitive Algorithm has
emerged as a promising solution for sparse coding, offering potential for
real-time and low-power processing on neuromorphic hardware, its applications
in neuromorphic speech classification have not been thoroughly studied. The
Adaptive Locally Competitive Algorithm builds upon the Locally Competitive
Algorithm by dynamically adjusting the modulation parameters of the filter bank
to fine-tune the filters' sensitivity. This adaptability enhances lateral
inhibition, improving reconstruction quality, sparsity, and convergence time,
which is crucial for real-time applications. This paper demonstrates the
potential of the Locally Competitive Algorithm and its adaptive variant as
robust feature extractors for neuromorphic speech classification. Results show
that the Locally Competitive Algorithm achieves better speech classification
accuracy at the expense of higher power consumption compared to the LAUSCHER
cochlea model used for benchmarking. On the other hand, the Adaptive Locally
Competitive Algorithm mitigates this power consumption issue without
compromising the accuracy. The dynamic power consumption is reduced to a range
of 4 to 13 milliwatts on neuromorphic hardware, three orders of magnitude less
than setups using Graphics Processing Units. These findings position the
Adaptive Locally Competitive Algorithm as a compelling solution for efficient
speech classification systems, promising substantial advancements in balancing
speech classification accuracy and power efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Self-consistent context aware conformer transducer for speech
  recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.06592v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.06592v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Konstantin Kolokolov, Pavel Pekichev, Karthik Raghunathan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a novel neural network module that adeptly handles recursive
data flow in neural network architectures. At its core, this module employs a
self-consistent approach where a set of recursive equations is solved
iteratively, halting when the difference between two consecutive iterations
falls below a defined threshold. Leveraging this mechanism, we construct a new
neural network architecture, an extension of the conformer transducer, which
enriches automatic speech recognition systems with a stream of contextual
information. Our method notably improves the accuracy of recognizing rare words
without adversely affecting the word error rate for common vocabulary. We
investigate the improvement in accuracy for these uncommon words using our
novel model, both independently and in conjunction with shallow fusion with a
context language model. Our findings reveal that the combination of both
approaches can improve the accuracy of detecting rare words by as much as 4.5
times. Our proposed self-consistent recursive methodology is versatile and
adaptable, compatible with many recently developed encoders, and has the
potential to drive model improvements in speech recognition and beyond.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SSDM: Scalable Speech Dysfluency Modeling <span class="chip">NeurIPS</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.16221v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.16221v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiachen Lian, Xuanru Zhou, Zoe Ezzes, Jet Vonk, Brittany Morin, David Baquirin, Zachary Mille, Maria Luisa Gorno Tempini, Gopala Krishna Anumanchipalli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Speech dysfluency modeling is the core module for spoken language learning,
and speech therapy. However, there are three challenges. First, current
state-of-the-art solutions\cite{lian2023unconstrained-udm,
lian-anumanchipalli-2024-towards-hudm} suffer from poor scalability. Second,
there is a lack of a large-scale dysfluency corpus. Third, there is not an
effective learning framework. In this paper, we propose \textit{SSDM: Scalable
Speech Dysfluency Modeling}, which (1) adopts articulatory gestures as scalable
forced alignment; (2) introduces connectionist subsequence aligner (CSA) to
achieve dysfluency alignment; (3) introduces a large-scale simulated dysfluency
corpus called Libri-Dys; and (4) develops an end-to-end system by leveraging
the power of large language models (LLMs). We expect SSDM to serve as a
standard in the area of dysfluency modeling. Demo is available at
\url{https://berkeley-speech-group.github.io/SSDM/}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>2024 NeurIPS</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Speech Processing <span class="chip" style="font-size: 60%">23</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Convolutional Variational Autoencoders for Spectrogram Compression in
  Automatic Speech Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02560v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02560v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Olga Yakovenko, Ivan Bondarenko
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For many Automatic Speech Recognition (ASR) tasks audio features as
spectrograms show better results than Mel-frequency Cepstral Coefficients
(MFCC), but in practice they are hard to use due to a complex dimensionality of
a feature space. The following paper presents an alternative approach towards
generating compressed spectrogram representation, based on Convolutional
Variational Autoencoders (VAE). A Convolutional VAE model was trained on a
subsample of the LibriSpeech dataset to reconstruct short fragments of audio
spectrograms (25 ms) from a 13-dimensional embedding. The trained model for a
40-dimensional (300 ms) embedding was used to generate features for corpus of
spoken commands on the GoogleSpeechCommands dataset. Using the generated
features an ASR system was built and compared to the model with MFCC features.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Theory and Practice of Natural Computing 9th International
  Conference, TPNC 2020, Taoyuan, Taiwan, 2020, Proceedings 9</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ NTU-NPU System for Voice Privacy 2024 Challenge 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02371v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02371v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nikita Kuzmin, Hieu-Thi Luong, Jixun Yao, Lei Xie, Kong Aik Lee, Eng Siong Chng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we describe our submissions for the Voice Privacy Challenge
2024. Rather than proposing a novel speech anonymization system, we enhance the
provided baselines to meet all required conditions and improve evaluated
metrics. Specifically, we implement emotion embedding and experiment with WavLM
and ECAPA2 speaker embedders for the B3 baseline. Additionally, we compare
different speaker and prosody anonymization techniques. Furthermore, we
introduce Mean Reversion F0 for B5, which helps to enhance privacy without a
loss in utility. Finally, we explore disentanglement models, namely $\beta$-VAE
and NaturalSpeech3 FACodec.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>System description for VPC 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ State-of-the-art Embeddings with Video-free Segmentation of the Source
  VoxCeleb Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02364v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02364v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sara Barahona, Ladislav Mošner, Themos Stafylakis, Oldřich Plchot, Junyi Peng, Lukáš Burget, Jan Černocký
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we refine and validate our method for training speaker
embedding extractors using weak annotations. More specifically, we use only the
audio stream of the source VoxCeleb videos and the names of the celebrities
without knowing the time intervals in which they appear in the recording. We
experiment with hyperparameters and embedding extractors based on ResNet and
WavLM. We show that the method achieves state-of-the-art results in speaker
verification, comparable with training the extractors in a standard supervised
way on the VoxCeleb dataset. We also extend it by considering segments
belonging to unknown speakers appearing alongside the celebrities, which are
typically being discarded. Overall, our approach can be used for directly
training state-of-the-art embedding extractors or as an alternative to the
VoxCeleb-like pipeline for dataset creation without needing image modality.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CoLLAP: Contrastive Long-form Language-Audio <span class="highlight-title">Pretrain</span>ing with Musical
  Temporal Structure Augmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02271v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02271v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junda Wu, Warren Li, Zachary Novack, Amit Namburi, Carol Chen, Julian McAuley
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modeling temporal characteristics plays a significant role in the
representation learning of audio waveform. We propose Contrastive Long-form
Language-Audio Pretraining (\textbf{CoLLAP}) to significantly extend the
perception window for both the input audio (up to 5 minutes) and the language
descriptions (exceeding 250 words), while enabling contrastive learning across
modalities and temporal dynamics. Leveraging recent Music-LLMs to generate
long-form music captions for full-length songs, augmented with musical temporal
structures, we collect 51.3K audio-text pairs derived from the large-scale
AudioSet training dataset, where the average audio length reaches 288 seconds.
We propose a novel contrastive learning architecture that fuses language
representations with structured audio representations by segmenting each song
into clips and extracting their embeddings. With an attention mechanism, we
capture multimodal temporal correlations, allowing the model to automatically
weigh and enhance the final fusion score for improved contrastive alignment.
Finally, we develop two variants of the CoLLAP model with different types of
backbone language models. Through comprehensive experiments on multiple
long-form music-text retrieval datasets, we demonstrate consistent performance
improvement in retrieval accuracy compared with baselines. We also show the
pretrained CoLLAP models can be transferred to various music information
retrieval tasks, with heterogeneous long-form multimodal contexts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Pilot Study of Applying Sequence-to-Sequence Voice Conversion to
  Evaluate the Intelligibility of L2 Speech Using a Native Speaker's Shadowings <span class="chip">SC 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02239v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02239v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haopeng Geng, Daisuke Saito, Nobuaki Minematsu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Utterances by L2 speakers can be unintelligible due to mispronunciation and
improper prosody. In computer-aided language learning systems, textual feedback
is often provided using a speech recognition engine. However, an ideal form of
feedback for L2 speakers should be so fine-grained that it enables them to
detect and diagnose unintelligible parts of L2 speakers' utterances. Inspired
by language teachers who correct students' pronunciation through a
voice-to-voice process, this pilot study utilizes a unique semi-parallel
dataset composed of non-native speakers' (L2) reading aloud, shadowing of
native speakers (L1) and their script-shadowing utterances. We explore the
technical possibility of replicating the process of an L1 speaker's shadowing
L2 speech using Voice Conversion techniques, to create a virtual shadower
system. Experimental results demonstrate the feasibility of the VC system in
simulating L1's shadowing behavior. The output of the virtual shadower system
shows a reasonable similarity to the real L1 shadowing utterances in both
linguistic and acoustic aspects.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by APSIPA ASC 2024. arXiv admin note: text overlap with
  arXiv:2409.11742</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SoundMorpher: Perceptually-Uniform Sound Morphing with Diffusion Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02144v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02144v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinlei Niu, Jing Zhang, Charles Patrick Martin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present SoundMorpher, a sound morphing method that generates perceptually
uniform morphing trajectories using a diffusion model. Traditional sound
morphing methods models the intractable relationship between morph factor and
perception of the stimuli for resulting sounds under a linear assumption, which
oversimplifies the complex nature of sound perception and limits their morph
quality. In contrast, SoundMorpher explores an explicit proportional mapping
between the morph factor and the perceptual stimuli of morphed sounds based on
Mel-spectrogram. This approach enables smoother transitions between
intermediate sounds and ensures perceptually consistent transformations, which
can be easily extended to diverse sound morphing tasks. Furthermore, we present
a set of quantitative metrics to comprehensively assess sound morphing systems
based on three objective criteria, namely, correspondence, perceptual
intermediateness, and smoothness. We provide extensive experiments to
demonstrate the effectiveness and versatility of SoundMorpher in real-world
scenarios, highlighting its potential impact on various applications such as
creative music composition, film post-production and interactive audio
technologies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MDSGen: Fast and Efficient Masked Diffusion Temporal-Aware <span class="highlight-title">Transformer</span>s
  for Open-Domain Sound Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02130v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02130v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Trung X. Pham, Tri Ton, Chang D. Yoo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce MDSGen, a novel framework for vision-guided open-domain sound
generation optimized for model parameter size, memory consumption, and
inference speed. This framework incorporates two key innovations: (1) a
redundant video feature removal module that filters out unnecessary visual
information, and (2) a temporal-aware masking strategy that leverages temporal
context for enhanced audio generation accuracy. In contrast to existing
resource-heavy Unet-based models, MDSGen employs denoising masked diffusion
transformers, facilitating efficient generation without reliance on pre-trained
diffusion models. Evaluated on the benchmark VGGSound dataset, our smallest
model (5M parameters) achieves 97.9% alignment accuracy, using 172x fewer
parameters, 371% less memory, and offering 36x faster inference than the
current 860M-parameter state-of-the-art model (93.9% accuracy). The larger
model (131M parameters) reaches nearly 99% accuracy while requiring 6.5x fewer
parameters. These results highlight the scalability and effectiveness of our
approach.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages, 16 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Disentangling Textual and Acoustic Features of Neural Speech
  Representations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03037v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03037v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hosein Mohebbi, Grzegorz Chrupała, Willem Zuidema, Afra Alishahi, Ivan Titov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural speech models build deeply entangled internal representations, which
capture a variety of features (e.g., fundamental frequency, loudness, syntactic
category, or semantic content of a word) in a distributed encoding. This
complexity makes it difficult to track the extent to which such representations
rely on textual and acoustic information, or to suppress the encoding of
acoustic features that may pose privacy risks (e.g., gender or speaker
identity) in critical, real-world applications. In this paper, we build upon
the Information Bottleneck principle to propose a disentanglement framework
that separates complex speech representations into two distinct components: one
encoding content (i.e., what can be transcribed as text) and the other encoding
acoustic features relevant to a given downstream task. We apply and evaluate
our framework to emotion recognition and speaker identification downstream
tasks, quantifying the contribution of textual and acoustic features at each
model layer. Additionally, we explore the application of our disentanglement
framework as an attribution method to identify the most salient speech frame
representations from both the textual and acoustic perspectives.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FastAdaSP: Multitask-Adapted Efficient Inference for Large Speech
  Language Model <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03007v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03007v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yichen Lu, Jiaqi Song, Chao-Han Huck Yang, Shinji Watanabe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this study, we aim to explore Multitask Speech Language Model (SpeechLM)
efficient inference via token reduction. Unlike other modalities such as vision
or text, speech has unique temporal dependencies, making previous efficient
inference works on other modalities not directly applicable. Furthermore,
methods for efficient SpeechLM inference on long sequence and sparse signals
remain largely unexplored. Then we propose FastAdaSP, a weighted token merging
framework specifically designed for various speech-related tasks to improve the
trade-off between efficiency and performance. Experimental results on WavLLM
and Qwen-Audio show that our method achieves the state-of-the-art (SOTA)
efficiency-performance trade-off compared with other baseline methods.
Specifically, FastAdaSP achieved 7x memory efficiency and 1.83x decoding
throughput without any degradation on tasks like Emotion Recognition (ER) and
Spoken Question Answering (SQA). The code will be available at
https://github.com/yichen14/FastAdaSP
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Industry Track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ People are poorly equipped to detect AI-powered voice clones 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03791v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03791v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sarah Barrington, Hany Farid
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As generative AI continues its ballistic trajectory, everything from text to
audio, image, and video generation continues to improve in mimicking
human-generated content. Through a series of perceptual studies, we report on
the realism of AI-generated voices in terms of identity matching and
naturalness. We find human participants cannot reliably identify short
recordings (less than 20 seconds) of AI-generated voices. Specifically,
participants mistook the identity of an AI-voice for its real counterpart 80%
of the time, and correctly identified a voice as AI-generated only 60% of the
time. In all cases, performance is independent of the demographics of the
speaker or listener.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Continual Test-time Adaptation for End-to-end Speech Recognition on
  Noisy Speech <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11064v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11064v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guan-Ting Lin, Wei-Ping Huang, Hung-yi Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep Learning-based end-to-end Automatic Speech Recognition (ASR) has made
significant strides but still struggles with performance on out-of-domain
samples due to domain shifts in real-world scenarios. Test-Time Adaptation
(TTA) methods address this issue by adapting models using test samples at
inference time. However, current ASR TTA methods have largely focused on
non-continual TTA, which limits cross-sample knowledge learning compared to
continual TTA. In this work, we first propose a Fast-slow TTA framework for ASR
that leverages the advantage of continual and non-continual TTA. Following this
framework, we introduce Dynamic SUTA (DSUTA), an entropy-minimization-based
continual TTA method for ASR. To enhance DSUTA robustness for time-varying
data, we design a dynamic reset strategy to automatically detect domain shifts
and reset the model, making it more effective at handling multi-domain data.
Our method demonstrates superior performance on various noisy ASR datasets,
outperforming both non-continual and continual TTA baselines while maintaining
robustness to domain changes without requiring domain boundary information.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TCSinger: Zero-Shot Singing Voice Synthesis with Style Transfer and
  Multi-Level Style Control <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15977v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15977v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu Zhang, Ziyue Jiang, Ruiqi Li, Changhao Pan, Jinzheng He, Rongjie Huang, Chuxin Wang, Zhou Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Zero-shot singing voice synthesis (SVS) with style transfer and style control
aims to generate high-quality singing voices with unseen timbres and styles
(including singing method, emotion, rhythm, technique, and pronunciation) from
audio and text prompts. However, the multifaceted nature of singing styles
poses a significant challenge for effective modeling, transfer, and control.
Furthermore, current SVS models often fail to generate singing voices rich in
stylistic nuances for unseen singers. To address these challenges, we introduce
TCSinger, the first zero-shot SVS model for style transfer across cross-lingual
speech and singing styles, along with multi-level style control. Specifically,
TCSinger proposes three primary modules: 1) the clustering style encoder
employs a clustering vector quantization model to stably condense style
information into a compact latent space; 2) the Style and Duration Language
Model (S\&D-LM) concurrently predicts style information and phoneme duration,
which benefits both; 3) the style adaptive decoder uses a novel mel-style
adaptive normalization method to generate singing voices with enhanced details.
Experimental results show that TCSinger outperforms all baseline models in
synthesis quality, singer similarity, and style controllability across various
tasks, including zero-shot style transfer, multi-level style control,
cross-lingual style transfer, and speech-to-singing style transfer. Singing
voice samples can be accessed at https://tcsinger.github.io/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SonicSense: Object Perception from In-Hand Acoustic Vibration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17932v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17932v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaxun Liu, Boyuan Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce SonicSense, a holistic design of hardware and software to enable
rich robot object perception through in-hand acoustic vibration sensing. While
previous studies have shown promising results with acoustic sensing for object
perception, current solutions are constrained to a handful of objects with
simple geometries and homogeneous materials, single-finger sensing, and mixing
training and testing on the same objects. SonicSense enables container
inventory status differentiation, heterogeneous material prediction, 3D shape
reconstruction, and object re-identification from a diverse set of 83
real-world objects. Our system employs a simple but effective heuristic
exploration policy to interact with the objects as well as end-to-end
learning-based algorithms to fuse vibration signals to infer object properties.
Our framework underscores the significance of in-hand acoustic vibration
sensing in advancing robot tactile perception.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Our project website is at: http://generalroboticslab.com/SonicSense</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ESC: Efficient Speech Coding with Cross-Scale Residual Vector Quantized
  <span class="highlight-title">Transformer</span>s <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.19441v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.19441v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuzhe Gu, Enmao Diao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural speech codecs aim to compress input signals into minimal bits while
maintaining content quality in a low-latency manner. However, existing neural
codecs often trade model complexity for reconstruction performance. These
codecs primarily use convolutional blocks for feature transformation, which are
not inherently suited for capturing the local redundancies in speech signals.
To compensate, they require either adversarial discriminators or a large number
of model parameters to enhance audio quality. In response to these challenges,
we introduce the Efficient Speech Codec (ESC), a lightweight,
parameter-efficient speech codec based on a cross-scale residual vector
quantization scheme and transformers. Our model employs mirrored hierarchical
window transformer blocks and performs step-wise decoding from coarse-to-fine
feature representations. To enhance bitrate efficiency, we propose a novel
combination of vector quantization techniques along with a pre-training
paradigm. Extensive experiments demonstrate that ESC can achieve high-fidelity
speech reconstruction with significantly lower model complexity, making it a
promising alternative to existing convolutional audio codecs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Wavelet<span class="highlight-title">GPT</span>: Wavelets Meet Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.12924v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.12924v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Prateek Verma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have ushered in a new wave of artificial
intelligence advancements impacting every scientific field and discipline. They
are trained on a simple objective: to predict the next token given the previous
context. We live in a world where most of the data around us, e.g., text,
audio, and music, has a multi-scale structure associated with it. This paper
infuses LLMs with traditional signal processing ideas, namely wavelets, during
pre-training to take advantage of the structure. Without adding \textbf{any
extra parameters} to a GPT-style LLM architecture, we achieve the same
pre-training performance almost twice as fast in text, raw audio, and symbolic
music. This is achieved by imposing a structure on intermediate embeddings.
When trained for the same number of training steps, we achieve significant
gains in performance, which is comparable to pre-training a larger neural
architecture. Our architecture allows every next token prediction access to
intermediate embeddings at different temporal resolutions in every Transformer
decoder block. This work will hopefully pave the way for incorporating
multi-rate signal processing ideas into traditional LLM pre-training. Further,
we showcase pushing model performance by improving internal structure instead
of just going after scale.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Comprehensive <span class="highlight-title">Survey</span> of Hallucination in Large Language, Image, Video
  and Audio Foundation Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.09589v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.09589v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pranab Sahoo, Prabhash Meharia, Akash Ghosh, Sriparna Saha, Vinija Jain, Aman Chadha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid advancement of foundation models (FMs) across language, image,
audio, and video domains has shown remarkable capabilities in diverse tasks.
However, the proliferation of FMs brings forth a critical challenge: the
potential to generate hallucinated outputs, particularly in high-stakes
applications. The tendency of foundation models to produce hallucinated content
arguably represents the biggest hindrance to their widespread adoption in
real-world scenarios, especially in domains where reliability and accuracy are
paramount. This survey paper presents a comprehensive overview of recent
developments that aim to identify and mitigate the problem of hallucination in
FMs, spanning text, image, video, and audio modalities. By synthesizing recent
advancements in detecting and mitigating hallucination across various
modalities, the paper aims to provide valuable insights for researchers,
developers, and practitioners. Essentially, it establishes a clear framework
encompassing definition, taxonomy, and detection strategies for addressing
hallucination in multimodal foundation models, laying the foundation for future
research in this pivotal area.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Melody Is All You Need For Music Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.20196v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.20196v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shaopeng Wei, Manzhen Wei, Haoyu Wang, Yu Zhao, Gang Kou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present the Melody Guided Music Generation (MMGen) model, the first novel
approach using melody to guide the music generation that, despite a pretty
simple method and extremely limited resources, achieves excellent performance.
Specifically, we first align the melody with audio waveforms and their
associated descriptions using the multimodal alignment module. Subsequently, we
condition the diffusion module on the learned melody representations. This
allows MMGen to generate music that matches the style of the provided audio
while also producing music that reflects the content of the given text
description. To address the scarcity of high-quality data, we construct a
multi-modal dataset, MusicSet, which includes melody, text, and audio, and will
be made publicly available. We conduct extensive experiments which demonstrate
the superiority of the proposed model both in terms of experimental metrics and
actual performance quality.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 1 figure, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GALD-SE: Guided Anisotropic Lightweight Diffusion for Efficient Speech
  Enhancement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15101v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15101v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengzhong Wang, Jianjun Gu, Dingding Yao, Zelin Qiu, Junfeng Li, Yonghong Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Speech enhancement is designed to enhance the intelligibility and quality of
speech across diverse noise conditions. Recently, diffusion model has gained
lots of attention in speech enhancement area, achieving competitive results.
Current diffusion-based methods blur the signal with isotropic Gaussian noise
and recover clean speech from the prior. However, these methods often suffer
from a substantial computational burden. We argue that the inefficiency
partially stems from the oversight that speech enhancement is not purely a
generative task; it primarily involves noise reduction and completion of
missing information, while the clean clues in the original mixture do not need
to be regenerated. In this paper, we propose a method that introduces noise
with anisotropic guidance during the diffusion process, allowing the neural
network to preserve clean clues within noisy recordings. This approach
substantially reduces computational complexity while exhibiting robustness
against various forms of noise interference and speech distortion. Experiments
demonstrate that the proposed method achieves state-of-the-art results with
only approximately 4.5 million parameters, a number significantly lower than
that required by other diffusion methods. This effectively narrows the model
size disparity between diffusion-based and predictive speech enhancement
approaches. Additionally, the proposed method performs well in very noisy
scenarios, demonstrating its potential for applications in highly challenging
environments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>We make reassessment and update the author list. All authors have
  approved this version of the manuscript</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PSLM: Parallel Generation of Text and Speech with LLMs for Low-Latency
  Spoken Dialogue Systems <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12428v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12428v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kentaro Mitsui, Koh Mitsuda, Toshiaki Wakatsuki, Yukiya Hono, Kei Sawada
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal language models that process both text and speech have a potential
for applications in spoken dialogue systems. However, current models face two
major challenges in response generation latency: (1) generating a spoken
response requires the prior generation of a written response, and (2) speech
sequences are significantly longer than text sequences. This study addresses
these issues by extending the input and output sequences of the language model
to support the parallel generation of text and speech. Our experiments on
spoken question answering tasks demonstrate that our approach improves latency
while maintaining the quality of response content. Additionally, we show that
latency can be further reduced by generating speech in multiple sequences. Demo
samples are available at https://rinnakk.github.io/research/publications/PSLM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 6 figures, 4 tables, accepted for Findings of EMNLP 2024.
  Demo samples: https://rinnakk.github.io/research/publications/PSLM</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Wanna Hear Your Voice: Adaptive, Effective, and Language-Agnostic
  Approach in Voice Extraction <span class="chip">ICASSP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00527v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00527v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        The Hieu Pham, Phuong Thanh Tran Nguyen, Xuan Tho Nguyen, Tan Dat Nguyen, Duc Dung Nguyen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The research on audio clue-based target speaker extraction (TSE) has mostly
focused on modeling the mixture and reference speech, achieving high
performance in English due to the availability of large datasets. However, less
attention has been given to the consistent properties of human speech across
languages. To bridge this gap, we introduce WHYV (Wanna Hear Your Voice), which
addresses the challenge of transferring TSE models from one language to another
without fine-tuning. In this work, we proposed a gating mechanism that be able
to modify specific frequencies based on the speaker's acoustic features. The
model achieves an SI-SDR of 17.3544 on clean English speech and 13.2032 on
clean speech mixed with Wham! noise, outperforming all other models in its
ability to adapt to different languages.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to ICASSP 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficient Sparse Coding with the Adaptive Locally Competitive Algorithm
  for Speech Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.08188v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.08188v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Soufiyan Bahadi, Eric Plourde, Jean Rouat
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Researchers are exploring novel computational paradigms such as sparse coding
and neuromorphic computing to bridge the efficiency gap between the human brain
and conventional computers in complex tasks. A key area of focus is
neuromorphic audio processing. While the Locally Competitive Algorithm has
emerged as a promising solution for sparse coding, offering potential for
real-time and low-power processing on neuromorphic hardware, its applications
in neuromorphic speech classification have not been thoroughly studied. The
Adaptive Locally Competitive Algorithm builds upon the Locally Competitive
Algorithm by dynamically adjusting the modulation parameters of the filter bank
to fine-tune the filters' sensitivity. This adaptability enhances lateral
inhibition, improving reconstruction quality, sparsity, and convergence time,
which is crucial for real-time applications. This paper demonstrates the
potential of the Locally Competitive Algorithm and its adaptive variant as
robust feature extractors for neuromorphic speech classification. Results show
that the Locally Competitive Algorithm achieves better speech classification
accuracy at the expense of higher power consumption compared to the LAUSCHER
cochlea model used for benchmarking. On the other hand, the Adaptive Locally
Competitive Algorithm mitigates this power consumption issue without
compromising the accuracy. The dynamic power consumption is reduced to a range
of 4 to 13 milliwatts on neuromorphic hardware, three orders of magnitude less
than setups using Graphics Processing Units. These findings position the
Adaptive Locally Competitive Algorithm as a compelling solution for efficient
speech classification systems, promising substantial advancements in balancing
speech classification accuracy and power efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Self-consistent context aware conformer transducer for speech
  recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.06592v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.06592v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Konstantin Kolokolov, Pavel Pekichev, Karthik Raghunathan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a novel neural network module that adeptly handles recursive
data flow in neural network architectures. At its core, this module employs a
self-consistent approach where a set of recursive equations is solved
iteratively, halting when the difference between two consecutive iterations
falls below a defined threshold. Leveraging this mechanism, we construct a new
neural network architecture, an extension of the conformer transducer, which
enriches automatic speech recognition systems with a stream of contextual
information. Our method notably improves the accuracy of recognizing rare words
without adversely affecting the word error rate for common vocabulary. We
investigate the improvement in accuracy for these uncommon words using our
novel model, both independently and in conjunction with shallow fusion with a
context language model. Our findings reveal that the combination of both
approaches can improve the accuracy of detecting rare words by as much as 4.5
times. Our proposed self-consistent recursive methodology is versatile and
adaptable, compatible with many recently developed encoders, and has the
potential to drive model improvements in speech recognition and beyond.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SSDM: Scalable Speech Dysfluency Modeling <span class="chip">NeurIPS</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.16221v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.16221v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiachen Lian, Xuanru Zhou, Zoe Ezzes, Jet Vonk, Brittany Morin, David Baquirin, Zachary Mille, Maria Luisa Gorno Tempini, Gopala Krishna Anumanchipalli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Speech dysfluency modeling is the core module for spoken language learning,
and speech therapy. However, there are three challenges. First, current
state-of-the-art solutions\cite{lian2023unconstrained-udm,
lian-anumanchipalli-2024-towards-hudm} suffer from poor scalability. Second,
there is a lack of a large-scale dysfluency corpus. Third, there is not an
effective learning framework. In this paper, we propose \textit{SSDM: Scalable
Speech Dysfluency Modeling}, which (1) adopts articulatory gestures as scalable
forced alignment; (2) introduces connectionist subsequence aligner (CSA) to
achieve dysfluency alignment; (3) introduces a large-scale simulated dysfluency
corpus called Libri-Dys; and (4) develops an end-to-end system by leveraging
the power of large language models (LLMs). We expect SSDM to serve as a
standard in the area of dysfluency modeling. Demo is available at
\url{https://berkeley-speech-group.github.io/SSDM/}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>2024 NeurIPS</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-10-02T00:00:00Z">2024-10-02</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language <span class="chip" style="font-size: 60%">150</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Locret: Enhancing Eviction in Long-Context LLM Inference with Trained
  Retaining Heads 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01805v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01805v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxiang Huang, Binhang Yuan, Xu Han, Chaojun Xiao, Zhiyuan Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have shown remarkable advances in supporting
long-context comprehension and processing tasks. However, scaling the
generation inference of LLMs to such long contexts incurs significant
additional computation load, and demands a substantial GPU memory footprint to
maintain the key-value (KV) cache of transformer-based LLMs. Existing KV cache
compression methods, such as quantization, face memory bottlenecks as context
length increases, while static-sized caches, such as eviction, suffer from
inefficient policies. These limitations restrict deployment on consumer-grade
devices like a single Nvidia 4090 GPU. To overcome this, we propose Locret, a
framework for long-context LLM inference that introduces retaining heads to
evaluate the causal importance of KV cache units, allowing for more accurate
eviction within a fixed cache size. Locret is fine-tuned on top of the frozen
backbone LLM using a minimal amount of data from standard long-context SFT
datasets. During inference, we evict low-importance cache units along with a
chunked prefill pattern, significantly reducing peak GPU memory usage. We
conduct an extensive empirical study to evaluate Locret, where the experimental
results show that Locret outperforms the recent competitive approaches,
including InfLLM, Quantization, SirLLM, and MInference, in terms of memory
efficiency and the quality of generated contents -- Locret achieves over a 20x
and 8x KV cache compression ratio compared to the full KV cache for
Phi-3-mini-128K and Llama-3.1-8B-instruct. Additionally, Locret can be combined
with other methods, such as quantization and token merging. To our knowledge,
Locret is the first framework capable of deploying Llama-3.1-8B or similar
models on a single Nvidia 4090 GPU, enabling 128K long-context inference
without compromising generation quality, and requiring little additional system
optimizations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprints</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Knowledge-Driven Feature Selection and Engineering for Genotype Data
  with Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01795v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01795v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joseph Lee, Shu Yang, Jae Young Baik, Xiaoxi Liu, Zhen Tan, Dawei Li, Zixuan Wen, Bojian Hou, Duy Duong-Tran, Tianlong Chen, Li Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Predicting phenotypes with complex genetic bases based on a small,
interpretable set of variant features remains a challenging task.
Conventionally, data-driven approaches are utilized for this task, yet the high
dimensional nature of genotype data makes the analysis and prediction
difficult. Motivated by the extensive knowledge encoded in pre-trained LLMs and
their success in processing complex biomedical concepts, we set to examine the
ability of LLMs in feature selection and engineering for tabular genotype data,
with a novel knowledge-driven framework. We develop FREEFORM, Free-flow
Reasoning and Ensembling for Enhanced Feature Output and Robust Modeling,
designed with chain-of-thought and ensembling principles, to select and
engineer features with the intrinsic knowledge of LLMs. Evaluated on two
distinct genotype-phenotype datasets, genetic ancestry and hereditary hearing
loss, we find this framework outperforms several data-driven methods,
particularly on low-shot regimes. FREEFORM is available as open-source
framework at GitHub: https://github.com/PennShenLab/FREEFORM.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Loki: An Open-Source Tool for Fact Verification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01794v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01794v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haonan Li, Xudong Han, Hao Wang, Yuxia Wang, Minghan Wang, Rui Xing, Yilin Geng, Zenan Zhai, Preslav Nakov, Timothy Baldwin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Loki, an open-source tool designed to address the growing
problem of misinformation. Loki adopts a human-centered approach, striking a
balance between the quality of fact-checking and the cost of human involvement.
It decomposes the fact-checking task into a five-step pipeline: breaking down
long texts into individual claims, assessing their check-worthiness, generating
queries, retrieving evidence, and verifying the claims. Instead of fully
automating the claim verification process, Loki provides essential information
at each step to assist human judgment, especially for general users such as
journalists and content moderators. Moreover, it has been optimized for
latency, robustness, and cost efficiency at a commercially usable level. Loki
is released under an MIT license and is available on GitHub. We also provide a
video presenting the system and its capabilities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ When a language model is optimized for reasoning, does it still show
  embers of autoregression? An analysis of OpenAI o1 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01792v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01792v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        R. Thomas McCoy, Shunyu Yao, Dan Friedman, Mathew D. Hardy, Thomas L. Griffiths
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In "Embers of Autoregression" (McCoy et al., 2023), we showed that several
large language models (LLMs) have some important limitations that are
attributable to their origins in next-word prediction. Here we investigate
whether these issues persist with o1, a new system from OpenAI that differs
from previous LLMs in that it is optimized for reasoning. We find that o1
substantially outperforms previous LLMs in many cases, with particularly large
improvements on rare variants of common tasks (e.g., forming acronyms from the
second letter of each word in a list, rather than the first letter). Despite
these quantitative improvements, however, o1 still displays the same
qualitative trends that we observed in previous systems. Specifically, o1 -
like previous LLMs - is sensitive to the probability of examples and tasks,
performing better and requiring fewer "thinking tokens" in high-probability
settings than in low-probability ones. These results show that optimizing a
language model for reasoning can mitigate but might not fully overcome the
language model's probability sensitivity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DreamGarden: A Designer Assistant for Growing Games from a Single <span class="highlight-title">Prompt</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01791v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01791v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sam Earle, Samyak Parajuli, Andrzej Banburski-Fahey
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Coding assistants are increasingly leveraged in game design, both generating
code and making high-level plans. To what degree can these tools align with
developer workflows, and what new modes of human-computer interaction can
emerge from their use? We present DreamGarden, an AI system capable of
assisting with the development of diverse game environments in Unreal Engine.
At the core of our method is an LLM-driven planner, capable of breaking down a
single, high-level prompt -- a dream, memory, or imagined scenario provided by
a human user -- into a hierarchical action plan, which is then distributed
across specialized submodules facilitating concrete implementation. This system
is presented to the user as a garden of plans and actions, both growing
independently and responding to user intervention via seed prompts, pruning,
and feedback. Through a user study, we explore design implications of this
system, charting courses for future work in semi-autonomous assistants and
open-ended simulation design.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages + appendix, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ OmniGenBench: Automating Large-scale in-silico Benchmarking for Genomic
  Foundation Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01784v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01784v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Heng Yang, Jack Cole, Ke Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The advancements in artificial intelligence in recent years, such as Large
Language Models (LLMs), have fueled expectations for breakthroughs in genomic
foundation models (GFMs). The code of nature, hidden in diverse genomes since
the very beginning of life's evolution, holds immense potential for impacting
humans and ecosystems through genome modeling. Recent breakthroughs in GFMs,
such as Evo, have attracted significant investment and attention to genomic
modeling, as they address long-standing challenges and transform in-silico
genomic studies into automated, reliable, and efficient paradigms. In the
context of this flourishing era of consecutive technological revolutions in
genomics, GFM studies face two major challenges: the lack of GFM benchmarking
tools and the absence of open-source software for diverse genomics. These
challenges hinder the rapid evolution of GFMs and their wide application in
tasks such as understanding and synthesizing genomes, problems that have
persisted for decades. To address these challenges, we introduce GFMBench, a
framework dedicated to GFM-oriented benchmarking. GFMBench standardizes
benchmark suites and automates benchmarking for a wide range of open-source
GFMs. It integrates millions of genomic sequences across hundreds of genomic
tasks from four large-scale benchmarks, democratizing GFMs for a wide range of
in-silico genomic applications. Additionally, GFMBench is released as
open-source software, offering user-friendly interfaces and diverse tutorials,
applicable for AutoBench and complex tasks like RNA design and structure
prediction. To facilitate further advancements in genome modeling, we have
launched a public leaderboard showcasing the benchmark performance derived from
AutoBench. GFMBench represents a step toward standardizing GFM benchmarking and
democratizing GFM applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://github.com/yangheng95/OmniGenomeBench</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Open-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large
  Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01782v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01782v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shayekh Bin Islam, Md Asib Rahman, K S M Tozammel Hossain, Enamul Hoque, Shafiq Joty, Md Rizwan Parvez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) has been shown to enhance the factual
accuracy of Large Language Models (LLMs), but existing methods often suffer
from limited reasoning capabilities in effectively using the retrieved
evidence, particularly when using open-source LLMs. To mitigate this gap, we
introduce a novel framework, Open-RAG, designed to enhance reasoning
capabilities in RAG with open-source LLMs. Our framework transforms an
arbitrary dense LLM into a parameter-efficient sparse mixture of experts (MoE)
model capable of handling complex reasoning tasks, including both single- and
multi-hop queries. Open-RAG uniquely trains the model to navigate challenging
distractors that appear relevant but are misleading. As a result, Open-RAG
leverages latent learning, dynamically selecting relevant experts and
integrating external knowledge effectively for more accurate and contextually
relevant responses. In addition, we propose a hybrid adaptive retrieval method
to determine retrieval necessity and balance the trade-off between performance
gain and inference speed. Experimental results show that the Llama2-7B-based
Open-RAG outperforms state-of-the-art LLMs and RAG models such as ChatGPT,
Self-RAG, and Command R+ in various knowledge-intensive tasks. We open-source
our code and models at https://openragmoe.github.io/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Findings. Website:
  https://openragmoe.github.io/. 14 pages, 7 figures, 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Composing Global Optimizers to Reasoning Tasks via Algebraic Objects in
  Neural Nets 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01779v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01779v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuandong Tian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We prove rich algebraic structures of the solution space for 2-layer neural
networks with quadratic activation and $L_2$ loss, trained on reasoning tasks
in Abelian group (e.g., modular addition). Such a rich structure enables
analytical construction of global optimal solutions from partial solutions that
only satisfy part of the loss, despite its high nonlinearity. We coin the
framework as CoGO (Composing Global Optimizers). Specifically, we show that the
weight space over different numbers of hidden nodes of the 2-layer network is
equipped with a semi-ring algebraic structure, and the loss function to be
optimized consists of monomial potentials, which are ring homomorphism,
allowing partial solutions to be composed into global ones by ring addition and
multiplication. Our experiments show that around $95\%$ of the solutions
obtained by gradient descent match exactly our theoretical constructions.
Although the global optimizers constructed only required a small number of
hidden nodes, our analysis on gradient dynamics shows that
over-parameterization asymptotically decouples training dynamics and is
beneficial. We further show that training dynamics favors simpler solutions
under weight decay, and thus high-order global optimizers such as perfect
memorization are unfavorable.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DeFine: Enhancing LLM Decision-Making with Factor Profiles and
  Analogical Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01772v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01772v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yebowen Hu, Xiaoyang Wang, Wenlin Yao, Yiming Lu, Daoan Zhang, Hassan Foroosh, Dong Yu, Fei Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLMs are ideal for decision-making due to their ability to reason over long
contexts and identify critical factors. However, challenges arise when
processing transcripts of spoken speech describing complex scenarios. These
transcripts often contain ungrammatical or incomplete sentences, repetitions,
hedging, and vagueness. For example, during a company's earnings call, an
executive might project a positive revenue outlook to reassure investors,
despite significant uncertainty regarding future earnings. It is crucial for
LLMs to incorporate this uncertainty systematically when making decisions. In
this paper, we introduce DeFine, a new framework that constructs probabilistic
factor profiles from complex scenarios. DeFine then integrates these profiles
with analogical reasoning, leveraging insights from similar past experiences to
guide LLMs in making critical decisions in novel situations. Our framework
separates the tasks of quantifying uncertainty in complex scenarios and
incorporating it into LLM decision-making. This approach is particularly useful
in fields such as medical consultations, negotiations, and political debates,
where making decisions under uncertainty is vital.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Quantifying Generalization Complexity for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01769v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01769v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenting Qi, Hongyin Luo, Xuliang Huang, Zhuokai Zhao, Yibo Jiang, Xiangjun Fan, Himabindu Lakkaraju, James Glass
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While large language models (LLMs) have shown exceptional capabilities in
understanding complex queries and performing sophisticated tasks, their
generalization abilities are often deeply entangled with memorization,
necessitating more precise evaluation. To address this challenge, we introduce
Scylla, a dynamic evaluation framework that quantitatively measures the
generalization abilities of LLMs. Scylla disentangles generalization from
memorization via assessing model performance on both in-distribution (ID) and
out-of-distribution (OOD) data through 20 tasks across 5 levels of complexity.
Through extensive experiments, we uncover a non-monotonic relationship between
task complexity and the performance gap between ID and OOD data, which we term
the generalization valley. Specifically, this phenomenon reveals a critical
threshold - referred to as critical complexity - where reliance on
non-generalizable behavior peaks, indicating the upper bound of LLMs'
generalization capabilities. As model size increases, the critical complexity
shifts toward higher levels of task complexity, suggesting that larger models
can handle more complex reasoning tasks before over-relying on memorization.
Leveraging Scylla and the concept of critical complexity, we benchmark 28LLMs
including both open-sourced models such as LLaMA and Qwen families, and
close-sourced models like Claude and GPT, providing a more robust evaluation
and establishing a clearer understanding of LLMs' generalization capabilities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LEOPARD : A Vision Language Model For Text-Rich Multi-Image Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01744v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01744v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mengzhao Jia, Wenhao Yu, Kaixin Ma, Tianqing Fang, Zhihan Zhang, Siru Ouyang, Hongming Zhang, Meng Jiang, Dong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-rich images, where text serves as the central visual element guiding the
overall understanding, are prevalent in real-world applications, such as
presentation slides, scanned documents, and webpage snapshots. Tasks involving
multiple text-rich images are especially challenging, as they require not only
understanding the content of individual images but reasoning about
inter-relationships and logical flows across multiple visual inputs. Despite
the importance of these scenarios, current multimodal large language models
(MLLMs) struggle to handle such tasks due to two key challenges: (1) the
scarcity of high-quality instruction tuning datasets for text-rich multi-image
scenarios, and (2) the difficulty in balancing image resolution with visual
feature sequence length. To address these challenges, we propose \OurMethod, a
MLLM designed specifically for handling vision-language tasks involving
multiple text-rich images. First, we curated about one million high-quality
multimodal instruction-tuning data, tailored to text-rich, multi-image
scenarios. Second, we developed an adaptive high-resolution multi-image
encoding module to dynamically optimize the allocation of visual sequence
length based on the original aspect ratios and resolutions of the input images.
Experiments across a wide range of benchmarks demonstrate our model's superior
capabilities in text-rich, multi-image evaluations and competitive performance
in general domain evaluations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Our code is available at https://github.com/Jill0001/Leopard</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Recursive Abstractive Processing for Retrieval in Dynamic <span class="highlight-title">Dataset</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01736v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01736v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Charbel Chucri, Rami Azouz, Joachim Ott
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent retrieval-augmented models enhance basic methods by building a
hierarchical structure over retrieved text chunks through recursive embedding,
clustering, and summarization. The most relevant information is then retrieved
from both the original text and generated summaries. However, such approaches
face limitations with dynamic datasets, where adding or removing documents over
time complicates the updating of hierarchical representations formed through
clustering. We propose a new algorithm to efficiently maintain the
recursive-abstractive tree structure in dynamic datasets, without compromising
performance. Additionally, we introduce a novel post-retrieval method that
applies query-focused recursive abstractive processing to substantially improve
context quality. Our method overcomes the limitations of other approaches by
functioning as a black-box post-retrieval layer compatible with any retrieval
algorithm. Both algorithms are validated through extensive experiments on
real-world datasets, demonstrating their effectiveness in handling dynamic data
and improving retrieval performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LASeR: Learning to Adaptively Select Reward Models with Multi-Armed
  Bandits 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01735v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01735v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Duy Nguyen, Archiki Prasad, Elias Stengel-Eskin, Mohit Bansal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reward Models (RMs) play a crucial role in aligning LLMs with human
preferences, enhancing their performance by ranking outputs during inference or
iterative training. However, the degree to which an RM generalizes to new tasks
is often not known a priori (e.g. some RMs may excel at scoring creative
writing vs. math reasoning). Therefore, using only one fixed RM while training
LLMs can be suboptimal. Moreover, optimizing LLMs with multiple RMs
simultaneously can be prohibitively computationally-intensive and challenging
due to conflicting signals from different RMs, potentially degrading
performance. To address these challenges, we introduce LASeR (Learning to
Adaptively Select Rewards), which iteratively trains LLMs using multiple RMs,
selecting and utilizing the most well-suited RM for each instance to rank
outputs and generate preference data, framed as a multi-armed bandit problem.
Our results on commonsense and math reasoning tasks demonstrate that LASeR can
boost iterative LLM optimization by optimizing for multiple RMs, improving the
absolute average accuracy of Llama-3-8B over three datasets by 2.67% over
training with ensemble RM scores while also showing superior training
efficiency (e.g., a 2x speedup). Moreover, on WildChat, a benchmark of
instruction-following prompts, we find that using Llama-3-8B LASeR leads to a
71.45% AlpacaEval win rate over sequentially optimizing multiple RMs. Extending
to long-context generation tasks, we find that on Llama-3-8B, LASeR achieves an
average improvement of 2.64 F1 and 2.42 F1 on single- and multi-document QA
over random RM selection when used with best-of-n sampling. LASeR is robust to
noisy rewards and generalizes to multiple settings. Finally, LASeR's RM
selection changes depending on the underlying task or instance and we verify
the presence of conflicting preferences from multiple RMs that can be mitigated
using LASeR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages; First two authors contributed equally. Code:
  https://github.com/duykhuongnguyen/LASeR-MAB</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Visual Perception in Text Strings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01733v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01733v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qi Jia, Xiang Yue, Shanshan Huang, Ziheng Qin, Yizhu Liu, Bill Yuchen Lin, Yang You
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Understanding visual semantics embedded in consecutive characters is a
crucial capability for both large language models (LLMs) and multi-modal large
language models (MLLMs). This type of artifact possesses the unique
characteristic that identical information can be readily formulated in both
texts and images, making them a significant proxy for analyzing modern LLMs'
and MLLMs' capabilities in modality-agnostic vision understanding. In this
work, we select ASCII art as a representative artifact, where the lines and
brightness used to depict each concept are rendered by characters, and we frame
the problem as an ASCII art recognition task. We benchmark model performance on
this task by constructing an evaluation dataset with an elaborate
categorization tree and also collect a training set to elicit the models'
visual perception ability. Through a comprehensive analysis of dozens of
models, results reveal that although humans can achieve nearly 100% accuracy,
the state-of-the-art LLMs and MLLMs lag far behind. Models are capable of
recognizing concepts depicted in the ASCII arts given only text inputs
indicated by over 60% accuracy for some concepts, but most of them achieves
merely around 30% accuracy when averaged across all categories. When provided
with images as inputs, GPT-4o gets 82.68%, outperforming the strongest
open-source MLLM by 21.95%. Although models favor different kinds of ASCII art
depending on the modality provided, none of the MLLMs successfully benefit when
both modalities are supplied simultaneously. Moreover, supervised fine-tuning
helps improve models' accuracy especially when provided with the image
modality, but also highlights the need for better training techniques to
enhance the information fusion among modalities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ComfyGen: <span class="highlight-title">Prompt</span>-Adaptive Workflows for Text-to-Image Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01731v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01731v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rinon Gal, Adi Haviv, Yuval Alaluf, Amit H. Bermano, Daniel Cohen-Or, Gal Chechik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The practical use of text-to-image generation has evolved from simple,
monolithic models to complex workflows that combine multiple specialized
components. While workflow-based approaches can lead to improved image quality,
crafting effective workflows requires significant expertise, owing to the large
number of available components, their complex inter-dependence, and their
dependence on the generation prompt. Here, we introduce the novel task of
prompt-adaptive workflow generation, where the goal is to automatically tailor
a workflow to each user prompt. We propose two LLM-based approaches to tackle
this task: a tuning-based method that learns from user-preference data, and a
training-free method that uses the LLM to select existing flows. Both
approaches lead to improved image quality when compared to monolithic models or
generic, prompt-independent workflows. Our work shows that prompt-dependent
flow prediction offers a new pathway to improving text-to-image generation
quality, complementing existing research directions in the field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project website: https://comfygen-paper.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluating Robustness of Reward Models for Mathematical Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01729v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01729v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sunghwan Kim, Dongjin Kang, Taeyoon Kwon, Hyungjoo Chae, Jungsoo Won, Dongha Lee, Jinyoung Yeo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reward models are key in reinforcement learning from human feedback (RLHF)
systems, aligning the model behavior with human preferences. Particularly in
the math domain, there have been plenty of studies using reward models to align
policies for improving reasoning capabilities. Recently, as the importance of
reward models has been emphasized, RewardBench is proposed to understand their
behavior. However, we figure out that the math subset of RewardBench has
different representations between chosen and rejected completions, and relies
on a single comparison, which may lead to unreliable results as it only see an
isolated case. Therefore, it fails to accurately present the robustness of
reward models, leading to a misunderstanding of its performance and potentially
resulting in reward hacking. In this work, we introduce a new design for
reliable evaluation of reward models, and to validate this, we construct
RewardMATH, a benchmark that effectively represents the robustness of reward
models in mathematical reasoning tasks. We demonstrate that the scores on
RewardMATH strongly correlate with the results of optimized policy and
effectively estimate reward overoptimization, whereas the existing benchmark
shows almost no correlation. The results underscore the potential of our design
to enhance the reliability of evaluation, and represent the robustness of
reward model. We make our code and data publicly available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Automated Knowledge Concept Annotation and Question Representation
  Learning for Knowledge Tracing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01727v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01727v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yilmazcan Ozyurt, Stefan Feuerriegel, Mrinmaya Sachan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge tracing (KT) is a popular approach for modeling students' learning
progress over time, which can enable more personalized and adaptive learning.
However, existing KT approaches face two major limitations: (1) they rely
heavily on expert-defined knowledge concepts (KCs) in questions, which is
time-consuming and prone to errors; and (2) KT methods tend to overlook the
semantics of both questions and the given KCs. In this work, we address these
challenges and present KCQRL, a framework for automated knowledge concept
annotation and question representation learning that can improve the
effectiveness of any existing KT model. First, we propose an automated KC
annotation process using large language models (LLMs), which generates question
solutions and then annotates KCs in each solution step of the questions.
Second, we introduce a contrastive learning approach to generate semantically
rich embeddings for questions and solution steps, aligning them with their
associated KCs via a tailored false negative elimination approach. These
embeddings can be readily integrated into existing KT models, replacing their
randomly initialized embeddings. We demonstrate the effectiveness of KCQRL
across 15 KT algorithms on two large real-world Math learning datasets, where
we achieve consistent performance improvements.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Auto-Demo <span class="highlight-title">Prompt</span>ing: Leveraging Generated Outputs as Demonstrations for
  Enhanced Batch <span class="highlight-title">Prompt</span>ing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01724v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01724v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Longyu Feng, Mengze Hong, Chen Jason Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Batch prompting is a common technique in large language models (LLMs) used to
process multiple inputs simultaneously, aiming to improve computational
efficiency. However, as batch sizes increase, performance degradation often
occurs due to the model's difficulty in handling lengthy context inputs.
Existing methods that attempt to mitigate these issues rely solely on batch
data arrangement and majority voting rather than improving the design of the
batch prompt itself. In this paper, we address these limitations by proposing
"Auto-Demo Prompting," a novel approach that leverages the question-output
pairs from earlier questions within a batch as demonstrations for subsequent
answer inference. We provide a formal theoretical analysis of how Auto-Demo
Prompting functions within the autoregressive generation process of LLMs,
illustrating how it utilizes prior outputs to optimize the model's internal
representations. Our method effectively bridges the gap between batch prompting
and few-shot prompting, enhancing performance with only a slight compromise in
token usage. Experimental results across five NLP tasks demonstrate its
effectiveness in mitigating performance degradation and occasionally
outperforming single prompts. Furthermore, it opens new avenues for applying
few-shot learning techniques, such as demonstration selection, within batch
prompting, making it a robust solution for real-world applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards a Theoretical Understanding of Synthetic Data in LLM
  Post-Training: A Reverse-Bottleneck Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01720v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01720v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zeyu Gan, Yong Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Synthetic data has become a pivotal resource in post-training tasks for large
language models (LLMs) due to the scarcity of high-quality, specific data.
While various methods have been developed to generate synthetic data, there
remains a discernible gap between the practical effects of synthetic data and
our theoretical comprehension. To address this challenge, we commence by
presenting a detailed modeling of the prevalent synthetic data generation
process. Building upon this modeling, we demonstrate that the generalization
capability of the post-trained model is critically determined by the
information gain derived from the generative model, as analyzed from a novel
reverse-bottleneck perspective. Moreover, we introduce the concept of
Generalization Gain via Mutual Information (GGMI) and elucidate the
relationship between generalization gain and information gain. This analysis
serves as a theoretical foundation for synthetic data generation and further
highlights its connection with the generalization capability of post-trained
models, offering an understanding about the design of synthetic data generation
techniques and the optimization of the post-training process. We open source
our code through an anonymous GitHub repository at
https://anonymous.4open.science/r/Understanding-Synthetic.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Examining the Role of Relationship Alignment in Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01708v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01708v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kristen M. Altenburger, Hongda Jiang, Robert E. Kraut, Yi-Chia Wang, Jane Dwivedi-Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid development and deployment of Generative AI in social settings
raise important questions about how to optimally personalize them for users
while maintaining accuracy and realism. Based on a Facebook public post-comment
dataset, this study evaluates the ability of Llama 3.0 (70B) to predict the
semantic tones across different combinations of a commenter's and poster's
gender, age, and friendship closeness and to replicate these differences in
LLM-generated comments.
  The study consists of two parts: Part I assesses differences in semantic
tones across social relationship categories, and Part II examines the
similarity between comments generated by Llama 3.0 (70B) and human comments
from Part I given public Facebook posts as input. Part I results show that
including social relationship information improves the ability of a model to
predict the semantic tone of human comments. However, Part II results show that
even without including social context information in the prompt, LLM-generated
comments and human comments are equally sensitive to social context, suggesting
that LLMs can comprehend semantics from the original post alone. When we
include all social relationship information in the prompt, the similarity
between human comments and LLM-generated comments decreases. This inconsistency
may occur because LLMs did not include social context information as part of
their training data. Together these results demonstrate the ability of LLMs to
comprehend semantics from the original post and respond similarly to human
comments, but also highlights their limitations in generalizing personalized
comments through prompting alone.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Interpretable Contrastive Monte Carlo Tree Search Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01707v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01707v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zitian Gao, Boye Niu, Xuzheng He, Haotian Xu, Hongzhang Liu, Aiwei Liu, Xuming Hu, Lijie Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose SC-MCTS*: a novel Monte Carlo Tree Search (MCTS) reasoning
algorithm for Large Language Models (LLMs), significantly improves both
reasoning accuracy and speed. Our motivation comes from: 1. Previous MCTS LLM
reasoning works often overlooked its biggest drawback--slower speed compared to
CoT; 2. Previous research mainly used MCTS as a tool for LLM reasoning on
various tasks with limited quantitative analysis or ablation studies of its
components from reasoning interpretability perspective. 3. The reward model is
the most crucial component in MCTS, however previous work has rarely conducted
in-depth study or improvement of MCTS's reward models. Thus, we conducted
extensive ablation studies and quantitative analysis on components of MCTS,
revealing the impact of each component on the MCTS reasoning performance of
LLMs. Building on this, (i) we designed a highly interpretable reward model
based on the principle of contrastive decoding and (ii) achieved an average
speed improvement of 51.9% per node using speculative decoding. Additionally,
(iii) we improved UCT node selection strategy and backpropagation used in
previous works, resulting in significant performance improvement. We
outperformed o1-mini by an average of 17.4% on the Blocksworld multi-step
reasoning dataset using Llama-3.1-70B with SC-MCTS*.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An Exploration of <span class="highlight-title">Self-Supervised</span> Mutual Information Alignment for
  Multi-Task Settings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01704v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01704v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Soham Govande
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  There is a growing need for pluralistic alignment methods that can steer
language models towards individual attributes and preferences. One such method,
Self-Supervised Alignment with Mutual Information (SAMI), uses conditional
mutual information to encourage the connection between behavioral preferences
and model responses. We conduct two experiments exploring SAMI in multi-task
settings. First, we compare SAMI to Direct Preference Optimization (DPO) on a
multi-task benchmark (MT-Bench), using a stronger model to generate training
data for a weaker one across diverse categories (humanities, STEM, extraction,
coding, math, reasoning, and roleplay). Our results indicate that one iteration
of SAMI has a 57% win rate against DPO, with significant variation in
performance between task categories. Second, we examine SAMI's impact on
mathematical accuracy (GSM-8K) relative to supervised fine-tuning (SFT). While
SAMI increases zero-shot performance by 1.1%, SFT is more effective with a 3.2%
boost. However, SAMI shows interesting scaling trends. When given 10 attempts,
SAMI improves accuracy by 3.9%, while SFT achieves a 10.1% increase. Combining
SAMI with SFT yields an additional improvement of 1.3% in multi-attempt
settings, though single-attempt accuracy remains unchanged.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CreDes: Causal Reasoning Enhancement and Dual-End Searching for Solving
  Long-Range Reasoning Problems using LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01696v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01696v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kangsheng Wang, Xiao Zhang, Hao Liu, Songde Han, Huimin Ma, Tianyu Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have demonstrated limitations in handling
combinatorial optimization problems involving long-range reasoning, partially
due to causal hallucinations and huge search space. As for causal
hallucinations, i.e., the inconsistency between reasoning and corresponding
state transition, this paper introduces the Causal Relationship Enhancement
(CRE) mechanism combining cause-effect interventions and the Individual
Treatment Effect (ITE) to guarantee the solid causal rightness between each
step of reasoning and state transition. As for the long causal range and huge
search space limiting the performances of existing models featuring
single-direction search, a Dual-End Searching (DES) approach is proposed to
seek solutions by simultaneously starting from both the initial and goal states
on the causal probability tree. By integrating CRE and DES (CreDes), our model
has realized simultaneous multi-step reasoning, circumventing the
inefficiencies from cascading multiple one-step reasoning like the
Chain-of-Thought (CoT). Experiments demonstrate that CreDes significantly
outperforms existing State-Of-The-Art (SOTA) solutions in long-range reasoning
tasks in terms of both accuracy and time efficiency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ U-shaped and Inverted-U Scaling behind Emergent Abilities of Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01692v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01692v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tung-Yu Wu, Pei-Yu Lo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have been shown to exhibit emergent abilities in
some downstream tasks, where performance seems to stagnate at first and then
improve sharply and unpredictably with scale beyond a threshold. By dividing
questions in the datasets according to difficulty level by average performance,
we observe U-shaped scaling for hard questions, and inverted-U scaling followed
by steady improvement for easy questions. Moreover, the emergence threshold
roughly coincides with the point at which performance on easy questions reverts
from inverse scaling to standard scaling. Capitalizing on the observable though
opposing scaling trend on easy and hard questions, we propose a simple yet
effective pipeline, called Slice-and-Sandwich, to predict both the emergence
threshold and model performance beyond the threshold.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint. Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FactAlign: Long-form Factuality Alignment of Large Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01691v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01691v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chao-Wei Huang, Yun-Nung Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models have demonstrated significant potential as the
next-generation information access engines. However, their reliability is
hindered by issues of hallucination and generating non-factual content. This is
particularly problematic in long-form responses, where assessing and ensuring
factual accuracy is complex. In this paper, we address this gap by proposing
FactAlign, a novel alignment framework designed to enhance the factuality of
LLMs' long-form responses while maintaining their helpfulness. We introduce
fKTO, a fine-grained, sentence-level alignment algorithm that extends the
Kahneman-Tversky Optimization (KTO) alignment method. Leveraging recent
advances in automatic factuality evaluation, FactAlign utilizes fine-grained
factuality assessments to guide the alignment process. Our experiments on
open-domain prompts and information-seeking questions demonstrate that
FactAlign significantly improves the factual accuracy of LLM responses while
also improving their helpfulness. Further analyses identify that FactAlign is
capable of training LLMs to provide more information without losing factual
precision, thus improving the factual F1 score. Our source code, datasets, and
trained models are publicly available at https://github.com/MiuLab/FactAlign
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VinePPO: Unlocking RL Potential For LLM Reasoning Through Refined Credit
  Assignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01679v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01679v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amirhossein Kazemnejad, Milad Aghajohari, Eva Portelance, Alessandro Sordoni, Siva Reddy, Aaron Courville, Nicolas Le Roux
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) are increasingly applied to complex reasoning
tasks that require executing several complex steps before receiving any reward.
Properly assigning credit to these steps is essential for enhancing model
performance. Proximal Policy Optimization (PPO), a state-of-the-art
reinforcement learning (RL) algorithm used for LLM finetuning, employs value
networks to tackle credit assignment. However, value networks face challenges
in predicting the expected cumulative rewards accurately in complex reasoning
tasks, often leading to high-variance updates and suboptimal performance. In
this work, we systematically evaluate the efficacy of value networks and reveal
their significant shortcomings in reasoning-heavy LLM tasks, showing that they
barely outperform a random baseline when comparing alternative steps. To
address this, we propose VinePPO, a straightforward approach that leverages the
flexibility of language environments to compute unbiased Monte Carlo-based
estimates, bypassing the need for large value networks. Our method consistently
outperforms PPO and other RL-free baselines across MATH and GSM8K datasets with
fewer gradient updates (up to 9x), less wall-clock time (up to 3.0x). These
results emphasize the importance of accurate credit assignment in RL finetuning
of LLM and demonstrate VinePPO's potential as a superior alternative.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Trying to be human: Linguistic traces of stochastic empathy in language
  models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01675v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01675v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bennett Kleinberg, Jari Zegers, Jonas Festor, Stefana Vida, Julian Präsent, Riccardo Loconte, Sanne Peereboom
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Differentiating between generated and human-written content is important for
navigating the modern world. Large language models (LLMs) are crucial drivers
behind the increased quality of computer-generated content. Reportedly, humans
find it increasingly difficult to identify whether an AI model generated a
piece of text. Our work tests how two important factors contribute to the human
vs AI race: empathy and an incentive to appear human. We address both aspects
in two experiments: human participants and a state-of-the-art LLM wrote
relationship advice (Study 1, n=530) or mere descriptions (Study 2, n=610),
either instructed to be as human as possible or not. New samples of humans
(n=428 and n=408) then judged the texts' source. Our findings show that when
empathy is required, humans excel. Contrary to expectations, instructions to
appear human were only effective for the LLM, so the human advantage
diminished. Computational text analysis revealed that LLMs become more human
because they may have an implicit representation of what makes a text human and
effortlessly apply these heuristics. The model resorts to a conversational,
self-referential, informal tone with a simpler vocabulary to mimic stochastic
empathy. We discuss these findings in light of recent claims on the on-par
performance of LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bridging Context Gaps: Leveraging Coreference Resolution for Long
  Contextual Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01671v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01671v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanming Liu, Xinyue Peng, Jiannan Cao, Shi Bo, Yanxin Shen, Xuhong Zhang, Sheng Cheng, Xun Wang, Jianwei Yin, Tianyu Du
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have shown remarkable capabilities in natural
language processing; however, they still face difficulties when tasked with
understanding lengthy contexts and executing effective question answering.
These challenges often arise due to the complexity and ambiguity present in
longer texts. To enhance the performance of LLMs in such scenarios, we
introduce the Long Question Coreference Adaptation (LQCA) method. This
innovative framework focuses on coreference resolution tailored to long
contexts, allowing the model to identify and manage references effectively. The
LQCA method encompasses four key steps: resolving coreferences within
sub-documents, computing the distances between mentions, defining a
representative mention for coreference, and answering questions through mention
replacement. By processing information systematically, the framework provides
easier-to-handle partitions for LLMs, promoting better understanding.
Experimental evaluations on a range of LLMs and datasets have yielded positive
results, with a notable improvements on OpenAI-o1-mini and GPT-4o models,
highlighting the effectiveness of leveraging coreference resolution to bridge
context gaps in question answering.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Underreview version of LQCA, Bridge context gap for long context</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient Long-range Language Modeling with <span class="highlight-title">Self-supervised</span> Causal
  Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01651v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01651v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiang Hu, Zhihao Teng, Wei Wu, Kewei Tu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, retrieval-based language models (RLMs) have received much
attention. However, most of them leverage a pre-trained retriever with fixed
parameters, which may not adapt well to causal language models. In this work,
we propose Grouped Cross-Attention, a novel module enabling joint pre-training
of the retriever and causal LM, and apply it to long-context modeling. For a
given input sequence, we split it into chunks and use the current chunk to
retrieve past chunks for subsequent text generation. Our innovation allows the
retriever to learn how to retrieve past chunks that better minimize the
auto-regressive loss of subsequent tokens in an end-to-end manner. By
integrating top-$k$ retrieval, our model can be pre-trained efficiently from
scratch with context lengths up to 64K tokens. Our experiments show our model,
compared with long-range LM baselines, can achieve lower perplexity with
comparable or lower pre-training and inference costs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DeIDClinic: A Multi-Layered Framework for De-identification of Clinical
  Free-text Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01648v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01648v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Angel Paul, Dhivin Shaji, Lifeng Han, Warren Del-Pinto, Goran Nenadic
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  De-identification is important in protecting patients' privacy for healthcare
text analytics. The MASK framework is one of the best on the de-identification
shared task organised by n2c2/i2b2 challenges. This work enhances the MASK
framework by integrating ClinicalBERT, a deep learning model specifically
fine-tuned on clinical texts, alongside traditional de-identification methods
like dictionary lookup and rule-based approaches. The system effectively
identifies and either redacts or replaces sensitive identifiable entities
within clinical documents, while also allowing users to customise the masked
documents according to their specific needs. The integration of ClinicalBERT
significantly improves the performance of entity recognition, achieving 0.9732
F1-score, especially for common entities such as names, dates, and locations.
  A risk assessment feature has also been developed, which analyses the
uniqueness of context within documents to classify them into risk levels,
guiding further de-identification efforts. While the system demonstrates strong
overall performance, this work highlights areas for future improvement,
including handling more complex entity occurrences and enhancing the system's
adaptability to different clinical settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ongoing work</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On The Adaptation of Unlimiformer for Decoder-Only <span class="highlight-title">Transformer</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01637v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01637v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kian Ahrabian, Alon Benhaim, Barun Patra, Jay Pujara, Saksham Singhal, Xia Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  One of the prominent issues stifling the current generation of large language
models is their limited context length. Recent proprietary models such as GPT-4
and Claude 2 have introduced longer context lengths, 8k/32k and 100k,
respectively; however, despite the efforts in the community, most common
models, such as LLama-2, have a context length of 4k or less. Unlimiformer
(Bertsch et al., 2023) is a recently popular vector-retrieval augmentation
method that offloads cross-attention computations to a kNN index. However, its
main limitation is incompatibility with decoder-only transformers out of the
box. In this work, we explore practical considerations of adapting Unlimiformer
to decoder-only transformers and introduce a series of modifications to
overcome this limitation. Moreover, we expand the original experimental setup
on summarization to include a new task (i.e., free-form Q&A) and an
instruction-tuned model (i.e., a custom 6.7B GPT model). Our results showcase
the effectiveness of these modifications on summarization, performing on par
with a model with 2x the context length. Moreover, we discuss limitations and
future directions for free-form Q&A and instruction-tuned models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Thematic Framework for Analyzing Large-scale Self-reported Social
  Media Data on Opioid Use Disorder Treatment Using Buprenorphine Product 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01633v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01633v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Madhusudan Basak, Omar Sharif, Sarah E. Lord, Jacob T. Borodovsky, Lisa A. Marsch, Sandra A. Springer, Edward Nunes, Charlie D. Brackett, Luke J. ArchiBald, Sarah M. Preum
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Background: One of the key FDA-approved medications for Opioid Use Disorder
(OUD) is buprenorphine. Despite its popularity, individuals often report
various information needs regarding buprenorphine treatment on social media
platforms like Reddit. However, the key challenge is to characterize these
needs. In this study, we propose a theme-based framework to curate and analyze
large-scale data from social media to characterize self-reported treatment
information needs (TINs).
  Methods: We collected 15,253 posts from r/Suboxone, one of the largest Reddit
sub-community for buprenorphine products. Following the standard protocol, we
first identified and defined five main themes from the data and then coded
6,000 posts based on these themes, where one post can be labeled with
applicable one to three themes. Finally, we determined the most frequently
appearing sub-themes (topics) for each theme by analyzing samples from each
group.
  Results: Among the 6,000 posts, 40.3% contained a single theme, 36% two
themes, and 13.9% three themes. The most frequent topics for each theme or
theme combination came with several key findings - prevalent reporting of
psychological and physical effects during recovery, complexities in accessing
buprenorphine, and significant information gaps regarding medication
administration, tapering, and usage of substances during different stages of
recovery. Moreover, self-treatment strategies and peer-driven advice reveal
valuable insights and potential misconceptions.
  Conclusions: The findings obtained using our proposed framework can inform
better patient education and patient-provider communication, design systematic
interventions to address treatment-related misconceptions and rumors, and
streamline the generation of hypotheses for future research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Intent Detection in the Age of LLMs <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01627v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01627v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gaurav Arora, Shreya Jain, Srujana Merugu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Intent detection is a critical component of task-oriented dialogue systems
(TODS) which enables the identification of suitable actions to address user
utterances at each dialog turn. Traditional approaches relied on
computationally efficient supervised sentence transformer encoder models, which
require substantial training data and struggle with out-of-scope (OOS)
detection. The emergence of generative large language models (LLMs) with
intrinsic world knowledge presents new opportunities to address these
challenges. In this work, we adapt 7 SOTA LLMs using adaptive in-context
learning and chain-of-thought prompting for intent detection, and compare their
performance with contrastively fine-tuned sentence transformer (SetFit) models
to highlight prediction quality and latency tradeoff. We propose a hybrid
system using uncertainty based routing strategy to combine the two approaches
that along with negative data augmentation results in achieving the best of
both worlds ( i.e. within 2% of native LLM accuracy with 50% less latency). To
better understand LLM OOS detection capabilities, we perform controlled
experiments revealing that this capability is significantly influenced by the
scope of intent labels and the size of the label space. We also introduce a
two-step approach utilizing internal LLM representations, demonstrating
empirical gains in OOS detection accuracy and F1-score by >5% for the
Mistral-7B model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024 Industry Track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Upcycling Instruction Tuning from Dense to Mixture-of-Experts via
  Parameter Merging 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01610v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01610v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tingfeng Hui, Zhenyu Zhang, Shuohuan Wang, Yu Sun, Hua Wu, Sen Su
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mixture-of-Experts (MoE) shines brightly in large language models (LLMs) and
demonstrates outstanding performance in plentiful natural language processing
tasks. However, existing methods transforming LLMs from dense to MoE face
significant data requirements and typically rely on large-scale post-training.
In this paper, we propose Upcycling Instruction Tuning (UpIT), a data-efficient
approach for tuning a dense pre-trained model into a MoE instruction model.
Specifically, we first point out that intermediate checkpoints during
instruction tuning of the dense model are naturally suitable for specialized
experts, and then propose an expert expansion stage to flexibly achieve models
with flexible numbers of experts, where genetic algorithm and parameter merging
are introduced to ensure sufficient diversity of new extended experts. To
ensure that each specialized expert in the MoE model works as expected, we
select a small amount of seed data that each expert excels to pre-optimize the
router. Extensive experiments with various data scales and upcycling settings
demonstrate the outstanding performance and data efficiency of UpIT, as well as
stable improvement in expert or data scaling. Further analysis reveals the
importance of ensuring expert diversity in upcycling.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ENTP: Encoder-only Next Token Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01600v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01600v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ethan Ewer, Daewon Chae, Thomas Zeng, Jinkyu Kim, Kangwook Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Next-token prediction models have predominantly relied on decoder-only
Transformers with causal attention, driven by the common belief that causal
attention is essential to prevent "cheating" by masking future tokens. We
challenge this widely accepted notion and argue that this design choice is
about efficiency rather than necessity. While decoder-only Transformers are
still a good choice for practical reasons, they are not the only viable option.
In this work, we introduce Encoder-only Next Token Prediction (ENTP). We
explore the differences between ENTP and decoder-only Transformers in
expressive power and complexity, highlighting potential advantages of ENTP. We
introduce the Triplet-Counting task and show, both theoretically and
experimentally, that while ENTP can perform this task easily, a decoder-only
Transformer cannot. Finally, we empirically demonstrate ENTP's superior
performance across various realistic tasks, such as length generalization and
in-context learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Spoken Grammar Assessment Using LLM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01579v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01579v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sunil Kumar Kopparapu, Chitralekha Bhat, Ashish Panda
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spoken language assessment (SLA) systems restrict themselves to evaluating
the pronunciation and oral fluency of a speaker by analysing the read and
spontaneous spoken utterances respectively. The assessment of language grammar
or vocabulary is relegated to written language assessment (WLA) systems. Most
WLA systems present a set of sentences from a curated finite-size database of
sentences thereby making it possible to anticipate the test questions and train
oneself. In this paper, we propose a novel end-to-end SLA system to assess
language grammar from spoken utterances thus making WLA systems redundant;
additionally, we make the assessment largely unteachable by employing a large
language model (LLM) to bring in variations in the test. We further demonstrate
that a hybrid automatic speech recognition (ASR) with a custom-built language
model outperforms the state-of-the-art ASR engine for spoken grammar
assessment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ OpenMathInstruct-2: Accelerating AI for Math with Massive Open-Source
  Instruction Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01560v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01560v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shubham Toshniwal, Wei Du, Ivan Moshkov, Branislav Kisacanin, Alexan Ayrapetyan, Igor Gitman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mathematical reasoning continues to be a critical challenge in large language
model (LLM) development with significant interest. However, most of the
cutting-edge progress in mathematical reasoning with LLMs has become
\emph{closed-source} due to lack of access to training data. This lack of data
access limits researchers from understanding the impact of different choices
for synthesizing and utilizing the data. With the goal of creating a
high-quality finetuning (SFT) dataset for math reasoning, we conduct careful
ablation experiments on data synthesis using the recently released
\texttt{Llama3.1} family of models. Our experiments show that: (a) solution
format matters, with excessively verbose solutions proving detrimental to SFT
performance, (b) data generated by a strong teacher outperforms
\emph{on-policy} data generated by a weak student model, (c) SFT is robust to
low-quality solutions, allowing for imprecise data filtering, and (d) question
diversity is crucial for achieving data scaling gains. Based on these insights,
we create the OpenMathInstruct-2 dataset, which consists of 14M
question-solution pairs ($\approx$ 600K unique questions), making it nearly
eight times larger than the previous largest open-source math reasoning
dataset. Finetuning the \texttt{Llama-3.1-8B-Base} using OpenMathInstruct-2
outperforms \texttt{Llama3.1-8B-Instruct} on MATH by an absolute 15.9\% (51.9\%
$\rightarrow$ 67.8\%). Finally, to accelerate the open-source efforts, we
release the code, the finetuned models, and the OpenMathInstruct-2 dataset
under a commercially permissive license.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Integrative Decoding: Improve Factuality via Implicit Self-consistency 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01556v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01556v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi Cheng, Xiao Liang, Yeyun Gong, Wen Xiao, Song Wang, Yuji Zhang, Wenjun Hou, Kaishuai Xu, Wenge Liu, Wenjie Li, Jian Jiao, Qi Chen, Peng Cheng, Wayne Xiong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Self-consistency-based approaches, which involve repeatedly sampling multiple
outputs and selecting the most consistent one as the final response, prove to
be remarkably effective in improving the factual accuracy of large language
models. Nonetheless, existing methods usually have strict constraints on the
task format, largely limiting their applicability. In this paper, we present
Integrative Decoding (ID), to unlock the potential of self-consistency in
open-ended generation tasks. ID operates by constructing a set of inputs, each
prepended with a previously sampled response, and then processes them
concurrently, with the next token being selected by aggregating of all their
corresponding predictions at each decoding step. In essence, this simple
approach implicitly incorporates self-consistency in the decoding objective.
Extensive evaluation shows that ID consistently enhances factuality over a wide
range of language models, with substantial improvements on the TruthfulQA
(+11.2%), Biographies (+15.4%) and LongFact (+8.5%) benchmarks. The performance
gains amplify progressively as the number of sampled responses increases,
indicating the potential of ID to scale up with repeated sampling.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ACE: A LLM-based Negotiation Coaching System <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01555v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01555v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ryan Shea, Aymen Kallala, Xin Lucy Liu, Michael W. Morris, Zhou Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The growing prominence of LLMs has led to an increase in the development of
AI tutoring systems. These systems are crucial in providing underrepresented
populations with improved access to valuable education. One important area of
education that is unavailable to many learners is strategic bargaining related
to negotiation. To address this, we develop a LLM-based Assistant for Coaching
nEgotiation (ACE). ACE not only serves as a negotiation partner for users but
also provides them with targeted feedback for improvement. To build our system,
we collect a dataset of negotiation transcripts between MBA students. These
transcripts come from trained negotiators and emulate realistic bargaining
scenarios. We use the dataset, along with expert consultations, to design an
annotation scheme for detecting negotiation mistakes. ACE employs this scheme
to identify mistakes and provide targeted feedback to users. To test the
effectiveness of ACE-generated feedback, we conducted a user experiment with
two consecutive trials of negotiation and found that it improves negotiation
performances significantly compared to a system that doesn't provide feedback
and one which uses an alternative method of providing feedback.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MedQA-CS: Benchmarking Large Language Models Clinical Skills Using an
  AI-SCE Framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01553v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01553v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zonghai Yao, Zihao Zhang, Chaolong Tang, Xingyu Bian, Youxia Zhao, Zhichao Yang, Junda Wang, Huixue Zhou, Won Seok Jang, Feiyun Ouyang, Hong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Artificial intelligence (AI) and large language models (LLMs) in healthcare
require advanced clinical skills (CS), yet current benchmarks fail to evaluate
these comprehensively. We introduce MedQA-CS, an AI-SCE framework inspired by
medical education's Objective Structured Clinical Examinations (OSCEs), to
address this gap. MedQA-CS evaluates LLMs through two instruction-following
tasks, LLM-as-medical-student and LLM-as-CS-examiner, designed to reflect real
clinical scenarios. Our contributions include developing MedQA-CS, a
comprehensive evaluation framework with publicly available data and expert
annotations, and providing the quantitative and qualitative assessment of LLMs
as reliable judges in CS evaluation. Our experiments show that MedQA-CS is a
more challenging benchmark for evaluating clinical skills than traditional
multiple-choice QA benchmarks (e.g., MedQA). Combined with existing benchmarks,
MedQA-CS enables a more comprehensive evaluation of LLMs' clinical capabilities
for both open- and closed-source LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ In-Context Transfer Learning: Demonstration Synthesis by Transferring
  Similar Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01548v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01548v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dingzirui Wang, Xuangliang Zhang, Qiguang Chen, Longxu Dou, Xiao Xu, Rongyu Cao, Yingwei Ma, Qingfu Zhu, Wanxiang Che, Binhua Li, Fei Huang, Yongbin Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In-context learning (ICL) is an effective approach to help large language
models (LLMs) adapt to various tasks by providing demonstrations of the target
task. Considering the high cost of labeling demonstrations, many methods
propose synthesizing demonstrations from scratch using LLMs. However, the
quality of the demonstrations synthesized from scratch is limited by the
capabilities and knowledge of LLMs. To address this, inspired by transfer
learning, we propose In-Context Transfer Learning (ICTL), which synthesizes
target task demonstrations by transferring labeled demonstrations from similar
source tasks. ICTL consists of two steps: source sampling and target transfer.
First, we define an optimization objective, which minimizes transfer error to
sample source demonstrations similar to the target task. Then, we employ LLMs
to transfer the sampled source demonstrations to the target task, matching the
definition and format of the target task. Experiments on Super-NI show that
ICTL outperforms synthesis from scratch by 2.0% on average, demonstrating the
effectiveness of our method.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Seeing Eye to AI: Human Alignment via Gaze-Based Response Rewards for
  Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01532v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01532v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Angela Lopez-Cardona, Carlos Segura, Alexandros Karatzoglou, Sergi Abadal, Ioannis Arapakis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Advancements in Natural Language Processing (NLP), have led to the emergence
of Large Language Models (LLMs) such as GPT, Llama, Claude, and Gemini, which
excel across a range of tasks but require extensive fine-tuning to align their
outputs with human expectations. A widely used method for achieving this
alignment is Reinforcement Learning from Human Feedback (RLHF), which, despite
its success, faces challenges in accurately modelling human preferences. In
this paper, we introduce GazeReward, a novel framework that integrates implicit
feedback -- and specifically eye-tracking (ET) data -- into the Reward Model
(RM). In addition, we explore how ET-based features can provide insights into
user preferences. Through ablation studies we test our framework with different
integration methods, LLMs, and ET generator models, demonstrating that our
approach significantly improves the accuracy of the RM on established human
preference datasets. This work advances the ongoing discussion on optimizing AI
alignment with human values, exploring the potential of cognitive data for
shaping future NLP research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         <span class="highlight-title">★</span> HarmAug: Effective Data Augmentation for Knowledge Distillation of
  Safety Guard Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01524v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01524v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seanie Lee, Haebin Seong, Dong Bok Lee, Minki Kang, Xiaoyin Chen, Dominik Wagner, <span class="highlight-author">Yoshua Bengio</span>, Juho Lee, Sung Ju Hwang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Safety guard models that detect malicious queries aimed at large language
models (LLMs) are essential for ensuring the secure and responsible deployment
of LLMs in real-world applications. However, deploying existing safety guard
models with billions of parameters alongside LLMs on mobile devices is
impractical due to substantial memory requirements and latency. To reduce this
cost, we distill a large teacher safety guard model into a smaller one using a
labeled dataset of instruction-response pairs with binary harmfulness labels.
Due to the limited diversity of harmful instructions in the existing labeled
dataset, naively distilled models tend to underperform compared to larger
models. To bridge the gap between small and large models, we propose HarmAug, a
simple yet effective data augmentation method that involves jailbreaking an LLM
and prompting it to generate harmful instructions. Given a prompt such as,
"Make a single harmful instruction prompt that would elicit offensive content",
we add an affirmative prefix (e.g., "I have an idea for a prompt:") to the
LLM's response. This encourages the LLM to continue generating the rest of the
response, leading to sampling harmful instructions. Another LLM generates a
response to the harmful instruction, and the teacher model labels the
instruction-response pair. We empirically show that our HarmAug outperforms
other relevant baselines. Moreover, a 435-million-parameter safety guard model
trained with HarmAug achieves an F1 score comparable to larger models with over
7 billion parameters, and even outperforms them in AUPRC, while operating at
less than 25% of their computational cost.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ InfiniPot: Infinite Context Processing on Memory-Constrained LLMs <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01518v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01518v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minsoo Kim, Kyuhong Shim, Jungwook Choi, Simyung Chang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Handling long input contexts remains a significant challenge for Large
Language Models (LLMs), particularly in resource-constrained environments such
as mobile devices. Our work aims to address this limitation by introducing
InfiniPot, a novel KV cache control framework designed to enable pre-trained
LLMs to manage extensive sequences within fixed memory constraints efficiently,
without requiring additional training. InfiniPot leverages Continual Context
Distillation (CCD), an iterative process that compresses and retains essential
information through novel importance metrics, effectively maintaining critical
data even without access to future context. Our comprehensive evaluations
indicate that InfiniPot significantly outperforms models trained for long
contexts in various NLP tasks, establishing its efficacy and versatility. This
work represents a substantial advancement toward making LLMs applicable to a
broader range of real-world scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ InstaTrans: An Instruction-Aware Translation Framework for Non-English
  Instruction <span class="highlight-title">Dataset</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01512v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01512v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yungi Kim, Chanjun Park
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  It is challenging to generate high-quality instruction datasets for
non-English languages due to tail phenomena, which limit performance on less
frequently observed data. To mitigate this issue, we propose translating
existing high-quality English instruction datasets as a solution, emphasizing
the need for complete and instruction-aware translations to maintain the
inherent attributes of these datasets. We claim that fine-tuning LLMs with
datasets translated in this way can improve their performance in the target
language. To this end, we introduces a new translation framework tailored for
instruction datasets, named InstaTrans (INSTruction-Aware TRANSlation). Through
extensive experiments, we demonstrate the superiority of InstaTrans over other
competitors in terms of completeness and instruction-awareness of translation,
highlighting its potential to broaden the accessibility of LLMs across diverse
languages at a relatively low cost. Furthermore, we have validated that
fine-tuning LLMs with datasets translated by InstaTrans can effectively improve
their performance in the target language.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Disentangling Latent Shifts of In-Context Learning Through Self-Training 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01508v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01508v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Josip Jukić, Jan Šnajder
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In-context learning (ICL) has become essential in natural language
processing, particularly with autoregressive large language models capable of
learning from demonstrations provided within the prompt. However, ICL faces
challenges with stability and long contexts, especially as the number of
demonstrations grows, leading to poor generalization and inefficient inference.
To address these issues, we introduce STICL (Self-Training ICL), an approach
that disentangles the latent shifts of demonstrations from the latent shift of
the query through self-training. STICL employs a teacher model to generate
pseudo-labels and trains a student model using these labels, encoded in an
adapter module. The student model exhibits weak-to-strong generalization,
progressively refining its predictions over time. Our empirical results show
that STICL improves generalization and stability, consistently outperforming
traditional ICL methods and other disentangling strategies across both
in-domain and out-of-domain data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PersonaMath: Enhancing Math Reasoning through Persona-Driven Data
  Augmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01504v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01504v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jing Luo, Run Luo, Longze Chen, Liang Zhu, Chang Ao, Jiaming Li, Yukun Chen, Xin Cheng, Wen Yang, Jiayuan Su, Chengming Li, Min Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While closed-source Large Language Models (LLMs) demonstrate strong
mathematical problem-solving abilities, open-source models continue to struggle
with such tasks. To bridge this gap, we propose a data augmentation approach
and introduce PersonaMathQA, a dataset derived from MATH and GSM8K, on which we
train the PersonaMath models. Our approach consists of two stages: the first
stage is learning from Persona Diversification, and the second stage is
learning from Reflection. In the first stage, we regenerate detailed
chain-of-thought (CoT) solutions as instructions using a closed-source LLM and
introduce a novel persona-driven data augmentation technique to enhance the
dataset's quantity and diversity. In the second stage, we incorporate
reflection to fully leverage more challenging and valuable questions.
Evaluation of our PersonaMath models on MATH and GSM8K reveals that the
PersonaMath-7B model (based on LLaMA-2-7B) achieves an accuracy of 24.2% on
MATH and 68.7% on GSM8K, surpassing all baseline methods and achieving
state-of-the-art performance. Notably, our dataset contains only 70.3K data
points-merely 17.8% of MetaMathQA and 27% of MathInstruct-yet our model
outperforms these baselines, demonstrating the high quality and diversity of
our dataset, which enables more efficient model training. We open-source the
PersonaMathQA dataset, PersonaMath models, and our code for public usage.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DLP-LoRA: Efficient Task-Specific LoRA Fusion with a Dynamic,
  Lightweight Plugin for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01497v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01497v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxuan Zhang, Ruizhe Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in Large Language Models (LLMs) have achieved robust
performance across diverse tasks, but fine-tuning these models for specific
domains remains resource-intensive. Parameter-Efficient Fine-Tuning (PEFT)
methods like Low-Rank Adaptation (LoRA) address this challenge by fine-tuning a
small subset of parameters. However, existing methods for fusing multiple LoRAs
lack dynamic fusion based on contextual inputs and often increase inference
time due to token-level operations. We propose DLP-LoRA, a Dynamic Lightweight
Plugin that employs a mini-MLP module with only 5M parameters to dynamically
fuse multiple LoRAs at the sentence level using top-p sampling strategies. This
approach reduces inference time to less than twice that of single LoRA
inference by leveraging parallel computation. Evaluations across 26
tasks-including multiple-choice questions and question answering-demonstrate
that DLP-LoRA achieves an average accuracy of 92.34% on multiple-choice
datasets and significant improvements in BLEU and ROUGE scores on QA datasets,
outperforming different LLMs backbones under composite task settings. DLP-LoRA
effectively balances performance and efficiency, making it a practical solution
for dynamic multi-task adaptation in LLMs. Our code is available at
https://github.com/MeCuping/DLP-LoRA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint under review, 18 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Extending Context Window of Large Language Models from a Distributional
  Perspective <span class="chip">EMNLP2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01490v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01490v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yingsheng Wu. Yuxuan Gu, Xiaocheng Feng, Weihong Zhong, Dongliang Xu, Qing Yang, Hongtao Liu, Bing Qin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scaling the rotary position embedding (RoPE) has become a common method for
extending the context window of RoPE-based large language models (LLMs).
However, existing scaling methods often rely on empirical approaches and lack a
profound understanding of the internal distribution within RoPE, resulting in
suboptimal performance in extending the context window length. In this paper,
we propose to optimize the context window extending task from the view of
rotary angle distribution. Specifically, we first estimate the distribution of
the rotary angles within the model and analyze the extent to which length
extension perturbs this distribution. Then, we present a novel extension
strategy that minimizes the disturbance between rotary angle distributions to
maintain consistency with the pre-training phase, enhancing the model's
capability to generalize to longer sequences. Experimental results compared to
the strong baseline methods demonstrate that our approach reduces by up to 72%
of the distributional disturbance when extending LLaMA2's context window to 8k,
and reduces by up to 32% when extending to 16k. On the LongBench-E benchmark,
our method achieves an average improvement of up to 4.33% over existing
state-of-the-art methods. Furthermore, Our method maintains the model's
performance on the Hugging Face Open LLM benchmark after context window
extension, with only an average performance fluctuation ranging from -0.12 to
+0.22.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 8 figures, Accepted to EMNLP2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Small Language Models Like Small Vocabularies: Probing the Linguistic
  Abilities of Grapheme- and Phoneme-Based Baby Llamas 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01487v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01487v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bastian Bunzeck, Daniel Duran, Leonie Schade, Sina Zarrieß
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Current language models use subword-based tokenization algorithms like Byte
Pair Encoding, which put their validity as models of linguistic representations
into question. In this paper, we explore the potential of tokenization-free,
phoneme- and grapheme-based language models. We demonstrate that small models
based on the Llama architecture can achieve strong linguistic performance on
standard syntactic and novel lexical/phonetic benchmarks when trained with
character-level vocabularies. We further show that phoneme-based models without
any graphemic biases almost match grapheme-based models in standard tasks and
novel evaluations. Our findings suggest a promising direction for creating more
linguistically plausible language models that are better suited for
computational studies of language acquisition and processing.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Little Goes a Long Way: Efficient Long Context Training and Inference
  with Partial Contexts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01485v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01485v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Suyu Ge, Xihui Lin, Yunan Zhang, Jiawei Han, Hao Peng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Training and serving long-context large language models (LLMs) incurs
substantial overhead. To address this, two critical steps are often required: a
pretrained LLM typically undergoes a separate stage for context length
extension by training on long-context data, followed by architectural
modifications to reduce the overhead of KV cache during serving. This paper
argues that integrating length extension with a GPU-friendly KV cache reduction
architecture not only reduces training overhead during length extension, but
also achieves better long-context performance. This leads to our proposed
LongGen, which finetunes a pretrained LLM into an efficient architecture during
length extension. LongGen builds on three key insights: (1) Sparse attention
patterns, such as window attention (attending to recent tokens), attention sink
(initial ones), and blockwise sparse attention (strided token blocks) are
well-suited for building efficient long-context models, primarily due to their
GPU-friendly memory access patterns, enabling efficiency gains not just
theoretically but in practice as well. (2) It is essential for the model to
have direct access to all tokens. A hybrid architecture with 1/3 full attention
layers and 2/3 efficient ones achieves a balanced trade-off between efficiency
and long-context performance. (3) Lightweight training on 5B long-context data
is sufficient to extend the hybrid model's context length from 4K to 128K.
  We evaluate LongGen on both Llama-2 7B and Llama-2 70B, demonstrating its
effectiveness across different scales. During training with 128K-long contexts,
LongGen achieves 1.55x training speedup and reduces wall-clock time by 36%,
compared to a full-attention baseline. During inference, LongGen reduces KV
cache memory by 62%, achieving 1.67x prefilling speedup and 1.41x decoding
speedup.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Agent-Driven Large Language Models for Mandarin Lyric Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01450v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01450v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hong-Hsiang Liu, Yi-Wen Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative Large Language Models have shown impressive in-context learning
abilities, performing well across various tasks with just a prompt. Previous
melody-to-lyric research has been limited by scarce high-quality aligned data
and unclear standard for creativeness. Most efforts focused on general themes
or emotions, which are less valuable given current language model capabilities.
In tonal contour languages like Mandarin, pitch contours are influenced by both
melody and tone, leading to variations in lyric-melody fit. Our study,
validated by the Mpop600 dataset, confirms that lyricists and melody writers
consider this fit during their composition process. In this research, we
developed a multi-agent system that decomposes the melody-to-lyric task into
sub-tasks, with each agent controlling rhyme, syllable count, lyric-melody
alignment, and consistency. Listening tests were conducted via a
diffusion-based singing voice synthesizer to evaluate the quality of lyrics
generated by different agent groups.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, figures, Accepted at O-COCOSDA 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Analyzing Byte-Pair Encoding on Monophonic and Polyphonic Symbolic
  Music: A Focus on Musical Phrase Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01448v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01448v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dinh-Viet-Toan Le, Louis Bigo, Mikaela Keller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Byte-Pair Encoding (BPE) is an algorithm commonly used in Natural Language
Processing to build a vocabulary of subwords, which has been recently applied
to symbolic music. Given that symbolic music can differ significantly from
text, particularly with polyphony, we investigate how BPE behaves with
different types of musical content. This study provides a qualitative analysis
of BPE's behavior across various instrumentations and evaluates its impact on a
musical phrase segmentation task for both monophonic and polyphonic music. Our
findings show that the BPE training process is highly dependent on the
instrumentation and that BPE "supertokens" succeed in capturing abstract
musical content. In a musical phrase segmentation task, BPE notably improves
performance in a polyphonic setting, but enhances performance in monophonic
tunes only within a specific range of BPE merges.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to 3rd Workshop on NLP for Music and Audio (NLP4MusA,
  co-located with ISMIR 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         <span class="highlight-title">★</span> Geometric Signatures of Compositionality Across a Language Model's
  Lifetime <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01444v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01444v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jin Hwa Lee, Thomas Jiralerspong, Lei Yu, <span class="highlight-author">Yoshua Bengio</span>, Emily Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Compositionality, the notion that the meaning of an expression is constructed
from the meaning of its parts and syntactic rules, permits the infinite
productivity of human language. For the first time, artificial language models
(LMs) are able to match human performance in a number of compositional
generalization tasks. However, much remains to be understood about the
representational mechanisms underlying these abilities. We take a high-level
geometric approach to this problem by relating the degree of compositionality
in a dataset to the intrinsic dimensionality of its representations under an
LM, a measure of feature complexity. We find not only that the degree of
dataset compositionality is reflected in representations' intrinsic
dimensionality, but that the relationship between compositionality and
geometric complexity arises due to learned linguistic features over training.
Finally, our analyses reveal a striking contrast between linear and nonlinear
dimensionality, showing that they respectively encode formal and semantic
aspects of linguistic composition.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review as a conference paper at ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Circuit Compositions: Exploring Modular Structures in <span class="highlight-title">Transformer</span>-Based
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01434v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01434v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Philipp Mondorf, Sondre Wold, Barbara Plank
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A fundamental question in interpretability research is to what extent neural
networks, particularly language models, implement reusable functions via
subnetworks that can be composed to perform more complex tasks. Recent
developments in mechanistic interpretability have made progress in identifying
subnetworks, often referred to as circuits, which represent the minimal
computational subgraph responsible for a model's behavior on specific tasks.
However, most studies focus on identifying circuits for individual tasks
without investigating how functionally similar circuits relate to each other.
To address this gap, we examine the modularity of neural networks by analyzing
circuits for highly compositional subtasks within a transformer-based language
model. Specifically, given a probabilistic context-free grammar, we identify
and compare circuits responsible for ten modular string-edit operations. Our
results indicate that functionally similar circuits exhibit both notable node
overlap and cross-task faithfulness. Moreover, we demonstrate that the circuits
identified can be reused and combined through subnetwork set operations to
represent more complex functional capabilities of the model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>24 pages, 17 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Can We Further Elicit Reasoning in LLMs? Critic-Guided Planning with
  Retrieval-Augmentation for Solving Challenging Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01428v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01428v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingxuan Li, Weiwen Xu, Ruochen Zhao, Fangkai Jiao, Shafiq Joty, Lidong Bing
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  State-of-the-art large language models (LLMs) exhibit impressive
problem-solving capabilities but may struggle with complex reasoning and
factual correctness. Existing methods harness the strengths of chain-of-thought
and retrieval-augmented generation (RAG) to decompose a complex problem into
simpler steps and apply retrieval to improve factual correctness. These methods
work well on straightforward reasoning tasks but often falter on challenging
tasks such as competitive programming and mathematics, due to frequent
reasoning errors and irrelevant knowledge retrieval. To address this, we
introduce Critic-guided planning with Retrieval-augmentation, CR-Planner, a
novel framework that leverages fine-tuned critic models to guide both reasoning
and retrieval processes through planning. CR-Planner solves a problem by
iteratively selecting and executing sub-goals. Initially, it identifies the
most promising sub-goal from reasoning, query generation, and retrieval, guided
by rewards given by a critic model named sub-goal critic. It then executes this
sub-goal through sampling and selecting the optimal output based on evaluations
from another critic model named execution critic. This iterative process,
informed by retrieved information and critic models, enables CR-Planner to
effectively navigate the solution space towards the final answer. We employ
Monte Carlo Tree Search to collect the data for training the critic models,
allowing for a systematic exploration of action sequences and their long-term
impacts. We validate CR-Planner on challenging domain-knowledge-intensive and
reasoning-heavy tasks, including competitive programming, theorem-driven math
reasoning, and complex domain retrieval problems. Our experiments demonstrate
that CR-Planner significantly outperforms baselines, highlighting its
effectiveness in addressing challenging problems by improving both reasoning
and retrieval.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Labyrinth of Links: Navigating the Associative Maze of Multi-modal
  LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01417v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01417v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hong Li, Nanxi Li, Yuanjie Chen, Jianbin Zhu, Qinlu Guo, Cewu Lu, Yong-Lu Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-modal Large Language Models (MLLMs) have exhibited impressive
capability. However, recently many deficiencies of MLLMs have been found
compared to human intelligence, $\textit{e.g.}$, hallucination. To drive the
MLLMs study, the community dedicated efforts to building larger benchmarks with
complex tasks. In this paper, we propose benchmarking an essential but usually
overlooked intelligence: $\textbf{association}$, a human's basic capability to
link observation and prior practice memory. To comprehensively investigate
MLLM's performance on the association, we formulate the association task and
devise a standard benchmark based on adjective and verb semantic concepts.
Instead of costly data annotation and curation, we propose a convenient
$\textbf{annotation-free}$ construction method transforming the general dataset
for our association tasks. Simultaneously, we devise a rigorous data refinement
process to eliminate confusion in the raw dataset. Building on this database,
we establish three levels of association tasks: single-step, synchronous, and
asynchronous associations. Moreover, we conduct a comprehensive investigation
into the MLLMs' zero-shot association capabilities, addressing multiple
dimensions, including three distinct memory strategies, both open-source and
closed-source MLLMs, cutting-edge Mixture-of-Experts (MoE) models, and the
involvement of human experts. Our systematic investigation shows that current
open-source MLLMs consistently exhibit poor capability in our association
tasks, even the currently state-of-the-art GPT-4V(vision) also has a
significant gap compared to humans. We believe our benchmark would pave the way
for future MLLM studies. $\textit{Our data and code are available at:}$
https://mvig-rhos.com/llm_inception.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Question-guided Knowledge Graph Re-scoring and Injection for Knowledge
  Graph Question Answering <span class="chip">EMNLP2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01401v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01401v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu Zhang, Kehai Chen, Xuefeng Bai, zhao kang, Quanjiang Guo, Min Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge graph question answering (KGQA) involves answering natural language
questions by leveraging structured information stored in a knowledge graph.
Typically, KGQA initially retrieve a targeted subgraph from a large-scale
knowledge graph, which serves as the basis for reasoning models to address
queries. However, the retrieved subgraph inevitably brings distraction
information for knowledge utilization, impeding the model's ability to perform
accurate reasoning. To address this issue, we propose a Question-guided
Knowledge Graph Re-scoring method (Q-KGR) to eliminate noisy pathways for the
input question, thereby focusing specifically on pertinent factual knowledge.
Moreover, we introduce Knowformer, a parameter-efficient method for injecting
the re-scored knowledge graph into large language models to enhance their
ability to perform factual reasoning. Extensive experiments on multiple KGQA
benchmarks demonstrate the superiority of our method over existing systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>findings of EMNLP2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CrowdCounter: A benchmark type-specific multi-target counterspeech
  <span class="highlight-title">dataset</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01400v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01400v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Punyajoy Saha, Abhilash Datta, Abhik Jana, Animesh Mukherjee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Counterspeech presents a viable alternative to banning or suspending users
for hate speech while upholding freedom of expression. However, writing
effective counterspeech is challenging for moderators/users. Hence, developing
suggestion tools for writing counterspeech is the need of the hour. One
critical challenge in developing such a tool is the lack of quality and
diversity of the responses in the existing datasets. Hence, we introduce a new
dataset - CrowdCounter containing 3,425 hate speech-counterspeech pairs
spanning six different counterspeech types (empathy, humor, questioning,
warning, shaming, contradiction), which is the first of its kind. The design of
our annotation platform itself encourages annotators to write type-specific,
non-redundant and high-quality counterspeech. We evaluate two frameworks for
generating counterspeech responses - vanilla and type-controlled prompts -
across four large language models. In terms of metrics, we evaluate the
responses using relevance, diversity and quality. We observe that Flan-T5 is
the best model in the vanilla framework across different models. Type-specific
prompts enhance the relevance of the responses, although they might reduce the
language quality. DialoGPT proves to be the best at following the instructions
and generating the type-specific counterspeech accurately.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 1 figure, 14 tables, Code available
  https://github.com/hate-alert/CrowdCounter</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PairDistill: Pairwise Relevance Distillation for Dense Retrieval <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01383v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01383v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chao-Wei Huang, Yun-Nung Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Effective information retrieval (IR) from vast datasets relies on advanced
techniques to extract relevant information in response to queries. Recent
advancements in dense retrieval have showcased remarkable efficacy compared to
traditional sparse retrieval methods. To further enhance retrieval performance,
knowledge distillation techniques, often leveraging robust cross-encoder
rerankers, have been extensively explored. However, existing approaches
primarily distill knowledge from pointwise rerankers, which assign absolute
relevance scores to documents, thus facing challenges related to inconsistent
comparisons. This paper introduces Pairwise Relevance Distillation
(PairDistill) to leverage pairwise reranking, offering fine-grained
distinctions between similarly relevant documents to enrich the training of
dense retrieval models. Our experiments demonstrate that PairDistill
outperforms existing methods, achieving new state-of-the-art results across
multiple benchmarks. This highlights the potential of PairDistill in advancing
dense retrieval techniques effectively. Our source code and trained models are
released at https://github.com/MiuLab/PairDistill
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Knowledge Entropy Decay during Language Model <span class="highlight-title">Pretrain</span>ing Hinders New
  Knowledge Acquisition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01380v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01380v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiyeon Kim, Hyunji Lee, Hyowon Cho, Joel Jang, Hyeonbin Hwang, Seungpil Won, Youbin Ahn, Dohaeng Lee, Minjoon Seo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we investigate how a model's tendency to broadly integrate its
parametric knowledge evolves throughout pretraining, and how this behavior
affects overall performance, particularly in terms of knowledge acquisition and
forgetting. We introduce the concept of knowledge entropy, which quantifies the
range of memory sources the model engages with; high knowledge entropy
indicates that the model utilizes a wide range of memory sources, while low
knowledge entropy suggests reliance on specific sources with greater certainty.
Our analysis reveals a consistent decline in knowledge entropy as pretraining
advances. We also find that the decline is closely associated with a reduction
in the model's ability to acquire and retain knowledge, leading us to conclude
that diminishing knowledge entropy (smaller number of active memory sources)
impairs the model's knowledge acquisition and retention capabilities. We find
further support for this by demonstrating that increasing the activity of
inactive memory sources enhances the model's capacity for knowledge acquisition
and retention.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PCQPR: Proactive Conversational Question Planning with Reflection <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01363v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01363v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shasha Guo, Lizi Liao, Jing Zhang, Cuiping Li, Hong Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Conversational Question Generation (CQG) enhances the interactivity of
conversational question-answering systems in fields such as education, customer
service, and entertainment. However, traditional CQG, focusing primarily on the
immediate context, lacks the conversational foresight necessary to guide
conversations toward specified conclusions. This limitation significantly
restricts their ability to achieve conclusion-oriented conversational outcomes.
In this work, we redefine the CQG task as Conclusion-driven Conversational
Question Generation (CCQG) by focusing on proactivity, not merely reacting to
the unfolding conversation but actively steering it towards a
conclusion-oriented question-answer pair. To address this, we propose a novel
approach, called Proactive Conversational Question Planning with self-Refining
(PCQPR). Concretely, by integrating a planning algorithm inspired by Monte
Carlo Tree Search (MCTS) with the analytical capabilities of large language
models (LLMs), PCQPR predicts future conversation turns and continuously
refines its questioning strategies. This iterative self-refining mechanism
ensures the generation of contextually relevant questions strategically devised
to reach a specified outcome. Our extensive evaluations demonstrate that PCQPR
significantly surpasses existing CQG methods, marking a paradigm shift towards
conclusion-oriented conversational question-answering systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Assisted Data Annotation for Business Process Information Extraction
  from Textual Documents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01356v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01356v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Julian Neuberger, Han van der Aa, Lars Ackermann, Daniel Buschek, Jannic Herrmann, Stefan Jablonski
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine-learning based generation of process models from natural language
text process descriptions provides a solution for the time-intensive and
expensive process discovery phase. Many organizations have to carry out this
phase, before they can utilize business process management and its benefits.
Yet, research towards this is severely restrained by an apparent lack of large
and high-quality datasets. This lack of data can be attributed to, among other
things, an absence of proper tool assistance for dataset creation, resulting in
high workloads and inferior data quality. We explore two assistance features to
support dataset creation, a recommendation system for identifying process
information in the text and visualization of the current state of already
identified process information as a graphical business process model. A
controlled user study with 31 participants shows that assisting dataset
creators with recommendations lowers all aspects of workload, up to $-51.0\%$,
and significantly improves annotation quality, up to $+38.9\%$. We make all
data and code available to encourage further research on additional novel
assistance strategies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Layer Swapping for Zero-Shot Cross-Lingual Transfer in Large Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01335v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01335v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lucas Bandarkar, Benjamin Muller, Pritish Yuvraj, Rui Hou, Nayan Singhal, Hongjiang Lv, Bing Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Model merging, such as model souping, is the practice of combining different
models with the same architecture together without further training. In this
work, we present a model merging methodology that addresses the difficulty of
fine-tuning Large Language Models (LLMs) for target tasks in non-English
languages, where task-specific data is often unavailable. We focus on
mathematical reasoning and without in-language math data, facilitate
cross-lingual transfer by composing language and math capabilities. Starting
from the same pretrained model, we fine-tune separate "experts" on math
instruction data in English and on generic instruction data in the target
language. We then replace the top and bottom transformer layers of the math
expert directly with layers from the language expert, which consequently
enhances math performance in the target language. The resulting merged models
outperform the individual experts and other merging methods on the math
benchmark, MGSM, by 10% across four major languages where math instruction data
is scarce. In addition, this layer swapping is simple, inexpensive, and
intuitive, as it is based on an interpretative analysis of the most important
parameter changes during the fine-tuning of each expert. The ability to
successfully re-compose LLMs for cross-lingual transfer in this manner opens up
future possibilities to combine model expertise, create modular solutions, and
transfer reasoning capabilities across languages all post hoc.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 main pages, 23 pages total, 9 figures, 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unveiling Language Skills under Circuits 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01334v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01334v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hang Chen, Jiaying Zhu, Xinyu Yang, Wenya Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The exploration of language skills in language models (LMs) has always been
one of the central goals in mechanistic interpretability. However, existing
circuit analyses often fall short in representing the full functional scope of
these models, primarily due to the exclusion of Feed-Forward layers.
Additionally, isolating the effect of a single language skill from a text,
which inherently involves multiple entangled skills, poses a significant
challenge. To address these gaps, we introduce a novel concept, Memory Circuit,
a minimum unit that fully and independently manipulates the memory-reading
functionality of a language model, and disentangle the transformer model
precisely into a circuit graph which is an ensemble of paths connecting
different memory circuits. Based on this disentanglement, we identify salient
circuit paths, named as skill paths, responsible for three crucial language
skills, i.e., the Previous Token Skill, Induction Skill and In-Context Learning
(ICL) Skill, leveraging causal effect estimation through interventions and
counterfactuals. Our experiments on various datasets confirm the correspondence
between our identified skill paths and language skills, and validate three
longstanding hypotheses: 1) Language skills are identifiable through circuit
dissection; 2) Simple language skills reside in shallow layers, whereas complex
language skills are found in deeper layers; 3) Complex language skills are
formed on top of simpler language skills. Our codes are available at:
https://github.com/Zodiark-ch/Language-Skill-of-LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Emotion-Aware Response Generation Using Affect-Enriched Embeddings with
  LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01306v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01306v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abdur Rasool, Muhammad Irfan Shahzad, Hafsa Aslam, Vincent Chan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  There is a need for empathetic and coherent responses in automated
chatbot-facilitated psychotherapy sessions. This study addresses the challenge
of enhancing the emotional and contextual understanding of large language
models (LLMs) in psychiatric applications. We introduce a novel framework that
integrates multiple emotion lexicons, including NRC Emotion Lexicon, VADER,
WordNet, and SentiWordNet, with state-of-the-art LLMs such as LLAMA 2, Flan-T5,
ChatGPT 3.0, and ChatGPT 4.0. The primary dataset comprises over 2,000 therapy
session transcripts from the Counseling and Psychotherapy database, covering
discussions on anxiety, depression, trauma, and addiction. We segment the
transcripts into smaller chunks, enhancing them with lexical features and
computing embeddings using BERT, GPT-3, and RoBERTa to capture semantic and
emotional nuances. These embeddings are stored in a FAISS vector database,
enabling efficient similarity search and clustering based on cosine similarity.
Upon user query, the most relevant segments are retrieved and provided as
context to the LLMs, significantly improving the models' ability to generate
empathetic and contextually appropriate responses. Experimental evaluations
demonstrate that in-corporating emotion lexicons enhances empathy, coherence,
informativeness, and fluency scores. Our findings highlight the critical role
of emotional embeddings in improving LLM performance for psychotherapy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Revisiting Hierarchical Text Classification: Inference and Metrics <span class="chip">CoNLL 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01305v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01305v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Roman Plaud, Matthieu Labeau, Antoine Saillenfest, Thomas Bonald
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Hierarchical text classification (HTC) is the task of assigning labels to a
text within a structured space organized as a hierarchy. Recent works treat HTC
as a conventional multilabel classification problem, therefore evaluating it as
such. We instead propose to evaluate models based on specifically designed
hierarchical metrics and we demonstrate the intricacy of metric choice and
prediction inference method. We introduce a new challenging dataset and we
evaluate fairly, recent sophisticated models, comparing them with a range of
simple but strong baselines, including a new theoretically motivated loss.
Finally, we show that those baselines are very often competitive with the
latest models. This highlights the importance of carefully considering the
evaluation methodology when proposing new methods for HTC. Code implementation
and dataset are available at \url{https://github.com/RomanPlaud/revisitingHTC}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at CoNLL 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Endless Jailbreaks with Bijection Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01294v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01294v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Brian R. Y. Huang, Maximilian Li, Leonard Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite extensive safety training, LLMs are vulnerable to adversarial inputs.
In this work, we introduce a simple but powerful attack paradigm, bijection
learning, that yields a practically endless set of jailbreak prompts. We
exploit language models' advanced reasoning capabilities to teach them
invertible languages (bijections) in context, pass encoded queries to the model
to bypass built-in safety mechanisms, and finally decode responses back into
English, yielding helpful replies to harmful requests. Our approach proves
effective on a wide range of frontier language models and harm categories.
Bijection learning is an automated and universal attack that grows stronger
with scale: larger models with more advanced reasoning capabilities are more
susceptible to bijection learning jailbreaks despite stronger safety
mechanisms.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mitigating Copy Bias in In-Context Learning through Neuron Pruning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01288v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01288v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ameen Ali, Lior Wolf, Ivan Titov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have demonstrated impressive few-shot in-context
learning (ICL) abilities. Still, we show that they are sometimes prone to a
`copying bias', where they copy answers from provided examples instead of
learning the underlying patterns. In this work, we propose a novel and simple
method to mitigate such copying bias. First, we create a synthetic task and use
the Integrated Gradients method to identify neurons that prioritize copying
over generalization. We demonstrate that pruning these neurons consistently
improves performance across a diverse set of ICL tasks. We also show that our
method is applicable across various LLM architectures, including Transformers
and State-Space Models, without requiring modifications. In our analysis, we
adopt a task-recognition perspective on ICL and examine task vectors (Hendel et
al., 2023) induced by the model. We find that pruning enhances the quality of
these vectors, suggesting that the pruned neurons previously hindered effective
task recognition.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Training Data Attribution for Large Language Models with
  Fitting Error Consideration <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01285v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01285v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kangxi Wu, Liang Pang, Huawei Shen, Xueqi Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The black-box nature of large language models (LLMs) poses challenges in
interpreting results, impacting issues such as data intellectual property
protection and hallucination tracing. Training data attribution (TDA) methods
are considered effective solutions to address these challenges. Most recent TDA
methods rely on influence functions, assuming the model achieves minimized
empirical risk. However, achieving this criterion is difficult, and sourcing
accuracy can be compromised by fitting errors during model training. In this
paper, we introduce a novel TDA method called Debias and Denoise Attribution
(DDA), which enhances influence functions by addressing fitting errors.
Specifically, the debias strategy seeks to improve the performance of influence
functions by eliminating the knowledge bias present in the base model before
fine-tuning, while the denoise strategy aims to reduce discrepancies in
influence scores arising from varying degrees of fitting during the training
process through smoothing techniques. Experimental results demonstrate that our
method significantly outperforms existing approaches, achieving an averaged AUC
of 91.64%. Moreover, DDA exhibits strong generality and scalability across
various sources and different-scale models like LLaMA2, QWEN2, and Mistral.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the EMNLP 2024 main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Deep Learning and Machine Learning, Advancing Big Data Analytics and
  Management: Unveiling AI's Potential Through Tools, Techniques, and
  Applications 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01268v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01268v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pohsun Feng, Ziqian Bi, Yizhu Wen, Xuanhe Pan, Benji Peng, Ming Liu, Jiawei Xu, Keyu Chen, Junyu Liu, Caitlyn Heqi Yin, Sen Zhang, Jinlang Wang, Qian Niu, Ming Li, Tianyang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This book serves as an introduction to deep learning and machine learning,
focusing on their applications in big data analytics. It covers essential
concepts, tools like ChatGPT and Claude, hardware recommendations, and
practical guidance on setting up development environments using libraries like
PyTorch and TensorFlow. Designed for beginners and advanced users alike, it
provides step-by-step instructions, hands-on projects, and insights into AI's
future, including AutoML and edge computing.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This book contains 156 pages and 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HelpSteer2-Preference: Complementing Ratings with Preferences 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01257v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01257v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhilin Wang, Alexander Bukharin, Olivier Delalleau, Daniel Egert, Gerald Shen, Jiaqi Zeng, Oleksii Kuchaiev, Yi Dong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reward models are critical for aligning models to follow instructions, and
are typically trained following one of two popular paradigms: Bradley-Terry
style or Regression style. However, there is a lack of evidence that either
approach is better than the other, when adequately matched for data. This is
primarily because these approaches require data collected in different (but
incompatible) formats, meaning that adequately matched data is not available in
existing public datasets. To tackle this problem, we release preference
annotations (designed for Bradley-Terry training) to complement existing
ratings (designed for Regression style training) in the HelpSteer2 dataset. To
improve data interpretability, preference annotations are accompanied with
human-written justifications. Using this data, we conduct the first
head-to-head comparison of Bradley-Terry and Regression models when adequately
matched for data. Based on insights derived from such a comparison, we propose
a novel approach to combine Bradley-Terry and Regression reward modeling. A
Llama-3.1-70B-Instruct model tuned with this approach scores 94.1 on
RewardBench, emerging top of more than 140 reward models as of 1 Oct 2024. We
also demonstrate the effectiveness of this reward model at aligning models to
follow instructions in RLHF. We open-source this dataset (CC-BY-4.0 license) at
https://huggingface.co/datasets/nvidia/HelpSteer2 and openly release the
trained Reward Model at
https://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Reward
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AHP-Powered LLM Reasoning for Multi-Criteria Evaluation of Open-Ended
  Responses <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01246v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01246v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaotian Lu, Jiyi Li, Koh Takeuchi, Hisashi Kashima
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Question answering (QA) tasks have been extensively studied in the field of
natural language processing (NLP). Answers to open-ended questions are highly
diverse and difficult to quantify, and cannot be simply evaluated as correct or
incorrect, unlike close-ended questions with definitive answers. While large
language models (LLMs) have demonstrated strong capabilities across various
tasks, they exhibit relatively weaker performance in evaluating answers to
open-ended questions. In this study, we propose a method that leverages LLMs
and the analytic hierarchy process (AHP) to assess answers to open-ended
questions. We utilized LLMs to generate multiple evaluation criteria for a
question. Subsequently, answers were subjected to pairwise comparisons under
each criterion with LLMs, and scores for each answer were calculated in the
AHP. We conducted experiments on four datasets using both ChatGPT-3.5-turbo and
GPT-4. Our results indicate that our approach more closely aligns with human
judgment compared to the four baselines. Additionally, we explored the impact
of the number of criteria, variations in models, and differences in datasets on
the results.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RGD: Multi-LLM Based Agent Debugger via Refinement and Generation
  Guidance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01242v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01242v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haolin Jin, Zechao Sun, Yiheng Yang, Huaming Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have shown incredible potential in code
generation tasks, and recent research in prompt engineering have enhanced LLMs'
understanding of textual information. However, ensuring the accuracy of
generated code often requires extensive testing and validation by programmers.
While LLMs can typically generate code based on task descriptions, their
accuracy remains limited, especially for complex tasks that require a deeper
understanding of both the problem statement and the code generation process.
This limitation is primarily due to the LLMs' need to simultaneously comprehend
text and generate syntactically and semantically correct code, without having
the capability to automatically refine the code. In real-world software
development, programmers rarely produce flawless code in a single attempt based
on the task description alone, they rely on iterative feedback and debugging to
refine their programs. Inspired by this process, we introduce a novel
architecture of LLM-based agents for code generation and automatic debugging:
Refinement and Guidance Debugging (RGD). The RGD framework is a multi-LLM-based
agent debugger that leverages three distinct LLM agents-Guide Agent, Debug
Agent, and Feedback Agent. RGD decomposes the code generation task into
multiple steps, ensuring a clearer workflow and enabling iterative code
refinement based on self-reflection and feedback. Experimental results
demonstrate that RGD exhibits remarkable code generation capabilities,
achieving state-of-the-art performance with a 9.8% improvement on the HumanEval
dataset and a 16.2% improvement on the MBPP dataset compared to the
state-of-the-art approaches and traditional direct prompting approaches. We
highlight the effectiveness of the RGD framework in enhancing LLMs' ability to
generate and refine code autonomously.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Automatic deductive coding in discourse analysis: an application of
  large language models in learning analytics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01240v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01240v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lishan Zhang, Han Wu, Xiaoshan Huang, Tengfei Duan, Hanxiang Du
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deductive coding is a common discourse analysis method widely used by
learning science and learning analytics researchers for understanding teaching
and learning interactions. It often requires researchers to manually label all
discourses to be analyzed according to a theoretically guided coding scheme,
which is time-consuming and labor-intensive. The emergence of large language
models such as GPT has opened a new avenue for automatic deductive coding to
overcome the limitations of traditional deductive coding. To evaluate the
usefulness of large language models in automatic deductive coding, we employed
three different classification methods driven by different artificial
intelligence technologies, including the traditional text classification method
with text feature engineering, BERT-like pretrained language model and GPT-like
pretrained large language model (LLM). We applied these methods to two
different datasets and explored the potential of GPT and prompt engineering in
automatic deductive coding. By analyzing and comparing the accuracy and Kappa
values of these three classification methods, we found that GPT with prompt
engineering outperformed the other two methods on both datasets with limited
number of training samples. By providing detailed prompt structures, the
reported work demonstrated how large language models can be used in the
implementation of automatic deductive coding.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CASE: Efficient Curricular Data <span class="highlight-title">Pre-train</span>ing for Building Assistive
  Psychology Expert Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.00314v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.00314v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sarthak Harne, Monjoy Narayan Choudhury, Madhav Rao, TK Srikanth, Seema Mehrotra, Apoorva Vashisht, Aarushi Basu, Manjit Sodhi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The limited availability of psychologists necessitates efficient
identification of individuals requiring urgent mental healthcare. This study
explores the use of Natural Language Processing (NLP) pipelines to analyze text
data from online mental health forums used for consultations. By analyzing
forum posts, these pipelines can flag users who may require immediate
professional attention. A crucial challenge in this domain is data privacy and
scarcity. To address this, we propose utilizing readily available curricular
texts used in institutes specializing in mental health for pre-training the NLP
pipelines. This helps us mimic the training process of a psychologist. Our work
presents CASE-BERT that flags potential mental health disorders based on forum
text. CASE-BERT demonstrates superior performance compared to existing methods,
achieving an f1 score of 0.91 for Depression and 0.88 for Anxiety, two of the
most commonly reported mental health disorders. Our code and data are publicly
available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ What is lost in Normalization? Exploring Pitfalls in Multilingual ASR
  Model Evaluations <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02449v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02449v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kavya Manohar, Leena G Pillai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper explores the pitfalls in evaluating multilingual automatic speech
recognition (ASR) models, with a particular focus on Indic language scripts. We
investigate the text normalization routine employed by leading ASR models,
including OpenAI Whisper, Meta's MMS, Seamless, and Assembly AI's Conformer,
and their unintended consequences on performance metrics. Our research reveals
that current text normalization practices, while aiming to standardize ASR
outputs for fair comparison, by removing inconsistencies such as variations in
spelling, punctuation, and special characters, are fundamentally flawed when
applied to Indic scripts. Through empirical analysis using text similarity
scores and in-depth linguistic examination, we demonstrate that these flaws
lead to artificially improved performance metrics for Indic languages. We
conclude by proposing a shift towards developing text normalization routines
that leverage native linguistic expertise, ensuring more robust and accurate
evaluations of multilingual ASR models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Social Conjuring: Multi-User Runtime Collaboration with AI in Building
  Virtual 3D Worlds 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00274v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00274v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amina Kobenova, Cyan DeVeaux, Samyak Parajuli, Andrzej Banburski-Fahey, Judith Amores Fernandez, Jaron Lanier
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative artificial intelligence has shown promise in prompting virtual
worlds into existence, yet little attention has been given to understanding how
this process unfolds as social interaction. We present Social Conjurer, a
framework for AI-augmented dynamic 3D scene co-creation, where multiple users
collaboratively build and modify virtual worlds in real-time. Through an
expanded set of interactions, including social and tool-based engagements as
well as spatial reasoning, our framework facilitates the creation of rich,
diverse virtual environments. Findings from a preliminary user study (N=12)
provide insight into the user experience of this approach, how social contexts
shape the prompting of spatial environments, and perspective on social
applications of prompt-based 3D co-creation. In addition to highlighting the
potential of AI-supported multi-user world creation and offering new pathways
for AI-augmented creative processes in VR, this article presents a set of
implications for designing human-centered interfaces that incorporate AI models
into 3D content generation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>27 pages + Appendix, 16 figures; fixed some minor UTF-8 encoding
  issues in arXiv compilation</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Eliminating Position Bias of Language Models: A Mechanistic Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.01100v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.01100v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziqi Wang, Hanlin Zhang, Xiner Li, Kuan-Hao Huang, Chi Han, Shuiwang Ji, Sham M. Kakade, Hao Peng, Heng Ji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Position bias has proven to be a prevalent issue of modern language models
(LMs), where the models prioritize content based on its position within the
given context. This bias often leads to unexpected model failures and hurts
performance, robustness, and reliability across various applications. Our
mechanistic analysis attributes the position bias to two components employed in
nearly all state-of-the-art LMs: causal attention and relative positional
encodings. Based on the analyses, we propose to eliminate position bias (e.g.,
different retrieved documents' orders in QA affect performance) with a
training-free zero-shot approach. Our method changes the causal attention to
bidirectional attention between documents and utilizes model attention values
to decide the relative orders of documents instead of using the order provided
in input prompts, therefore enabling Position-INvariant inferencE (PINE) at the
document level. By eliminating position bias, models achieve better performance
and reliability in downstream tasks, including LM-as-a-judge,
retrieval-augmented QA, molecule generation, and math reasoning. Notably, PINE
is especially useful when adapting LMs for evaluating reasoning pairs: it
consistently provides 8 to 10 percentage points performance gains, making
Llama-3-70B-Instruct perform even better than GPT-4-0125-preview and
GPT-4o-2024-08-06 on the RewardBench reasoning set.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages, 6 figures, 15 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Scaling Optimal LR Across Token Horizons 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19913v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19913v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Johan Bjorck, Alon Benhaim, Vishrav Chaudhary, Furu Wei, Xia Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  State-of-the-art LLMs are powered by scaling -- scaling model size, dataset
size and cluster size. It is economically infeasible to extensively tune
hyperparameter for the largest runs. Instead, approximately optimal
hyperparameters must be inferred or \textit{transferred} from smaller
experiments. Hyperparameter transfer across model sizes has been studied in
Yang et al. However, hyperparameter transfer across dataset size -- or token
horizon -- has not been studied yet. To remedy this we conduct a large scale
empirical study on how optimal learning rate (LR) depends on token horizon in
LLM training. We first demonstrate that the optimal LR changes significantly
with token horizon -- longer training necessitates smaller LR. Secondly we
demonstrate the the optimal LR follows a scaling law, and that the optimal LR
for longer horizons can be accurately estimated from shorter horizons via such
scaling laws. We also provide a rule-of-thumb for transferring LR across token
horizons with zero overhead over current practices. Lastly we provide evidence
that LLama-1 used too high LR, and estimate the performance hit from this. We
thus argue that hyperparameter transfer across data size is an important and
overlooked component of LLM training.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Controllable Preference Optimization: Toward Controllable
  Multi-Objective Alignment <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.19085v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.19085v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiju Guo, Ganqu Cui, Lifan Yuan, Ning Ding, Zexu Sun, Bowen Sun, Huimin Chen, Ruobing Xie, Jie Zhou, Yankai Lin, Zhiyuan Liu, Maosong Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Alignment in artificial intelligence pursues the consistency between model
responses and human preferences as well as values. In practice, the
multifaceted nature of human preferences inadvertently introduces what is known
as the "alignment tax" -a compromise where enhancements in alignment within one
objective (e.g.,harmlessness) can diminish performance in others
(e.g.,helpfulness). However, existing alignment techniques are mostly
unidirectional, leading to suboptimal trade-offs and poor flexibility over
various objectives. To navigate this challenge, we argue the prominence of
grounding LLMs with evident preferences. We introduce controllable preference
optimization (CPO), which explicitly specifies preference scores for different
objectives, thereby guiding the model to generate responses that meet the
requirements. Our experimental analysis reveals that the aligned models can
provide responses that match various preferences among the "3H" (helpfulness,
honesty, harmlessness) desiderata. Furthermore, by introducing diverse data and
alignment goals, we surpass baseline methods in aligning with single
objectives, hence mitigating the impact of the alignment tax and achieving
Pareto improvements in multi-objective alignment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 main conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ README: Bridging Medical Jargon and Lay Understanding for Patient
  Education through Data-Centric NLP <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.15561v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.15561v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zonghai Yao, Nandyala Siddharth Kantu, Guanghao Wei, Hieu Tran, Zhangqi Duan, Sunjae Kwon, Zhichao Yang, README annotation team, Hong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The advancement in healthcare has shifted focus toward patient-centric
approaches, particularly in self-care and patient education, facilitated by
access to Electronic Health Records (EHR). However, medical jargon in EHRs
poses significant challenges in patient comprehension. To address this, we
introduce a new task of automatically generating lay definitions, aiming to
simplify complex medical terms into patient-friendly lay language. We first
created the README dataset, an extensive collection of over 50,000 unique
(medical term, lay definition) pairs and 300,000 mentions, each offering
context-aware lay definitions manually annotated by domain experts. We have
also engineered a data-centric Human-AI pipeline that synergizes data
filtering, augmentation, and selection to improve data quality. We then used
README as the training data for models and leveraged a Retrieval-Augmented
Generation method to reduce hallucinations and improve the quality of model
outputs. Our extensive automatic and human evaluations demonstrate that
open-source mobile-friendly models, when fine-tuned with high-quality data, are
capable of matching or even surpassing the performance of state-of-the-art
closed-source large language models like ChatGPT. This research represents a
significant stride in closing the knowledge gap in patient education and
advancing patient-centric healthcare solutions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear in Findings of the Association for Computational
  Linguistics: EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning Dynamics of LLM Finetuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10490v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10490v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi Ren, Danica J. Sutherland
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning dynamics, which describes how the learning of specific training
examples influences the model's predictions on other examples, gives us a
powerful tool for understanding the behavior of deep learning systems. We study
the learning dynamics of large language models during different types of
finetuning, by analyzing the step-wise decomposition of how influence
accumulates among different potential responses. Our framework allows a uniform
interpretation of many interesting observations about the training of popular
algorithms for both instruction tuning and preference tuning. In particular, we
propose a hypothetical explanation of why specific types of hallucination are
strengthened after finetuning, e.g., the model might use phrases or facts in
the response for question B to answer question A, or the model might keep
repeating similar simple phrases when generating responses. We also extend our
framework and highlight a unique "squeezing effect" to explain a previously
observed phenomenon in off-policy direct preference optimization (DPO), where
running DPO for too long makes even the desired outputs less likely. This
framework also provides insights into where the benefits of on-policy DPO and
other variants come from. The analysis not only provides a novel perspective of
understanding LLM's finetuning but also inspires a simple, effective method to
improve alignment performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SCAR: Efficient Instruction-Tuning for Large Language Models via Style
  Consistency-Aware Response Ranking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.10882v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.10882v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhuang Li, Yuncheng Hua, Thuy-Trang Vu, Haolan Zhan, Lizhen Qu, Gholamreza Haffari
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent studies have shown that maintaining a consistent response style by
human experts and enhancing data quality in training sets can significantly
improve the performance of fine-tuned Large Language Models (LLMs) while
reducing the number of training examples needed. However, the precise
definition of style and the relationship between style, data quality, and LLM
performance remains unclear. This research identifies two key stylistic
elements in responses: linguistic form and semantic surprisal. We find that,
among training data of comparable quality, higher consistency in these response
elements leads to better LLM performance. Inspired by this, we introduce Style
Consistency-Aware Response Ranking (SCAR), which automatically prioritizes
instruction-response pairs in the training set based on their response
stylistic consistency. By selecting the most style-consistent examples,
sometimes as few as 0.7% of the full dataset, the fine-tuned LLMs can match or
even surpass the performance of models trained on the entire dataset in coding
and open-ended question-answering benchmarks. Code and data are available at
https://github.com/zhuang-li/SCAR .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>27 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LogicAsker: Evaluating and Improving the Logical Reasoning Ability of
  Large Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.00757v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.00757v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxuan Wan, Wenxuan Wang, Yiliu Yang, Youliang Yuan, Jen-tse Huang, Pinjia He, Wenxiang Jiao, Michael R. Lyu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce LogicAsker, a novel approach for evaluating and enhancing the
logical reasoning capabilities of large language models (LLMs) such as ChatGPT
and GPT-4. Despite LLMs' prowess in tasks like writing assistance, code
generation, and machine translation, assessing their ability to reason has been
challenging. Traditional evaluations often prioritize accuracy on downstream
tasks over direct assessments of reasoning processes. LogicAsker addresses this
gap by employing a set of atomic reasoning skills grounded in propositional and
predicate logic to systematically examine and improve the reasoning prowess of
LLMs. Our methodology reveals significant gaps in LLMs' learning of logical
rules, with identified reasoning failures ranging from 29\% to 90\% across
different models. Moreover, we leverage these findings to construct targeted
demonstration examples and fine-tune data, notably enhancing logical reasoning
in models like GPT-4o by up to 5\%. To our knowledge, this is the first effort
to utilize test case outcomes to effectively refine LLMs' formal reasoning
capabilities. We make our code, data, and results publicly available
(https://github.com/yxwan123/LogicAsker) to facilitate further research and
replication of our findings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SysCaps: Language Interfaces for Simulation Surrogates of Complex
  Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.19653v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.19653v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Patrick Emami, Zhaonan Li, Saumya Sinha, Truc Nguyen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Surrogate models are used to predict the behavior of complex energy systems
that are too expensive to simulate with traditional numerical methods. Our work
introduces the use of language descriptions, which we call "system captions" or
SysCaps, to interface with such surrogates. We argue that interacting with
surrogates through text, particularly natural language, makes these models more
accessible for both experts and non-experts. We introduce a lightweight
multimodal text and timeseries regression model and a training pipeline that
uses large language models (LLMs) to synthesize high-quality captions from
simulation metadata. Our experiments on two real-world simulators of buildings
and wind farms show that our SysCaps-augmented surrogates have better accuracy
on held-out systems than traditional methods while enjoying new generalization
abilities, such as handling semantically related descriptions of the same test
system. Additional experiments also highlight the potential of SysCaps to
unlock language-driven design space exploration and to regularize training
through prompt augmentation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages. Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Optimized Multi-Token Joint Decoding with Auxiliary Model for LLM
  Inference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.09722v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.09722v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zongyue Qin, Ziniu Hu, Zifan He, Neha Prakriya, Jason Cong, Yizhou Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have achieved remarkable success across diverse
tasks, yet their inference processes are hindered by substantial time and
energy demands due to single-token generation at each decoding step. While
previous methods such as speculative decoding mitigate these inefficiencies by
producing multiple tokens per step, each token is still generated by its
single-token distribution, thereby enhancing speed without improving
effectiveness. In contrast, our work simultaneously enhances inference speed
and improves the output effectiveness. We consider multi-token joint decoding
(MTJD), which generates multiple tokens from their joint distribution at each
iteration, theoretically reducing perplexity and enhancing task performance.
However, MTJD suffers from the high cost of sampling from the joint
distribution of multiple tokens. Inspired by speculative decoding, we introduce
multi-token assisted decoding (MTAD), a novel framework designed to accelerate
MTJD. MTAD leverages a smaller auxiliary model to approximate the joint
distribution of a larger model, incorporating a verification mechanism that not
only ensures the accuracy of this approximation, but also improves the decoding
efficiency over conventional speculative decoding. Theoretically, we
demonstrate that MTAD closely approximates exact MTJD with bounded error.
Empirical evaluations using Llama-2 and OPT models ranging from 13B to 70B
parameters across various tasks reveal that MTAD reduces perplexity by 21.2%
and improves downstream performance compared to standard single-token sampling.
Furthermore, MTAD achieves a 1.42x speed-up and consumes 1.54x less energy than
conventional speculative decoding methods. These results highlight MTAD's
ability to make multi-token joint decoding both effective and efficient,
promoting more sustainable and high-performance deployment of LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tool-Planner: Task Planning with Clusters across Multiple Tools 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.03807v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.03807v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanming Liu, Xinyue Peng, Jiannan Cao, Shi Bo, Yuwei Zhang, Xuhong Zhang, Sheng Cheng, Xun Wang, Jianwei Yin, Tianyu Du
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have demonstrated exceptional reasoning
capabilities, enabling them to solve various complex problems. Recently, this
ability has been applied to the paradigm of tool learning. Tool learning
involves providing examples of tool usage and their corresponding functions,
allowing LLMs to formulate plans and demonstrate the process of invoking and
executing each tool. LLMs can address tasks that they cannot complete
independently, thereby enhancing their potential across different tasks.
However, this approach faces two key challenges. First, redundant error
correction leads to unstable planning and long execution time. Additionally,
designing a correct plan among multiple tools is also a challenge in tool
learning. To address these issues, we propose Tool-Planner, a task-processing
framework based on toolkits. Tool-Planner groups tools based on the API
functions with the same function into a toolkit and allows LLMs to implement
planning across the various toolkits. When a tool error occurs, the language
model can reselect and adjust tools based on the toolkit. Experiments show that
our approach demonstrates a high pass and win rate across different datasets
and optimizes the planning scheme for tool learning in models such as GPT-4 and
Claude 3, showcasing the potential of our method. Our code is public at
\url{https://github.com/OceannTwT/Tool-Planner}
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>48pages second version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TuBA: Cross-Lingual Transferability of Backdoor Attacks in LLMs with
  Instruction Tuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.19597v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.19597v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuanli He, Jun Wang, Qiongkai Xu, Pasquale Minervini, Pontus Stenetorp, Benjamin I. P. Rubinstein, Trevor Cohn
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The implications of backdoor attacks on English-centric large language models
(LLMs) have been widely examined - such attacks can be achieved by embedding
malicious behaviors during training and activated under specific conditions
that trigger malicious outputs. Despite the increasing support for multilingual
capabilities in open-source and proprietary LLMs, the impact of backdoor
attacks on these systems remains largely under-explored. Our research focuses
on cross-lingual backdoor attacks against multilingual LLMs, particularly
investigating how poisoning the instruction-tuning data for one or two
languages can affect the outputs for languages whose instruction-tuning data
were not poisoned. Despite its simplicity, our empirical analysis reveals that
our method exhibits remarkable efficacy in models like mT5 and GPT-4o, with
high attack success rates, surpassing 90% in more than 7 out of 12 languages
across various scenarios. Our findings also indicate that more powerful models
show increased susceptibility to transferable cross-lingual backdoor attacks,
which also applies to LLMs predominantly pre-trained on English data, such as
Llama2, Llama3, and Gemma. Moreover, our experiments demonstrate 1) High
Transferability: the backdoor mechanism operates successfully in cross-lingual
response scenarios across 26 languages, achieving an average attack success
rate of 99%, and 2) Robustness: the proposed attack remains effective even
after defenses are applied. These findings expose critical security
vulnerabilities in multilingual LLMs and highlight the urgent need for more
robust, targeted defense strategies to address the unique challenges posed by
cross-lingual backdoor transfer.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Addition is All You Need for Energy-efficient Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00907v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00907v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongyin Luo, Wei Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large neural networks spend most computation on floating point tensor
multiplications. In this work, we find that a floating point multiplier can be
approximated by one integer adder with high precision. We propose the
linear-complexity multiplication L-Mul algorithm that approximates floating
point number multiplication with integer addition operations. The new algorithm
costs significantly less computation resource than 8-bit floating point
multiplication but achieves higher precision. Compared to 8-bit floating point
multiplications, the proposed method achieves higher precision but consumes
significantly less bit-level computation. Since multiplying floating point
numbers requires substantially higher energy compared to integer addition
operations, applying the L-Mul operation in tensor processing hardware can
potentially reduce 95% energy cost by element-wise floating point tensor
multiplications and 80% energy cost of dot products. We calculated the
theoretical error expectation of L-Mul, and evaluated the algorithm on a wide
range of textual, visual, and symbolic tasks, including natural language
understanding, structural reasoning, mathematics, and commonsense question
answering. Our numerical analysis experiments agree with the theoretical error
estimation, which indicates that L-Mul with 4-bit mantissa achieves comparable
precision as float8_e4m3 multiplications, and L-Mul with 3-bit mantissa
outperforms float8_e5m2. Evaluation results on popular benchmarks show that
directly applying L-Mul to the attention mechanism is almost lossless. We
further show that replacing all floating point multiplications with 3-bit
mantissa L-Mul in a transformer model achieves equivalent precision as using
float8_e4m3 as accumulation precision in both fine-tuning and inference.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ What is "Typological Diversity" in NLP? <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.04222v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.04222v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Esther Ploeger, Wessel Poelman, Miryam de Lhoneux, Johannes Bjerva
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The NLP research community has devoted increased attention to languages
beyond English, resulting in considerable improvements for multilingual NLP.
However, these improvements only apply to a small subset of the world's
languages. Aiming to extend this, an increasing number of papers aspires to
enhance generalizable multilingual performance across languages. To this end,
linguistic typology is commonly used to motivate language selection, on the
basis that a broad typological sample ought to imply generalization across a
broad range of languages. These selections are often described as being
'typologically diverse'. In this work, we systematically investigate NLP
research that includes claims regarding 'typological diversity'. We find there
are no set definitions or criteria for such claims. We introduce metrics to
approximate the diversity of language selection along several axes and find
that the results vary considerably across papers. Crucially, we show that
skewed language selection can lead to overestimated multilingual performance.
We recommend future work to include an operationalization of 'typological
diversity' that empirically justifies the diversity of language samples.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024: Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Gemma 2: Improving Open Language Models at a Practical Size 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.00118v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.00118v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                         Gemma Team, Morgane Riviere, Shreya Pathak, Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupatiraju, Léonard Hussenot, Thomas Mesnard, Bobak Shahriari, Alexandre Ramé, Johan Ferret, Peter Liu, Pouya Tafti, Abe Friesen, Michelle Casbon, Sabela Ramos, Ravin Kumar, Charline Le Lan, Sammy Jerome, Anton Tsitsulin, Nino Vieillard, Piotr Stanczyk, Sertan Girgin, Nikola Momchev, Matt Hoffman, Shantanu Thakoor, Jean-Bastien Grill, Behnam Neyshabur, Olivier Bachem, Alanna Walton, Aliaksei Severyn, Alicia Parrish, Aliya Ahmad, Allen Hutchison, Alvin Abdagic, Amanda Carl, Amy Shen, Andy Brock, Andy Coenen, Anthony Laforge, Antonia Paterson, Ben Bastian, Bilal Piot, Bo Wu, Brandon Royal, Charlie Chen, Chintu Kumar, Chris Perry, Chris Welty, Christopher A. Choquette-Choo, Danila Sinopalnikov, David Weinberger, Dimple Vijaykumar, Dominika Rogozińska, Dustin Herbison, Elisa Bandy, Emma Wang, Eric Noland, Erica Moreira, Evan Senter, Evgenii Eltyshev, Francesco Visin, Gabriel Rasskin, Gary Wei, Glenn Cameron, Gus Martins, Hadi Hashemi, Hanna Klimczak-Plucińska, Harleen Batra, Harsh Dhand, Ivan Nardini, Jacinda Mein, Jack Zhou, James Svensson, Jeff Stanway, Jetha Chan, Jin Peng Zhou, Joana Carrasqueira, Joana Iljazi, Jocelyn Becker, Joe Fernandez, Joost van Amersfoort, Josh Gordon, Josh Lipschultz, Josh Newlan, Ju-yeong Ji, Kareem Mohamed, Kartikeya Badola, Kat Black, Katie Millican, Keelin McDonell, Kelvin Nguyen, Kiranbir Sodhia, Kish Greene, Lars Lowe Sjoesund, Lauren Usui, Laurent Sifre, Lena Heuermann, Leticia Lago, Lilly McNealus, Livio Baldini Soares, Logan Kilpatrick, Lucas Dixon, Luciano Martins, Machel Reid, Manvinder Singh, Mark Iverson, Martin Görner, Mat Velloso, Mateo Wirth, Matt Davidow, Matt Miller, Matthew Rahtz, Matthew Watson, Meg Risdal, Mehran Kazemi, Michael Moynihan, Ming Zhang, Minsuk Kahng, Minwoo Park, Mofi Rahman, Mohit Khatwani, Natalie Dao, Nenshad Bardoliwalla, Nesh Devanathan, Neta Dumai, Nilay Chauhan, Oscar Wahltinez, Pankil Botarda, Parker Barnes, Paul Barham, Paul Michel, Pengchong Jin, Petko Georgiev, Phil Culliton, Pradeep Kuppala, Ramona Comanescu, Ramona Merhej, Reena Jana, Reza Ardeshir Rokni, Rishabh Agarwal, Ryan Mullins, Samaneh Saadat, Sara Mc Carthy, Sarah Cogan, Sarah Perrin, Sébastien M. R. Arnold, Sebastian Krause, Shengyang Dai, Shruti Garg, Shruti Sheth, Sue Ronstrom, Susan Chan, Timothy Jordan, Ting Yu, Tom Eccles, Tom Hennigan, Tomas Kocisky, Tulsee Doshi, Vihan Jain, Vikas Yadav, Vilobh Meshram, Vishal Dharmadhikari, Warren Barkley, Wei Wei, Wenming Ye, Woohyun Han, Woosuk Kwon, Xiang Xu, Zhe Shen, Zhitao Gong, Zichuan Wei, Victor Cotruta, Phoebe Kirk, Anand Rao, Minh Giang, Ludovic Peran, Tris Warkentin, Eli Collins, Joelle Barral, Zoubin Ghahramani, Raia Hadsell, D. Sculley, Jeanine Banks, Anca Dragan, Slav Petrov, Oriol Vinyals, Jeff Dean, Demis Hassabis, Koray Kavukcuoglu, Clement Farabet, Elena Buchatskaya, Sebastian Borgeaud, Noah Fiedel, Armand Joulin, Kathleen Kenealy, Robert Dadashi, Alek Andreev
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we introduce Gemma 2, a new addition to the Gemma family of
lightweight, state-of-the-art open models, ranging in scale from 2 billion to
27 billion parameters. In this new version, we apply several known technical
modifications to the Transformer architecture, such as interleaving
local-global attentions (Beltagy et al., 2020a) and group-query attention
(Ainslie et al., 2023). We also train the 2B and 9B models with knowledge
distillation (Hinton et al., 2015) instead of next token prediction. The
resulting models deliver the best performance for their size, and even offer
competitive alternatives to models that are 2-3 times bigger. We release all
our models to the community.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Reliable and diverse evaluation of LLM medical knowledge mastery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.14302v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.14302v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxuan Zhou, Xien Liu, Chen Ning, Xiao Zhang, Ji Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mastering medical knowledge is crucial for medical-specific LLMs. However,
despite the existence of medical benchmarks like MedQA, a unified framework
that fully leverages existing knowledge bases to evaluate LLMs' mastery of
medical knowledge is still lacking. In the study, we propose a novel framework
PretexEval that dynamically generates reliable and diverse test samples to
evaluate LLMs for any given medical knowledge base. We notice that test samples
produced directly from knowledge bases by templates or LLMs may introduce
factual errors and also lack diversity. To address these issues, we introduce a
novel schema into our proposed evaluation framework that employs predicate
equivalence transformations to produce a series of variants for any given
medical knowledge point. Finally, these produced predicate variants are
converted into textual language, resulting in a series of reliable and diverse
test samples to evaluate whether LLMs fully master the given medical factual
knowledge point. Here, we use our proposed framework to systematically
investigate the mastery of medical factual knowledge of 12 well-known LLMs,
based on two knowledge bases that are crucial for clinical diagnosis and
treatment. The evaluation results illustrate that current LLMs still exhibit
significant deficiencies in fully mastering medical knowledge, despite
achieving considerable success on some famous public benchmarks. These new
findings provide valuable insights for developing medical-specific LLMs,
highlighting that current LLMs urgently need to strengthen their comprehensive
and in-depth mastery of medical knowledge before being applied to real-world
medical scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Late Chunking: Contextual Chunk Embeddings Using Long-Context Embedding
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04701v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04701v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michael Günther, Isabelle Mohr, Daniel James Williams, Bo Wang, Han Xiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many use cases require retrieving smaller portions of text, and dense
vector-based retrieval systems often perform better with shorter text segments,
as the semantics are less likely to be over-compressed in the embeddings.
Consequently, practitioners often split text documents into smaller chunks and
encode them separately. However, chunk embeddings created in this way can lose
contextual information from surrounding chunks, resulting in sub-optimal
representations. In this paper, we introduce a novel method called late
chunking, which leverages long context embedding models to first embed all
tokens of the long text, with chunking applied after the transformer model and
just before mean pooling - hence the term late in its naming. The resulting
chunk embeddings capture the full contextual information, leading to superior
results across various retrieval tasks. The method is generic enough to be
applied to a wide range of long-context embedding models and works without
additional training. To further increase the effectiveness of late chunking, we
propose a dedicated fine-tuning approach for embedding models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 3rd draft</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TOPFORMER: Topology-Aware Authorship Attribution of Deepfake Texts with
  Diverse Writing Styles <span class="chip">ECAI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.12934v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.12934v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Adaku Uchendu, Thai Le, Dongwon Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in Large Language Models (LLMs) have enabled the generation
of open-ended high-quality texts, that are non-trivial to distinguish from
human-written texts. We refer to such LLM-generated texts as deepfake texts.
There are currently over 72K text generation models in the huggingface model
repo. As such, users with malicious intent can easily use these open-sourced
LLMs to generate harmful texts and dis/misinformation at scale. To mitigate
this problem, a computational method to determine if a given text is a deepfake
text or not is desired--i.e., Turing Test (TT). In particular, in this work, we
investigate the more general version of the problem, known as Authorship
Attribution (AA), in a multi-class setting--i.e., not only determining if a
given text is a deepfake text or not but also being able to pinpoint which LLM
is the author. We propose TopFormer to improve existing AA solutions by
capturing more linguistic patterns in deepfake texts by including a Topological
Data Analysis (TDA) layer in the Transformer-based model. We show the benefits
of having a TDA layer when dealing with imbalanced, and multi-style datasets,
by extracting TDA features from the reshaped $pooled\_output$ of our backbone
as input. This Transformer-based model captures contextual representations
(i.e., semantic and syntactic linguistic features), while TDA captures the
shape and structure of data (i.e., linguistic structures). Finally, TopFormer,
outperforms all baselines in all 3 datasets, achieving up to 7\% increase in
Macro F1 score. Our code and datasets are available at:
https://github.com/AdaUchendu/topformer
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at The 27th European Conference on Artificial Intelligence
  (ECAI 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multiple Heads are Better than One: Mixture of Modality Knowledge
  Experts for Entity Representation Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.16869v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.16869v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yichi Zhang, Zhuo Chen, Lingbing Guo, Yajing Xu, Binbin Hu, Ziqi Liu, Wen Zhang, Huajun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning high-quality multi-modal entity representations is an important goal
of multi-modal knowledge graph (MMKG) representation learning, which can
enhance reasoning tasks within the MMKGs, such as MMKG completion (MMKGC). The
main challenge is to collaboratively model the structural information concealed
in massive triples and the multi-modal features of the entities. Existing
methods focus on crafting elegant entity-wise multi-modal fusion strategies,
yet they overlook the utilization of multi-perspective features concealed
within the modalities under diverse relational contexts. To address this issue,
we introduce a novel framework with Mixture of Modality Knowledge experts
(MoMoK for short) to learn adaptive multi-modal entity representations for
better MMKGC. We design relation-guided modality knowledge experts to acquire
relation-aware modality embeddings and integrate the predictions from
multi-modalities to achieve joint decisions. Additionally, we disentangle the
experts by minimizing their mutual information. Experiments on four public MMKG
benchmarks demonstrate the outstanding performance of MoMoK under complex
scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress. Code and data will be released at
  https://github.com/zjukg/MoMoK</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CUTE: Measuring LLMs' Understanding of Their Tokens <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15452v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15452v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lukas Edman, Helmut Schmid, Alexander Fraser
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) show remarkable performance on a wide variety of
tasks. Most LLMs split text into multi-character tokens and process them as
atomic units without direct access to individual characters. This raises the
question: To what extent can LLMs learn orthographic information? To answer
this, we propose a new benchmark, CUTE, which features a collection of tasks
designed to test the orthographic knowledge of LLMs. We evaluate popular LLMs
on CUTE, finding that most of them seem to know the spelling of their tokens,
yet fail to use this information effectively to manipulate text, calling into
question how much of this knowledge is generalizable.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 main conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Contextual Compression in Retrieval-Augmented Generation for Large
  Language Models: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.13385v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.13385v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sourav Verma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) showcase remarkable abilities, yet they struggle
with limitations such as hallucinations, outdated knowledge, opacity, and
inexplicable reasoning. To address these challenges, Retrieval-Augmented
Generation (RAG) has proven to be a viable solution, leveraging external
databases to improve the consistency and coherence of generated content,
especially valuable for complex, knowledge-rich tasks, and facilitates
continuous improvement by leveraging domain-specific insights. By combining the
intrinsic knowledge of LLMs with the vast, dynamic repositories of external
databases, RAG achieves a synergistic effect. However, RAG is not without its
limitations, including a limited context window, irrelevant information, and
the high processing overhead for extensive contextual data. In this
comprehensive work, we explore the evolution of Contextual Compression
paradigms, providing an in-depth examination of the field. Finally, we outline
the current challenges and suggest potential research and development
directions, paving the way for future advancements in this area.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Ongoing Work</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Entity or Relation Embeddings? An Analysis of Encoding Strategies for
  Relation Extraction <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.11062v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.11062v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Frank Mtumbuka, Steven Schockaert
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Relation extraction is essentially a text classification problem, which can
be tackled by fine-tuning a pre-trained language model (LM). However, a key
challenge arises from the fact that relation extraction cannot
straightforwardly be reduced to sequence or token classification. Existing
approaches therefore solve the problem in an indirect way: they fine-tune an LM
to learn embeddings of the head and tail entities, and then predict the
relationship from these entity embeddings. Our hypothesis in this paper is that
relation extraction models can be improved by capturing relationships in a more
direct way. In particular, we experiment with appending a prompt with a [MASK]
token, whose contextualised representation is treated as a relation embedding.
While, on its own, this strategy significantly underperforms the aforementioned
approach, we find that the resulting relation embeddings are highly
complementary to what is captured by embeddings of the head and tail entity. By
jointly considering both types of representations, we end up with a simple
model that outperforms the state-of-the-art across several relation extraction
benchmarks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in the Findings of EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SciEx: Benchmarking Large Language Models on Scientific Exams with Human
  Expert Grading and Automatic Grading <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.10421v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.10421v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tu Anh Dinh, Carlos Mullov, Leonard Bärmann, Zhaolin Li, Danni Liu, Simon Reiß, Jueun Lee, Nathan Lerzer, Fabian Ternava, Jianfeng Gao, Tobias Röddiger, Alexander Waibel, Tamim Asfour, Michael Beigl, Rainer Stiefelhagen, Carsten Dachsbacher, Klemens Böhm, Jan Niehues
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid development of Large Language Models (LLMs), it is crucial to
have benchmarks which can evaluate the ability of LLMs on different domains.
One common use of LLMs is performing tasks on scientific topics, such as
writing algorithms, querying databases or giving mathematical proofs. Inspired
by the way university students are evaluated on such tasks, in this paper, we
propose SciEx - a benchmark consisting of university computer science exam
questions, to evaluate LLMs ability on solving scientific tasks. SciEx is (1)
multilingual, containing both English and German exams, and (2) multi-modal,
containing questions that involve images, and (3) contains various types of
freeform questions with different difficulty levels, due to the nature of
university exams. We evaluate the performance of various state-of-the-art LLMs
on our new benchmark. Since SciEx questions are freeform, it is not
straightforward to evaluate LLM performance. Therefore, we provide human expert
grading of the LLM outputs on SciEx. We show that the free-form exams in SciEx
remain challenging for the current LLMs, where the best LLM only achieves
59.4\% exam grade on average. We also provide detailed comparisons between LLM
performance and student performance on SciEx. To enable future evaluation of
new LLMs, we propose using LLM-as-a-judge to grade the LLM answers on SciEx.
Our experiments show that, although they do not perform perfectly on solving
the exams, LLMs are decent as graders, achieving 0.948 Pearson correlation with
expert grading.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ KnowTuning: Knowledge-aware Fine-tuning for Large Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.11176v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.11176v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yougang Lyu, Lingyong Yan, Shuaiqiang Wang, Haibo Shi, Dawei Yin, Pengjie Ren, Zhumin Chen, Maarten de Rijke, Zhaochun Ren
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite their success at many natural language processing (NLP) tasks, large
language models still struggle to effectively leverage knowledge for
knowledge-intensive tasks, manifesting limitations such as generating
incomplete, non-factual, or illogical answers. These limitations stem from
inadequate knowledge awareness of LLMs during vanilla fine-tuning. To address
these problems, we propose a knowledge-aware fine-tuning (KnowTuning) method to
improve fine-grained and coarse-grained knowledge awareness of LLMs. We devise
a fine-grained knowledge augmentation stage to train LLMs to identify difficult
fine-grained knowledge in answers. We also propose a coarse-grained knowledge
comparison stage to train LLMs to distinguish between reliable and unreliable
knowledge, in three aspects: completeness, factuality, and logicality.
Extensive experiments on both generic and medical question answering (QA)
datasets confirm the effectiveness of KnowTuning, through automatic and human
evaluations, across various sizes of LLMs. We further verify that KnowTuning
generates more facts with less factual error rate under fine-grained facts
evaluation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 main paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AutoPal: Autonomous Adaptation to Users for Personal AI Companisonship 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13960v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13960v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi Cheng, Wenge Liu, Kaishuai Xu, Wenjun Hou, Yi Ouyang, Chak Tou Leong, Xian Wu, Yefeng Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Previous research has demonstrated the potential of AI agents to act as
companions that can provide constant emotional support for humans. In this
paper, we emphasize the necessity of autonomous adaptation in personal AI
companionship, an underexplored yet promising direction. Such adaptability is
crucial as it can facilitate more tailored interactions with users and allow
the agent to evolve in response to users' changing needs. However, imbuing
agents with autonomous adaptability presents unique challenges, including
identifying optimal adaptations to meet users' expectations and ensuring a
smooth transition during the adaptation process. To address them, we devise a
hierarchical framework, AutoPal, that enables controllable and authentic
adjustments to the agent's persona based on user interactions. A
personamatching dataset is constructed to facilitate the learning of optimal
persona adaptations. Extensive experiments demonstrate the effectiveness of
AutoPal and highlight the importance of autonomous adaptability in AI
companionship.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ EfficientQAT: Efficient Quantization-Aware Training for Large Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11062v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11062v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mengzhao Chen, Wenqi Shao, Peng Xu, Jiahao Wang, Peng Gao, Kaipeng Zhang, Ping Luo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) are crucial in modern natural language
processing and artificial intelligence. However, they face challenges in
managing their significant memory requirements. Although quantization-aware
training (QAT) offers a solution by reducing memory consumption through low-bit
representations with minimal accuracy loss, it is impractical due to
substantial training resources. To address this, we propose Efficient
Quantization-Aware Training (EfficientQAT), a more feasible QAT algorithm.
EfficientQAT involves two consecutive phases: Block-wise training of all
parameters (Block-AP) and end-to-end training of quantization parameters
(E2E-QP). To the best of our knowledge, Block-AP is the first method to enable
direct training of all parameters in a block-wise manner, reducing accuracy
loss in low-bit scenarios by enhancing the solution space during optimization.
E2E-QP then trains only the quantization parameters (step sizes) end-to-end,
further improving the performance of quantized models by considering
interactions among all sub-modules. Extensive experiments demonstrate that
EfficientQAT outperforms previous quantization methods across a range of
models, including base LLMs, instruction-tuned LLMs, and multimodal LLMs, with
scales from 7B to 70B parameters at various quantization bits. For instance,
EfficientQAT obtains a 2-bit Llama-2-70B model on a single A100-80GB GPU in 41
hours, with less than 3 points accuracy degradation compared to the full
precision (69.48 vs. 72.41). Code is available at
https://github.com/OpenGVLab/EfficientQAT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>An efficient and effective quantization technical to improve the
  performance of low-bits LMMs and LVLMs</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unveiling the Invisible: Captioning Videos with Metaphors 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.04886v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.04886v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abisek Rajakumar Kalarani, Pushpak Bhattacharyya, Sumit Shekhar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Metaphors are a common communication tool used in our day-to-day life. The
detection and generation of metaphors in textual form have been studied
extensively but metaphors in other forms have been under-explored. Recent
studies have shown that Vision-Language (VL) models cannot understand visual
metaphors in memes and adverts. As of now, no probing studies have been done
that involve complex language phenomena like metaphors with videos. Hence, we
introduce a new VL task of describing the metaphors present in the videos in
our work. To facilitate this novel task, we construct and release a manually
created dataset with 705 videos and 2115 human-written captions, along with a
new metric called Average Concept Distance (ACD), to automatically evaluate the
creativity of the metaphors generated. We also propose a novel low-resource
video metaphor captioning system: GIT-LLaVA, which obtains comparable
performance to SoTA video language models on the proposed task. We perform a
comprehensive analysis of existing video language models on this task and
publish our dataset, models, and benchmark results to enable further research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Judging the Judges: A Systematic Investigation of Position Bias in
  Pairwise Comparative Assessments by LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.07791v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.07791v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lin Shi, Chiyu Ma, Wenhua Liang, Weicheng Ma, Soroush Vosoughi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLM-as-a-Judge presents a promising alternative to human evaluators across
various tasks, but inherent biases, especially position bias - a tendency to
favor solutions based on their position in the prompt - have compromised its
effectiveness. Our study introduces a systematic framework to examine position
bias in pairwise comparisons, focusing on repetition stability, position
consistency, and preference fairness. This research significantly contributes
to the field by introducing new concepts for understanding position bias and
providing a multi-dimensional framework for evaluations. We conducted
experiments with 12 LLM judges across MTBench and DevBench, covering 22 tasks
and approximately 40 solution-generating models - candidates, resulting in over
100,000 evaluation instances. Our findings confirm that position bias in
capable LLM judges is not due to random chances, along with notable variations
observed across judges and tasks. Moreover, position bias is weakly influenced
by the length of prompt components but significantly impacted by the quality
gap between solutions. These insights can help optimize judge model selections,
improve benchmark design, and inform future research on debiasing strategies,
ultimately enhancing the reliability of LLM judges.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Large Language Model Confidence Estimation via Black-Box Access 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.04370v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.04370v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tejaswini Pedapati, Amit Dhurandhar, Soumya Ghosh, Soham Dan, Prasanna Sattigeri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Estimating uncertainty or confidence in the responses of a model can be
significant in evaluating trust not only in the responses, but also in the
model as a whole. In this paper, we explore the problem of estimating
confidence for responses of large language models (LLMs) with simply black-box
or query access to them. We propose a simple and extensible framework where, we
engineer novel features and train a (interpretable) model (viz. logistic
regression) on these features to estimate the confidence. We empirically
demonstrate that our simple framework is effective in estimating confidence of
Flan-ul2, Llama-13b and Mistral-7b on four benchmark Q\&A tasks as well as of
Pegasus-large and BART-large on two benchmark summarization tasks with it
surpassing baselines by even over $10\%$ (on AUROC) in some cases.
Additionally, our interpretable approach provides insight into features that
are predictive of confidence, leading to the interesting and useful discovery
that our confidence models built for one LLM generalize zero-shot across others
on a given dataset.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ S2-Attention: Hardware-Aware Context Sharding Among Attention Heads 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.17678v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.17678v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xihui Lin, Yunan Zhang, Suyu Ge, Liliang Ren, Barun Patra, Vishrav Chaudhary, Hao Peng, Xia Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sparse attention, which selectively attends to a subset of tokens in the
context was supposed to be efficient. However, its theoretical reduction in
FLOPs has rarely translated into wall-clock speed-up over its dense attention
counterparts due to the lack of hardware-aware optimizations like
FlashAttention. Meanwhile, it remains unclear whether sparse attention can
maintain the model's quality at a scale of today's large language models (LLMs)
and how. This paper presents Sparsely-Sharded(S2) Attention, a Triton library
that provides kernel optimization for sparse attention customizable at both
per-head and per-context-range levels. S2-Attention enables the exploration of
novel and high-performance sparse attention techniques, which we demonstrate
through extensive ablations across a wide range of sparse attention designs at
various model scales. From these insights, we present several basic guidelines
to design sparse attention that can achieve not only practical efficiency
improvements, but also strong downstream performance. To achieve high
parallelization and optimized memory IO, sparse attention should shard the
context heterogeneously across attention heads, where each head attends to a
different subset of tokens while collectively covering the full context.
Meanwhile, we find hybrid architectures combining sparse and dense attention
particularly beneficial in practice. S2-Attention achieves wall-clock speedup
of 8.79X, 15.87X, 25.3X compared to the strong FlashAttention-2 baseline with
strong downstream performance on-par with full attention and perfect retrieval
performance at a 128k context length. At inference, for 7B models, our model,
with the help of our S2-Attention kernel, achieves 4.5x speed-up compared to
dense counterparts. S2-Attention is released with easy-to-customize APIs for
direct usage in Megatron and vLLM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">GPT</span> vs RETRO: Exploring the Intersection of Retrieval and
  Parameter-Efficient Fine-Tuning <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.04528v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.04528v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aleksander Ficek, Jiaqi Zeng, Oleksii Kuchaiev
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Parameter-Efficient Fine-Tuning (PEFT) and Retrieval-Augmented Generation
(RAG) have become popular methods for adapting large language models while
minimizing compute requirements. In this paper, we apply PEFT methods
(P-tuning, Adapters, and LoRA) to a modified Retrieval-Enhanced Transformer
(RETRO) and a baseline GPT model across several sizes, ranging from 823 million
to 48 billion parameters. We show that RETRO models outperform GPT models in
zero-shot settings due to their unique pre-training process but GPT models have
higher performance potential with PEFT. Additionally, our study indicates that
8B parameter models strike an optimal balance between cost and performance and
P-tuning lags behind other PEFT techniques. We further provide a comparative
analysis between applying PEFT to an Instruction-tuned RETRO model and base
RETRO model. This work presents the first comprehensive comparison of various
PEFT methods integrated with RAG, applied to both GPT and RETRO models,
highlighting their relative performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring Multilingual Concepts of Human Value in Large Language Models:
  Is Value Alignment Consistent, Transferable and Controllable across
  Languages? <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.18120v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.18120v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shaoyang Xu, Weilong Dong, Zishan Guo, Xinwei Wu, Deyi Xiong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prior research has revealed that certain abstract concepts are linearly
represented as directions in the representation space of LLMs, predominantly
centered around English. In this paper, we extend this investigation to a
multilingual context, with a specific focus on human values-related concepts
(i.e., value concepts) due to their significance for AI safety. Through our
comprehensive exploration covering 7 types of human values, 16 languages and 3
LLM series with distinct multilinguality (e.g., monolingual, bilingual and
multilingual), we first empirically confirm the presence of value concepts
within LLMs in a multilingual format. Further analysis on the cross-lingual
characteristics of these concepts reveals 3 traits arising from language
resource disparities: cross-lingual inconsistency, distorted linguistic
relationships, and unidirectional cross-lingual transfer between high- and
low-resource languages, all in terms of value concepts. Moreover, we validate
the feasibility of cross-lingual control over value alignment capabilities of
LLMs, leveraging the dominant language as a source language. Ultimately,
recognizing the significant impact of LLMs' multilinguality on our results, we
consolidate our findings and provide prudent suggestions on the composition of
multilingual data for LLMs pre-training.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 findings, code&dataset:
  https://github.com/shaoyangxu/Multilingual-Human-Value-Concepts</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evaluating Large Language Models Using Contrast Sets: An Experimental
  Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.01569v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.01569v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manish Sanwal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the domain of Natural Language Inference (NLI), especially in tasks
involving the classification of multiple input texts, the Cross-Entropy Loss
metric is widely employed as a standard for error measurement. However, this
metric falls short in effectively evaluating a model's capacity to understand
language entailments. In this study, we introduce an innovative technique for
generating a contrast set for the Stanford Natural Language Inference (SNLI)
dataset. Our strategy involves the automated substitution of verbs, adverbs,
and adjectives with their synonyms to preserve the original meaning of
sentences. This method aims to assess whether a model's performance is based on
genuine language comprehension or simply on pattern recognition. We conducted
our analysis using the ELECTRA-small model. The model achieved an accuracy of
89.9% on the conventional SNLI dataset but showed a reduced accuracy of 72.5%
on our contrast set, indicating a substantial 17% decline. This outcome led us
to conduct a detailed examination of the model's learning behaviors. Following
this, we improved the model's resilience by fine-tuning it with a
contrast-enhanced training dataset specifically designed for SNLI, which
increased its accuracy to 85.5% on the contrast sets. Our findings highlight
the importance of incorporating diverse linguistic expressions into datasets
for NLI tasks. We hope that our research will encourage the creation of more
inclusive datasets, thereby contributing to the development of NLI models that
are both more sophisticated and effective.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ What's Mine becomes Yours: Defining, Annotating and Detecting
  Context-Dependent Paraphrases in News Interview Dialogs <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.06670v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.06670v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anna Wegmann, Tijs van den Broek, Dong Nguyen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Best practices for high conflict conversations like counseling or customer
support almost always include recommendations to paraphrase the previous
speaker. Although paraphrase classification has received widespread attention
in NLP, paraphrases are usually considered independent from context, and common
models and datasets are not applicable to dialog settings. In this work, we
investigate paraphrases in dialog (e.g., Speaker 1: "That book is mine."
becomes Speaker 2: "That book is yours."). We provide an operationalization of
context-dependent paraphrases, and develop a training for crowd-workers to
classify paraphrases in dialog. We introduce a dataset with utterance pairs
from NPR and CNN news interviews annotated for context-dependent paraphrases.
To enable analyses on label variation, the dataset contains 5,581 annotations
on 600 utterance pairs. We present promising results with in-context learning
and with token classification models for automatic paraphrase detection in
dialog.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted as main conference paper to EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SAAS: Solving Ability Amplification Strategy for Enhanced Mathematical
  Reasoning in Large Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.03887v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.03887v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hyeonwoo Kim, Gyoungjin Gim, Yungi Kim, Jihoo Kim, Byungju Kim, Wonseok Lee, Chanjun Park
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study presents a novel learning approach designed to enhance both
mathematical reasoning and problem-solving abilities of Large Language Models
(LLMs). We focus on integrating the Chain-of-Thought (CoT) and the
Program-of-Thought (PoT) learning, hypothesizing that prioritizing the learning
of mathematical reasoning ability is helpful for the amplification of
problem-solving ability. Thus, the initial learning with CoT is essential for
solving challenging mathematical problems. To this end, we propose a sequential
learning approach, named SAAS (Solving Ability Amplification Strategy), which
strategically transitions from CoT learning to PoT learning. Our empirical
study, involving an extensive performance comparison using several benchmarks,
demonstrates that our SAAS achieves state-of-the-art (SOTA) performance. The
results underscore the effectiveness of our sequential learning approach,
marking a significant advancement in the field of mathematical reasoning in
LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Industry Track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Dual-Phase Accelerated <span class="highlight-title">Prompt</span> Optimization <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13443v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13443v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Muchen Yang, Moxin Li, Yongle Li, Zijun Chen, Chongming Gao, Junqi Zhang, Yangyang Li, Fuli Feng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Gradient-free prompt optimization methods have made significant strides in
enhancing the performance of closed-source Large Language Models (LLMs) across
a wide range of tasks. However, existing approaches make light of the
importance of high-quality prompt initialization and the identification of
effective optimization directions, thus resulting in substantial optimization
steps to obtain satisfactory performance. In this light, we aim to accelerate
prompt optimization process to tackle the challenge of low convergence rate. We
propose a dual-phase approach which starts with generating high-quality initial
prompts by adopting a well-designed meta-instruction to delve into
task-specific information, and iteratively optimize the prompts at the sentence
level, leveraging previous tuning experience to expand prompt candidates and
accept effective ones. Extensive experiments on eight datasets demonstrate the
effectiveness of our proposed method, achieving a consistent accuracy gain over
baselines with less than five optimization steps.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Urdu Dependency Parsing and Treebank Development: A Syntactic and
  Morphological Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.09549v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.09549v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nudrat Habib
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Parsing is the process of analyzing a sentence's syntactic structure by
breaking it down into its grammatical components. and is critical for various
linguistic applications. Urdu is a low-resource, free word-order language and
exhibits complex morphology. Literature suggests that dependency parsing is
well-suited for such languages. Our approach begins with a basic feature model
encompassing word location, head word identification, and dependency relations,
followed by a more advanced model integrating part-of-speech (POS) tags and
morphological attributes (e.g., suffixes, gender). We manually annotated a
corpus of news articles of varying complexity. Using Maltparser and the
NivreEager algorithm, we achieved a best-labeled accuracy (LA) of 70% and an
unlabeled attachment score (UAS) of 84%, demonstrating the feasibility of
dependency parsing for Urdu.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Detecting Sexism in German Online Newspaper Comments with Open-Source
  Text Embeddings (Team GDA, GermEval2024 Shared Task 1: GerMS-Detect, Subtasks
  1 and 2, Closed Track) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.10341v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.10341v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Florian Bremm, Patrick Gustav Blaneck, Tobias Bornheim, Niklas Grieger, Stephan Bialonski
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sexism in online media comments is a pervasive challenge that often manifests
subtly, complicating moderation efforts as interpretations of what constitutes
sexism can vary among individuals. We study monolingual and multilingual
open-source text embeddings to reliably detect sexism and misogyny in
German-language online comments from an Austrian newspaper. We observed
classifiers trained on text embeddings to mimic closely the individual
judgements of human annotators. Our method showed robust performance in the
GermEval 2024 GerMS-Detect Subtask 1 challenge, achieving an average macro F1
score of 0.597 (4th place, as reported on Codabench). It also accurately
predicted the distribution of human annotations in GerMS-Detect Subtask 2, with
an average Jensen-Shannon distance of 0.301 (2nd place). The computational
efficiency of our approach suggests potential for scalable applications across
various languages and linguistic contexts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 4 figures, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Document-Level In-Context Few-Shot Relation Extraction via <span class="highlight-title">Pre-Train</span>ed
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.11085v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.11085v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yilmazcan Ozyurt, Stefan Feuerriegel, Ce Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Document-level relation extraction aims at inferring structured human
knowledge from textual documents. State-of-the-art methods for this task use
pre-trained language models (LMs) via fine-tuning, yet fine-tuning is
computationally expensive and cannot adapt to new relation types or new LMs. As
a remedy, we leverage the generalization capabilities of pre-trained LMs and
present a novel framework for document-level in-context few-shot relation
extraction. Our framework has three strengths: it eliminates the need (1) for
named entity recognition and (2) for human annotations of documents, and (3) it
can be updated to new LMs without re-training. We evaluate our framework using
DocRED, the largest publicly available dataset for document-level relation
extraction, and demonstrate that our framework achieves state-of-the-art
performance. We further show that our framework actually performs much better
than the original labels from the development set of DocRED. Finally, we
conduct an extensive benchmark demonstrating the effectiveness of our
framework, achieving state-of-the-art results across six relation extraction
datasets and outperforming more than 30 baseline methods. Unlike our framework,
the baseline methods have large computational overhead (e.g., from
fine-tuning). To the best of our knowledge, we are the first to reformulate the
document-level relation extraction task as a tailored in-context few-shot
learning paradigm.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LongGenBench: Benchmarking Long-Form Generation in Long Context LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02076v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02076v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuhao Wu, Ming Shan Hee, Zhiqing Hu, Roy Ka-Wei Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In evaluating the long-context capabilities of large language models (LLMs),
benchmarks such as "Needle-in-a-Haystack" (NIAH), Ruler, and Needlebench are
commonly used. While these benchmarks measure how well models understand
long-context input sequences, they do not effectively gauge the quality of
long-form text generation--a critical aspect for applications such as design
proposals and creative writing. To address this gap, we have introduced a new
long-form text evaluation benchmark, LongGenBench, which tests models' ability
to identify specific events within generated long text sequences. In this
benchmark, we prompt long-context LMs to create long-form text that must
include particular events or constraints and evaluate their ability to
incorporate these elements. We evaluated ten long-context LMs across four
distinct scenarios, three types of prompt instructions, and two different
generation-length settings (16K and 32K). Although these models perform well on
NIAH benchmarks, none demonstrated satisfactory performance on the
LongGenBench, raising concerns about their ability to generate coherent
long-form text that follows instructions. Additionally, as the length of the
generated text increases, all models exhibit a significant drop in performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>work in progress; Github: https://github.com/mozhu621/LongGenBench/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Model-based Preference Optimization in Abstractive Summarization without
  Human Feedback <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18618v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18618v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jaepill Choi, Kyubyung Chae, Jiwoo Song, Yohan Jo, Taesup Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In abstractive summarization, the challenge of producing concise and accurate
summaries arises from the vast amount of information contained in the source
document. Consequently, although Large Language Models (LLMs) can generate
fluent text, they often introduce inaccuracies by hallucinating content not
found in the original source. While supervised fine-tuning methods that
maximize likelihood contribute to this issue, they do not consistently enhance
the faithfulness of the summaries. Preference-based optimization methods, such
as Direct Preference Optimization (DPO), can further refine the model to align
with human preferences. However, these methods still heavily depend on costly
human feedback. In this work, we introduce a novel and straightforward approach
called Model-based Preference Optimization (MPO) to fine-tune LLMs for improved
summarization abilities without any human feedback. By leveraging the model's
inherent summarization capabilities, we create a preference dataset that is
fully generated by the model using different decoding strategies. Our
experiments on standard summarization datasets and various metrics demonstrate
that our proposed MPO significantly enhances the quality of generated summaries
without relying on human feedback.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LLM-as-a-Judge & Reward Model: What They Can and Cannot Do 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.11239v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.11239v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guijin Son, Hyunwoo Ko, Hoyoung Lee, Yewon Kim, Seunghyeok Hong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLM-as-a-Judge and reward models are widely used alternatives of
multiple-choice questions or human annotators for large language model (LLM)
evaluation. Their efficacy shines in evaluating long-form responses, serving a
critical role as evaluators of leaderboards and as proxies to align LLMs via
reinforcement learning. However, despite their popularity, their effectiveness
in diverse contexts, such as non-English prompts, factual verification, or
challenging questions, remains unexplored. In this paper, we conduct a
comprehensive analysis of automated evaluators, reporting several key findings
on their behavior. First, we discover that English evaluation capabilities
significantly influence language-specific evaluation capabilities, often more
than the language proficiency itself, enabling evaluators trained in English to
easily transfer their skills to other languages. Second, we identify critical
shortcomings, where LLMs fail to detect and penalize errors, such as factual
inaccuracies, cultural misrepresentations, and the presence of unwanted
language. Finally, we find that state-of-the-art evaluators struggle with
challenging prompts, in either English or Korean, underscoring their
limitations in assessing or generating complex reasoning questions. We release
the dataset and codes used.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ An LLM Feature-based Framework for Dialogue Constructiveness Assessment <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14760v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14760v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lexin Zhou, Youmna Farag, Andreas Vlachos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Research on dialogue constructiveness assessment focuses on (i) analysing
conversational factors that influence individuals to take specific actions, win
debates, change their perspectives or broaden their open-mindedness and (ii)
predicting constructiveness outcomes following dialogues for such use cases.
These objectives can be achieved by training either interpretable feature-based
models (which often involve costly human annotations) or neural models such as
pre-trained language models (which have empirically shown higher task accuracy
but lack interpretability). In this paper we propose an LLM feature-based
framework for dialogue constructiveness assessment that combines the strengths
of feature-based and neural approaches, while mitigating their downsides. The
framework first defines a set of dataset-independent and interpretable
linguistic features, which can be extracted by both prompting an LLM and simple
heuristics. Such features are then used to train LLM feature-based models. We
apply this framework to three datasets of dialogue constructiveness and find
that our LLM feature-based models outperform or performs at least as well as
standard feature-based models and neural models. We also find that the LLM
feature-based model learns more robust prediction rules instead of relying on
superficial shortcuts, which often trouble neural models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Paper accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Leveraging the Context through Multi-Round Interactions for Jailbreaking
  Attacks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.09177v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.09177v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yixin Cheng, Markos Georgopoulos, Volkan Cevher, Grigorios G. Chrysos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are susceptible to Jailbreaking attacks, which
aim to extract harmful information by subtly modifying the attack query. As
defense mechanisms evolve, directly obtaining harmful information becomes
increasingly challenging for Jailbreaking attacks. In this work, inspired from
Chomsky's transformational-generative grammar theory and human practices of
indirect context to elicit harmful information, we focus on a new attack form,
called Contextual Interaction Attack. We contend that the prior
context\u2014the information preceding the attack query\u2014plays a pivotal
role in enabling strong Jailbreaking attacks. Specifically, we propose a first
multi-turn approach that leverages benign preliminary questions to interact
with the LLM. Due to the autoregressive nature of LLMs, which use previous
conversation rounds as context during generation, we guide the model's
question-response pair to construct a context that is semantically aligned with
the attack query to execute the attack. We conduct experiments on seven
different LLMs and demonstrate the efficacy of this attack, which is black-box
and can also transfer across LLMs. We believe this can lead to further
developments and understanding of security in LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>29 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Cross-Domain Content Generation with Domain-Specific Small Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.17171v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.17171v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ankit Maloo, Abhinav Garg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating domain-specific content using small language models poses
challenges, especially when dealing with multiple distinct datasets with
minimal overlap. In this study, we explore methods to enable a small language
model to produce coherent and relevant outputs for two different domains:
stories (Dataset A) and recipes (Dataset B). Our initial experiments show that
training individual models on each dataset yields satisfactory results, with
each model generating appropriate content within its domain. We find that
utilizing custom tokenizers tailored to each dataset significantly enhances
generation quality compared to using a generic tokenizer. Attempts to adapt a
single model to both domains using Low-Rank Adaptation (LoRA) or standard
fine-tuning do not yield substantial results, often failing to produce
meaningful outputs. Moreover, full fine-tuning without freezing the model's
existing weights leads to catastrophic forgetting, where the model loses
previously learned information and only retains knowledge from the new data. To
overcome these challenges, we employ a knowledge expansion strategy: training
only with additional parameters. This approach enables the model to generate
both stories and recipes upon request, effectively handling multiple domains
without suffering from catastrophic forgetting. Our findings demonstrate that
knowledge expansion with frozen layers is an effective method for small
language models to generate domain-specific content across distinct datasets.
This work contributes to the development of efficient multi-domain language
models and provides insights into managing catastrophic forgetting in
small-scale architectures.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Do We Need Domain-Specific Embedding Models? An Empirical Investigation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18511v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18511v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yixuan Tang, Yi Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Embedding models play a crucial role in representing and retrieving
information across various NLP applications. Recent advancements in Large
Language Models (LLMs) have further enhanced the performance of embedding
models, which are trained on massive amounts of text covering almost every
domain. These models are often benchmarked on general-purpose datasets like
Massive Text Embedding Benchmark (MTEB), where they demonstrate superior
performance. However, a critical question arises: Is the development of
domain-specific embedding models necessary when general-purpose models are
trained on vast corpora that already include specialized domain texts? In this
paper, we empirically investigate this question, choosing the finance domain as
an example. We introduce the Finance Massive Text Embedding Benchmark
(FinMTEB), a counterpart to MTEB that consists of financial domain-specific
text datasets. We evaluate the performance of seven state-of-the-art embedding
models on FinMTEB and observe a significant performance drop compared to their
performance on MTEB. To account for the possibility that this drop is driven by
FinMTEB's higher complexity, we propose four measures to quantify dataset
complexity and control for this factor in our analysis. Our analysis provides
compelling evidence that state-of-the-art embedding models struggle to capture
domain-specific linguistic and semantic patterns. Moreover, we find that the
performance of general-purpose embedding models on MTEB is not correlated with
their performance on FinMTEB, indicating the need for domain-specific embedding
benchmarks for domain-specific embedding models. This study sheds light on
developing domain-specific embedding models in the LLM era.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://github.com/yixuantt/FinMTEB</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DataSculpt: Crafting Data Landscapes for Long-Context LLMs through
  Multi-Objective Partitioning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.00997v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.00997v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Keer Lu, Xiaonan Nie, Zheng Liang, Da Pan, Shusen Zhang, Keshi Zhao, Weipeng Chen, Zenan Zhou, Guosheng Dong, Bin Cui, Wentao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, Large Language Models (LLMs) have demonstrated significant
improvements across a variety of tasks, one of which is the long-context
capability. The key to improving long-context performance lies in effective
data organization and management strategies that integrate data from multiple
domains and optimize the context window during training. Through extensive
experimental analysis, we identified three key challenges in designing
effective data management strategies that enable the model to achieve
long-context capability without sacrificing performance in other tasks: (1) a
shortage of long documents across multiple domains, (2) effective construction
of context windows, and (3) efficient organization of large-scale datasets. To
address these challenges, we introduce DataSculpt, a novel data management
framework designed for long-context training. We first formulate the
organization of training data as a multi-objective combinatorial optimization
problem, focusing on attributes including relevance, homogeneity, integrity,
and efficiency. Specifically, our approach utilizes a coarse-to-fine
methodology to optimize training data organization both efficiently and
effectively. We begin by clustering the data based on semantic similarity
(coarse), followed by a multi-objective greedy search within each cluster to
score and concatenate documents into various context windows (fine). Our
comprehensive evaluations demonstrate that DataSculpt significantly enhances
long-context training performance, resulting in improvements of 18.09% in
retrieval augmentation, 21.23% in summarization, 21.27% in reading
comprehension, and a 3.81% increase in code completion, while also maintaining
overall model proficiency with a 4.88% improvement.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ How Reliable Are Automatic Evaluation Methods for Instruction-Tuned
  LLMs? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.10770v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.10770v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ehsan Doostmohammadi, Oskar Holmström, Marco Kuhlmann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Work on instruction-tuned Large Language Models (LLMs) has used automatic
methods based on text overlap and LLM judgments as cost-effective alternatives
to human evaluation. In this paper, we perform a meta-evaluation of such
methods and assess their reliability across a broad range of tasks. In
evaluating how well automatic methods align with human evaluations, correlation
metrics are the most commonly employed method despite their inherent
limitations when dealing with ties and different scales. To address these
shortcomings, we use Pairwise Accuracy as an alternative to standard
correlation measures. We observe that while automatic evaluation methods can
approximate human ratings under specific conditions, their validity is highly
context-dependent. Specifically, the simple ROUGE-L metric correlates very well
with human ratings for short-answer English tasks but is unreliable in
free-form generation tasks and cross-lingual scenarios. The effectiveness of
the more advanced method of using GPT-4 as a judge diminishes significantly if
reference answers are not included in the prompt, which is the scenario where
this method has the potential to provide the most value compared to other
metrics. Our findings enhance the understanding of how automatic methods should
be applied and interpreted when developing and evaluating instruction-tuned
LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Moshi: a speech-text foundation model for real-time dialogue 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00037v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00037v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexandre Défossez, Laurent Mazaré, Manu Orsini, Amélie Royer, Patrick Pérez, Hervé Jégou, Edouard Grave, Neil Zeghidour
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Moshi, a speech-text foundation model and full-duplex spoken
dialogue framework. Current systems for spoken dialogue rely on pipelines of
independent components, namely voice activity detection, speech recognition,
textual dialogue and text-to-speech. Such frameworks cannot emulate the
experience of real conversations. First, their complexity induces a latency of
several seconds between interactions. Second, text being the intermediate
modality for dialogue, non-linguistic information that modifies meaning -- such
as emotion or non-speech sounds -- is lost in the interaction. Finally, they
rely on a segmentation into speaker turns, which does not take into account
overlapping speech, interruptions and interjections. Moshi solves these
independent issues altogether by casting spoken dialogue as speech-to-speech
generation. Starting from a text language model backbone, Moshi generates
speech as tokens from the residual quantizer of a neural audio codec, while
modeling separately its own speech and that of the user into parallel streams.
This allows for the removal of explicit speaker turns, and the modeling of
arbitrary conversational dynamics. We moreover extend the hierarchical
semantic-to-acoustic token generation of previous work to first predict
time-aligned text tokens as a prefix to audio tokens. Not only this "Inner
Monologue" method significantly improves the linguistic quality of generated
speech, but we also illustrate how it can provide streaming speech recognition
and text-to-speech. Our resulting model is the first real-time full-duplex
spoken large language model, with a theoretical latency of 160ms, 200ms in
practice, and is available at https://github.com/kyutai-labs/moshi.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out
  Document <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.11184v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.11184v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joonho Yang, Seunghyun Yoon, Byeongjeong Kim, Hwanhee Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Through the advent of pre-trained language models, there have been notable
advancements in abstractive summarization systems. Simultaneously, a
considerable number of novel methods for evaluating factual consistency in
abstractive summarization systems has been developed. But these evaluation
approaches incorporate substantial limitations, especially on refinement and
interpretability. In this work, we propose highly effective and interpretable
factual inconsistency detection method metric Factual Inconsistency Detection
by Zoom-in Summary and Zoom-out Document for abstractive summarization systems
that is based on fine-grained atomic facts decomposition. Moreover, we align
atomic facts decomposed from the summary with the source document through
adaptive granularity expansion. These atomic facts represent a more
fine-grained unit of information, facilitating detailed understanding and
interpretability of the summary's factual inconsistency. Experimental results
demonstrate that our proposed factual consistency checking system significantly
outperforms existing systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published as a main conference paper at EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Routoo: Learning to Route to Large Language Models Effectively 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.13979v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.13979v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alireza Mohammadshahi, Arshad Rafiq Shaikh, Majid Yazdani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLMs with superior response quality--particularly larger or closed-source
models--often come with higher inference costs, making their deployment
inefficient and costly. Meanwhile, developing foundational LLMs from scratch is
becoming increasingly resource-intensive and impractical for many applications.
To address the challenge of balancing quality and cost, we introduce Routoo, an
architecture designed to optimize the selection of LLMs for specific prompts
based on performance, cost, and efficiency. Routoo provides controllability
over the trade-off between inference cost and quality, enabling significant
reductions in inference costs for a given quality requirement. Routoo comprises
two key components: a performance predictor and cost-aware selector. The
performance predictor is a lightweight LLM that estimates the expected
performance of various underlying LLMs on a given prompt without executing
them. The cost-aware selector module then selects the most suitable model based
on these predictions and constraints such as cost and latency, significantly
reducing inference costs for the same quality. We evaluated Routoo using the
MMLU benchmark across 57 domains employing open-source models. Our results show
that Routoo matches the performance of the Mixtral 8x7b model while reducing
inference costs by one-third. Additionally, by allowing increased costs, Routoo
surpasses Mixtral's accuracy by over 5% at equivalent costs, achieving an
accuracy of 75.9%. When integrating GPT4 into our model pool, Routoo nearly
matches GPT4's performance at half the cost and exceeds it with a 25% cost
reduction. These outcomes highlight Routoo's potential to significantly reduce
inference costs without compromising quality, and even to establish new
state-of-the-art results by leveraging the collective capabilities of multiple
LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Bayesian WeakS-to-Strong from Text Classification to Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.03199v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.03199v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziyun Cui, Ziyang Zhang, Wen Wu, Guangzhi Sun, Chao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Advances in large language models raise the question of how alignment
techniques will adapt as models become increasingly complex and humans will
only be able to supervise them weakly. Weak-to-Strong mimics such a scenario
where weak model supervision attempts to harness the full capabilities of a
much stronger model. This work extends Weak-to-Strong to WeakS-to-Strong by
exploring an ensemble of weak models which simulate the variability in human
opinions. Confidence scores are estimated using a Bayesian approach to guide
the WeakS-to-Strong generalization. Furthermore, we extend the application of
WeakS-to-Strong from text classification tasks to text generation tasks where
more advanced strategies are investigated for supervision. Moreover, direct
preference optimization is applied to advance the student model's preference
learning, beyond the basic learning framework of teacher forcing. Results
demonstrate the effectiveness of the proposed approach for the reliability of a
strong student model, showing potential for superalignment.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Nebula: A discourse aware Minecraft Builder <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18164v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18164v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Akshay Chaturvedi, Kate Thompson, Nicholas Asher
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  When engaging in collaborative tasks, humans efficiently exploit the semantic
structure of a conversation to optimize verbal and nonverbal interactions. But
in recent "language to code" or "language to action" models, this information
is lacking. We show how incorporating the prior discourse and nonlinguistic
context of a conversation situated in a nonlinguistic environment can improve
the "language to action" component of such interactions. We finetune an LLM to
predict actions based on prior context; our model, Nebula, doubles the
net-action F1 score over the baseline on this task of Jayannavar et al.(2020).
We also investigate our model's ability to construct shapes and understand
location descriptions using a synthetic dataset
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Are LLMs Effective Negotiators? Systematic Evaluation of the
  Multifaceted Capabilities of LLMs in Negotiation Dialogues <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.13550v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.13550v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Deuksin Kwon, Emily Weiss, Tara Kulshrestha, Kushal Chawla, Gale M. Lucas, Jonathan Gratch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A successful negotiation requires a range of capabilities, including
comprehension of the conversation context, Theory-of-Mind (ToM) skills to infer
the partner's motives, strategic reasoning, and effective communication, making
it challenging for automated systems. Despite the remarkable performance of
LLMs in various NLP tasks, there is no systematic evaluation of their
capabilities in negotiation. Such an evaluation is critical for advancing AI
negotiation agents and negotiation research, ranging from designing dialogue
systems to providing pedagogical feedback and scaling up data collection
practices. This work aims to systematically analyze the multifaceted
capabilities of LLMs across diverse dialogue scenarios throughout the stages of
a typical negotiation interaction. Our analysis highlights GPT-4's superior
performance in many tasks while identifying specific challenges, such as making
subjective assessments and generating contextually appropriate, strategically
advantageous responses.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to Findings of EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Federated Instruction Tuning of LLMs with Domain Coverage Augmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.20135v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.20135v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zezhou Wang, Yaxin Du, Zhuzhong Qian, Siheng Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Federated Domain-specific Instruction Tuning (FedDIT) utilizes limited
cross-client private data together with server-side public data for instruction
augmentation, ultimately boosting model performance within specific domains. To
date, the factors affecting FedDIT remain unclear, and existing instruction
augmentation methods primarily focus on the centralized setting without
considering distributed environments. Our experiments reveal that the
cross-client domain coverage, rather than data heterogeneity, drives model
performance in FedDIT. In response, we propose FedDCA, which optimizes domain
coverage through greedy client center selection and retrieval-based
augmentation. For client-side computational efficiency and system scalability,
FedDCA$^*$, the variant of FedDCA, utilizes heterogeneous encoders with
server-side feature alignment. Extensive experiments across four distinct
domains (code, medical, financial, and mathematical) substantiate the
effectiveness of both methods. Additionally, we investigate privacy
preservation against memory extraction attacks utilizing various amounts of
public data. Results show that there is no significant correlation between the
volume of public data and the privacy-preserving capability. However, as the
fine-tuning rounds increase, the risk of privacy leakage reduces or converges.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Llamipa: An Incremental Discourse Parser <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.18256v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.18256v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kate Thompson, Akshay Chaturvedi, Julie Hunter, Nicholas Asher
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper provides the first discourse parsing experiments with a large
language model(LLM) finetuned on corpora annotated in the style of SDRT
(Segmented Discourse Representation Theory Asher, 1993; Asher and Lascarides,
2003). The result is a discourse parser, Llamipa (Llama Incremental Parser),
that leverages discourse context, leading to substantial performance gains over
approaches that use encoder-only models to provide local, context-sensitive
representations of discourse units. Furthermore, it can process discourse data
incrementally, which is essential for the eventual use of discourse information
in downstream tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Show Me What's Wrong!: Combining Charts and Text to Guide Data Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00727v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00727v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Beatriz Feliciano, Rita Costa, Jean Alves, Javier Liébana, Diogo Duarte, Pedro Bizarro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Analyzing and finding anomalies in multi-dimensional datasets is a cumbersome
but vital task across different domains. In the context of financial fraud
detection, analysts must quickly identify suspicious activity among
transactional data. This is an iterative process made of complex exploratory
tasks such as recognizing patterns, grouping, and comparing. To mitigate the
information overload inherent to these steps, we present a tool combining
automated information highlights, Large Language Model generated textual
insights, and visual analytics, facilitating exploration at different levels of
detail. We perform a segmentation of the data per analysis area and visually
represent each one, making use of automated visual cues to signal which require
more attention. Upon user selection of an area, our system provides textual and
graphical summaries. The text, acting as a link between the high-level and
detailed views of the chosen segment, allows for a quick understanding of
relevant details. A thorough exploration of the data comprising the selection
can be done through graphical representations. The feedback gathered in a study
performed with seven domain experts suggests our tool effectively supports and
guides exploratory analysis, easing the identification of suspicious
information.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Just ASR + LLM? A Study on Speech Large Language Models' Ability to
  Identify and Understand Speaker in Spoken Dialogue 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04927v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04927v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junkai Wu, Xulin Fan, Bo-Ru Lu, Xilin Jiang, Nima Mesgarani, Mark Hasegawa-Johnson, Mari Ostendorf
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, we have observed a rapid advancement in speech language
models (SpeechLLMs), catching up with humans' listening and reasoning
abilities. SpeechLLMs have demonstrated impressive spoken dialog
question-answering (SQA) performance in benchmarks like Gaokao, the English
listening test of the college entrance exam in China, which seemingly requires
understanding both the spoken content and voice characteristics of speakers in
a conversation. However, after carefully examining Gaokao's questions, we find
the correct answers to many questions can be inferred from the conversation
transcript alone, i.e.\ without speaker segmentation and identification. Our
evaluation of state-of-the-art models Qwen-Audio and WavLLM on both Gaokao and
our proposed "What Do You Like?" dataset shows a significantly higher accuracy
in these context-based questions than in identity-critical questions, which can
only be answered reliably with correct speaker identification. The results and
analysis suggest that when solving SQA, the current SpeechLLMs exhibit limited
speaker awareness from the audio and behave similarly to an LLM reasoning from
the conversation transcription without sound. We propose that tasks focused on
identity-critical questions could offer a more accurate evaluation framework of
SpeechLLMs in SQA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to IEEE SLT 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Pruning Multilingual Large Language Models for Multilingual Inference <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.16911v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.16911v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hwichan Kim, Jun Suzuki, Tosho Hirasawa, Mamoru Komachi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multilingual large language models (MLLMs), trained on multilingual balanced
data, demonstrate better zero-shot learning performance in non-English
languages compared to large language models trained on English-dominant data.
However, the disparity in performance between English and non-English languages
remains a challenge yet to be fully addressed. A distinctive characteristic of
MLLMs is their high-quality translation capabilities, indicating an acquired
proficiency in aligning between languages. This study explores how to enhance
the zero-shot performance of MLLMs in non-English languages by leveraging their
alignment capability between English and non-English languages. To achieve
this, we first analyze the behavior of MLLMs when performing translation and
reveal that there are large magnitude features that play a critical role in the
translation process. Inspired by these findings, we retain the weights
associated with operations involving the large magnitude features and prune
other weights to force MLLMs to rely on these features for tasks beyond
translation. We empirically demonstrate that this pruning strategy can enhance
the MLLMs' performance in non-English language.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ 3D Data Long-Term Preservation in Cultural Heritage 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04507v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04507v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nicola Amico, Achille Felicetti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The report explores the challenges and strategies for preserving 3D digital
data in cultural heritage. It discusses the issue of technological
obsolescence, emphasising the need for ustainable storage solutions and ongoing
data management strategies. Key topics include understanding technological
obsolescence, the lifecycle of digital content, digital continuity, data
management plans (DMP), FAIR principles, and the use of public repositories.
The report also covers the importance of metadata in long-term digital
preservation, including types of metadata and strategies for building valuable
metadata. It examines the evolving standards and interoperability in 3D format
preservation and the importance of managing metadata and paradata. The document
provides a comprehensive overview of the challenges and solutions for
preserving 3D cultural heritage data in the long term.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Pre-train</span>ing Cross-lingual Open Domain Question Answering with
  Large-scale Synthetic Supervision <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.16508v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.16508v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fan Jiang, Tom Drummond, Trevor Cohn
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cross-lingual open domain question answering (CLQA) is a complex problem,
comprising cross-lingual retrieval from a multilingual knowledge base, followed
by answer generation in the query language. Both steps are usually tackled by
separate models, requiring substantial annotated datasets, and typically
auxiliary resources, like machine translation systems to bridge between
languages. In this paper, we show that CLQA can be addressed using a single
encoder-decoder model. To effectively train this model, we propose a
self-supervised method based on exploiting the cross-lingual link structure
within Wikipedia. We demonstrate how linked Wikipedia pages can be used to
synthesise supervisory signals for cross-lingual retrieval, through a form of
cloze query, and generate more natural questions to supervise answer
generation. Together, we show our approach, \texttt{CLASS}, outperforms
comparable methods on both supervised and zero-shot language adaptation
settings, including those using machine translation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Bone: Block Affine Transformation as Parameter Efficient Fine-tuning
  Methods for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15371v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15371v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiale Kang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low-Rank Adaptation (LoRA) has achieved remarkable training results by
freezing the original weights and training only low-rank matrices, establishing
itself as the predominant fine-tuning method for LLMs. In pursuit of
performance closer to full-parameter training, a series of LoRA variants have
emerged, such as LoRA+, PISSA, Olora, and LoRA-GA. However, these improvements
complicate the initial setup of model training and increase initialization
time. More importantly, they overlook the internal interactions of the original
weight information. To address these issues, we introduce a novel theory,
``Weight Guide'' aimed at continuously guiding trainable matrices through the
original weights during training to enhance the utilization of weight
information. Based on this theory, we designed a new PEFT technique called Bone
(\textbf{B}l\textbf{o}ck Affi\textbf{ne}), which not only enhances the
utilization of original weight information but also emphasizes the internal
connections between weights, leading to faster convergence and better data
fitting. Experimental comparisons across two different LLM architectures
(LLaMA2, RWKV6) and various parameter scales demonstrate that the Bone
structure can achieve rapid convergence and superior data fitting without the
need for complex initialization. For example, when fine-tuning LLaMA2-7B on the
MetaMathQA dataset and validating on GSM8k and math benchmarks, Bone achieved
fine-tuning scores of 49.36 and 8.8, respectively, outperforming PISSA by
5.84\% and 1.96\%.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.08700v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.08700v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seyed Mahed Mousavi, Simone Alghisi, Giuseppe Riccardi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLMs acquire knowledge from massive data snapshots collected at different
timestamps. Their knowledge is then commonly evaluated using static benchmarks.
However, factual knowledge is generally subject to time-sensitive changes, and
static benchmarks cannot address those cases. We present an approach to
dynamically evaluate the knowledge in LLMs and their time-sensitiveness against
Wikidata, a publicly available up-to-date knowledge graph. We evaluate the
time-sensitive knowledge in twenty-four private and open-source LLMs, as well
as the effectiveness of four editing methods in updating the outdated facts.
Our results show that 1) outdatedness is a critical problem across
state-of-the-art LLMs; 2) LLMs output inconsistent answers when prompted with
slight variations of the question prompt; and 3) the performance of the
state-of-the-art knowledge editing algorithms is very limited, as they can not
reduce the cases of outdatedness and output inconsistency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unlocking the Power of GANs in Non-Autoregressive Text Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.03977v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.03977v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Da Ren, Yi Cai, Qing Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative Adversarial Networks (GANs) have been studied in text generation
to tackle the exposure bias problem. Despite their remarkable development, they
adopt autoregressive structures so suffering from high latency in both training
and inference stages. Although GANs have potential to support efficient
generation by adopting non-autoregressive (NAR) structures, their explorations
in NAR models are extremely limited. In this work, we conduct pioneering study
of building language GANs based on NAR structures. We identify two issues that
constrain the performance of GAN-based NAR models. Firstly, existing methods of
incorporating latent variables provide highly similar representations which
cannot describe the diversity of different words in sentences. We tackle this
problem by proposing Position-Aware Self-Modulation, providing more diverse and
effective representations. Secondly, the attention mechanism in Transformer
cannot accurately build word dependencies in the unstable training of GANs, and
we adopt Dependency Feed Forward Network to enhance the model capacity in
dependency modeling. Armed with these two facilities, we propose a GAN-based
NAR model, Adversarial Non-autoregressive Transformer (ANT). The experimental
results demonstrate that ANT can achieve comparable performance with mainstream
models in a single forward pass and has great potential in various applications
like latent interpolation and semi-supervised learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Breaking Language Barriers: Cross-Lingual Continual <span class="highlight-title">Pre-Train</span>ing at
  Scale <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.02118v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.02118v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenzhen Zheng, Wenbo Pan, Xu Xu, Libo Qin, Li Yue, Ming Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, Large Language Models (LLMs) have made significant strides
towards Artificial General Intelligence. However, training these models from
scratch requires substantial computational resources and vast amounts of text
data. In this paper, we explore an alternative approach to constructing an LLM
for a new language by continually pretraining (CPT) from existing pretrained
LLMs, instead of using randomly initialized parameters. Based on parallel
experiments on 40 model sizes ranging from 40M to 5B parameters, we find that
1) CPT converges faster and saves significant resources in a scalable manner;
2) CPT adheres to an extended scaling law derived from Hoffmann et al. (2022)
with a joint data-parameter scaling term; 3) The compute-optimal data-parameter
allocation for CPT markedly differs based on our estimated scaling factors; 4)
The effectiveness of transfer at scale is influenced by training duration and
linguistic properties, while robust to data replaying, a method that
effectively mitigates catastrophic forgetting in CPT. We hope our findings
provide deeper insights into the transferability of LLMs at scale for the
research community.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages. Accepted at EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Aspect-Based Sentiment Analysis Techniques: A Comparative Study 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.02834v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.02834v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dineth Jayakody, Koshila Isuranda, A V A Malkith, Nisansa de Silva, Sachintha Rajith Ponnamperuma, G G N Sandamali, K L K Sudheera
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Since the dawn of the digitalisation era, customer feedback and online
reviews are unequivocally major sources of insights for businesses.
Consequently, conducting comparative analyses of such sources has become the de
facto modus operandi of any business that wishes to give itself a competitive
edge over its peers and improve customer loyalty. Sentiment analysis is one
such method instrumental in gauging public interest, exposing market trends,
and analysing competitors. While traditional sentiment analysis focuses on
overall sentiment, as the needs advance with time, it has become important to
explore public opinions and sentiments on various specific subjects, products
and services mentioned in the reviews on a finer-granular level. To this end,
Aspect-based Sentiment Analysis (ABSA), supported by advances in Artificial
Intelligence (AI) techniques which have contributed to a paradigm shift from
simple word-level analysis to tone and context-aware analyses, focuses on
identifying specific aspects within the text and determining the sentiment
associated with each aspect. In this study, we compare several deep-NN methods
for ABSA on two benchmark datasets (Restaurant14 and Laptop-14) and found that
FAST LSA obtains the best overall results of 87.6% and 82.6% accuracy but does
not pass LSA+DeBERTa which reports 90.33% and 86.21% accuracy respectively.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Advancing Event Causality Identification via Heuristic Semantic
  Dependency Inquiry Network <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.13621v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.13621v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoran Li, Qiang Gao, Hongmei Wu, Li Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Event Causality Identification (ECI) focuses on extracting causal relations
between events in texts. Existing methods for ECI primarily rely on causal
features and external knowledge. However, these approaches fall short in two
dimensions: (1) causal features between events in a text often lack explicit
clues, and (2) external knowledge may introduce bias, while specific problems
require tailored analyses. To address these issues, we propose SemDI - a simple
and effective Semantic Dependency Inquiry Network for ECI. SemDI captures
semantic dependencies within the context using a unified encoder. Then, it
utilizes a Cloze Analyzer to generate a fill-in token based on comprehensive
context understanding. Finally, this fill-in token is used to inquire about the
causal relation between two events. Extensive experiments demonstrate the
effectiveness of SemDI, surpassing state-of-the-art methods on three widely
used benchmarks. Code is available at https://github.com/hrlics/SemDI.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 camera-ready version. Code is released at
  https://github.com/hrlics/SemDI</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Extract, Define, Canonicalize: An LLM-based Framework for Knowledge
  Graph Construction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.03868v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.03868v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bowen Zhang, Harold Soh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we are interested in automated methods for knowledge graph
creation (KGC) from input text. Progress on large language models (LLMs) has
prompted a series of recent works applying them to KGC, e.g., via zero/few-shot
prompting. Despite successes on small domain-specific datasets, these models
face difficulties scaling up to text common in many real-world applications. A
principal issue is that, in prior methods, the KG schema has to be included in
the LLM prompt to generate valid triplets; larger and more complex schemas
easily exceed the LLMs' context window length. Furthermore, there are scenarios
where a fixed pre-defined schema is not available and we would like the method
to construct a high-quality KG with a succinct self-generated schema. To
address these problems, we propose a three-phase framework named
Extract-Define-Canonicalize (EDC): open information extraction followed by
schema definition and post-hoc canonicalization. EDC is flexible in that it can
be applied to settings where a pre-defined target schema is available and when
it is not; in the latter case, it constructs a schema automatically and applies
self-canonicalization. To further improve performance, we introduce a trained
component that retrieves schema elements relevant to the input text; this
improves the LLMs' extraction performance in a retrieval-augmented
generation-like manner. We demonstrate on three KGC benchmarks that EDC is able
to extract high-quality triplets without any parameter tuning and with
significantly larger schemas compared to prior works. Code for EDC is available
at https://github.com/clear-nus/edc.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 3 figures, Proceedings of the 2024 Conference on Empirical
  Methods in Natural Language Processing</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ OneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05152v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05152v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jintian Zhang, Cheng Peng, Mengshu Sun, Xiang Chen, Lei Liang, Zhiqiang Zhang, Jun Zhou, Huajun Chen, Ningyu Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the recent advancements in Large Language Models (LLMs), which have
significantly enhanced the generative capabilities for various NLP tasks, LLMs
still face limitations in directly handling retrieval tasks. However, many
practical applications demand the seamless integration of both retrieval and
generation. This paper introduces a novel and efficient One-pass Generation and
retrieval framework (OneGen), designed to improve LLMs' performance on tasks
that require both generation and retrieval. The proposed framework bridges the
traditionally separate training approaches for generation and retrieval by
incorporating retrieval tokens generated autoregressively. This enables a
single LLM to handle both tasks simultaneously in a unified forward pass. We
conduct experiments on two distinct types of composite tasks, RAG and Entity
Linking, to validate the pluggability, effectiveness, and efficiency of OneGen
in training and inference. Furthermore, our results show that integrating
generation and retrieval within the same context preserves the generative
capabilities of LLMs while improving retrieval performance. To the best of our
knowledge, OneGen is the first to enable LLMs to conduct vector retrieval
during the generation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Findings; code is available at
  https://github.com/zjunlp/OneGen</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ UI-JEPA: Towards Active Perception of User Intent through Onscreen User
  Activity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04081v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04081v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yicheng Fu, Raviteja Anantha, Prabal Vashisht, Jianpeng Cheng, Etai Littwin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating user intent from a sequence of user interface (UI) actions is a
core challenge in comprehensive UI understanding. Recent advancements in
multimodal large language models (MLLMs) have led to substantial progress in
this area, but their demands for extensive model parameters, computing power,
and high latency makes them impractical for scenarios requiring lightweight,
on-device solutions with low latency or heightened privacy. Additionally, the
lack of high-quality datasets has hindered the development of such lightweight
models. To address these challenges, we propose UI-JEPA, a novel framework that
employs masking strategies to learn abstract UI embeddings from unlabeled data
through self-supervised learning, combined with an LLM decoder fine-tuned for
user intent prediction. We also introduce two new UI-grounded multimodal
datasets, "Intent in the Wild" (IIW) and "Intent in the Tame" (IIT), designed
for few-shot and zero-shot UI understanding tasks. IIW consists of 1.7K videos
across 219 intent categories, while IIT contains 914 videos across 10
categories. We establish the first baselines for these datasets, showing that
representations learned using a JEPA-style objective, combined with an LLM
decoder, can achieve user intent predictions that match the performance of
state-of-the-art large MLLMs, but with significantly reduced annotation and
deployment resources. Measured by intent similarity scores, UI-JEPA outperforms
GPT-4 Turbo and Claude 3.5 Sonnet by 10.0% and 7.2% respectively, averaged
across two datasets. Notably, UI-JEPA accomplishes the performance with a 50.5x
reduction in computational cost and a 6.6x improvement in latency in the IIW
dataset. These results underscore the effectiveness of UI-JEPA, highlighting
its potential for lightweight, high-performance UI understanding.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unleashing the Power of Task-Specific Directions in Parameter Efficient
  Fine-tuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.01035v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.01035v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chongjie Si, Zhiyi Shi, Shifan Zhang, Xiaokang Yang, Hanspeter Pfister, Wei Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models demonstrate impressive performance on downstream tasks,
yet requiring extensive resource consumption when fully fine-tuning all
parameters. To mitigate this, Parameter Efficient Fine-Tuning (PEFT)
strategies, such as LoRA, have been developed. In this paper, we delve into the
concept of task-specific directions (TSDs)-critical for transitioning large
models from pretrained states to task-specific enhancements in PEFT. We propose
a framework to clearly define these directions and explore their properties,
and practical utilization challenges. We then introduce a novel approach,
LoRA-Dash, which aims to maximize the impact of TSDs during the fine-tuning
process, thereby enhancing model performance on targeted tasks. Extensive
experiments have conclusively demonstrated the effectiveness of LoRA-Dash, and
in-depth analyses further reveal the underlying mechanisms of LoRA-Dash. The
code is available at https://github.com/Chongjie-Si/Subspace-Tuning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Revisions ongoing. Codes in
  https://github.com/Chongjie-Si/Subspace-Tuning</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Block-Diagonal Orthogonal Relation and Matrix Entity for Knowledge Graph
  Embedding <span class="chip">EMNLP2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.05967v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.05967v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yihua Zhu, Hidetoshi Shimodaira
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The primary aim of Knowledge Graph embeddings (KGE) is to learn
low-dimensional representations of entities and relations for predicting
missing facts. While rotation-based methods like RotatE and QuatE perform well
in KGE, they face two challenges: limited model flexibility requiring
proportional increases in relation size with entity dimension, and difficulties
in generalizing the model for higher-dimensional rotations. To address these
issues, we introduce OrthogonalE, a novel KGE model employing matrices for
entities and block-diagonal orthogonal matrices with Riemannian optimization
for relations. This approach enhances the generality and flexibility of KGE
models. The experimental results indicate that our new KGE model, OrthogonalE,
is both general and flexible, significantly outperforming state-of-the-art KGE
models while substantially reducing the number of relation parameters.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP2024 findings (Long)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unlabeled Debiasing in Downstream Tasks via Class-wise Low Variance
  Regularization <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19541v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19541v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shahed Masoudian, Markus Frohmann, Navid Rekabsaz, Markus Schedl
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language models frequently inherit societal biases from their training data.
Numerous techniques have been proposed to mitigate these biases during both the
pre-training and fine-tuning stages. However, fine-tuning a pre-trained
debiased language model on a downstream task can reintroduce biases into the
model. Additionally, existing debiasing methods for downstream tasks either (i)
require labels of protected attributes (e.g., age, race, or political views)
that are often not available or (ii) rely on indicators of bias, which
restricts their applicability to gender debiasing since they rely on
gender-specific words. To address this, we introduce a novel debiasing
regularization technique based on the class-wise variance of embeddings.
Crucially, our method does not require attribute labels and targets any
attribute, thus addressing the shortcomings of existing debiasing methods. Our
experiments on encoder language models and three datasets demonstrate that our
method outperforms existing strong debiasing baselines that rely on target
attribute labels while maintaining performance on the target task.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Sound <span class="chip" style="font-size: 60%">18</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HRTF Estimation using a Score-based Prior 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01562v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01562v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Etienne Thuillier, Jean-Marie Lemercier, Eloi Moliner, Timo Gerkmann, Vesa Välimäki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a head-related transfer function (HRTF) estimation method which
relies on a data-driven prior given by a score-based diffusion model. The HRTF
is estimated in reverberant environments using natural excitation signals, e.g.
human speech. The impulse response of the room is estimated along with the HRTF
by optimizing a parametric model of reverberation based on the statistical
behaviour of room acoustics. The posterior distribution of HRTF given the
reverberant measurement and excitation signal is modelled using the score-based
HRTF prior and a log-likelihood approximation. We show that the resulting
method outperforms several baselines, including an oracle recommender system
that assigns the optimal HRTF in our training set based on the smallest
distance to the true HRTF at the given direction of arrival. In particular, we
show that the diffusion prior can account for the large variability of
high-frequency content in HRTFs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SonicSim: A customizable simulation platform for speech processing in
  moving sound source scenarios 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01481v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01481v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kai Li, Wendi Sang, Chang Zeng, Runxuan Yang, Guo Chen, Xiaolin Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The systematic evaluation of speech separation and enhancement models under
moving sound source conditions typically requires extensive data comprising
diverse scenarios. However, real-world datasets often contain insufficient data
to meet the training and evaluation requirements of models. Although synthetic
datasets offer a larger volume of data, their acoustic simulations lack
realism. Consequently, neither real-world nor synthetic datasets effectively
fulfill practical needs. To address these issues, we introduce SonicSim, a
synthetic toolkit de-designed to generate highly customizable data for moving
sound sources. SonicSim is developed based on the embodied AI simulation
platform, Habitat-sim, supporting multi-level adjustments, including
scene-level, microphone-level, and source-level, thereby generating more
diverse synthetic data. Leveraging SonicSim, we constructed a moving sound
source benchmark dataset, SonicSet, using the Librispeech, the Freesound
Dataset 50k (FSD50K) and Free Music Archive (FMA), and 90 scenes from the
Matterport3D to evaluate speech separation and enhancement models.
Additionally, to validate the differences between synthetic data and real-world
data, we randomly selected 5 hours of raw data without reverberation from the
SonicSet validation set to record a real-world speech separation dataset, which
was then compared with the corresponding synthetic datasets. Similarly, we
utilized the real-world speech enhancement dataset RealMAN to validate the
acoustic gap between other synthetic datasets and the SonicSet dataset for
speech enhancement. The results indicate that the synthetic data generated by
SonicSim can effectively generalize to real-world scenarios. Demo and code are
publicly available at https://cslikai.cn/SonicSim/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical report</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TIGER: Time-frequency Interleaved Gain Extraction and Reconstruction for
  Efficient Speech Separation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01469v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01469v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohan Xu, Kai Li, Guo Chen, Xiaolin Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, much speech separation research has focused primarily on
improving model performance. However, for low-latency speech processing
systems, high efficiency is equally important. Therefore, we propose a speech
separation model with significantly reduced parameters and computational costs:
Time-frequency Interleaved Gain Extraction and Reconstruction network (TIGER).
TIGER leverages prior knowledge to divide frequency bands and compresses
frequency information. We employ a multi-scale selective attention module to
extract contextual features, while introducing a full-frequency-frame attention
module to capture both temporal and frequency contextual information.
Additionally, to more realistically evaluate the performance of speech
separation models in complex acoustic environments, we introduce a dataset
called EchoSet. This dataset includes noise and more realistic reverberation
(e.g., considering object occlusions and material properties), with speech from
two speakers overlapping at random proportions. Experimental results showed
that models trained on EchoSet had better generalization ability than those
trained on other datasets to the data collected in the physical world, which
validated the practical value of the EchoSet. On EchoSet and real-world data,
TIGER significantly reduces the number of parameters by 94.3% and the MACs by
95.3% while achieving performance surpassing state-of-the-art (SOTA) model
TF-GridNet. This is the first speech separation model with fewer than 1 million
parameters that achieves performance comparable to the SOTA model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical report, demo page: https://cslikai.cn/TIGER/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Analyzing Byte-Pair Encoding on Monophonic and Polyphonic Symbolic
  Music: A Focus on Musical Phrase Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01448v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01448v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dinh-Viet-Toan Le, Louis Bigo, Mikaela Keller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Byte-Pair Encoding (BPE) is an algorithm commonly used in Natural Language
Processing to build a vocabulary of subwords, which has been recently applied
to symbolic music. Given that symbolic music can differ significantly from
text, particularly with polyphony, we investigate how BPE behaves with
different types of musical content. This study provides a qualitative analysis
of BPE's behavior across various instrumentations and evaluates its impact on a
musical phrase segmentation task for both monophonic and polyphonic music. Our
findings show that the BPE training process is highly dependent on the
instrumentation and that BPE "supertokens" succeed in capturing abstract
musical content. In a musical phrase segmentation task, BPE notably improves
performance in a polyphonic setting, but enhances performance in monophonic
tunes only within a specific range of BPE merges.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to 3rd Workshop on NLP for Music and Audio (NLP4MusA,
  co-located with ISMIR 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Takin-VC: Zero-shot Voice Conversion via Jointly Hybrid Content and
  Memory-Augmented Context-Aware Timbre Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01350v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01350v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuguang Yang, Yu Pan, Jixun Yao, Xiang Zhang, Jianhao Ye, Hongbin Zhou, Lei Xie, Lei Ma, Jianjun Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Zero-shot voice conversion (VC) aims to transform the source speaker timbre
into an arbitrary unseen one without altering the original speech content.While
recent advancements in zero-shot VC methods have shown remarkable progress,
there still remains considerable potential for improvement in terms of
improving speaker similarity and speech naturalness.In this paper, we propose
Takin-VC, a novel zero-shot VC framework based on jointly hybrid content and
memory-augmented context-aware timbre modeling to tackle this challenge.
Specifically, an effective hybrid content encoder, guided by neural codec
training, that leverages quantized features from pre-trained WavLM and
HybridFormer is first presented to extract the linguistic content of the source
speech. Subsequently, we introduce an advanced cross-attention-based
context-aware timbre modeling approach that learns the fine-grained,
semantically associated target timbre features. To further enhance both speaker
similarity and real-time performance, we utilize a conditional flow matching
model to reconstruct the Mel-spectrogram of the source speech. Additionally, we
advocate an efficient memory-augmented module designed to generate high-quality
conditional target inputs for the flow matching process, thereby improving the
overall performance of the proposed system. Experimental results demonstrate
that the proposed Takin-VC method surpasses state-of-the-art zero-shot VC
systems, delivering superior performance in terms of both speech naturalness
and speaker similarity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in Progress; Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Frozen Large Language Models Can Perceive Paralinguistic Aspects of
  Speech 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01162v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01162v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wonjune Kang, Junteng Jia, Chunyang Wu, Wei Zhou, Egor Lakomkin, Yashesh Gaur, Leda Sari, Suyoun Kim, Ke Li, Jay Mahadeokar, Ozlem Kalinli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As speech becomes an increasingly common modality for interacting with large
language models (LLMs), it is becoming desirable to develop systems where LLMs
can take into account users' emotions or speaking styles when providing their
responses. In this work, we study the potential of an LLM to understand these
aspects of speech without fine-tuning its weights. To do this, we utilize an
end-to-end system with a speech encoder; the encoder is trained to produce
token embeddings such that the LLM's response to an expressive speech prompt is
aligned with its response to a semantically matching text prompt where the
speaker's emotion has also been specified. We find that this training framework
allows the encoder to generate tokens that capture both semantic and
paralinguistic information in speech and effectively convey it to the LLM, even
when the LLM remains completely frozen. We also explore training on additional
emotion and style-related response alignment tasks, finding that they further
increase the amount of paralinguistic information explicitly captured in the
speech tokens. Experiments demonstrate that our system is able to produce
higher quality and more empathetic responses to expressive speech prompts
compared to several baselines.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Restorative Speech Enhancement: A Progressive Approach Using SE and
  Codec Modules 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01150v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01150v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hsin-Tien Chiang, Hao Zhang, Yong Xu, Meng Yu, Dong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In challenging environments with significant noise and reverberation,
traditional speech enhancement (SE) methods often lead to over-suppressed
speech, creating artifacts during listening and harming downstream tasks
performance. To overcome these limitations, we propose a novel approach called
Restorative SE (RestSE), which combines a lightweight SE module with a
generative codec module to progressively enhance and restore speech quality.
The SE module initially reduces noise, while the codec module subsequently
performs dereverberation and restores speech using generative capabilities. We
systematically explore various quantization techniques within the codec module
to optimize performance. Additionally, we introduce a weighted loss function
and feature fusion that merges the SE output with the original mixture,
particularly at segments where the SE output is heavily distorted. Experimental
results demonstrate the effectiveness of our proposed method in enhancing
speech quality under adverse conditions. Audio demos are available at:
https://sophie091524.github.io/RestorativeSE/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Paper in submission</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generating Symbolic Music from Natural Language <span class="highlight-title">Prompt</span>s using an
  LLM-Enhanced <span class="highlight-title">Dataset</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02084v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02084v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weihan Xu, Julian McAuley, Taylor Berg-Kirkpatrick, Shlomo Dubnov, Hao-Wen Dong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent years have seen many audio-domain text-to-music generation models that
rely on large amounts of text-audio pairs for training. However,
symbolic-domain controllable music generation has lagged behind partly due to
the lack of a large-scale symbolic music dataset with extensive metadata and
captions. In this work, we present MetaScore, a new dataset consisting of 963K
musical scores paired with rich metadata, including free-form user-annotated
tags, collected from an online music forum. To approach text-to-music
generation, we leverage a pretrained large language model (LLM) to generate
pseudo natural language captions from the metadata. With the LLM-enhanced
MetaScore, we train a text-conditioned music generation model that learns to
generate symbolic music from the pseudo captions, allowing control of
instruments, genre, composer, complexity and other free-form music descriptors.
In addition, we train a tag-conditioned system that supports a predefined set
of tags available in MetaScore. Our experimental results show that both the
proposed text-to-music and tags-to-music models outperform a baseline
text-to-music model in a listening test, while the text-based system offers a
more natural interface that allows free-form natural language prompts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PerTok: Expressive Encoding and Modeling of Symbolic Musical Ideas and
  Variations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02060v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02060v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Julian Lenz, Anirudh Mani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Cadenza, a new multi-stage generative framework for predicting
expressive variations of symbolic musical ideas as well as unconditional
generations. To accomplish this we propose a novel MIDI encoding method, PerTok
(Performance Tokenizer) that captures minute expressive details whilst reducing
sequence length up to 59% and vocabulary size up to 95% for polyphonic,
monophonic and rhythmic tasks. The proposed framework comprises of two
sequential stages: 1) Composer and 2) Performer. The Composer model is a
transformer-based Variational Autoencoder (VAE), with Rotary Positional
Embeddings (RoPE)ROPE and an autoregressive decoder modified to more
effectively integrate the latent codes of the input musical idea. The Performer
model is a bidirectional transformer encoder that is separately trained to
predict velocities and microtimings on MIDI sequences. Objective and human
evaluations demonstrate Cadenza's versatile capability in 1) matching other
unconditional state-of-the-art symbolic models in musical quality whilst
sounding more expressive, and 2) composing new, expressive ideas that are both
stylistically related to the input whilst providing novel ideas to the user.
Our framework is designed, researched and implemented with the objective of
ethically providing inspiration for musicians.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient Streaming LLM for Speech Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03752v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03752v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junteng Jia, Gil Keren, Wei Zhou, Egor Lakomkin, Xiaohui Zhang, Chunyang Wu, Frank Seide, Jay Mahadeokar, Ozlem Kalinli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent works have shown that prompting large language models with audio
encodings can unlock speech recognition capabilities. However, existing
techniques do not scale efficiently, especially while handling long form
streaming audio inputs -- not only do they extrapolate poorly beyond the audio
length seen during training, but they are also computationally inefficient due
to the quadratic cost of attention.
  In this work, we introduce SpeechLLM-XL, a linear scaling decoder-only model
for streaming speech recognition. We process audios in configurable chunks
using limited attention window for reduced computation, and the text tokens for
each audio chunk are generated auto-regressively until an EOS is predicted.
During training, the transcript is segmented into chunks, using a CTC forced
alignment estimated from encoder output. SpeechLLM-XL with 1.28 seconds chunk
size achieves 2.7%/6.7% WER on LibriSpeech test clean/other, and it shows no
quality degradation on long form utterances 10x longer than the training
utterances.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DiffSSD: A Diffusion-Based <span class="highlight-title">Dataset</span> For Speech Forensics <span class="chip">ICASSP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.13049v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.13049v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kratika Bhagtani, Amit Kumar Singh Yadav, Paolo Bestagini, Edward J. Delp
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion-based speech generators are ubiquitous. These methods can generate
very high quality synthetic speech and several recent incidents report their
malicious use. To counter such misuse, synthetic speech detectors have been
developed. Many of these detectors are trained on datasets which do not include
diffusion-based synthesizers. In this paper, we demonstrate that existing
detectors trained on one such dataset, ASVspoof2019, do not perform well in
detecting synthetic speech from recent diffusion-based synthesizers. We propose
the Diffusion-Based Synthetic Speech Dataset (DiffSSD), a dataset consisting of
about 200 hours of labeled speech, including synthetic speech generated by 8
diffusion-based open-source and 2 commercial generators. We also examine the
performance of existing synthetic speech detectors on DiffSSD in both
closed-set and open-set scenarios. The results highlight the importance of this
dataset in detecting synthetic speech generated from recent open-source and
commercial speech generators.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to IEEE International Conference on Acoustics, Speech, and
  Signal Processing (ICASSP) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Moshi: a speech-text foundation model for real-time dialogue 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00037v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00037v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexandre Défossez, Laurent Mazaré, Manu Orsini, Amélie Royer, Patrick Pérez, Hervé Jégou, Edouard Grave, Neil Zeghidour
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Moshi, a speech-text foundation model and full-duplex spoken
dialogue framework. Current systems for spoken dialogue rely on pipelines of
independent components, namely voice activity detection, speech recognition,
textual dialogue and text-to-speech. Such frameworks cannot emulate the
experience of real conversations. First, their complexity induces a latency of
several seconds between interactions. Second, text being the intermediate
modality for dialogue, non-linguistic information that modifies meaning -- such
as emotion or non-speech sounds -- is lost in the interaction. Finally, they
rely on a segmentation into speaker turns, which does not take into account
overlapping speech, interruptions and interjections. Moshi solves these
independent issues altogether by casting spoken dialogue as speech-to-speech
generation. Starting from a text language model backbone, Moshi generates
speech as tokens from the residual quantizer of a neural audio codec, while
modeling separately its own speech and that of the user into parallel streams.
This allows for the removal of explicit speaker turns, and the modeling of
arbitrary conversational dynamics. We moreover extend the hierarchical
semantic-to-acoustic token generation of previous work to first predict
time-aligned text tokens as a prefix to audio tokens. Not only this "Inner
Monologue" method significantly improves the linguistic quality of generated
speech, but we also illustrate how it can provide streaming speech recognition
and text-to-speech. Our resulting model is the first real-time full-duplex
spoken large language model, with a theoretical latency of 160ms, 200ms in
practice, and is available at https://github.com/kyutai-labs/moshi.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Integrating Text-to-Music Models with Language Models: Composing Long
  Structured Music Pieces 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00344v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00344v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lilac Atassi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent music generation methods based on transformers have a context window
of up to a minute. The music generated by these methods are largely
unstructured beyond the context window. With a longer context window, learning
long scale structures from musical data is a prohibitively challenging problem.
This paper proposes integrating a text-to-music model with a large language
model to generate music with form. We discuss our solutions to the challenges
of such integration. The experimental results show that the proposed method can
generate 2.5-minute-long music that is highly structured, strongly organized,
and cohesive.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: substantial text overlap with arXiv:2404.11976</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VoxHakka: A Dialectally Diverse Multi-speaker Text-to-Speech System for
  Taiwanese Hakka 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.01548v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.01548v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Li-Wei Chen, Hung-Shin Lee, Chen-Chi Chang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces VoxHakka, a text-to-speech (TTS) system designed for
Taiwanese Hakka, a critically under-resourced language spoken in Taiwan.
Leveraging the YourTTS framework, VoxHakka achieves high naturalness and
accuracy and low real-time factor in speech synthesis while supporting six
distinct Hakka dialects. This is achieved by training the model with
dialect-specific data, allowing for the generation of speaker-aware Hakka
speech. To address the scarcity of publicly available Hakka speech corpora, we
employed a cost-effective approach utilizing a web scraping pipeline coupled
with automatic speech recognition (ASR)-based data cleaning techniques. This
process ensured the acquisition of a high-quality, multi-speaker, multi-dialect
dataset suitable for TTS training. Subjective listening tests conducted using
comparative mean opinion scores (CMOS) demonstrate that VoxHakka significantly
outperforms existing publicly available Hakka TTS systems in terms of
pronunciation accuracy, tone correctness, and overall naturalness. This work
represents a significant advancement in Hakka language technology and provides
a valuable resource for language preservation and revitalization efforts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to O-COCOSDA 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large
  Language Models <span class="chip">EMNLP24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18680v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18680v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiming Chen, Xianghu Yue, Xiaoxue Gao, Chen Zhang, Luis Fernando D'Haro, Robby T. Tan, Haizhou Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Various audio-LLMs (ALLMs) have been explored recently for tackling different
audio tasks simultaneously using a single, unified model. While existing
evaluations of ALLMs primarily focus on single-audio tasks, real-world
applications often involve processing multiple audio streams simultaneously. To
bridge this gap, we propose the first multi-audio evaluation (MAE) benchmark
that consists of 20 datasets from 11 multi-audio tasks encompassing both speech
and sound scenarios. Comprehensive experiments on MAE demonstrate that the
existing ALLMs, while being powerful in comprehending primary audio elements in
individual audio inputs, struggling to handle multi-audio scenarios. To this
end, we propose a novel multi-audio-LLM (MALLM) to capture audio context among
multiple similar audios using discriminative learning on our proposed synthetic
data. The results demonstrate that the proposed MALLM outperforms all baselines
and achieves high data efficiency using synthetic data without requiring human
annotations. The proposed MALLM opens the door for ALLMs towards multi-audio
processing era and brings us closer to replicating human auditory capabilities
in machines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP24 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Fly on the Wall -- Exploiting Acoustic Side-Channels in Differential
  Pressure Sensors <span class="chip">ACSA</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18213v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18213v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yonatan Gizachew Achamyeleh, Mohamad Habib Fakih, Gabriel Garcia, Anomadarshi Barua, Mohammad Al Faruque
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Differential Pressure Sensors are widely deployed to monitor critical
environments. However, our research unveils a previously overlooked
vulnerability: their high sensitivity to pressure variations makes them
susceptible to acoustic side-channel attacks. We demonstrate that the
pressure-sensing diaphragms in DPS can inadvertently capture subtle air
vibrations caused by speech, which propagate through the sensor's components
and affect the pressure readings. Exploiting this discovery, we introduce
BaroVox, a novel attack that reconstructs speech from DPS readings, effectively
turning DPS into a "fly on the wall." We model the effect of sound on DPS,
exploring the limits and challenges of acoustic leakage. To overcome these
challenges, we propose two solutions: a signal-processing approach using a
unique spectral subtraction method and a deep learning-based approach for
keyword classification. Evaluations under various conditions demonstrate
BaroVox's effectiveness, achieving a word error rate of 0.29 for manual
recognition and 90.51% accuracy for automatic recognition. Our findings
highlight the significant privacy implications of this vulnerability. We also
discuss potential defense strategies to mitigate the risks posed by BaroVox.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ACSAC 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ dMel: Speech Tokenization made Simple 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.15835v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.15835v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        He Bai, Tatiana Likhomanenko, Ruixiang Zhang, Zijin Gu, Zakaria Aldeneh, Navdeep Jaitly
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models have revolutionized natural language processing by
leveraging self-supervised pretraining on vast textual data. Inspired by this
success, researchers have investigated complicated speech tokenization methods
to discretize continuous speech signals so that language modeling techniques
can be applied to speech data. However, existing approaches either model
semantic (content) tokens, potentially losing acoustic information, or model
acoustic tokens, risking the loss of semantic (content) information. Having
multiple token types also complicates the architecture and requires additional
pretraining. Here we show that discretizing mel-filterbank channels into
discrete intensity bins produces a simple representation (dMel), that performs
better than other existing speech tokenization methods. Using an LM-style
transformer architecture for speech-text modeling, we comprehensively evaluate
different speech tokenization methods on speech recognition (ASR) and speech
synthesis (TTS). Our results demonstrate the effectiveness of dMel in achieving
high performance on both tasks within a unified framework, paving the way for
efficient and effective joint modeling of speech and text.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Harmony and Duality: An introduction to Music Theory 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.10719v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.10719v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maksim Lipyanskiy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We develop aspects of music theory related to harmony, such as scales, chord
formation and improvisation from a combinatorial perspective. The goal is to
provide a foundation for this subject by deriving the basic structure from a
few assumptions, rather than writing down long lists of chords/scales to
memorize without an underlying principle. Our approach involves introducing
constraints that limit the possible scales we can consider. For example, we may
impose the constraint that two voices cannot be only a semitone apart as this
is too dissonant. We can then study scales that do not contain notes that are a
semitone apart. A more refined constraint avoids three voices colliding by
studying scales that do not have three notes separated only by semitones.
Additionally, we require that our scales are complete, which roughly means that
they are the maximal sets of tones that satisfy these constraints. As it turns
out, completeness as applied to these simple two/three voice constraints
characterizes the types of scales that are commonly used in music composition.
Surprisingly, there is a correspondence between scales subject to the two-voice
constraint and those subject to the three-voice constraint. We formulate this
correspondence as a duality statement that provides a way to understand scales
subject to one type of constraint in terms of scales subject to the other.
Finally, we combine these constraint ideas to provide a classification of
chords.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>75 pages, 72 figures</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Speech Processing <span class="chip" style="font-size: 60%">20</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HRTF Estimation using a Score-based Prior 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01562v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01562v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Etienne Thuillier, Jean-Marie Lemercier, Eloi Moliner, Timo Gerkmann, Vesa Välimäki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a head-related transfer function (HRTF) estimation method which
relies on a data-driven prior given by a score-based diffusion model. The HRTF
is estimated in reverberant environments using natural excitation signals, e.g.
human speech. The impulse response of the room is estimated along with the HRTF
by optimizing a parametric model of reverberation based on the statistical
behaviour of room acoustics. The posterior distribution of HRTF given the
reverberant measurement and excitation signal is modelled using the score-based
HRTF prior and a log-likelihood approximation. We show that the resulting
method outperforms several baselines, including an oracle recommender system
that assigns the optimal HRTF in our training set based on the smallest
distance to the true HRTF at the given direction of arrival. In particular, we
show that the diffusion prior can account for the large variability of
high-frequency content in HRTFs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SonicSim: A customizable simulation platform for speech processing in
  moving sound source scenarios 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01481v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01481v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kai Li, Wendi Sang, Chang Zeng, Runxuan Yang, Guo Chen, Xiaolin Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The systematic evaluation of speech separation and enhancement models under
moving sound source conditions typically requires extensive data comprising
diverse scenarios. However, real-world datasets often contain insufficient data
to meet the training and evaluation requirements of models. Although synthetic
datasets offer a larger volume of data, their acoustic simulations lack
realism. Consequently, neither real-world nor synthetic datasets effectively
fulfill practical needs. To address these issues, we introduce SonicSim, a
synthetic toolkit de-designed to generate highly customizable data for moving
sound sources. SonicSim is developed based on the embodied AI simulation
platform, Habitat-sim, supporting multi-level adjustments, including
scene-level, microphone-level, and source-level, thereby generating more
diverse synthetic data. Leveraging SonicSim, we constructed a moving sound
source benchmark dataset, SonicSet, using the Librispeech, the Freesound
Dataset 50k (FSD50K) and Free Music Archive (FMA), and 90 scenes from the
Matterport3D to evaluate speech separation and enhancement models.
Additionally, to validate the differences between synthetic data and real-world
data, we randomly selected 5 hours of raw data without reverberation from the
SonicSet validation set to record a real-world speech separation dataset, which
was then compared with the corresponding synthetic datasets. Similarly, we
utilized the real-world speech enhancement dataset RealMAN to validate the
acoustic gap between other synthetic datasets and the SonicSet dataset for
speech enhancement. The results indicate that the synthetic data generated by
SonicSim can effectively generalize to real-world scenarios. Demo and code are
publicly available at https://cslikai.cn/SonicSim/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical report</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TIGER: Time-frequency Interleaved Gain Extraction and Reconstruction for
  Efficient Speech Separation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01469v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01469v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohan Xu, Kai Li, Guo Chen, Xiaolin Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, much speech separation research has focused primarily on
improving model performance. However, for low-latency speech processing
systems, high efficiency is equally important. Therefore, we propose a speech
separation model with significantly reduced parameters and computational costs:
Time-frequency Interleaved Gain Extraction and Reconstruction network (TIGER).
TIGER leverages prior knowledge to divide frequency bands and compresses
frequency information. We employ a multi-scale selective attention module to
extract contextual features, while introducing a full-frequency-frame attention
module to capture both temporal and frequency contextual information.
Additionally, to more realistically evaluate the performance of speech
separation models in complex acoustic environments, we introduce a dataset
called EchoSet. This dataset includes noise and more realistic reverberation
(e.g., considering object occlusions and material properties), with speech from
two speakers overlapping at random proportions. Experimental results showed
that models trained on EchoSet had better generalization ability than those
trained on other datasets to the data collected in the physical world, which
validated the practical value of the EchoSet. On EchoSet and real-world data,
TIGER significantly reduces the number of parameters by 94.3% and the MACs by
95.3% while achieving performance surpassing state-of-the-art (SOTA) model
TF-GridNet. This is the first speech separation model with fewer than 1 million
parameters that achieves performance comparable to the SOTA model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical report, demo page: https://cslikai.cn/TIGER/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Analyzing Byte-Pair Encoding on Monophonic and Polyphonic Symbolic
  Music: A Focus on Musical Phrase Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01448v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01448v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dinh-Viet-Toan Le, Louis Bigo, Mikaela Keller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Byte-Pair Encoding (BPE) is an algorithm commonly used in Natural Language
Processing to build a vocabulary of subwords, which has been recently applied
to symbolic music. Given that symbolic music can differ significantly from
text, particularly with polyphony, we investigate how BPE behaves with
different types of musical content. This study provides a qualitative analysis
of BPE's behavior across various instrumentations and evaluates its impact on a
musical phrase segmentation task for both monophonic and polyphonic music. Our
findings show that the BPE training process is highly dependent on the
instrumentation and that BPE "supertokens" succeed in capturing abstract
musical content. In a musical phrase segmentation task, BPE notably improves
performance in a polyphonic setting, but enhances performance in monophonic
tunes only within a specific range of BPE merges.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to 3rd Workshop on NLP for Music and Audio (NLP4MusA,
  co-located with ISMIR 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Takin-VC: Zero-shot Voice Conversion via Jointly Hybrid Content and
  Memory-Augmented Context-Aware Timbre Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01350v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01350v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuguang Yang, Yu Pan, Jixun Yao, Xiang Zhang, Jianhao Ye, Hongbin Zhou, Lei Xie, Lei Ma, Jianjun Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Zero-shot voice conversion (VC) aims to transform the source speaker timbre
into an arbitrary unseen one without altering the original speech content.While
recent advancements in zero-shot VC methods have shown remarkable progress,
there still remains considerable potential for improvement in terms of
improving speaker similarity and speech naturalness.In this paper, we propose
Takin-VC, a novel zero-shot VC framework based on jointly hybrid content and
memory-augmented context-aware timbre modeling to tackle this challenge.
Specifically, an effective hybrid content encoder, guided by neural codec
training, that leverages quantized features from pre-trained WavLM and
HybridFormer is first presented to extract the linguistic content of the source
speech. Subsequently, we introduce an advanced cross-attention-based
context-aware timbre modeling approach that learns the fine-grained,
semantically associated target timbre features. To further enhance both speaker
similarity and real-time performance, we utilize a conditional flow matching
model to reconstruct the Mel-spectrogram of the source speech. Additionally, we
advocate an efficient memory-augmented module designed to generate high-quality
conditional target inputs for the flow matching process, thereby improving the
overall performance of the proposed system. Experimental results demonstrate
that the proposed Takin-VC method surpasses state-of-the-art zero-shot VC
systems, delivering superior performance in terms of both speech naturalness
and speaker similarity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in Progress; Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Frozen Large Language Models Can Perceive Paralinguistic Aspects of
  Speech 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01162v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01162v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wonjune Kang, Junteng Jia, Chunyang Wu, Wei Zhou, Egor Lakomkin, Yashesh Gaur, Leda Sari, Suyoun Kim, Ke Li, Jay Mahadeokar, Ozlem Kalinli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As speech becomes an increasingly common modality for interacting with large
language models (LLMs), it is becoming desirable to develop systems where LLMs
can take into account users' emotions or speaking styles when providing their
responses. In this work, we study the potential of an LLM to understand these
aspects of speech without fine-tuning its weights. To do this, we utilize an
end-to-end system with a speech encoder; the encoder is trained to produce
token embeddings such that the LLM's response to an expressive speech prompt is
aligned with its response to a semantically matching text prompt where the
speaker's emotion has also been specified. We find that this training framework
allows the encoder to generate tokens that capture both semantic and
paralinguistic information in speech and effectively convey it to the LLM, even
when the LLM remains completely frozen. We also explore training on additional
emotion and style-related response alignment tasks, finding that they further
increase the amount of paralinguistic information explicitly captured in the
speech tokens. Experiments demonstrate that our system is able to produce
higher quality and more empathetic responses to expressive speech prompts
compared to several baselines.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Restorative Speech Enhancement: A Progressive Approach Using SE and
  Codec Modules 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01150v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01150v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hsin-Tien Chiang, Hao Zhang, Yong Xu, Meng Yu, Dong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In challenging environments with significant noise and reverberation,
traditional speech enhancement (SE) methods often lead to over-suppressed
speech, creating artifacts during listening and harming downstream tasks
performance. To overcome these limitations, we propose a novel approach called
Restorative SE (RestSE), which combines a lightweight SE module with a
generative codec module to progressively enhance and restore speech quality.
The SE module initially reduces noise, while the codec module subsequently
performs dereverberation and restores speech using generative capabilities. We
systematically explore various quantization techniques within the codec module
to optimize performance. Additionally, we introduce a weighted loss function
and feature fusion that merges the SE output with the original mixture,
particularly at segments where the SE output is heavily distorted. Experimental
results demonstrate the effectiveness of our proposed method in enhancing
speech quality under adverse conditions. Audio demos are available at:
https://sophie091524.github.io/RestorativeSE/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Paper in submission</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generating Symbolic Music from Natural Language <span class="highlight-title">Prompt</span>s using an
  LLM-Enhanced <span class="highlight-title">Dataset</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02084v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02084v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weihan Xu, Julian McAuley, Taylor Berg-Kirkpatrick, Shlomo Dubnov, Hao-Wen Dong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent years have seen many audio-domain text-to-music generation models that
rely on large amounts of text-audio pairs for training. However,
symbolic-domain controllable music generation has lagged behind partly due to
the lack of a large-scale symbolic music dataset with extensive metadata and
captions. In this work, we present MetaScore, a new dataset consisting of 963K
musical scores paired with rich metadata, including free-form user-annotated
tags, collected from an online music forum. To approach text-to-music
generation, we leverage a pretrained large language model (LLM) to generate
pseudo natural language captions from the metadata. With the LLM-enhanced
MetaScore, we train a text-conditioned music generation model that learns to
generate symbolic music from the pseudo captions, allowing control of
instruments, genre, composer, complexity and other free-form music descriptors.
In addition, we train a tag-conditioned system that supports a predefined set
of tags available in MetaScore. Our experimental results show that both the
proposed text-to-music and tags-to-music models outperform a baseline
text-to-music model in a listening test, while the text-based system offers a
more natural interface that allows free-form natural language prompts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PerTok: Expressive Encoding and Modeling of Symbolic Musical Ideas and
  Variations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02060v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02060v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Julian Lenz, Anirudh Mani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Cadenza, a new multi-stage generative framework for predicting
expressive variations of symbolic musical ideas as well as unconditional
generations. To accomplish this we propose a novel MIDI encoding method, PerTok
(Performance Tokenizer) that captures minute expressive details whilst reducing
sequence length up to 59% and vocabulary size up to 95% for polyphonic,
monophonic and rhythmic tasks. The proposed framework comprises of two
sequential stages: 1) Composer and 2) Performer. The Composer model is a
transformer-based Variational Autoencoder (VAE), with Rotary Positional
Embeddings (RoPE)ROPE and an autoregressive decoder modified to more
effectively integrate the latent codes of the input musical idea. The Performer
model is a bidirectional transformer encoder that is separately trained to
predict velocities and microtimings on MIDI sequences. Objective and human
evaluations demonstrate Cadenza's versatile capability in 1) matching other
unconditional state-of-the-art symbolic models in musical quality whilst
sounding more expressive, and 2) composing new, expressive ideas that are both
stylistically related to the input whilst providing novel ideas to the user.
Our framework is designed, researched and implemented with the objective of
ethically providing inspiration for musicians.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Synthio: Augmenting Small-Scale Audio Classification <span class="highlight-title">Dataset</span>s with
  Synthetic Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.02056v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.02056v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sreyan Ghosh, Sonal Kumar, Zhifeng Kong, Rafael Valle, Bryan Catanzaro, Dinesh Manocha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present Synthio, a novel approach for augmenting small-scale audio
classification datasets with synthetic data. Our goal is to improve audio
classification accuracy with limited labeled data. Traditional data
augmentation techniques, which apply artificial transformations (e.g., adding
random noise or masking segments), struggle to create data that captures the
true diversity present in real-world audios. To address this shortcoming, we
propose to augment the dataset with synthetic audio generated from
text-to-audio (T2A) diffusion models. However, synthesizing effective
augmentations is challenging because not only should the generated data be
acoustically consistent with the underlying small-scale dataset, but they
should also have sufficient compositional diversity. To overcome the first
challenge, we align the generations of the T2A model with the small-scale
dataset using preference optimization. This ensures that the acoustic
characteristics of the generated data remain consistent with the small-scale
dataset. To address the second challenge, we propose a novel caption generation
technique that leverages the reasoning capabilities of Large Language Models to
(1) generate diverse and meaningful audio captions and (2) iteratively refine
their quality. The generated captions are then used to prompt the aligned T2A
model. We extensively evaluate Synthio on ten datasets and four simulated
limited-data settings. Results indicate our method consistently outperforms all
baselines by 0.1%-39% using a T2A model trained only on weakly-captioned
AudioSet.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code and Checkpoints will be soon available here:
  https://github.com/Sreyan88/Synthio</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient Streaming LLM for Speech Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03752v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03752v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junteng Jia, Gil Keren, Wei Zhou, Egor Lakomkin, Xiaohui Zhang, Chunyang Wu, Frank Seide, Jay Mahadeokar, Ozlem Kalinli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent works have shown that prompting large language models with audio
encodings can unlock speech recognition capabilities. However, existing
techniques do not scale efficiently, especially while handling long form
streaming audio inputs -- not only do they extrapolate poorly beyond the audio
length seen during training, but they are also computationally inefficient due
to the quadratic cost of attention.
  In this work, we introduce SpeechLLM-XL, a linear scaling decoder-only model
for streaming speech recognition. We process audios in configurable chunks
using limited attention window for reduced computation, and the text tokens for
each audio chunk are generated auto-regressively until an EOS is predicted.
During training, the transcript is segmented into chunks, using a CTC forced
alignment estimated from encoder output. SpeechLLM-XL with 1.28 seconds chunk
size achieves 2.7%/6.7% WER on LibriSpeech test clean/other, and it shows no
quality degradation on long form utterances 10x longer than the training
utterances.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DiffSSD: A Diffusion-Based <span class="highlight-title">Dataset</span> For Speech Forensics <span class="chip">ICASSP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.13049v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.13049v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kratika Bhagtani, Amit Kumar Singh Yadav, Paolo Bestagini, Edward J. Delp
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion-based speech generators are ubiquitous. These methods can generate
very high quality synthetic speech and several recent incidents report their
malicious use. To counter such misuse, synthetic speech detectors have been
developed. Many of these detectors are trained on datasets which do not include
diffusion-based synthesizers. In this paper, we demonstrate that existing
detectors trained on one such dataset, ASVspoof2019, do not perform well in
detecting synthetic speech from recent diffusion-based synthesizers. We propose
the Diffusion-Based Synthetic Speech Dataset (DiffSSD), a dataset consisting of
about 200 hours of labeled speech, including synthetic speech generated by 8
diffusion-based open-source and 2 commercial generators. We also examine the
performance of existing synthetic speech detectors on DiffSSD in both
closed-set and open-set scenarios. The results highlight the importance of this
dataset in detecting synthetic speech generated from recent open-source and
commercial speech generators.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to IEEE International Conference on Acoustics, Speech, and
  Signal Processing (ICASSP) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Moshi: a speech-text foundation model for real-time dialogue 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00037v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00037v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexandre Défossez, Laurent Mazaré, Manu Orsini, Amélie Royer, Patrick Pérez, Hervé Jégou, Edouard Grave, Neil Zeghidour
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Moshi, a speech-text foundation model and full-duplex spoken
dialogue framework. Current systems for spoken dialogue rely on pipelines of
independent components, namely voice activity detection, speech recognition,
textual dialogue and text-to-speech. Such frameworks cannot emulate the
experience of real conversations. First, their complexity induces a latency of
several seconds between interactions. Second, text being the intermediate
modality for dialogue, non-linguistic information that modifies meaning -- such
as emotion or non-speech sounds -- is lost in the interaction. Finally, they
rely on a segmentation into speaker turns, which does not take into account
overlapping speech, interruptions and interjections. Moshi solves these
independent issues altogether by casting spoken dialogue as speech-to-speech
generation. Starting from a text language model backbone, Moshi generates
speech as tokens from the residual quantizer of a neural audio codec, while
modeling separately its own speech and that of the user into parallel streams.
This allows for the removal of explicit speaker turns, and the modeling of
arbitrary conversational dynamics. We moreover extend the hierarchical
semantic-to-acoustic token generation of previous work to first predict
time-aligned text tokens as a prefix to audio tokens. Not only this "Inner
Monologue" method significantly improves the linguistic quality of generated
speech, but we also illustrate how it can provide streaming speech recognition
and text-to-speech. Our resulting model is the first real-time full-duplex
spoken large language model, with a theoretical latency of 160ms, 200ms in
practice, and is available at https://github.com/kyutai-labs/moshi.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Just ASR + LLM? A Study on Speech Large Language Models' Ability to
  Identify and Understand Speaker in Spoken Dialogue 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04927v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04927v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junkai Wu, Xulin Fan, Bo-Ru Lu, Xilin Jiang, Nima Mesgarani, Mark Hasegawa-Johnson, Mari Ostendorf
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, we have observed a rapid advancement in speech language
models (SpeechLLMs), catching up with humans' listening and reasoning
abilities. SpeechLLMs have demonstrated impressive spoken dialog
question-answering (SQA) performance in benchmarks like Gaokao, the English
listening test of the college entrance exam in China, which seemingly requires
understanding both the spoken content and voice characteristics of speakers in
a conversation. However, after carefully examining Gaokao's questions, we find
the correct answers to many questions can be inferred from the conversation
transcript alone, i.e.\ without speaker segmentation and identification. Our
evaluation of state-of-the-art models Qwen-Audio and WavLLM on both Gaokao and
our proposed "What Do You Like?" dataset shows a significantly higher accuracy
in these context-based questions than in identity-critical questions, which can
only be answered reliably with correct speaker identification. The results and
analysis suggest that when solving SQA, the current SpeechLLMs exhibit limited
speaker awareness from the audio and behave similarly to an LLM reasoning from
the conversation transcription without sound. We propose that tasks focused on
identity-critical questions could offer a more accurate evaluation framework of
SpeechLLMs in SQA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to IEEE SLT 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Integrating Text-to-Music Models with Language Models: Composing Long
  Structured Music Pieces 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00344v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00344v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lilac Atassi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent music generation methods based on transformers have a context window
of up to a minute. The music generated by these methods are largely
unstructured beyond the context window. With a longer context window, learning
long scale structures from musical data is a prohibitively challenging problem.
This paper proposes integrating a text-to-music model with a large language
model to generate music with form. We discuss our solutions to the challenges
of such integration. The experimental results show that the proposed method can
generate 2.5-minute-long music that is highly structured, strongly organized,
and cohesive.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: substantial text overlap with arXiv:2404.11976</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VoxHakka: A Dialectally Diverse Multi-speaker Text-to-Speech System for
  Taiwanese Hakka 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.01548v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.01548v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Li-Wei Chen, Hung-Shin Lee, Chen-Chi Chang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces VoxHakka, a text-to-speech (TTS) system designed for
Taiwanese Hakka, a critically under-resourced language spoken in Taiwan.
Leveraging the YourTTS framework, VoxHakka achieves high naturalness and
accuracy and low real-time factor in speech synthesis while supporting six
distinct Hakka dialects. This is achieved by training the model with
dialect-specific data, allowing for the generation of speaker-aware Hakka
speech. To address the scarcity of publicly available Hakka speech corpora, we
employed a cost-effective approach utilizing a web scraping pipeline coupled
with automatic speech recognition (ASR)-based data cleaning techniques. This
process ensured the acquisition of a high-quality, multi-speaker, multi-dialect
dataset suitable for TTS training. Subjective listening tests conducted using
comparative mean opinion scores (CMOS) demonstrate that VoxHakka significantly
outperforms existing publicly available Hakka TTS systems in terms of
pronunciation accuracy, tone correctness, and overall naturalness. This work
represents a significant advancement in Hakka language technology and provides
a valuable resource for language preservation and revitalization efforts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to O-COCOSDA 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large
  Language Models <span class="chip">EMNLP24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18680v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18680v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiming Chen, Xianghu Yue, Xiaoxue Gao, Chen Zhang, Luis Fernando D'Haro, Robby T. Tan, Haizhou Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Various audio-LLMs (ALLMs) have been explored recently for tackling different
audio tasks simultaneously using a single, unified model. While existing
evaluations of ALLMs primarily focus on single-audio tasks, real-world
applications often involve processing multiple audio streams simultaneously. To
bridge this gap, we propose the first multi-audio evaluation (MAE) benchmark
that consists of 20 datasets from 11 multi-audio tasks encompassing both speech
and sound scenarios. Comprehensive experiments on MAE demonstrate that the
existing ALLMs, while being powerful in comprehending primary audio elements in
individual audio inputs, struggling to handle multi-audio scenarios. To this
end, we propose a novel multi-audio-LLM (MALLM) to capture audio context among
multiple similar audios using discriminative learning on our proposed synthetic
data. The results demonstrate that the proposed MALLM outperforms all baselines
and achieves high data efficiency using synthetic data without requiring human
annotations. The proposed MALLM opens the door for ALLMs towards multi-audio
processing era and brings us closer to replicating human auditory capabilities
in machines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP24 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Fly on the Wall -- Exploiting Acoustic Side-Channels in Differential
  Pressure Sensors <span class="chip">ACSA</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18213v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18213v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yonatan Gizachew Achamyeleh, Mohamad Habib Fakih, Gabriel Garcia, Anomadarshi Barua, Mohammad Al Faruque
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Differential Pressure Sensors are widely deployed to monitor critical
environments. However, our research unveils a previously overlooked
vulnerability: their high sensitivity to pressure variations makes them
susceptible to acoustic side-channel attacks. We demonstrate that the
pressure-sensing diaphragms in DPS can inadvertently capture subtle air
vibrations caused by speech, which propagate through the sensor's components
and affect the pressure readings. Exploiting this discovery, we introduce
BaroVox, a novel attack that reconstructs speech from DPS readings, effectively
turning DPS into a "fly on the wall." We model the effect of sound on DPS,
exploring the limits and challenges of acoustic leakage. To overcome these
challenges, we propose two solutions: a signal-processing approach using a
unique spectral subtraction method and a deep learning-based approach for
keyword classification. Evaluations under various conditions demonstrate
BaroVox's effectiveness, achieving a word error rate of 0.29 for manual
recognition and 90.51% accuracy for automatic recognition. Our findings
highlight the significant privacy implications of this vulnerability. We also
discuss potential defense strategies to mitigate the risks posed by BaroVox.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ACSAC 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ dMel: Speech Tokenization made Simple 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.15835v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.15835v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        He Bai, Tatiana Likhomanenko, Ruixiang Zhang, Zijin Gu, Zakaria Aldeneh, Navdeep Jaitly
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models have revolutionized natural language processing by
leveraging self-supervised pretraining on vast textual data. Inspired by this
success, researchers have investigated complicated speech tokenization methods
to discretize continuous speech signals so that language modeling techniques
can be applied to speech data. However, existing approaches either model
semantic (content) tokens, potentially losing acoustic information, or model
acoustic tokens, risking the loss of semantic (content) information. Having
multiple token types also complicates the architecture and requires additional
pretraining. Here we show that discretizing mel-filterbank channels into
discrete intensity bins produces a simple representation (dMel), that performs
better than other existing speech tokenization methods. Using an LM-style
transformer architecture for speech-text modeling, we comprehensively evaluate
different speech tokenization methods on speech recognition (ASR) and speech
synthesis (TTS). Our results demonstrate the effectiveness of dMel in achieving
high performance on both tasks within a unified framework, paving the way for
efficient and effective joint modeling of speech and text.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Harmony and Duality: An introduction to Music Theory 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2309.10719v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2309.10719v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maksim Lipyanskiy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We develop aspects of music theory related to harmony, such as scales, chord
formation and improvisation from a combinatorial perspective. The goal is to
provide a foundation for this subject by deriving the basic structure from a
few assumptions, rather than writing down long lists of chords/scales to
memorize without an underlying principle. Our approach involves introducing
constraints that limit the possible scales we can consider. For example, we may
impose the constraint that two voices cannot be only a semitone apart as this
is too dissonant. We can then study scales that do not contain notes that are a
semitone apart. A more refined constraint avoids three voices colliding by
studying scales that do not have three notes separated only by semitones.
Additionally, we require that our scales are complete, which roughly means that
they are the maximal sets of tones that satisfy these constraints. As it turns
out, completeness as applied to these simple two/three voice constraints
characterizes the types of scales that are commonly used in music composition.
Surprisingly, there is a correspondence between scales subject to the two-voice
constraint and those subject to the three-voice constraint. We formulate this
correspondence as a duality statement that provides a way to understand scales
subject to one type of constraint in terms of scales subject to the other.
Finally, we combine these constraint ideas to provide a classification of
chords.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>75 pages, 72 figures</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Artificial Intelligence <span class="chip" style="font-size: 60%">150</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Samba: Synchronized Set-of-Sequences Modeling for Multiple Object
  Tracking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01806v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01806v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mattia Segu, Luigi Piccinelli, Siyuan Li, Yung-Hsu Yang, Bernt Schiele, Luc Van Gool
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multiple object tracking in complex scenarios - such as coordinated dance
performances, team sports, or dynamic animal groups - presents unique
challenges. In these settings, objects frequently move in coordinated patterns,
occlude each other, and exhibit long-term dependencies in their trajectories.
However, it remains a key open research question on how to model long-range
dependencies within tracklets, interdependencies among tracklets, and the
associated temporal occlusions. To this end, we introduce Samba, a novel
linear-time set-of-sequences model designed to jointly process multiple
tracklets by synchronizing the multiple selective state-spaces used to model
each tracklet. Samba autoregressively predicts the future track query for each
sequence while maintaining synchronized long-term memory representations across
tracklets. By integrating Samba into a tracking-by-propagation framework, we
propose SambaMOTR, the first tracker effectively addressing the aforementioned
issues, including long-range dependencies, tracklet interdependencies, and
temporal occlusions. Additionally, we introduce an effective technique for
dealing with uncertain observations (MaskObs) and an efficient training recipe
to scale SambaMOTR to longer sequences. By modeling long-range dependencies and
interactions among tracked objects, SambaMOTR implicitly learns to track
objects accurately through occlusions without any hand-crafted heuristics. Our
approach significantly surpasses prior state-of-the-art on the DanceTrack, BFT,
and SportsMOT datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FabricDiffusion: High-Fidelity Texture Transfer for 3D Garments
  Generation from In-The-Wild Clothing Images <span class="chip">SIGGRAPH</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01801v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01801v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cheng Zhang, Yuanhao Wang, Francisco Vicente Carrasco, Chenglei Wu, Jinlong Yang, Thabo Beeler, Fernando De la Torre
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce FabricDiffusion, a method for transferring fabric textures from
a single clothing image to 3D garments of arbitrary shapes. Existing approaches
typically synthesize textures on the garment surface through 2D-to-3D texture
mapping or depth-aware inpainting via generative models. Unfortunately, these
methods often struggle to capture and preserve texture details, particularly
due to challenging occlusions, distortions, or poses in the input image.
Inspired by the observation that in the fashion industry, most garments are
constructed by stitching sewing patterns with flat, repeatable textures, we
cast the task of clothing texture transfer as extracting distortion-free,
tileable texture materials that are subsequently mapped onto the UV space of
the garment. Building upon this insight, we train a denoising diffusion model
with a large-scale synthetic dataset to rectify distortions in the input
texture image. This process yields a flat texture map that enables a tight
coupling with existing Physically-Based Rendering (PBR) material generation
pipelines, allowing for realistic relighting of the garment under various
lighting conditions. We show that FabricDiffusion can transfer various features
from a single clothing image including texture patterns, material properties,
and detailed prints and logos. Extensive experiments demonstrate that our model
significantly outperforms state-to-the-art methods on both synthetic data and
real-world, in-the-wild clothing images while generalizing to unseen textures
and garment shapes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to SIGGRAPH Asia 2024. Project page:
  https://humansensinglab.github.io/fabric-diffusion</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Windowed MAPF with Completeness Guarantees 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01798v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01798v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rishi Veerapaneni, Muhammad Suhail Saleem, Jiaoyang Li, Maxim Likhachev
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Traditional multi-agent path finding (MAPF) methods try to compute entire
start-goal paths which are collision free. However, computing an entire path
can take too long for MAPF systems where agents need to replan fast. Methods
that address this typically employ a "windowed" approach and only try to find
collision free paths for a small windowed timestep horizon. This adaptation
comes at the cost of incompleteness; all current windowed approaches can become
stuck in deadlock or livelock. Our main contribution is to introduce our
framework, WinC-MAPF, for Windowed MAPF that enables completeness. Our
framework uses heuristic update insights from single-agent real-time heuristic
search algorithms as well as agent independence ideas from MAPF algorithms. We
also develop Single-Step CBS (SS-CBS), an instantiation of this framework using
a novel modification to CBS. We show how SS-CBS, which only plans a single step
and updates heuristics, can effectively solve tough scenarios where existing
windowed approaches fail.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ When a language model is optimized for reasoning, does it still show
  embers of autoregression? An analysis of OpenAI o1 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01792v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01792v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        R. Thomas McCoy, Shunyu Yao, Dan Friedman, Mathew D. Hardy, Thomas L. Griffiths
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In "Embers of Autoregression" (McCoy et al., 2023), we showed that several
large language models (LLMs) have some important limitations that are
attributable to their origins in next-word prediction. Here we investigate
whether these issues persist with o1, a new system from OpenAI that differs
from previous LLMs in that it is optimized for reasoning. We find that o1
substantially outperforms previous LLMs in many cases, with particularly large
improvements on rare variants of common tasks (e.g., forming acronyms from the
second letter of each word in a list, rather than the first letter). Despite
these quantitative improvements, however, o1 still displays the same
qualitative trends that we observed in previous systems. Specifically, o1 -
like previous LLMs - is sensitive to the probability of examples and tasks,
performing better and requiring fewer "thinking tokens" in high-probability
settings than in low-probability ones. These results show that optimizing a
language model for reasoning can mitigate but might not fully overcome the
language model's probability sensitivity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DreamGarden: A Designer Assistant for Growing Games from a Single <span class="highlight-title">Prompt</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01791v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01791v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sam Earle, Samyak Parajuli, Andrzej Banburski-Fahey
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Coding assistants are increasingly leveraged in game design, both generating
code and making high-level plans. To what degree can these tools align with
developer workflows, and what new modes of human-computer interaction can
emerge from their use? We present DreamGarden, an AI system capable of
assisting with the development of diverse game environments in Unreal Engine.
At the core of our method is an LLM-driven planner, capable of breaking down a
single, high-level prompt -- a dream, memory, or imagined scenario provided by
a human user -- into a hierarchical action plan, which is then distributed
across specialized submodules facilitating concrete implementation. This system
is presented to the user as a garden of plans and actions, both growing
independently and responding to user intervention via seed prompts, pruning,
and feedback. Through a user study, we explore design implications of this
system, charting courses for future work in semi-autonomous assistants and
open-ended simulation design.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages + appendix, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Investigating on RLHF methodology 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01789v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01789v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexey Kutalev, Sergei Markoff
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this article, we investigate the alignment of Large Language Models
according to human preferences. We discuss the features of training a
Preference Model, which simulates human preferences, and the methods and
details we found essential for achieving the best results. We also discuss
using Reinforcement Learning to fine-tune Large Language Models and describe
the challenges we faced and the ways to overcome them. Additionally, we present
our experience with the Direct Preference Optimization method, which enables us
to align a Large Language Model with human preferences without creating a
separate Preference Model. As our contribution, we introduce the approach for
collecting a preference dataset through perplexity filtering, which makes the
process of creating such a dataset for a specific Language Model much easier
and more cost-effective.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages, 6 figures, 6 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Open-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large
  Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01782v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01782v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shayekh Bin Islam, Md Asib Rahman, K S M Tozammel Hossain, Enamul Hoque, Shafiq Joty, Md Rizwan Parvez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) has been shown to enhance the factual
accuracy of Large Language Models (LLMs), but existing methods often suffer
from limited reasoning capabilities in effectively using the retrieved
evidence, particularly when using open-source LLMs. To mitigate this gap, we
introduce a novel framework, Open-RAG, designed to enhance reasoning
capabilities in RAG with open-source LLMs. Our framework transforms an
arbitrary dense LLM into a parameter-efficient sparse mixture of experts (MoE)
model capable of handling complex reasoning tasks, including both single- and
multi-hop queries. Open-RAG uniquely trains the model to navigate challenging
distractors that appear relevant but are misleading. As a result, Open-RAG
leverages latent learning, dynamically selecting relevant experts and
integrating external knowledge effectively for more accurate and contextually
relevant responses. In addition, we propose a hybrid adaptive retrieval method
to determine retrieval necessity and balance the trade-off between performance
gain and inference speed. Experimental results show that the Llama2-7B-based
Open-RAG outperforms state-of-the-art LLMs and RAG models such as ChatGPT,
Self-RAG, and Command R+ in various knowledge-intensive tasks. We open-source
our code and models at https://openragmoe.github.io/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Findings. Website:
  https://openragmoe.github.io/. 14 pages, 7 figures, 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Composing Global Optimizers to Reasoning Tasks via Algebraic Objects in
  Neural Nets 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01779v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01779v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuandong Tian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We prove rich algebraic structures of the solution space for 2-layer neural
networks with quadratic activation and $L_2$ loss, trained on reasoning tasks
in Abelian group (e.g., modular addition). Such a rich structure enables
analytical construction of global optimal solutions from partial solutions that
only satisfy part of the loss, despite its high nonlinearity. We coin the
framework as CoGO (Composing Global Optimizers). Specifically, we show that the
weight space over different numbers of hidden nodes of the 2-layer network is
equipped with a semi-ring algebraic structure, and the loss function to be
optimized consists of monomial potentials, which are ring homomorphism,
allowing partial solutions to be composed into global ones by ring addition and
multiplication. Our experiments show that around $95\%$ of the solutions
obtained by gradient descent match exactly our theoretical constructions.
Although the global optimizers constructed only required a small number of
hidden nodes, our analysis on gradient dynamics shows that
over-parameterization asymptotically decouples training dynamics and is
beneficial. We further show that training dynamics favors simpler solutions
under weight decay, and thus high-order global optimizers such as perfect
memorization are unfavorable.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DeFine: Enhancing LLM Decision-Making with Factor Profiles and
  Analogical Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01772v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01772v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yebowen Hu, Xiaoyang Wang, Wenlin Yao, Yiming Lu, Daoan Zhang, Hassan Foroosh, Dong Yu, Fei Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLMs are ideal for decision-making due to their ability to reason over long
contexts and identify critical factors. However, challenges arise when
processing transcripts of spoken speech describing complex scenarios. These
transcripts often contain ungrammatical or incomplete sentences, repetitions,
hedging, and vagueness. For example, during a company's earnings call, an
executive might project a positive revenue outlook to reassure investors,
despite significant uncertainty regarding future earnings. It is crucial for
LLMs to incorporate this uncertainty systematically when making decisions. In
this paper, we introduce DeFine, a new framework that constructs probabilistic
factor profiles from complex scenarios. DeFine then integrates these profiles
with analogical reasoning, leveraging insights from similar past experiences to
guide LLMs in making critical decisions in novel situations. Our framework
separates the tasks of quantifying uncertainty in complex scenarios and
incorporating it into LLM decision-making. This approach is particularly useful
in fields such as medical consultations, negotiations, and political debates,
where making decisions under uncertainty is vital.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mimicking Human Intuition: Cognitive Belief-Driven Q-Learning <span class="chip">ICLR 25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01739v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01739v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingrui Gu, Guanren Qiao, Chuyi Jiang, Tianqing Xia, Hangyu Mao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement learning encounters challenges in various environments related
to robustness and explainability. Traditional Q-learning algorithms cannot
effectively make decisions and utilize the historical learning experience. To
overcome these limitations, we propose Cognitive Belief-Driven Q-Learning
(CBDQ), which integrates subjective belief modeling into the Q-learning
framework, enhancing decision-making accuracy by endowing agents with
human-like learning and reasoning capabilities. Drawing inspiration from
cognitive science, our method maintains a subjective belief distribution over
the expectation of actions, leveraging a cluster-based subjective belief model
that enables agents to reason about the potential probability associated with
each decision. CBDQ effectively mitigates overestimated phenomena and optimizes
decision-making policies by integrating historical experiences with current
contextual information, mimicking the dynamics of human decision-making. We
evaluate the proposed method on discrete control benchmark tasks in various
complicate environments. The results demonstrate that CBDQ exhibits stronger
adaptability, robustness, and human-like characteristics in handling these
environments, outperforming other baselines. We hope this work will give
researchers a fresh perspective on understanding and explaining Q-learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review by ICLR 25</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VitaGlyph: Vitalizing Artistic Typography with Flexible Dual-branch
  Diffusion Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01738v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01738v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kailai Feng, Yabo Zhang, Haodong Yu, Zhilong Ji, Jinfeng Bai, Hongzhi Zhang, Wangmeng Zuo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Artistic typography is a technique to visualize the meaning of input
character in an imaginable and readable manner. With powerful text-to-image
diffusion models, existing methods directly design the overall geometry and
texture of input character, making it challenging to ensure both creativity and
legibility. In this paper, we introduce a dual-branch and training-free method,
namely VitaGlyph, enabling flexible artistic typography along with controllable
geometry change to maintain the readability. The key insight of VitaGlyph is to
treat input character as a scene composed of Subject and Surrounding, followed
by rendering them under varying degrees of geometry transformation. The subject
flexibly expresses the essential concept of input character, while the
surrounding enriches relevant background without altering the shape.
Specifically, we implement VitaGlyph through a three-phase framework: (i)
Knowledge Acquisition leverages large language models to design text
descriptions of subject and surrounding. (ii) Regional decomposition detects
the part that most matches the subject description and divides input glyph
image into subject and surrounding regions. (iii) Typography Stylization
firstly refines the structure of subject region via Semantic Typography, and
then separately renders the textures of Subject and Surrounding regions through
Controllable Compositional Generation. Experimental results demonstrate that
VitaGlyph not only achieves better artistry and readability, but also manages
to depict multiple customize concepts, facilitating more creative and pleasing
artistic typography generation. Our code will be made publicly at
https://github.com/Carlofkl/VitaGlyph.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://github.com/Carlofkl/VitaGlyph</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluating Robustness of Reward Models for Mathematical Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01729v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01729v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sunghwan Kim, Dongjin Kang, Taeyoon Kwon, Hyungjoo Chae, Jungsoo Won, Dongha Lee, Jinyoung Yeo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reward models are key in reinforcement learning from human feedback (RLHF)
systems, aligning the model behavior with human preferences. Particularly in
the math domain, there have been plenty of studies using reward models to align
policies for improving reasoning capabilities. Recently, as the importance of
reward models has been emphasized, RewardBench is proposed to understand their
behavior. However, we figure out that the math subset of RewardBench has
different representations between chosen and rejected completions, and relies
on a single comparison, which may lead to unreliable results as it only see an
isolated case. Therefore, it fails to accurately present the robustness of
reward models, leading to a misunderstanding of its performance and potentially
resulting in reward hacking. In this work, we introduce a new design for
reliable evaluation of reward models, and to validate this, we construct
RewardMATH, a benchmark that effectively represents the robustness of reward
models in mathematical reasoning tasks. We demonstrate that the scores on
RewardMATH strongly correlate with the results of optimized policy and
effectively estimate reward overoptimization, whereas the existing benchmark
shows almost no correlation. The results underscore the potential of our design
to enhance the reliability of evaluation, and represent the robustness of
reward model. We make our code and data publicly available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Auto-Demo <span class="highlight-title">Prompt</span>ing: Leveraging Generated Outputs as Demonstrations for
  Enhanced Batch <span class="highlight-title">Prompt</span>ing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01724v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01724v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Longyu Feng, Mengze Hong, Chen Jason Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Batch prompting is a common technique in large language models (LLMs) used to
process multiple inputs simultaneously, aiming to improve computational
efficiency. However, as batch sizes increase, performance degradation often
occurs due to the model's difficulty in handling lengthy context inputs.
Existing methods that attempt to mitigate these issues rely solely on batch
data arrangement and majority voting rather than improving the design of the
batch prompt itself. In this paper, we address these limitations by proposing
"Auto-Demo Prompting," a novel approach that leverages the question-output
pairs from earlier questions within a batch as demonstrations for subsequent
answer inference. We provide a formal theoretical analysis of how Auto-Demo
Prompting functions within the autoregressive generation process of LLMs,
illustrating how it utilizes prior outputs to optimize the model's internal
representations. Our method effectively bridges the gap between batch prompting
and few-shot prompting, enhancing performance with only a slight compromise in
token usage. Experimental results across five NLP tasks demonstrate its
effectiveness in mitigating performance degradation and occasionally
outperforming single prompts. Furthermore, it opens new avenues for applying
few-shot learning techniques, such as demonstration selection, within batch
prompting, making it a robust solution for real-world applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards a Theoretical Understanding of Synthetic Data in LLM
  Post-Training: A Reverse-Bottleneck Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01720v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01720v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zeyu Gan, Yong Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Synthetic data has become a pivotal resource in post-training tasks for large
language models (LLMs) due to the scarcity of high-quality, specific data.
While various methods have been developed to generate synthetic data, there
remains a discernible gap between the practical effects of synthetic data and
our theoretical comprehension. To address this challenge, we commence by
presenting a detailed modeling of the prevalent synthetic data generation
process. Building upon this modeling, we demonstrate that the generalization
capability of the post-trained model is critically determined by the
information gain derived from the generative model, as analyzed from a novel
reverse-bottleneck perspective. Moreover, we introduce the concept of
Generalization Gain via Mutual Information (GGMI) and elucidate the
relationship between generalization gain and information gain. This analysis
serves as a theoretical foundation for synthetic data generation and further
highlights its connection with the generalization capability of post-trained
models, offering an understanding about the design of synthetic data generation
techniques and the optimization of the post-training process. We open source
our code through an anonymous GitHub repository at
https://anonymous.4open.science/r/Understanding-Synthetic.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Performant, Memory Efficient and Scalable Multi-Agent Reinforcement
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01706v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01706v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Omayma Mahjoub, Sasha Abramowitz, Ruan de Kock, Wiem Khlifi, Simon du Toit, Jemma Daniel, Louay Ben Nessir, Louise Beyers, Claude Formanek, Liam Clark, Arnu Pretorius
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As the field of multi-agent reinforcement learning (MARL) progresses towards
larger and more complex environments, achieving strong performance while
maintaining memory efficiency and scalability to many agents becomes
increasingly important. Although recent research has led to several advanced
algorithms, to date, none fully address all of these key properties
simultaneously. In this work, we introduce Sable, a novel and theoretically
sound algorithm that adapts the retention mechanism from Retentive Networks to
MARL. Sable's retention-based sequence modelling architecture allows for
computationally efficient scaling to a large number of agents, as well as
maintaining a long temporal context, making it well-suited for large-scale
partially observable environments. Through extensive evaluations across six
diverse environments, we demonstrate how Sable is able to significantly
outperform existing state-of-the-art methods in the majority of tasks (34 out
of 45, roughly 75\%). Furthermore, Sable demonstrates stable performance as we
scale the number of agents, handling environments with more than a thousand
agents while exhibiting a linear increase in memory usage. Finally, we conduct
ablation studies to isolate the source of Sable's performance gains and confirm
its efficient computational memory usage. Our results highlight Sable's
performance and efficiency, positioning it as a leading approach to MARL at
scale.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CreDes: Causal Reasoning Enhancement and Dual-End Searching for Solving
  Long-Range Reasoning Problems using LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01696v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01696v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kangsheng Wang, Xiao Zhang, Hao Liu, Songde Han, Huimin Ma, Tianyu Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have demonstrated limitations in handling
combinatorial optimization problems involving long-range reasoning, partially
due to causal hallucinations and huge search space. As for causal
hallucinations, i.e., the inconsistency between reasoning and corresponding
state transition, this paper introduces the Causal Relationship Enhancement
(CRE) mechanism combining cause-effect interventions and the Individual
Treatment Effect (ITE) to guarantee the solid causal rightness between each
step of reasoning and state transition. As for the long causal range and huge
search space limiting the performances of existing models featuring
single-direction search, a Dual-End Searching (DES) approach is proposed to
seek solutions by simultaneously starting from both the initial and goal states
on the causal probability tree. By integrating CRE and DES (CreDes), our model
has realized simultaneous multi-step reasoning, circumventing the
inefficiencies from cascading multiple one-step reasoning like the
Chain-of-Thought (CoT). Experiments demonstrate that CreDes significantly
outperforms existing State-Of-The-Art (SOTA) solutions in long-range reasoning
tasks in terms of both accuracy and time efficiency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ From Prohibition to Adoption: How Hong Kong Universities Are Navigating
  Chat<span class="highlight-title">GPT</span> in Academic Workflows 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01695v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01695v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junjun Huang, Jifan Wu, Qing Wang, Kemeng Yuan, Jiefeng Li, Di Lu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper aims at comparing the time when Hong Kong universities used to ban
ChatGPT to the current periods where it has become integrated in the academic
processes. Bolted by concerns of integrity and ethical issues in technologies,
institutions have adapted by moving towards the center adopting AI literacy and
responsibility policies. This study examines new paradigms which have been
developed to help implement these positives while preventing negative effects
on academia. Keywords: ChatGPT, Academic Integrity, AI Literacy, Ethical AI
Use, Generative AI in Education, University Policy, AI Integration in Academia,
Higher Education and Technology
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ U-shaped and Inverted-U Scaling behind Emergent Abilities of Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01692v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01692v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tung-Yu Wu, Pei-Yu Lo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have been shown to exhibit emergent abilities in
some downstream tasks, where performance seems to stagnate at first and then
improve sharply and unpredictably with scale beyond a threshold. By dividing
questions in the datasets according to difficulty level by average performance,
we observe U-shaped scaling for hard questions, and inverted-U scaling followed
by steady improvement for easy questions. Moreover, the emergence threshold
roughly coincides with the point at which performance on easy questions reverts
from inverse scaling to standard scaling. Capitalizing on the observable though
opposing scaling trend on easy and hard questions, we propose a simple yet
effective pipeline, called Slice-and-Sandwich, to predict both the emergence
threshold and model performance beyond the threshold.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint. Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FactAlign: Long-form Factuality Alignment of Large Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01691v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01691v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chao-Wei Huang, Yun-Nung Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models have demonstrated significant potential as the
next-generation information access engines. However, their reliability is
hindered by issues of hallucination and generating non-factual content. This is
particularly problematic in long-form responses, where assessing and ensuring
factual accuracy is complex. In this paper, we address this gap by proposing
FactAlign, a novel alignment framework designed to enhance the factuality of
LLMs' long-form responses while maintaining their helpfulness. We introduce
fKTO, a fine-grained, sentence-level alignment algorithm that extends the
Kahneman-Tversky Optimization (KTO) alignment method. Leveraging recent
advances in automatic factuality evaluation, FactAlign utilizes fine-grained
factuality assessments to guide the alignment process. Our experiments on
open-domain prompts and information-seeking questions demonstrate that
FactAlign significantly improves the factual accuracy of LLM responses while
also improving their helpfulness. Further analyses identify that FactAlign is
capable of training LLMs to provide more information without losing factual
precision, thus improving the factual F1 score. Our source code, datasets, and
trained models are publicly available at https://github.com/MiuLab/FactAlign
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Why context matters in VQA and Reasoning: Semantic interventions for VLM
  input modalities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01690v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01690v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kenza Amara, Lukas Klein, Carsten Lüth, Paul Jäger, Hendrik Strobelt, Mennatallah El-Assady
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The various limitations of Generative AI, such as hallucinations and model
failures, have made it crucial to understand the role of different modalities
in Visual Language Model (VLM) predictions. Our work investigates how the
integration of information from image and text modalities influences the
performance and behavior of VLMs in visual question answering (VQA) and
reasoning tasks. We measure this effect through answer accuracy, reasoning
quality, model uncertainty, and modality relevance. We study the interplay
between text and image modalities in different configurations where visual
content is essential for solving the VQA task. Our contributions include (1)
the Semantic Interventions (SI)-VQA dataset, (2) a benchmark study of various
VLM architectures under different modality configurations, and (3) the
Interactive Semantic Interventions (ISI) tool. The SI-VQA dataset serves as the
foundation for the benchmark, while the ISI tool provides an interface to test
and apply semantic interventions in image and text inputs, enabling more
fine-grained analysis. Our results show that complementary information between
modalities improves answer and reasoning quality, while contradictory
information harms model performance and confidence. Image text annotations have
minimal impact on accuracy and uncertainty, slightly increasing image
relevance. Attention analysis confirms the dominant role of image inputs over
text in VQA tasks. In this study, we evaluate state-of-the-art VLMs that allow
us to extract attention coefficients for each modality. A key finding is
PaliGemma's harmful overconfidence, which poses a higher risk of silent
failures compared to the LLaVA models. This work sets the foundation for
rigorous analysis of modality integration, supported by datasets specifically
designed for this purpose.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Uncertainty Quantification with Bayesian Higher Order ReLU KANs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01687v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01687v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        James Giroux, Cristiano Fanelli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce the first method of uncertainty quantification in the domain of
Kolmogorov-Arnold Networks, specifically focusing on (Higher Order) ReLUKANs to
enhance computational efficiency given the computational demands of Bayesian
methods. The method we propose is general in nature, providing access to both
epistemic and aleatoric uncertainties. It is also capable of generalization to
other various basis functions. We validate our method through a series of
closure tests, including simple one-dimensional functions and application to
the domain of (Stochastic) Partial Differential Equations. Referring to the
latter, we demonstrate the method's ability to correctly identify functional
dependencies introduced through the inclusion of a stochastic term. The code
supporting this work can be found at
https://github.com/wmdataphys/Bayesian-HR-KAN
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 7 Figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Positional Attention: Out-of-Distribution Generalization and
  Expressivity for Neural Algorithmic Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01686v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01686v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Artur Back de Luca, George Giapitzakis, Shenghao Yang, Petar Veličković, Kimon Fountoulakis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  There has been a growing interest in the ability of neural networks to solve
algorithmic tasks, such as arithmetic, summary statistics, and sorting. While
state-of-the-art models like Transformers have demonstrated good generalization
performance on in-distribution tasks, their out-of-distribution (OOD)
performance is poor when trained end-to-end. In this paper, we focus on value
generalization, a common instance of OOD generalization where the test
distribution has the same input sequence length as the training distribution,
but the value ranges in the training and test distributions do not necessarily
overlap. To address this issue, we propose that using fixed positional
encodings to determine attention weights-referred to as positional
attention-enhances empirical OOD performance while maintaining expressivity. We
support our claim about expressivity by proving that Transformers with
positional attention can effectively simulate parallel algorithms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>37 pages, 22 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PHI-S: Distribution Balancing for Label-Free Multi-Teacher Distillation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01680v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01680v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mike Ranzinger, Jon Barker, Greg Heinrich, Pavlo Molchanov, Bryan Catanzaro, Andrew Tao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Various visual foundation models have distinct strengths and weaknesses, both
of which can be improved through heterogeneous multi-teacher knowledge
distillation without labels, termed "agglomerative models." We build upon this
body of work by studying the effect of the teachers' activation statistics,
particularly the impact of the loss function on the resulting student model
quality. We explore a standard toolkit of statistical normalization techniques
to better align the different distributions and assess their effects. Further,
we examine the impact on downstream teacher-matching metrics, which motivates
the use of Hadamard matrices. With these matrices, we demonstrate useful
properties, showing how they can be used for isotropic standardization, where
each dimension of a multivariate distribution is standardized using the same
scale. We call this technique "PHI Standardization" (PHI-S) and empirically
demonstrate that it produces the best student model across the suite of methods
studied.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mind Scramble: Unveiling Large Language Model Psychology Via
  Typoglycemia 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01677v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01677v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Miao Yu, Junyuan Mao, Guibin Zhang, Jingheng Ye, Junfeng Fang, Aoxiao Zhong, Yang Liu, Yuxuan Liang, Kun Wang, Qingsong Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Research into the external behaviors and internal mechanisms of large
language models (LLMs) has shown promise in addressing complex tasks in the
physical world. Studies suggest that powerful LLMs, like GPT-4, are beginning
to exhibit human-like cognitive abilities, including planning, reasoning, and
reflection. In this paper, we introduce a research line and methodology called
LLM Psychology, leveraging human psychology experiments to investigate the
cognitive behaviors and mechanisms of LLMs. We migrate the Typoglycemia
phenomenon from psychology to explore the "mind" of LLMs. Unlike human brains,
which rely on context and word patterns to comprehend scrambled text, LLMs use
distinct encoding and decoding processes. Through Typoglycemia experiments at
the character, word, and sentence levels, we observe: (I) LLMs demonstrate
human-like behaviors on a macro scale, such as lower task accuracy and higher
token/time consumption; (II) LLMs exhibit varying robustness to scrambled
input, making Typoglycemia a benchmark for model evaluation without new
datasets; (III) Different task types have varying impacts, with complex logical
tasks (e.g., math) being more challenging in scrambled form; (IV) Each LLM has
a unique and consistent "cognitive pattern" across tasks, revealing general
mechanisms in its psychology process. We provide an in-depth analysis of hidden
layers to explain these phenomena, paving the way for future research in LLM
Psychology and deeper interpretability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Trying to be human: Linguistic traces of stochastic empathy in language
  models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01675v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01675v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bennett Kleinberg, Jari Zegers, Jonas Festor, Stefana Vida, Julian Präsent, Riccardo Loconte, Sanne Peereboom
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Differentiating between generated and human-written content is important for
navigating the modern world. Large language models (LLMs) are crucial drivers
behind the increased quality of computer-generated content. Reportedly, humans
find it increasingly difficult to identify whether an AI model generated a
piece of text. Our work tests how two important factors contribute to the human
vs AI race: empathy and an incentive to appear human. We address both aspects
in two experiments: human participants and a state-of-the-art LLM wrote
relationship advice (Study 1, n=530) or mere descriptions (Study 2, n=610),
either instructed to be as human as possible or not. New samples of humans
(n=428 and n=408) then judged the texts' source. Our findings show that when
empathy is required, humans excel. Contrary to expectations, instructions to
appear human were only effective for the LLM, so the human advantage
diminished. Computational text analysis revealed that LLMs become more human
because they may have an implicit representation of what makes a text human and
effortlessly apply these heuristics. The model resorts to a conversational,
self-referential, informal tone with a simpler vocabulary to mimic stochastic
empathy. We discuss these findings in light of recent claims on the on-par
performance of LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bridging Context Gaps: Leveraging Coreference Resolution for Long
  Contextual Understanding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01671v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01671v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanming Liu, Xinyue Peng, Jiannan Cao, Shi Bo, Yanxin Shen, Xuhong Zhang, Sheng Cheng, Xun Wang, Jianwei Yin, Tianyu Du
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have shown remarkable capabilities in natural
language processing; however, they still face difficulties when tasked with
understanding lengthy contexts and executing effective question answering.
These challenges often arise due to the complexity and ambiguity present in
longer texts. To enhance the performance of LLMs in such scenarios, we
introduce the Long Question Coreference Adaptation (LQCA) method. This
innovative framework focuses on coreference resolution tailored to long
contexts, allowing the model to identify and manage references effectively. The
LQCA method encompasses four key steps: resolving coreferences within
sub-documents, computing the distances between mentions, defining a
representative mention for coreference, and answering questions through mention
replacement. By processing information systematically, the framework provides
easier-to-handle partitions for LLMs, promoting better understanding.
Experimental evaluations on a range of LLMs and datasets have yielded positive
results, with a notable improvements on OpenAI-o1-mini and GPT-4o models,
highlighting the effectiveness of leveraging coreference resolution to bridge
context gaps in question answering.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Underreview version of LQCA, Bridge context gap for long context</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards a vision foundation model for comprehensive assessment of
  Cardiac MRI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01665v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01665v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Athira J Jacob, Indraneel Borgohain, Teodora Chitiboi, Puneet Sharma, Dorin Comaniciu, Daniel Rueckert
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cardiac magnetic resonance imaging (CMR), considered the gold standard for
noninvasive cardiac assessment, is a diverse and complex modality requiring a
wide variety of image processing tasks for comprehensive assessment of cardiac
morphology and function. Advances in deep learning have enabled the development
of state-of-the-art (SoTA) models for these tasks. However, model training is
challenging due to data and label scarcity, especially in the less common
imaging sequences. Moreover, each model is often trained for a specific task,
with no connection between related tasks. In this work, we introduce a vision
foundation model trained for CMR assessment, that is trained in a
self-supervised fashion on 36 million CMR images. We then finetune the model in
supervised way for 9 clinical tasks typical to a CMR workflow, across
classification, segmentation, landmark localization, and pathology detection.
We demonstrate improved accuracy and robustness across all tasks, over a range
of available labeled dataset sizes. We also demonstrate improved few-shot
learning with fewer labeled samples, a common challenge in medical image
analyses. We achieve an out-of-box performance comparable to SoTA for most
clinical tasks. The proposed method thus presents a resource-efficient, unified
framework for CMR assessment, with the potential to accelerate the development
of deep learning-based solutions for image analysis tasks, even with few
annotated data available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 3 figures, 4 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Finding path and cycle counting formulae in graphs with Deep
  Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01661v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01661v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jason Piquenot, Maxime Bérar, Pierre Héroux, Jean-Yves Ramel, Romain Raveaux, Sébastien Adam
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents Grammar Reinforcement Learning (GRL), a reinforcement
learning algorithm that uses Monte Carlo Tree Search (MCTS) and a transformer
architecture that models a Pushdown Automaton (PDA) within a context-free
grammar (CFG) framework. Taking as use case the problem of efficiently counting
paths and cycles in graphs, a key challenge in network analysis, computer
science, biology, and social sciences, GRL discovers new matrix-based formulas
for path/cycle counting that improve computational efficiency by factors of two
to six w.r.t state-of-the-art approaches. Our contributions include: (i) a
framework for generating gramformers that operate within a CFG, (ii) the
development of GRL for optimizing formulas within grammatical structures, and
(iii) the discovery of novel formulas for graph substructure counting, leading
to significant computational improvements.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Conformal Generative Modeling with Improved Sample Efficiency through
  Sequential Greedy Filtering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01660v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01660v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Klaus-Rudolf Kladny, Bernhard Schölkopf, Michael Muehlebach
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative models lack rigorous statistical guarantees for their outputs and
are therefore unreliable in safety-critical applications. In this work, we
propose Sequential Conformal Prediction for Generative Models (SCOPE-Gen), a
sequential conformal prediction method producing prediction sets that satisfy a
rigorous statistical guarantee called conformal admissibility control. This
guarantee states that with high probability, the prediction sets contain at
least one admissible (or valid) example. To this end, our method first samples
an initial set of i.i.d. examples from a black box generative model. Then, this
set is iteratively pruned via so-called greedy filters. As a consequence of the
iterative generation procedure, admissibility of the final prediction set
factorizes as a Markov chain. This factorization is crucial, because it allows
to control each factor separately, using conformal prediction. In comparison to
prior work, our method demonstrates a large reduction in the number of
admissibility evaluations during calibration. This reduction is important in
safety-critical applications, where these evaluations must be conducted
manually by domain experts and are therefore costly and time consuming. We
highlight the advantages of our method in terms of admissibility evaluations
and cardinality of the prediction sets through experiments in natural language
generation and molecular graph extension tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient Long-range Language Modeling with <span class="highlight-title">Self-supervised</span> Causal
  Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01651v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01651v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiang Hu, Zhihao Teng, Wei Wu, Kewei Tu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, retrieval-based language models (RLMs) have received much
attention. However, most of them leverage a pre-trained retriever with fixed
parameters, which may not adapt well to causal language models. In this work,
we propose Grouped Cross-Attention, a novel module enabling joint pre-training
of the retriever and causal LM, and apply it to long-context modeling. For a
given input sequence, we split it into chunks and use the current chunk to
retrieve past chunks for subsequent text generation. Our innovation allows the
retriever to learn how to retrieve past chunks that better minimize the
auto-regressive loss of subsequent tokens in an end-to-end manner. By
integrating top-$k$ retrieval, our model can be pre-trained efficiently from
scratch with context lengths up to 64K tokens. Our experiments show our model,
compared with long-range LM baselines, can achieve lower perplexity with
comparable or lower pre-training and inference costs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ shapiq: Shapley Interactions for Machine Learning <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01649v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01649v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maximilian Muschalik, Hubert Baniecki, Fabian Fumagalli, Patrick Kolpaczki, Barbara Hammer, Eyke Hüllermeier
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Originally rooted in game theory, the Shapley Value (SV) has recently become
an important tool in machine learning research. Perhaps most notably, it is
used for feature attribution and data valuation in explainable artificial
intelligence. Shapley Interactions (SIs) naturally extend the SV and address
its limitations by assigning joint contributions to groups of entities, which
enhance understanding of black box machine learning models. Due to the
exponential complexity of computing SVs and SIs, various methods have been
proposed that exploit structural assumptions or yield probabilistic estimates
given limited resources. In this work, we introduce shapiq, an open-source
Python package that unifies state-of-the-art algorithms to efficiently compute
SVs and any-order SIs in an application-agnostic framework. Moreover, it
includes a benchmarking suite containing 11 machine learning applications of
SIs with pre-computed games and ground-truth values to systematically assess
computational performance across domains. For practitioners, shapiq is able to
explain and visualize any-order feature interactions in predictions of models,
including vision transformers, language models, as well as XGBoost and LightGBM
with TreeSHAP-IQ. With shapiq, we extend shap beyond feature attributions and
consolidate the application of SVs and SIs in machine learning that facilitates
future research. The source code and documentation are available at
https://github.com/mmschlk/shapiq.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Stable Offline Value Function Learning with Bisimulation-based
  Representations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01643v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01643v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Brahma S. Pavse, Yudong Chen, Qiaomin Xie, Josiah P. Hanna
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In reinforcement learning, offline value function learning is the procedure
of using an offline dataset to estimate the expected discounted return from
each state when taking actions according to a fixed target policy. The
stability of this procedure, i.e., whether it converges to its fixed-point,
critically depends on the representations of the state-action pairs. Poorly
learned representations can make value function learning unstable, or even
divergent. Therefore, it is critical to stabilize value function learning by
explicitly shaping the state-action representations. Recently, the class of
bisimulation-based algorithms have shown promise in shaping representations for
control. However, it is still unclear if this class of methods can stabilize
value function learning. In this work, we investigate this question and answer
it affirmatively. We introduce a bisimulation-based algorithm called kernel
representations for offline policy evaluation (KROPE). KROPE uses a kernel to
shape state-action representations such that state-action pairs that have
similar immediate rewards and lead to similar next state-action pairs under the
target policy also have similar representations. We show that KROPE: 1) learns
stable representations and 2) leads to lower value error than baselines. Our
analysis provides new theoretical insight into the stability properties of
bisimulation-based methods and suggests that practitioners can use these
methods for stable and accurate evaluation of offline reinforcement learning
agents.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Moral Alignment for LLM Agents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01639v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01639v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elizaveta Tennant, Stephen Hailes, Mirco Musolesi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Decision-making agents based on pre-trained Large Language Models (LLMs) are
increasingly being deployed across various domains of human activity. While
their applications are currently rather specialized, several research efforts
are under way to develop more generalist agents. As LLM-based systems become
more agentic, their influence on human activity will grow and the transparency
of this will decrease. Consequently, developing effective methods for aligning
them to human values is vital.
  The prevailing practice in alignment often relies on human preference data
(e.g., in RLHF or DPO), in which values are implicit and are essentially
deduced from relative preferences over different model outputs. In this work,
instead of relying on human feedback, we introduce the design of reward
functions that explicitly encode core human values for Reinforcement
Learning-based fine-tuning of foundation agent models. Specifically, we use
intrinsic rewards for the moral alignment of LLM agents.
  We evaluate our approach using the traditional philosophical frameworks of
Deontological Ethics and Utilitarianism, quantifying moral rewards for agents
in terms of actions and consequences on the Iterated Prisoner's Dilemma (IPD)
environment. We also show how moral fine-tuning can be deployed to enable an
agent to unlearn a previously developed selfish strategy. Finally, we find that
certain moral strategies learned on the IPD game generalize to several other
matrix game environments. In summary, we demonstrate that fine-tuning with
intrinsic rewards is a promising general solution for aligning LLM agents to
human values, and it might represent a more transparent and cost-effective
alternative to currently predominant alignment techniques.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Data Extrapolation for Text-to-image Generation on Small <span class="highlight-title">Dataset</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01638v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01638v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Senmao Ye, Fei Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-image generation requires large amount of training data to
synthesizing high-quality images. For augmenting training data, previous
methods rely on data interpolations like cropping, flipping, and mixing up,
which fail to introduce new information and yield only marginal improvements.
In this paper, we propose a new data augmentation method for text-to-image
generation using linear extrapolation. Specifically, we apply linear
extrapolation only on text feature, and new image data are retrieved from the
internet by search engines. For the reliability of new text-image pairs, we
design two outlier detectors to purify retrieved images. Based on
extrapolation, we construct training samples dozens of times larger than the
original dataset, resulting in a significant improvement in text-to-image
performance. Moreover, we propose a NULL-guidance to refine score estimation,
and apply recurrent affine transformation to fuse text information. Our model
achieves FID scores of 7.91, 9.52 and 5.00 on the CUB, Oxford and COCO
datasets. The code and data will be available on GitHub
(https://github.com/senmaoy/RAT-Diffusion).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Does Graph <span class="highlight-title">Prompt</span> Work? A Data Operation Perspective with Theoretical
  Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01635v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01635v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qunzhong Wang, Xiangguo Sun, Hong Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, graph prompting has emerged as a promising research
direction, enabling the learning of additional tokens or subgraphs appended to
the original graphs without requiring retraining of pre-trained graph models
across various applications. This novel paradigm, shifting from the traditional
pretraining and finetuning to pretraining and prompting has shown significant
empirical success in simulating graph data operations, with applications
ranging from recommendation systems to biological networks and graph
transferring. However, despite its potential, the theoretical underpinnings of
graph prompting remain underexplored, raising critical questions about its
fundamental effectiveness. The lack of rigorous theoretical proof of why and
how much it works is more like a dark cloud over the graph prompt area to go
further. To fill this gap, this paper introduces a theoretical framework that
rigorously analyzes graph prompting from a data operation perspective. Our
contributions are threefold: First, we provide a formal guarantee theorem,
demonstrating graph prompts capacity to approximate graph transformation
operators, effectively linking upstream and downstream tasks. Second, we derive
upper bounds on the error of these data operations by graph prompts for a
single graph and extend this discussion to batches of graphs, which are common
in graph model training. Third, we analyze the distribution of data operation
errors, extending our theoretical findings from linear graph models (e.g., GCN)
to non-linear graph models (e.g., GAT). Extensive experiments support our
theoretical results and confirm the practical implications of these guarantees.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Entropy-Based Uncertainty Modeling for Trajectory Prediction in
  Autonomous Driving 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01628v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01628v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aron Distelzweig, Andreas Look, Eitan Kosman, Faris Janjoš, Jörg Wagner, Abhinav Valadaa
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In autonomous driving, accurate motion prediction is essential for safe and
efficient motion planning. To ensure safety, planners must rely on reliable
uncertainty information about the predicted future behavior of surrounding
agents, yet this aspect has received limited attention. This paper addresses
the so-far neglected problem of uncertainty modeling in trajectory prediction.
We adopt a holistic approach that focuses on uncertainty quantification,
decomposition, and the influence of model composition. Our method is based on a
theoretically grounded information-theoretic approach to measure uncertainty,
allowing us to decompose total uncertainty into its aleatoric and epistemic
components. We conduct extensive experiments on the nuScenes dataset to assess
how different model architectures and configurations affect uncertainty
quantification and model robustness.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 5 figures, submitted to International Conference on
  Learning Representations (2025)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fira: Can We Achieve Full-rank Training of LLMs Under Low-rank
  Constraint? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01623v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01623v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xi Chen, Kaituo Feng, Changsheng Li, Xunhao Lai, Xiangyu Yue, Ye Yuan, Guoren Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low-rank training has emerged as a promising approach for reducing memory
usage in training Large Language Models (LLMs). Previous methods either rely on
decomposing weight matrices (e.g., LoRA), or seek to decompose gradient
matrices (e.g., GaLore) to ensure reduced memory consumption. However, both of
them constrain the training in a low-rank subspace, thus inevitably leading to
sub-optimal performance. This raises a question: whether it is possible to
consistently preserve the low-rank constraint for memory efficiency, while
achieving full-rank training (i.e., training with full-rank gradients of
full-rank weights) to avoid inferior outcomes? In this paper, we propose a new
plug-and-play training framework for LLMs called Fira, as the first attempt to
achieve this goal. First, we observe an interesting phenomenon during LLM
training: the scaling impact of adaptive optimizers (e.g., Adam) on the
gradient norm remains similar from low-rank to full-rank training. Based on
this observation, we propose a norm-based scaling method, which utilizes the
scaling impact of low-rank optimizers as substitutes for that of original
full-rank optimizers to enable full-rank training. In this way, we can preserve
the low-rank constraint in the optimizer while achieving full-rank training for
better performance. Moreover, we find that there are sudden gradient rises
during the optimization process, potentially causing loss spikes. To address
this, we further put forward a norm-growth limiter to smooth the gradient via
regulating the relative increase of gradient norms. Extensive experiments on
the pre-training and fine-tuning of LLMs show that Fira outperforms both LoRA
and GaLore, achieving performance that is comparable to or even better than
full-rank training.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code is available at: https://github.com/xichen-fy/Fira</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DRUPI: <span class="highlight-title">Dataset</span> Reduction Using Privileged Information 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01611v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01611v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shaobo Wang, Yantai Yang, Shuaiyu Zhang, Chenghao Sun, Weiya Li, Xuming Hu, Linfeng Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dataset reduction (DR) seeks to select or distill samples from large datasets
into smaller subsets while preserving performance on target tasks. Existing
methods primarily focus on pruning or synthesizing data in the same format as
the original dataset, typically the input data and corresponding labels.
However, in DR settings, we find it is possible to synthesize more information
beyond the data-label pair as an additional learning target to facilitate model
training. In this paper, we introduce Dataset Reduction Using Privileged
Information (DRUPI), which enriches DR by synthesizing privileged information
alongside the reduced dataset. This privileged information can take the form of
feature labels or attention labels, providing auxiliary supervision to improve
model learning. Our findings reveal that effective feature labels must balance
between being overly discriminative and excessively diverse, with a moderate
level proving optimal for improving the reduced dataset's efficacy. Extensive
experiments on ImageNet, CIFAR-10/100, and Tiny ImageNet demonstrate that DRUPI
integrates seamlessly with existing dataset reduction methods, offering
significant performance gains.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Upcycling Instruction Tuning from Dense to Mixture-of-Experts via
  Parameter Merging 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01610v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01610v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tingfeng Hui, Zhenyu Zhang, Shuohuan Wang, Yu Sun, Hua Wu, Sen Su
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mixture-of-Experts (MoE) shines brightly in large language models (LLMs) and
demonstrates outstanding performance in plentiful natural language processing
tasks. However, existing methods transforming LLMs from dense to MoE face
significant data requirements and typically rely on large-scale post-training.
In this paper, we propose Upcycling Instruction Tuning (UpIT), a data-efficient
approach for tuning a dense pre-trained model into a MoE instruction model.
Specifically, we first point out that intermediate checkpoints during
instruction tuning of the dense model are naturally suitable for specialized
experts, and then propose an expert expansion stage to flexibly achieve models
with flexible numbers of experts, where genetic algorithm and parameter merging
are introduced to ensure sufficient diversity of new extended experts. To
ensure that each specialized expert in the MoE model works as expected, we
select a small amount of seed data that each expert excels to pre-optimize the
router. Extensive experiments with various data scales and upcycling settings
demonstrate the outstanding performance and data efficiency of UpIT, as well as
stable improvement in expert or data scaling. Further analysis reveals the
importance of ensuring expert diversity in upcycling.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Automated Red Teaming with GOAT: the Generative Offensive Agent Tester 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01606v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01606v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maya Pavlova, Erik Brinkman, Krithika Iyer, Vitor Albiero, Joanna Bitton, Hailey Nguyen, Joe Li, Cristian Canton Ferrer, Ivan Evtimov, Aaron Grattafiori
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Red teaming assesses how large language models (LLMs) can produce content
that violates norms, policies, and rules set during their safety training.
However, most existing automated methods in the literature are not
representative of the way humans tend to interact with AI models. Common users
of AI models may not have advanced knowledge of adversarial machine learning
methods or access to model internals, and they do not spend a lot of time
crafting a single highly effective adversarial prompt. Instead, they are likely
to make use of techniques commonly shared online and exploit the multiturn
conversational nature of LLMs. While manual testing addresses this gap, it is
an inefficient and often expensive process. To address these limitations, we
introduce the Generative Offensive Agent Tester (GOAT), an automated agentic
red teaming system that simulates plain language adversarial conversations
while leveraging multiple adversarial prompting techniques to identify
vulnerabilities in LLMs. We instantiate GOAT with 7 red teaming attacks by
prompting a general-purpose model in a way that encourages reasoning through
the choices of methods available, the current target model's response, and the
next steps. Our approach is designed to be extensible and efficient, allowing
human testers to focus on exploring new areas of risk while automation covers
the scaled adversarial stress-testing of known risk territory. We present the
design and evaluation of GOAT, demonstrating its effectiveness in identifying
vulnerabilities in state-of-the-art LLMs, with an ASR@10 of 97% against Llama
3.1 and 88% against GPT-4 on the JailbreakBench dataset.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Elaborative Subtopic Query Reformulation for Broad and Indirect Queries
  in Travel Destination Recommendation <span class="chip">RecSys 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01598v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01598v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qianfeng Wen, Yifan Liu, Joshua Zhang, George Saad, Anton Korikov, Yury Sambale, Scott Sanner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In Query-driven Travel Recommender Systems (RSs), it is crucial to understand
the user intent behind challenging natural language(NL) destination queries
such as the broadly worded "youth-friendly activities" or the indirect
description "a high school graduation trip". Such queries are challenging due
to the wide scope and subtlety of potential user intents that confound the
ability of retrieval methods to infer relevant destinations from available
textual descriptions such as WikiVoyage. While query reformulation (QR) has
proven effective in enhancing retrieval by addressing user intent, existing QR
methods tend to focus only on expanding the range of potentially matching query
subtopics (breadth) or elaborating on the potential meaning of a query (depth),
but not both. In this paper, we introduce Elaborative Subtopic Query
Reformulation (EQR), a large language model-based QR method that combines both
breadth and depth by generating potential query subtopics with information-rich
elaborations. We also release TravelDest, a novel dataset for query-driven
travel destination RSs. Experiments on TravelDest show that EQR achieves
significant improvements in recall and precision over existing state-of-the-art
QR methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 7 figures,The 1st Workshop on Risks, Opportunities, and
  Evaluation of Generative Models in Recommender Systems (ROEGEN@RecSys 2024),
  October 2024, Bari, Italy</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ KnobGen: Controlling the Sophistication of Artwork in Sketch-Based
  Diffusion Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01595v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01595v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pouyan Navard, Amin Karimi Monsefi, Mengxi Zhou, Wei-Lun Chao, Alper Yilmaz, Rajiv Ramnath
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in diffusion models have significantly improved text-to-image
(T2I) generation, but they often struggle to balance fine-grained precision
with high-level control. Methods like ControlNet and T2I-Adapter excel at
following sketches by seasoned artists but tend to be overly rigid, replicating
unintentional flaws in sketches from novice users. Meanwhile, coarse-grained
methods, such as sketch-based abstraction frameworks, offer more accessible
input handling but lack the precise control needed for detailed, professional
use. To address these limitations, we propose KnobGen, a dual-pathway framework
that democratizes sketch-based image generation by seamlessly adapting to
varying levels of sketch complexity and user skill. KnobGen uses a
Coarse-Grained Controller (CGC) module for high-level semantics and a
Fine-Grained Controller (FGC) module for detailed refinement. The relative
strength of these two modules can be adjusted through our knob inference
mechanism to align with the user's specific needs. These mechanisms ensure that
KnobGen can flexibly generate images from both novice sketches and those drawn
by seasoned artists. This maintains control over the final output while
preserving the natural appearance of the image, as evidenced on the
MultiGen-20M dataset and a newly collected sketch dataset.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Imaging foundation model for universal enhancement of non-ideal
  measurement CT 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01591v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01591v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxin Liu, Rongjun Ge, Yuting He, Zhan Wu, Chenyu You, Shuo Li, Yang Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Non-ideal measurement computed tomography (NICT), which sacrifices optimal
imaging standards for new advantages in CT imaging, is expanding the clinical
application scope of CT images. However, with the reduction of imaging
standards, the image quality has also been reduced, extremely limiting the
clinical acceptability. Although numerous studies have demonstrated the
feasibility of deep learning for the NICT enhancement in specific scenarios,
their high data cost and limited generalizability have become large obstacles.
The recent research on the foundation model has brought new opportunities for
building a universal NICT enhancement model - bridging the image quality
degradation with minimal data cost. However, owing to the challenges in the
collection of large pre-training datasets and the compatibility of data
variation, no success has been reported. In this paper, we propose a
multi-scale integrated Transformer AMPlifier (TAMP), the first imaging
foundation model for universal NICT enhancement. It has been pre-trained on a
large-scale physical-driven simulation dataset with 3.6 million NICT-ICT image
pairs, and is able to directly generalize to the NICT enhancement tasks with
various non-ideal settings and body regions. Via the adaptation with few data,
it can further achieve professional performance in real-world specific
scenarios. Our extensive experiments have demonstrated that the proposed TAMP
has significant potential for promoting the exploration and application of NICT
and serving a wider range of medical scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Iterated Local Search with Linkage Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01583v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01583v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Renato Tinós, Michal W. Przewozniczek, Darrell Whitley, Francisco Chicano
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In pseudo-Boolean optimization, a variable interaction graph represents
variables as vertices, and interactions between pairs of variables as edges. In
black-box optimization, the variable interaction graph may be at least
partially discovered by using empirical linkage learning techniques. These
methods never report false variable interactions, but they are computationally
expensive. The recently proposed local search with linkage learning discovers
the partial variable interaction graph as a side-effect of iterated local
search. However, information about the strength of the interactions is not
learned by the algorithm. We propose local search with linkage learning 2,
which builds a weighted variable interaction graph that stores information
about the strength of the interaction between variables. The weighted variable
interaction graph can provide new insights about the optimization problem and
behavior of optimizers. Experiments with NK landscapes, knapsack problem, and
feature selection show that local search with linkage learning 2 is able to
efficiently build weighted variable interaction graphs. In particular,
experiments with feature selection show that the weighted variable interaction
graphs can be used for visualizing the feature interactions in machine
learning. Additionally, new transformation operators that exploit the
interactions between variables can be designed. We illustrate this ability by
proposing a new perturbation operator for iterated local search.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Spoken Grammar Assessment Using LLM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01579v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01579v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sunil Kumar Kopparapu, Chitralekha Bhat, Ashish Panda
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spoken language assessment (SLA) systems restrict themselves to evaluating
the pronunciation and oral fluency of a speaker by analysing the read and
spontaneous spoken utterances respectively. The assessment of language grammar
or vocabulary is relegated to written language assessment (WLA) systems. Most
WLA systems present a set of sentences from a curated finite-size database of
sentences thereby making it possible to anticipate the test questions and train
oneself. In this paper, we propose a novel end-to-end SLA system to assess
language grammar from spoken utterances thus making WLA systems redundant;
additionally, we make the assessment largely unteachable by employing a large
language model (LLM) to bring in variations in the test. We further demonstrate
that a hybrid automatic speech recognition (ASR) with a custom-built language
model outperforms the state-of-the-art ASR engine for spoken grammar
assessment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Computing Ex Ante Equilibrium in Heterogeneous Zero-Sum Team Games 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01575v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01575v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Naming Liu, Mingzhi Wang, Xihuai Wang, Weinan Zhang, Yaodong Yang, Youzhi Zhang, Bo An, Ying Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The ex ante equilibrium for two-team zero-sum games, where agents within each
team collaborate to compete against the opposing team, is known to be the best
a team can do for coordination. Many existing works on ex ante equilibrium
solutions are aiming to extend the scope of ex ante equilibrium solving to
large-scale team games based on Policy Space Response Oracle (PSRO). However,
the joint team policy space constructed by the most prominent method, Team
PSRO, cannot cover the entire team policy space in heterogeneous team games
where teammates play distinct roles. Such insufficient policy expressiveness
causes Team PSRO to be trapped into a sub-optimal ex ante equilibrium with
significantly higher exploitability and never converges to the global ex ante
equilibrium. To find the global ex ante equilibrium without introducing
additional computational complexity, we first parameterize heterogeneous
policies for teammates, and we prove that optimizing the heterogeneous
teammates' policies sequentially can guarantee a monotonic improvement in team
rewards. We further propose Heterogeneous-PSRO (H-PSRO), a novel framework for
heterogeneous team games, which integrates the sequential correlation mechanism
into the PSRO framework and serves as the first PSRO framework for
heterogeneous team games. We prove that H-PSRO achieves lower exploitability
than Team PSRO in heterogeneous team games. Empirically, H-PSRO achieves
convergence in matrix heterogeneous games that are unsolvable by
non-heterogeneous baselines. Further experiments reveal that H-PSRO outperforms
non-heterogeneous baselines in both heterogeneous team games and homogeneous
settings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ OpenMathInstruct-2: Accelerating AI for Math with Massive Open-Source
  Instruction Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01560v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01560v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shubham Toshniwal, Wei Du, Ivan Moshkov, Branislav Kisacanin, Alexan Ayrapetyan, Igor Gitman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mathematical reasoning continues to be a critical challenge in large language
model (LLM) development with significant interest. However, most of the
cutting-edge progress in mathematical reasoning with LLMs has become
\emph{closed-source} due to lack of access to training data. This lack of data
access limits researchers from understanding the impact of different choices
for synthesizing and utilizing the data. With the goal of creating a
high-quality finetuning (SFT) dataset for math reasoning, we conduct careful
ablation experiments on data synthesis using the recently released
\texttt{Llama3.1} family of models. Our experiments show that: (a) solution
format matters, with excessively verbose solutions proving detrimental to SFT
performance, (b) data generated by a strong teacher outperforms
\emph{on-policy} data generated by a weak student model, (c) SFT is robust to
low-quality solutions, allowing for imprecise data filtering, and (d) question
diversity is crucial for achieving data scaling gains. Based on these insights,
we create the OpenMathInstruct-2 dataset, which consists of 14M
question-solution pairs ($\approx$ 600K unique questions), making it nearly
eight times larger than the previous largest open-source math reasoning
dataset. Finetuning the \texttt{Llama-3.1-8B-Base} using OpenMathInstruct-2
outperforms \texttt{Llama3.1-8B-Instruct} on MATH by an absolute 15.9\% (51.9\%
$\rightarrow$ 67.8\%). Finally, to accelerate the open-source efforts, we
release the code, the finetuned models, and the OpenMathInstruct-2 dataset
under a commercially permissive license.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Integrative Decoding: Improve Factuality via Implicit Self-consistency 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01556v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01556v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi Cheng, Xiao Liang, Yeyun Gong, Wen Xiao, Song Wang, Yuji Zhang, Wenjun Hou, Kaishuai Xu, Wenge Liu, Wenjie Li, Jian Jiao, Qi Chen, Peng Cheng, Wayne Xiong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Self-consistency-based approaches, which involve repeatedly sampling multiple
outputs and selecting the most consistent one as the final response, prove to
be remarkably effective in improving the factual accuracy of large language
models. Nonetheless, existing methods usually have strict constraints on the
task format, largely limiting their applicability. In this paper, we present
Integrative Decoding (ID), to unlock the potential of self-consistency in
open-ended generation tasks. ID operates by constructing a set of inputs, each
prepended with a previously sampled response, and then processes them
concurrently, with the next token being selected by aggregating of all their
corresponding predictions at each decoding step. In essence, this simple
approach implicitly incorporates self-consistency in the decoding objective.
Extensive evaluation shows that ID consistently enhances factuality over a wide
range of language models, with substantial improvements on the TruthfulQA
(+11.2%), Biographies (+15.4%) and LongFact (+8.5%) benchmarks. The performance
gains amplify progressively as the number of sampled responses increases,
indicating the potential of ID to scale up with repeated sampling.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MedQA-CS: Benchmarking Large Language Models Clinical Skills Using an
  AI-SCE Framework 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01553v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01553v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zonghai Yao, Zihao Zhang, Chaolong Tang, Xingyu Bian, Youxia Zhao, Zhichao Yang, Junda Wang, Huixue Zhou, Won Seok Jang, Feiyun Ouyang, Hong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Artificial intelligence (AI) and large language models (LLMs) in healthcare
require advanced clinical skills (CS), yet current benchmarks fail to evaluate
these comprehensively. We introduce MedQA-CS, an AI-SCE framework inspired by
medical education's Objective Structured Clinical Examinations (OSCEs), to
address this gap. MedQA-CS evaluates LLMs through two instruction-following
tasks, LLM-as-medical-student and LLM-as-CS-examiner, designed to reflect real
clinical scenarios. Our contributions include developing MedQA-CS, a
comprehensive evaluation framework with publicly available data and expert
annotations, and providing the quantitative and qualitative assessment of LLMs
as reliable judges in CS evaluation. Our experiments show that MedQA-CS is a
more challenging benchmark for evaluating clinical skills than traditional
multiple-choice QA benchmarks (e.g., MedQA). Combined with existing benchmarks,
MedQA-CS enables a more comprehensive evaluation of LLMs' clinical capabilities
for both open- and closed-source LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Edge-preserving noise for diffusion models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01540v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01540v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jente Vandersanden, Sascha Holl, Xingchang Huang, Gurprit Singh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Classical generative diffusion models learn an isotropic Gaussian denoising
process, treating all spatial regions uniformly, thus neglecting potentially
valuable structural information in the data. Inspired by the long-established
work on anisotropic diffusion in image processing, we present a novel
edge-preserving diffusion model that is a generalization of denoising diffusion
probablistic models (DDPM). In particular, we introduce an edge-aware noise
scheduler that varies between edge-preserving and isotropic Gaussian noise. We
show that our model's generative process converges faster to results that more
closely match the target distribution. We demonstrate its capability to better
learn the low-to-mid frequencies within the dataset, which plays a crucial role
in representing shapes and structural information. Our edge-preserving
diffusion process consistently outperforms state-of-the-art baselines in
unconditional image generation. It is also more robust for generative tasks
guided by a shape-based prior, such as stroke-to-image generation. We present
qualitative and quantitative results showing consistent improvements (FID
score) of up to 30% for both tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Seeing Eye to AI: Human Alignment via Gaze-Based Response Rewards for
  Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01532v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01532v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Angela Lopez-Cardona, Carlos Segura, Alexandros Karatzoglou, Sergi Abadal, Ioannis Arapakis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Advancements in Natural Language Processing (NLP), have led to the emergence
of Large Language Models (LLMs) such as GPT, Llama, Claude, and Gemini, which
excel across a range of tasks but require extensive fine-tuning to align their
outputs with human expectations. A widely used method for achieving this
alignment is Reinforcement Learning from Human Feedback (RLHF), which, despite
its success, faces challenges in accurately modelling human preferences. In
this paper, we introduce GazeReward, a novel framework that integrates implicit
feedback -- and specifically eye-tracking (ET) data -- into the Reward Model
(RM). In addition, we explore how ET-based features can provide insights into
user preferences. Through ablation studies we test our framework with different
integration methods, LLMs, and ET generator models, demonstrating that our
approach significantly improves the accuracy of the RM on established human
preference datasets. This work advances the ongoing discussion on optimizing AI
alignment with human values, exploring the potential of cognitive data for
shaping future NLP research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TiVaT: Joint-Axis Attention for Time Series Forecasting with Lead-Lag
  Dynamics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01531v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01531v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junwoo Ha, Hyukjae Kwon, Sungsoo Kim, Kisu Lee, Ha Young Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multivariate time series (MTS) forecasting plays a crucial role in various
real-world applications, yet simultaneously capturing both temporal and
inter-variable dependencies remains a challenge. Conventional Channel-Dependent
(CD) models handle these dependencies separately, limiting their ability to
model complex interactions such as lead-lag dynamics. To address these
limitations, we propose TiVaT (Time-Variable Transformer), a novel architecture
that integrates temporal and variate dependencies through its Joint-Axis (JA)
attention mechanism. TiVaT's ability to capture intricate variate-temporal
dependencies, including asynchronous interactions, is further enhanced by the
incorporation of Distance-aware Time-Variable (DTV) Sampling, which reduces
noise and improves accuracy through a learned 2D map that focuses on key
interactions. TiVaT effectively models both temporal and variate dependencies,
consistently delivering strong performance across diverse datasets. Notably, it
excels in capturing complex patterns within multivariate time series, enabling
it to surpass or remain competitive with state-of-the-art methods. This
positions TiVaT as a new benchmark in MTS forecasting, particularly in handling
datasets characterized by intricate and challenging dependencies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ InstaTrans: An Instruction-Aware Translation Framework for Non-English
  Instruction <span class="highlight-title">Dataset</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01512v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01512v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yungi Kim, Chanjun Park
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  It is challenging to generate high-quality instruction datasets for
non-English languages due to tail phenomena, which limit performance on less
frequently observed data. To mitigate this issue, we propose translating
existing high-quality English instruction datasets as a solution, emphasizing
the need for complete and instruction-aware translations to maintain the
inherent attributes of these datasets. We claim that fine-tuning LLMs with
datasets translated in this way can improve their performance in the target
language. To this end, we introduces a new translation framework tailored for
instruction datasets, named InstaTrans (INSTruction-Aware TRANSlation). Through
extensive experiments, we demonstrate the superiority of InstaTrans over other
competitors in terms of completeness and instruction-awareness of translation,
highlighting its potential to broaden the accessibility of LLMs across diverse
languages at a relatively low cost. Furthermore, we have validated that
fine-tuning LLMs with datasets translated by InstaTrans can effectively improve
their performance in the target language.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LEGO: Learnable Expansion of Graph Operators for Multi-Modal Feature
  Fusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01506v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01506v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dexuan Ding, Lei Wang, Liyun Zhu, Tom Gedeon, Piotr Koniusz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In computer vision tasks, features often come from diverse representations,
domains, and modalities, such as text, images, and videos. Effectively fusing
these features is essential for robust performance, especially with the
availability of powerful pre-trained models like vision-language models.
However, common fusion methods, such as concatenation, element-wise operations,
and non-linear techniques, often fail to capture structural relationships, deep
feature interactions, and suffer from inefficiency or misalignment of features
across domains. In this paper, we shift from high-dimensional feature space to
a lower-dimensional, interpretable graph space by constructing similarity
graphs that encode feature relationships at different levels, e.g., clip,
frame, patch, token, etc. To capture deeper interactions, we use graph power
expansions and introduce a learnable graph fusion operator to combine these
graph powers for more effective fusion. Our approach is relationship-centric,
operates in a homogeneous space, and is mathematically principled, resembling
element-wise similarity score aggregation via multilinear polynomials. We
demonstrate the effectiveness of our graph-based fusion method on video anomaly
detection, showing strong performance across multi-representational,
multi-modal, and multi-domain feature fusion tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Research paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Discrete Diffusion Schrödinger Bridge Matching for Graph
  Transformation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01500v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01500v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jun Hyeong Kim, Seonghwan Kim, Seokhyun Moon, Hyeongwoo Kim, Jeheon Woo, Woo Youn Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transporting between arbitrary distributions is a fundamental goal in
generative modeling. Recently proposed diffusion bridge models provide a
potential solution, but they rely on a joint distribution that is difficult to
obtain in practice. Furthermore, formulations based on continuous domains limit
their applicability to discrete domains such as graphs. To overcome these
limitations, we propose Discrete Diffusion Schr\"odinger Bridge Matching
(DDSBM), a novel framework that utilizes continuous-time Markov chains to solve
the SB problem in a high-dimensional discrete state space. Our approach extends
Iterative Markovian Fitting to discrete domains, and we have proved its
convergence to the SB. Furthermore, we adapt our framework for the graph
transformation and show that our design choice of underlying dynamics
characterized by independent modifications of nodes and edges can be
interpreted as the entropy-regularized version of optimal transport with a cost
function described by the graph edit distance. To demonstrate the effectiveness
of our framework, we have applied DDSBM to molecular optimization in the field
of chemistry. Experimental results demonstrate that DDSBM effectively optimizes
molecules' property-of-interest with minimal graph transformation, successfully
retaining other features.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DLP-LoRA: Efficient Task-Specific LoRA Fusion with a Dynamic,
  Lightweight Plugin for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01497v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01497v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxuan Zhang, Ruizhe Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in Large Language Models (LLMs) have achieved robust
performance across diverse tasks, but fine-tuning these models for specific
domains remains resource-intensive. Parameter-Efficient Fine-Tuning (PEFT)
methods like Low-Rank Adaptation (LoRA) address this challenge by fine-tuning a
small subset of parameters. However, existing methods for fusing multiple LoRAs
lack dynamic fusion based on contextual inputs and often increase inference
time due to token-level operations. We propose DLP-LoRA, a Dynamic Lightweight
Plugin that employs a mini-MLP module with only 5M parameters to dynamically
fuse multiple LoRAs at the sentence level using top-p sampling strategies. This
approach reduces inference time to less than twice that of single LoRA
inference by leveraging parallel computation. Evaluations across 26
tasks-including multiple-choice questions and question answering-demonstrate
that DLP-LoRA achieves an average accuracy of 92.34% on multiple-choice
datasets and significant improvements in BLEU and ROUGE scores on QA datasets,
outperforming different LLMs backbones under composite task settings. DLP-LoRA
effectively balances performance and efficiency, making it a practical solution
for dynamic multi-task adaptation in LLMs. Our code is available at
https://github.com/MeCuping/DLP-LoRA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint under review, 18 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ One Wave to Explain Them All: A Unifying Perspective on Post-hoc
  Explainability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01482v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01482v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gabriel Kasmi, Amandine Brunetto, Thomas Fel, Jayneel Parekh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the growing use of deep neural networks in safety-critical
decision-making, their inherent black-box nature hinders transparency and
interpretability. Explainable AI (XAI) methods have thus emerged to understand
a model's internal workings, and notably attribution methods also called
saliency maps. Conventional attribution methods typically identify the
locations -- the where -- of significant regions within an input. However,
because they overlook the inherent structure of the input data, these methods
often fail to interpret what these regions represent in terms of structural
components (e.g., textures in images or transients in sounds). Furthermore,
existing methods are usually tailored to a single data modality, limiting their
generalizability. In this paper, we propose leveraging the wavelet domain as a
robust mathematical foundation for attribution. Our approach, the Wavelet
Attribution Method (WAM) extends the existing gradient-based feature
attributions into the wavelet domain, providing a unified framework for
explaining classifiers across images, audio, and 3D shapes. Empirical
evaluations demonstrate that WAM matches or surpasses state-of-the-art methods
across faithfulness metrics and models in image, audio, and 3D explainability.
Finally, we show how our method explains not only the where -- the important
parts of the input -- but also the what -- the relevant patterns in terms of
structural components.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>main: 10 pages, appendix: 14 pages, 5 Tables, 25 Figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SonicSim: A customizable simulation platform for speech processing in
  moving sound source scenarios 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01481v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01481v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kai Li, Wendi Sang, Chang Zeng, Runxuan Yang, Guo Chen, Xiaolin Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The systematic evaluation of speech separation and enhancement models under
moving sound source conditions typically requires extensive data comprising
diverse scenarios. However, real-world datasets often contain insufficient data
to meet the training and evaluation requirements of models. Although synthetic
datasets offer a larger volume of data, their acoustic simulations lack
realism. Consequently, neither real-world nor synthetic datasets effectively
fulfill practical needs. To address these issues, we introduce SonicSim, a
synthetic toolkit de-designed to generate highly customizable data for moving
sound sources. SonicSim is developed based on the embodied AI simulation
platform, Habitat-sim, supporting multi-level adjustments, including
scene-level, microphone-level, and source-level, thereby generating more
diverse synthetic data. Leveraging SonicSim, we constructed a moving sound
source benchmark dataset, SonicSet, using the Librispeech, the Freesound
Dataset 50k (FSD50K) and Free Music Archive (FMA), and 90 scenes from the
Matterport3D to evaluate speech separation and enhancement models.
Additionally, to validate the differences between synthetic data and real-world
data, we randomly selected 5 hours of raw data without reverberation from the
SonicSet validation set to record a real-world speech separation dataset, which
was then compared with the corresponding synthetic datasets. Similarly, we
utilized the real-world speech enhancement dataset RealMAN to validate the
acoustic gap between other synthetic datasets and the SonicSet dataset for
speech enhancement. The results indicate that the synthetic data generated by
SonicSim can effectively generalize to real-world scenarios. Demo and code are
publicly available at https://cslikai.cn/SonicSim/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical report</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Peeling Back the Layers: An In-Depth Evaluation of Encoder Architectures
  in Neural News Recommenders <span class="chip">RecSys 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01470v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01470v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andreea Iana, Goran Glavaš, Heiko Paulheim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Encoder architectures play a pivotal role in neural news recommenders by
embedding the semantic and contextual information of news and users. Thus,
research has heavily focused on enhancing the representational capabilities of
news and user encoders to improve recommender performance. Despite the
significant impact of encoder architectures on the quality of news and user
representations, existing analyses of encoder designs focus only on the overall
downstream recommendation performance. This offers a one-sided assessment of
the encoders' similarity, ignoring more nuanced differences in their behavior,
and potentially resulting in sub-optimal model selection. In this work, we
perform a comprehensive analysis of encoder architectures in neural news
recommender systems. We systematically evaluate the most prominent news and
user encoder architectures, focusing on their (i) representational similarity,
measured with the Central Kernel Alignment, (ii) overlap of generated
recommendation lists, quantified with the Jaccard similarity, and (iii) the
overall recommendation performance. Our analysis reveals that the complexity of
certain encoding techniques is often empirically unjustified, highlighting the
potential for simpler, more efficient architectures. By isolating the effects
of individual components, we provide valuable insights for researchers and
practitioners to make better informed decisions about encoder selection and
avoid unnecessary complexity in the design of news recommenders.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at the 12th International Workshop on News Recommendation
  and Analytics (INRA 2024) in conjunction with ACM RecSys 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TIGER: Time-frequency Interleaved Gain Extraction and Reconstruction for
  Efficient Speech Separation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01469v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01469v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohan Xu, Kai Li, Guo Chen, Xiaolin Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, much speech separation research has focused primarily on
improving model performance. However, for low-latency speech processing
systems, high efficiency is equally important. Therefore, we propose a speech
separation model with significantly reduced parameters and computational costs:
Time-frequency Interleaved Gain Extraction and Reconstruction network (TIGER).
TIGER leverages prior knowledge to divide frequency bands and compresses
frequency information. We employ a multi-scale selective attention module to
extract contextual features, while introducing a full-frequency-frame attention
module to capture both temporal and frequency contextual information.
Additionally, to more realistically evaluate the performance of speech
separation models in complex acoustic environments, we introduce a dataset
called EchoSet. This dataset includes noise and more realistic reverberation
(e.g., considering object occlusions and material properties), with speech from
two speakers overlapping at random proportions. Experimental results showed
that models trained on EchoSet had better generalization ability than those
trained on other datasets to the data collected in the physical world, which
validated the practical value of the EchoSet. On EchoSet and real-world data,
TIGER significantly reduces the number of parameters by 94.3% and the MACs by
95.3% while achieving performance surpassing state-of-the-art (SOTA) model
TF-GridNet. This is the first speech separation model with fewer than 1 million
parameters that achieves performance comparable to the SOTA model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical report, demo page: https://cslikai.cn/TIGER/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ From Reward Shaping to Q-Shaping: Achieving Unbiased Learning with
  LLM-Guided Knowledge 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01458v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01458v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiefeng Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Q-shaping is an extension of Q-value initialization and serves as an
alternative to reward shaping for incorporating domain knowledge to accelerate
agent training, thereby improving sample efficiency by directly shaping
Q-values. This approach is both general and robust across diverse tasks,
allowing for immediate impact assessment while guaranteeing optimality. We
evaluated Q-shaping across 20 different environments using a large language
model (LLM) as the heuristic provider. The results demonstrate that Q-shaping
significantly enhances sample efficiency, achieving a \textbf{16.87\%}
improvement over the best baseline in each environment and a \textbf{253.80\%}
improvement compared to LLM-based reward shaping methods. These findings
establish Q-shaping as a superior and unbiased alternative to conventional
reward shaping in reinforcement learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>q-shaping, reinforcement learning, reward shaping</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Agent-Driven Large Language Models for Mandarin Lyric Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01450v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01450v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hong-Hsiang Liu, Yi-Wen Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative Large Language Models have shown impressive in-context learning
abilities, performing well across various tasks with just a prompt. Previous
melody-to-lyric research has been limited by scarce high-quality aligned data
and unclear standard for creativeness. Most efforts focused on general themes
or emotions, which are less valuable given current language model capabilities.
In tonal contour languages like Mandarin, pitch contours are influenced by both
melody and tone, leading to variations in lyric-melody fit. Our study,
validated by the Mpop600 dataset, confirms that lyricists and melody writers
consider this fit during their composition process. In this research, we
developed a multi-agent system that decomposes the melody-to-lyric task into
sub-tasks, with each agent controlling rhyme, syllable count, lyric-melody
alignment, and consistency. Listening tests were conducted via a
diffusion-based singing voice synthesizer to evaluate the quality of lyrics
generated by different agent groups.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, figures, Accepted at O-COCOSDA 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         <span class="highlight-title">★</span> Geometric Signatures of Compositionality Across a Language Model's
  Lifetime <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01444v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01444v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jin Hwa Lee, Thomas Jiralerspong, Lei Yu, <span class="highlight-author">Yoshua Bengio</span>, Emily Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Compositionality, the notion that the meaning of an expression is constructed
from the meaning of its parts and syntactic rules, permits the infinite
productivity of human language. For the first time, artificial language models
(LMs) are able to match human performance in a number of compositional
generalization tasks. However, much remains to be understood about the
representational mechanisms underlying these abilities. We take a high-level
geometric approach to this problem by relating the degree of compositionality
in a dataset to the intrinsic dimensionality of its representations under an
LM, a measure of feature complexity. We find not only that the degree of
dataset compositionality is reflected in representations' intrinsic
dimensionality, but that the relationship between compositionality and
geometric complexity arises due to learned linguistic features over training.
Finally, our analyses reveal a striking contrast between linear and nonlinear
dimensionality, showing that they respectively encode formal and semantic
aspects of linguistic composition.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review as a conference paper at ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fair4Free: Generating High-fidelity Fair Synthetic Samples using Data
  Free Distillation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01423v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01423v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Md Fahim Sikder, Daniel de Leng, Fredrik Heintz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work presents Fair4Free, a novel generative model to generate synthetic
fair data using data-free distillation in the latent space. Fair4Free can work
on the situation when the data is private or inaccessible. In our approach, we
first train a teacher model to create fair representation and then distil the
knowledge to a student model (using a smaller architecture). The process of
distilling the student model is data-free, i.e. the student model does not have
access to the training dataset while distilling. After the distillation, we use
the distilled model to generate fair synthetic samples. Our extensive
experiments show that our synthetic samples outperform state-of-the-art models
in all three criteria (fairness, utility and synthetic quality) with a
performance increase of 5% for fairness, 8% for utility and 12% in synthetic
quality for both tabular and image datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Labyrinth of Links: Navigating the Associative Maze of Multi-modal
  LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01417v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01417v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hong Li, Nanxi Li, Yuanjie Chen, Jianbin Zhu, Qinlu Guo, Cewu Lu, Yong-Lu Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-modal Large Language Models (MLLMs) have exhibited impressive
capability. However, recently many deficiencies of MLLMs have been found
compared to human intelligence, $\textit{e.g.}$, hallucination. To drive the
MLLMs study, the community dedicated efforts to building larger benchmarks with
complex tasks. In this paper, we propose benchmarking an essential but usually
overlooked intelligence: $\textbf{association}$, a human's basic capability to
link observation and prior practice memory. To comprehensively investigate
MLLM's performance on the association, we formulate the association task and
devise a standard benchmark based on adjective and verb semantic concepts.
Instead of costly data annotation and curation, we propose a convenient
$\textbf{annotation-free}$ construction method transforming the general dataset
for our association tasks. Simultaneously, we devise a rigorous data refinement
process to eliminate confusion in the raw dataset. Building on this database,
we establish three levels of association tasks: single-step, synchronous, and
asynchronous associations. Moreover, we conduct a comprehensive investigation
into the MLLMs' zero-shot association capabilities, addressing multiple
dimensions, including three distinct memory strategies, both open-source and
closed-source MLLMs, cutting-edge Mixture-of-Experts (MoE) models, and the
involvement of human experts. Our systematic investigation shows that current
open-source MLLMs consistently exhibit poor capability in our association
tasks, even the currently state-of-the-art GPT-4V(vision) also has a
significant gap compared to humans. We believe our benchmark would pave the way
for future MLLM studies. $\textit{Our data and code are available at:}$
https://mvig-rhos.com/llm_inception.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving Fuzzy Rule Classifier with Brain Storm Optimization and Rule
  Modification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01413v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01413v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yan Huang, Wei Liu, Xiaogang Zang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The expanding complexity and dimensionality in the search space can adversely
affect inductive learning in fuzzy rule classifiers, thus impacting the
scalability and accuracy of fuzzy systems. This research specifically addresses
the challenge of diabetic classification by employing the Brain Storm
Optimization (BSO) algorithm to propose a novel fuzzy system that redefines
rule generation for this context. An exponential model is integrated into the
standard BSO algorithm to enhance rule derivation, tailored specifically for
diabetes-related data. The innovative fuzzy system is then applied to
classification tasks involving diabetic datasets, demonstrating a substantial
improvement in classification accuracy, as evidenced by our experiments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages,8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On the Convergence of FedProx with Extrapolation and Inexact Prox 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01410v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01410v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hanmin Li, Peter Richtárik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Enhancing the FedProx federated learning algorithm (Li et al., 2020) with
server-side extrapolation, Li et al. (2024a) recently introduced the FedExProx
method. Their theoretical analysis, however, relies on the assumption that each
client computes a certain proximal operator exactly, which is impractical since
this is virtually never possible to do in real settings. In this paper, we
investigate the behavior of FedExProx without this exactness assumption in the
smooth and globally strongly convex setting. We establish a general convergence
result, showing that inexactness leads to convergence to a neighborhood of the
solution. Additionally, we demonstrate that, with careful control, the adverse
effects of this inexactness can be mitigated. By linking inexactness to biased
compression (Beznosikov et al., 2023), we refine our analysis, highlighting
robustness of extrapolation to inexact proximal updates. We also examine the
local iteration complexity required by each client to achieved the required
level of inexactness using various local optimizers. Our theoretical insights
are validated through comprehensive numerical experiments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>36 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Can We Delegate Learning to Automation?: A Comparative Study of LLM
  Chatbots, Search Engines, and Books 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01396v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01396v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yeonsun Yang, Ahyeon Shin, Mincheol Kang, Jiheon Kang, Jean Young Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning is a key motivator behind information search behavior. With the
emergence of LLM-based chatbots, students are increasingly turning to these
tools as their primary resource for acquiring knowledge. However, the
transition from traditional resources like textbooks and web searches raises
concerns among educators. They worry that these fully-automated LLMs might lead
students to delegate critical steps of search as learning. In this paper, we
systematically uncover three main concerns from educators' perspectives. In
response to these concerns, we conducted a mixed-methods study with 92
university students to compare three learning sources with different automation
levels. Our results show that LLMs support comprehensive understanding of key
concepts without promoting passive learning, though their effectiveness in
knowledge retention was limited. Additionally, we found that academic
performance impacted both learning outcomes and search patterns. Notably,
higher-competence learners engaged more deeply with content through
reading-intensive behaviors rather than relying on search activities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages, 14 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FLAME: Adaptive and Reactive Concept Drift Mitigation for Federated
  Learning Deployments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01386v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01386v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ioannis Mavromatis, Stefano De Feo, Aftab Khan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents Federated Learning with Adaptive Monitoring and
Elimination (FLAME), a novel solution capable of detecting and mitigating
concept drift in Federated Learning (FL) Internet of Things (IoT) environments.
Concept drift poses significant challenges for FL models deployed in dynamic
and real-world settings. FLAME leverages an FL architecture, considers a
real-world FL pipeline, and proves capable of maintaining model performance and
accuracy while addressing bandwidth and privacy constraints. Introducing
various features and extensions on previous works, FLAME offers a robust
solution to concept drift, significantly reducing computational load and
communication overhead. Compared to well-known lightweight mitigation methods,
FLAME demonstrates superior performance in maintaining high F1 scores and
reducing resource utilisation in large-scale IoT deployments, making it a
promising approach for real-world applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for Publication at EMERGE Workshop - EWSN 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Knowledge Entropy Decay during Language Model <span class="highlight-title">Pretrain</span>ing Hinders New
  Knowledge Acquisition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01380v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01380v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiyeon Kim, Hyunji Lee, Hyowon Cho, Joel Jang, Hyeonbin Hwang, Seungpil Won, Youbin Ahn, Dohaeng Lee, Minjoon Seo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we investigate how a model's tendency to broadly integrate its
parametric knowledge evolves throughout pretraining, and how this behavior
affects overall performance, particularly in terms of knowledge acquisition and
forgetting. We introduce the concept of knowledge entropy, which quantifies the
range of memory sources the model engages with; high knowledge entropy
indicates that the model utilizes a wide range of memory sources, while low
knowledge entropy suggests reliance on specific sources with greater certainty.
Our analysis reveals a consistent decline in knowledge entropy as pretraining
advances. We also find that the decline is closely associated with a reduction
in the model's ability to acquire and retain knowledge, leading us to conclude
that diminishing knowledge entropy (smaller number of active memory sources)
impairs the model's knowledge acquisition and retention capabilities. We find
further support for this by demonstrating that increasing the activity of
inactive memory sources enhances the model's capacity for knowledge acquisition
and retention.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Theoretical Lower Bounds for the Oven Scheduling Problem 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01368v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01368v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Francesca Da Ros, Marie-Louise Lackner, Nysret Musliu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Oven Scheduling Problem (OSP) is an NP-hard real-world parallel batch
scheduling problem arising in the semiconductor industry. The objective of the
problem is to schedule a set of jobs on ovens while minimizing several factors,
namely total oven runtime, job tardiness, and setup costs. At the same time, it
must adhere to various constraints such as oven eligibility and availability,
job release dates, setup times between batches, and oven capacity limitations.
The key to obtaining efficient schedules is to process compatible jobs
simultaneously in batches. In this paper, we develop theoretical,
problem-specific lower bounds for the OSP that can be computed very quickly. We
thoroughly examine these lower bounds, evaluating their quality and exploring
their integration into existing solution methods. Specifically, we investigate
their contribution to exact methods and a metaheuristic local search approach
using simulated annealing. Moreover, these problem-specific lower bounds enable
us to assess the solution quality for large instances for which exact methods
often fail to provide tight lower bounds.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: text overlap with arXiv:2203.12517</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PCQPR: Proactive Conversational Question Planning with Reflection <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01363v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01363v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shasha Guo, Lizi Liao, Jing Zhang, Cuiping Li, Hong Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Conversational Question Generation (CQG) enhances the interactivity of
conversational question-answering systems in fields such as education, customer
service, and entertainment. However, traditional CQG, focusing primarily on the
immediate context, lacks the conversational foresight necessary to guide
conversations toward specified conclusions. This limitation significantly
restricts their ability to achieve conclusion-oriented conversational outcomes.
In this work, we redefine the CQG task as Conclusion-driven Conversational
Question Generation (CCQG) by focusing on proactivity, not merely reacting to
the unfolding conversation but actively steering it towards a
conclusion-oriented question-answer pair. To address this, we propose a novel
approach, called Proactive Conversational Question Planning with self-Refining
(PCQPR). Concretely, by integrating a planning algorithm inspired by Monte
Carlo Tree Search (MCTS) with the analytical capabilities of large language
models (LLMs), PCQPR predicts future conversation turns and continuously
refines its questioning strategies. This iterative self-refining mechanism
ensures the generation of contextually relevant questions strategically devised
to reach a specified outcome. Our extensive evaluations demonstrate that PCQPR
significantly surpasses existing CQG methods, marking a paradigm shift towards
conclusion-oriented conversational question-answering systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Codev-Bench: How Do LLMs Understand Developer-Centric Code Completion? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01353v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01353v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenyu Pan, Rongyu Cao, Yongchang Cao, Yingwei Ma, Binhua Li, Fei Huang, Han Liu, Yongbin Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Code completion, a key downstream task in code generation, is one of the most
frequent and impactful methods for enhancing developer productivity in software
development. As intelligent completion tools evolve, we need a robust
evaluation benchmark that enables meaningful comparisons between products and
guides future advancements. However, existing benchmarks focus more on
coarse-grained tasks without industrial analysis resembling general code
generation rather than the real-world scenarios developers encounter. Moreover,
these benchmarks often rely on costly and time-consuming human annotation, and
the standalone test cases fail to leverage minimal tests for maximum
repository-level understanding and code coverage. To address these limitations,
we first analyze business data from an industrial code completion tool and
redefine the evaluation criteria to better align with the developer's intent
and desired completion behavior throughout the coding process. Based on these
insights, we introduce Codev-Agent, an agent-based system that automates
repository crawling, constructs execution environments, extracts dynamic
calling chains from existing unit tests, and generates new test samples to
avoid data leakage, ensuring fair and effective comparisons. Using Codev-Agent,
we present the Code-Development Benchmark (Codev-Bench), a fine-grained,
real-world, repository-level, and developer-centric evaluation framework.
Codev-Bench assesses whether a code completion tool can capture a developer's
immediate intent and suggest appropriate code across diverse contexts,
providing a more realistic benchmark for code completion in modern software
development.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Takin-VC: Zero-shot Voice Conversion via Jointly Hybrid Content and
  Memory-Augmented Context-Aware Timbre Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01350v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01350v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuguang Yang, Yu Pan, Jixun Yao, Xiang Zhang, Jianhao Ye, Hongbin Zhou, Lei Xie, Lei Ma, Jianjun Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Zero-shot voice conversion (VC) aims to transform the source speaker timbre
into an arbitrary unseen one without altering the original speech content.While
recent advancements in zero-shot VC methods have shown remarkable progress,
there still remains considerable potential for improvement in terms of
improving speaker similarity and speech naturalness.In this paper, we propose
Takin-VC, a novel zero-shot VC framework based on jointly hybrid content and
memory-augmented context-aware timbre modeling to tackle this challenge.
Specifically, an effective hybrid content encoder, guided by neural codec
training, that leverages quantized features from pre-trained WavLM and
HybridFormer is first presented to extract the linguistic content of the source
speech. Subsequently, we introduce an advanced cross-attention-based
context-aware timbre modeling approach that learns the fine-grained,
semantically associated target timbre features. To further enhance both speaker
similarity and real-time performance, we utilize a conditional flow matching
model to reconstruct the Mel-spectrogram of the source speech. Additionally, we
advocate an efficient memory-augmented module designed to generate high-quality
conditional target inputs for the flow matching process, thereby improving the
overall performance of the proposed system. Experimental results demonstrate
that the proposed Takin-VC method surpasses state-of-the-art zero-shot VC
systems, delivering superior performance in terms of both speech naturalness
and speaker similarity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in Progress; Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Life, uh, Finds a Way: Systematic Neural Search 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01349v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01349v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alex Baranski, Jun Tani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We tackle the challenge of rapidly adapting an agent's behavior to solve
spatiotemporally continuous problems in novel settings. Animals exhibit
extraordinary abilities to adapt to new contexts, a capacity unmatched by
artificial systems. Instead of focusing on generalization through deep
reinforcement learning, we propose viewing behavior as the physical
manifestation of a search procedure, where robust problem-solving emerges from
an exhaustive search across all possible behaviors. Surprisingly, this can be
done efficiently using online modification of a cognitive graph that guides
action, challenging the predominant view that exhaustive search in continuous
spaces is impractical. We describe an algorithm that implicitly enumerates
behaviors by regulating the tight feedback loop between execution of behaviors
and mutation of the graph, and provide a neural implementation based on Hebbian
learning and a novel high-dimensional harmonic representation inspired by
entorhinal cortex. By framing behavior as search, we provide a mathematically
simple and biologically plausible model for real-time behavioral adaptation,
successfully solving a variety of continuous state-space navigation problems.
This framework not only offers a flexible neural substrate for other
applications but also presents a powerful paradigm for understanding adaptive
behavior. Our results suggest potential advancements in developmental learning
and unsupervised skill acquisition, paving the way for autonomous robots to
master complex skills in data-sparse environments demanding flexibility.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PhyMPGN: Physics-encoded Message Passing Graph Network for
  spatiotemporal PDE systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01337v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01337v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bocheng Zeng, Qi Wang, Mengtao Yan, Yang Liu, Ruizhi Chengze, Yi Zhang, Hongsheng Liu, Zidong Wang, Hao Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Solving partial differential equations (PDEs) serves as a cornerstone for
modeling complex dynamical systems. Recent progresses have demonstrated grand
benefits of data-driven neural-based models for predicting spatiotemporal
dynamics (e.g., tremendous speedup gain compared with classical numerical
methods). However, most existing neural models rely on rich training data, have
limited extrapolation and generalization abilities, and suffer to produce
precise or reliable physical prediction under intricate conditions (e.g.,
irregular mesh or geometry, complex boundary conditions, diverse PDE
parameters, etc.). To this end, we propose a new graph learning approach,
namely, Physics-encoded Message Passing Graph Network (PhyMPGN), to model
spatiotemporal PDE systems on irregular meshes given small training datasets.
Specifically, we incorporate a GNN into a numerical integrator to approximate
the temporal marching of spatiotemporal dynamics for a given PDE system.
Considering that many physical phenomena are governed by diffusion processes,
we further design a learnable Laplace block, which encodes the discrete
Laplace-Beltrami operator, to aid and guide the GNN learning in a physically
feasible solution space. A boundary condition padding strategy is also designed
to improve the model convergence and accuracy. Extensive experiments
demonstrate that PhyMPGN is capable of accurately predicting various types of
spatiotemporal dynamics on coarse unstructured meshes, consistently achieves
the state-of-the-art results, and outperforms other baselines with considerable
gains.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Layer Swapping for Zero-Shot Cross-Lingual Transfer in Large Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01335v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01335v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lucas Bandarkar, Benjamin Muller, Pritish Yuvraj, Rui Hou, Nayan Singhal, Hongjiang Lv, Bing Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Model merging, such as model souping, is the practice of combining different
models with the same architecture together without further training. In this
work, we present a model merging methodology that addresses the difficulty of
fine-tuning Large Language Models (LLMs) for target tasks in non-English
languages, where task-specific data is often unavailable. We focus on
mathematical reasoning and without in-language math data, facilitate
cross-lingual transfer by composing language and math capabilities. Starting
from the same pretrained model, we fine-tune separate "experts" on math
instruction data in English and on generic instruction data in the target
language. We then replace the top and bottom transformer layers of the math
expert directly with layers from the language expert, which consequently
enhances math performance in the target language. The resulting merged models
outperform the individual experts and other merging methods on the math
benchmark, MGSM, by 10% across four major languages where math instruction data
is scarce. In addition, this layer swapping is simple, inexpensive, and
intuitive, as it is based on an interpretative analysis of the most important
parameter changes during the fine-tuning of each expert. The ability to
successfully re-compose LLMs for cross-lingual transfer in this manner opens up
future possibilities to combine model expertise, create modular solutions, and
transfer reasoning capabilities across languages all post hoc.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 main pages, 23 pages total, 9 figures, 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unveiling Language Skills under Circuits 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01334v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01334v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hang Chen, Jiaying Zhu, Xinyu Yang, Wenya Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The exploration of language skills in language models (LMs) has always been
one of the central goals in mechanistic interpretability. However, existing
circuit analyses often fall short in representing the full functional scope of
these models, primarily due to the exclusion of Feed-Forward layers.
Additionally, isolating the effect of a single language skill from a text,
which inherently involves multiple entangled skills, poses a significant
challenge. To address these gaps, we introduce a novel concept, Memory Circuit,
a minimum unit that fully and independently manipulates the memory-reading
functionality of a language model, and disentangle the transformer model
precisely into a circuit graph which is an ensemble of paths connecting
different memory circuits. Based on this disentanglement, we identify salient
circuit paths, named as skill paths, responsible for three crucial language
skills, i.e., the Previous Token Skill, Induction Skill and In-Context Learning
(ICL) Skill, leveraging causal effect estimation through interventions and
counterfactuals. Our experiments on various datasets confirm the correspondence
between our identified skill paths and language skills, and validate three
longstanding hypotheses: 1) Language skills are identifiable through circuit
dissection; 2) Simple language skills reside in shallow layers, whereas complex
language skills are found in deeper layers; 3) Complex language skills are
formed on top of simpler language skills. Our codes are available at:
https://github.com/Zodiark-ch/Language-Skill-of-LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fair Class-Incremental Learning using Sample Weighting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01324v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01324v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jaeyoung Park, Minsu Kim, Steven Euijong Whang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Model fairness is becoming important in class-incremental learning for
Trustworthy AI. While accuracy has been a central focus in class-incremental
learning, fairness has been relatively understudied. However, naively using all
the samples of the current task for training results in unfair catastrophic
forgetting for certain sensitive groups including classes. We theoretically
analyze that forgetting occurs if the average gradient vector of the current
task data is in an "opposite direction" compared to the average gradient vector
of a sensitive group, which means their inner products are negative. We then
propose a fair class-incremental learning framework that adjusts the training
weights of current task samples to change the direction of the average gradient
vector and thus reduce the forgetting of underperforming groups and achieve
fairness. For various group fairness measures, we formulate optimization
problems to minimize the overall losses of sensitive groups while minimizing
the disparities among them. We also show the problems can be solved with linear
programming and propose an efficient Fairness-aware Sample Weighting (FSW)
algorithm. Experiments show that FSW achieves better accuracy-fairness tradeoff
results than state-of-the-art approaches on real datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Forte : Finding Outliers with Representation Typicality Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01322v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01322v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Debargha Ganguly, Warren Morningstar, Andrew Yu, Vipin Chaudhary
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative models can now produce photorealistic synthetic data which is
virtually indistinguishable from the real data used to train it. This is a
significant evolution over previous models which could produce reasonable
facsimiles of the training data, but ones which could be visually distinguished
from the training data by human evaluation. Recent work on OOD detection has
raised doubts that generative model likelihoods are optimal OOD detectors due
to issues involving likelihood misestimation, entropy in the generative
process, and typicality. We speculate that generative OOD detectors also failed
because their models focused on the pixels rather than the semantic content of
the data, leading to failures in near-OOD cases where the pixels may be similar
but the information content is significantly different. We hypothesize that
estimating typical sets using self-supervised learners leads to better OOD
detectors. We introduce a novel approach that leverages representation
learning, and informative summary statistics based on manifold estimation, to
address all of the aforementioned issues. Our method outperforms other
unsupervised approaches and achieves state-of-the art performance on
well-established challenging benchmarks, and new synthetic data detection
tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Finetuning <span class="highlight-title">Pre-train</span>ed Model with Limited Data for LiDAR-based 3D Object
  Detection by Bridging Domain Gaps <span class="chip">IROS</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01319v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01319v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiyun Jang, Mincheol Chang, Jongwon Park, Jinkyu Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LiDAR-based 3D object detectors have been largely utilized in various
applications, including autonomous vehicles or mobile robots. However,
LiDAR-based detectors often fail to adapt well to target domains with different
sensor configurations (e.g., types of sensors, spatial resolution, or FOVs) and
location shifts. Collecting and annotating datasets in a new setup is commonly
required to reduce such gaps, but it is often expensive and time-consuming.
Recent studies suggest that pre-trained backbones can be learned in a
self-supervised manner with large-scale unlabeled LiDAR frames. However,
despite their expressive representations, they remain challenging to generalize
well without substantial amounts of data from the target domain. Thus, we
propose a novel method, called Domain Adaptive Distill-Tuning (DADT), to adapt
a pre-trained model with limited target data (approximately 100 LiDAR frames),
retaining its representation power and preventing it from overfitting.
Specifically, we use regularizers to align object-level and context-level
representations between the pre-trained and finetuned models in a
teacher-student architecture. Our experiments with driving benchmarks, i.e.,
Waymo Open dataset and KITTI, confirm that our method effectively finetunes a
pre-trained model, achieving significant gains in accuracy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS) 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AgentStudio: A Toolkit for Building General Virtual Agents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.17918v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.17918v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Longtao Zheng, Zhiyuan Huang, Zhenghai Xue, Xinrun Wang, Bo An, Shuicheng Yan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  General virtual agents need to handle multimodal observations, master complex
action spaces, and self-improve in dynamic, open-domain environments. However,
existing environments are often domain-specific and require complex setups,
which limits agent development and evaluation in real-world settings. As a
result, current evaluations lack in-depth analyses that decompose fundamental
agent capabilities. We introduce AgentStudio, a trinity of environments, tools,
and benchmarks to address these issues. AgentStudio provides a lightweight,
interactive environment with highly generic observation and action spaces,
e.g., video observations and GUI/API actions. It integrates tools for creating
online benchmark tasks, annotating GUI elements, and labeling actions in
videos. Based on our environment and tools, we curate an online task suite that
benchmarks both GUI interactions and function calling with efficient
auto-evaluation. We also reorganize existing datasets and collect new ones
using our tools to establish three datasets: GroundUI, IDMBench, and
CriticBench. These datasets evaluate fundamental agent abilities, including GUI
grounding, learning from videos, and success detection, pointing to the
desiderata for robust, general, and open-ended virtual agents.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>42 pages, 22 figures, 15 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Do Large Language Models Learn Human-Like Strategic Preferences? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.08710v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.08710v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jesse Roberts, Kyle Moore, Doug Fisher
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we evaluate whether LLMs learn to make human-like preference
judgements in strategic scenarios as compared with known empirical results.
Solar and Mistral are shown to exhibit stable value-based preference consistent
with humans and exhibit human-like preference for cooperation in the prisoner's
dilemma (including stake-size effect) and traveler's dilemma (including
penalty-size effect). We establish a relationship between model size,
value-based preference, and superficiality. Finally, results here show that
models tending to be less brittle have relied on sliding window attention
suggesting a potential link. Additionally, we contribute a novel method for
constructing preference relations from arbitrary LLMs and support for a
hypothesis regarding human behavior in the traveler's dilemma.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CASE: Efficient Curricular Data <span class="highlight-title">Pre-train</span>ing for Building Assistive
  Psychology Expert Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.00314v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.00314v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sarthak Harne, Monjoy Narayan Choudhury, Madhav Rao, TK Srikanth, Seema Mehrotra, Apoorva Vashisht, Aarushi Basu, Manjit Sodhi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The limited availability of psychologists necessitates efficient
identification of individuals requiring urgent mental healthcare. This study
explores the use of Natural Language Processing (NLP) pipelines to analyze text
data from online mental health forums used for consultations. By analyzing
forum posts, these pipelines can flag users who may require immediate
professional attention. A crucial challenge in this domain is data privacy and
scarcity. To address this, we propose utilizing readily available curricular
texts used in institutes specializing in mental health for pre-training the NLP
pipelines. This helps us mimic the training process of a psychologist. Our work
presents CASE-BERT that flags potential mental health disorders based on forum
text. CASE-BERT demonstrates superior performance compared to existing methods,
achieving an f1 score of 0.91 for Depression and 0.88 for Anxiety, two of the
most commonly reported mental health disorders. Our code and data are publicly
available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ What is lost in Normalization? Exploring Pitfalls in Multilingual ASR
  Model Evaluations <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02449v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02449v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kavya Manohar, Leena G Pillai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper explores the pitfalls in evaluating multilingual automatic speech
recognition (ASR) models, with a particular focus on Indic language scripts. We
investigate the text normalization routine employed by leading ASR models,
including OpenAI Whisper, Meta's MMS, Seamless, and Assembly AI's Conformer,
and their unintended consequences on performance metrics. Our research reveals
that current text normalization practices, while aiming to standardize ASR
outputs for fair comparison, by removing inconsistencies such as variations in
spelling, punctuation, and special characters, are fundamentally flawed when
applied to Indic scripts. Through empirical analysis using text similarity
scores and in-depth linguistic examination, we demonstrate that these flaws
lead to artificially improved performance metrics for Indic languages. We
conclude by proposing a shift towards developing text normalization routines
that leverage native linguistic expertise, ensuring more robust and accurate
evaluations of multilingual ASR models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Social Conjuring: Multi-User Runtime Collaboration with AI in Building
  Virtual 3D Worlds 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00274v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00274v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amina Kobenova, Cyan DeVeaux, Samyak Parajuli, Andrzej Banburski-Fahey, Judith Amores Fernandez, Jaron Lanier
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative artificial intelligence has shown promise in prompting virtual
worlds into existence, yet little attention has been given to understanding how
this process unfolds as social interaction. We present Social Conjurer, a
framework for AI-augmented dynamic 3D scene co-creation, where multiple users
collaboratively build and modify virtual worlds in real-time. Through an
expanded set of interactions, including social and tool-based engagements as
well as spatial reasoning, our framework facilitates the creation of rich,
diverse virtual environments. Findings from a preliminary user study (N=12)
provide insight into the user experience of this approach, how social contexts
shape the prompting of spatial environments, and perspective on social
applications of prompt-based 3D co-creation. In addition to highlighting the
potential of AI-supported multi-user world creation and offering new pathways
for AI-augmented creative processes in VR, this article presents a set of
implications for designing human-centered interfaces that incorporate AI models
into 3D content generation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>27 pages + Appendix, 16 figures; fixed some minor UTF-8 encoding
  issues in arXiv compilation</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Temporal Test-Time Adaptation with State-Space Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12492v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12492v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mona Schirmer, Dan Zhang, Eric Nalisnick
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Distribution shifts between training and test data are inevitable over the
lifecycle of a deployed model, leading to performance decay. Adapting a model
on test samples can help mitigate this drop in performance. However, most
test-time adaptation methods have focused on synthetic corruption shifts,
leaving a variety of distribution shifts underexplored. In this paper, we focus
on distribution shifts that evolve gradually over time, which are common in the
wild but challenging for existing methods, as we show. To address this, we
propose STAD, a probabilistic state-space model that adapts a deployed model to
temporal distribution shifts by learning the time-varying dynamics in the last
set of hidden features. Without requiring labels, our model infers
time-evolving class prototypes that act as a dynamic classification head.
Through experiments on real-world temporal distribution shifts, we show that
our method excels in handling small batch sizes and label shift.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VisionTS: Visual Masked Autoencoders Are Free-Lunch Zero-Shot Time
  Series Forecasters 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.17253v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.17253v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mouxiang Chen, Lefei Shen, Zhuo Li, Xiaoyun Joy Wang, Jianling Sun, Chenghao Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Foundation models have emerged as a promising approach in time series
forecasting (TSF). Existing approaches either repurpose large language models
(LLMs) or build large-scale time series datasets to develop TSF foundation
models for universal forecasting. However, these methods face challenges due to
the severe cross-domain gap or in-domain heterogeneity. This paper explores a
new road to building a TSF foundation model from rich, high-quality natural
images. Our key insight is that a visual masked autoencoder, pre-trained on the
ImageNet dataset, can naturally be a numeric series forecaster. By
reformulating TSF as an image reconstruction task, we bridge the gap between
image pre-training and TSF downstream tasks. Surprisingly, without further
adaptation in the time-series domain, the proposed VisionTS could achieve
superior zero-shot forecasting performance compared to existing TSF foundation
models. With fine-tuning for one epoch, VisionTS could further improve the
forecasting and achieve state-of-the-art performance in most cases. Extensive
experiments reveal intrinsic similarities between images and real-world time
series, suggesting visual models may offer a ``free lunch'' for TSF and
highlight the potential for future cross-modality research. Our code is
publicly available at https://github.com/Keytoyze/VisionTS.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>v2: add more experiments</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ WatChat: Explaining perplexing programs by debugging mental models <span class="chip">ACL</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.05334v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.05334v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kartik Chandra, Katherine M. Collins, Will Crichton, Tony Chen, Tzu-Mao Li, Adrian Weller, Rachit Nigam, Joshua Tenenbaum, Jonathan Ragan-Kelley
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Often, a good explanation for a program's unexpected behavior is a bug in the
programmer's code. But sometimes, an even better explanation is a bug in the
programmer's mental model of the language or API they are using. Instead of
merely debugging our current code ("giving the programmer a fish"), what if our
tools could directly debug our mental models ("teaching the programmer to
fish")? In this paper, we apply recent ideas from computational cognitive
science to offer a principled framework for doing exactly that. Given a "why?"
question about a program, we automatically infer potential misconceptions about
the language/API that might cause the user to be surprised by the program's
behavior -- and then analyze those misconceptions to provide explanations of
the program's behavior. Our key idea is to formally represent misconceptions as
counterfactual (erroneous) semantics for the language/API, which can be
inferred and debugged using program synthesis techniques. We demonstrate our
framework, WatChat, by building systems for explanation in two domains:
JavaScript type coercion, and the Git version control system. We evaluate
WatChatJS and WatChatGit by comparing their outputs to experimentally-collected
human-written explanations in these two domains: we show that WatChat's
explanations exhibit key features of human-written explanation, unlike those of
a state-of-the-art language model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This is a preprint of work presented in early-stage non-archival form
  at the ACL Natural Language Reasoning and Structured Explanations Workshop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Scaling Optimal LR Across Token Horizons 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19913v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19913v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Johan Bjorck, Alon Benhaim, Vishrav Chaudhary, Furu Wei, Xia Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  State-of-the-art LLMs are powered by scaling -- scaling model size, dataset
size and cluster size. It is economically infeasible to extensively tune
hyperparameter for the largest runs. Instead, approximately optimal
hyperparameters must be inferred or \textit{transferred} from smaller
experiments. Hyperparameter transfer across model sizes has been studied in
Yang et al. However, hyperparameter transfer across dataset size -- or token
horizon -- has not been studied yet. To remedy this we conduct a large scale
empirical study on how optimal learning rate (LR) depends on token horizon in
LLM training. We first demonstrate that the optimal LR changes significantly
with token horizon -- longer training necessitates smaller LR. Secondly we
demonstrate the the optimal LR follows a scaling law, and that the optimal LR
for longer horizons can be accurately estimated from shorter horizons via such
scaling laws. We also provide a rule-of-thumb for transferring LR across token
horizons with zero overhead over current practices. Lastly we provide evidence
that LLama-1 used too high LR, and estimate the performance hit from this. We
thus argue that hyperparameter transfer across data size is an important and
overlooked component of LLM training.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Privacy-Preserving Relational Data Synthesis via Probabilistic
  Relational Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04194v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04194v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Malte Luttermann, Ralf Möller, Mattis Hartwig
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Probabilistic relational models provide a well-established formalism to
combine first-order logic and probabilistic models, thereby allowing to
represent relationships between objects in a relational domain. At the same
time, the field of artificial intelligence requires increasingly large amounts
of relational training data for various machine learning tasks. Collecting
real-world data, however, is often challenging due to privacy concerns, data
protection regulations, high costs, and so on. To mitigate these challenges,
the generation of synthetic data is a promising approach. In this paper, we
solve the problem of generating synthetic relational data via probabilistic
relational models. In particular, we propose a fully-fledged pipeline to go
from relational database to probabilistic relational model, which can then be
used to sample new synthetic relational data points from its underlying
probability distribution. As part of our proposed pipeline, we introduce a
learning algorithm to construct a probabilistic relational model from a given
relational database.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the Proceedings of the 47th German Conference on
  Artificial Intelligence (KI 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Controllable Preference Optimization: Toward Controllable
  Multi-Objective Alignment <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.19085v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.19085v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiju Guo, Ganqu Cui, Lifan Yuan, Ning Ding, Zexu Sun, Bowen Sun, Huimin Chen, Ruobing Xie, Jie Zhou, Yankai Lin, Zhiyuan Liu, Maosong Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Alignment in artificial intelligence pursues the consistency between model
responses and human preferences as well as values. In practice, the
multifaceted nature of human preferences inadvertently introduces what is known
as the "alignment tax" -a compromise where enhancements in alignment within one
objective (e.g.,harmlessness) can diminish performance in others
(e.g.,helpfulness). However, existing alignment techniques are mostly
unidirectional, leading to suboptimal trade-offs and poor flexibility over
various objectives. To navigate this challenge, we argue the prominence of
grounding LLMs with evident preferences. We introduce controllable preference
optimization (CPO), which explicitly specifies preference scores for different
objectives, thereby guiding the model to generate responses that meet the
requirements. Our experimental analysis reveals that the aligned models can
provide responses that match various preferences among the "3H" (helpfulness,
honesty, harmlessness) desiderata. Furthermore, by introducing diverse data and
alignment goals, we surpass baseline methods in aligning with single
objectives, hence mitigating the impact of the alignment tax and achieving
Pareto improvements in multi-objective alignment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 main conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ README: Bridging Medical Jargon and Lay Understanding for Patient
  Education through Data-Centric NLP <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.15561v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.15561v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zonghai Yao, Nandyala Siddharth Kantu, Guanghao Wei, Hieu Tran, Zhangqi Duan, Sunjae Kwon, Zhichao Yang, README annotation team, Hong Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The advancement in healthcare has shifted focus toward patient-centric
approaches, particularly in self-care and patient education, facilitated by
access to Electronic Health Records (EHR). However, medical jargon in EHRs
poses significant challenges in patient comprehension. To address this, we
introduce a new task of automatically generating lay definitions, aiming to
simplify complex medical terms into patient-friendly lay language. We first
created the README dataset, an extensive collection of over 50,000 unique
(medical term, lay definition) pairs and 300,000 mentions, each offering
context-aware lay definitions manually annotated by domain experts. We have
also engineered a data-centric Human-AI pipeline that synergizes data
filtering, augmentation, and selection to improve data quality. We then used
README as the training data for models and leveraged a Retrieval-Augmented
Generation method to reduce hallucinations and improve the quality of model
outputs. Our extensive automatic and human evaluations demonstrate that
open-source mobile-friendly models, when fine-tuned with high-quality data, are
capable of matching or even surpassing the performance of state-of-the-art
closed-source large language models like ChatGPT. This research represents a
significant stride in closing the knowledge gap in patient education and
advancing patient-centric healthcare solutions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear in Findings of the Association for Computational
  Linguistics: EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning Dynamics of LLM Finetuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10490v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10490v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi Ren, Danica J. Sutherland
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning dynamics, which describes how the learning of specific training
examples influences the model's predictions on other examples, gives us a
powerful tool for understanding the behavior of deep learning systems. We study
the learning dynamics of large language models during different types of
finetuning, by analyzing the step-wise decomposition of how influence
accumulates among different potential responses. Our framework allows a uniform
interpretation of many interesting observations about the training of popular
algorithms for both instruction tuning and preference tuning. In particular, we
propose a hypothetical explanation of why specific types of hallucination are
strengthened after finetuning, e.g., the model might use phrases or facts in
the response for question B to answer question A, or the model might keep
repeating similar simple phrases when generating responses. We also extend our
framework and highlight a unique "squeezing effect" to explain a previously
observed phenomenon in off-policy direct preference optimization (DPO), where
running DPO for too long makes even the desired outputs less likely. This
framework also provides insights into where the benefits of on-policy DPO and
other variants come from. The analysis not only provides a novel perspective of
understanding LLM's finetuning but also inspires a simple, effective method to
improve alignment performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Latent Diffusion Models for Controllable RNA Sequence Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.09828v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.09828v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaixuan Huang, Yukang Yang, Kaidi Fu, Yanyi Chu, Le Cong, Mengdi Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work presents RNAdiffusion, a latent diffusion model for generating and
optimizing discrete RNA sequences of variable lengths. RNA is a key
intermediary between DNA and protein, exhibiting high sequence diversity and
complex three-dimensional structures to support a wide range of functions. We
utilize pretrained BERT-type models to encode raw RNA sequences into
token-level, biologically meaningful representations. A Query Transformer is
employed to compress such representations into a set of fixed-length latent
vectors, with an autoregressive decoder trained to reconstruct RNA sequences
from these latent variables. We then develop a continuous diffusion model
within this latent space. To enable optimization, we integrate the gradients of
reward models--surrogates for RNA functional properties--into the backward
diffusion process, thereby generating RNAs with high reward scores. Empirical
results confirm that RNAdiffusion generates non-coding RNAs that align with
natural distributions across various biological metrics. Further, we fine-tune
the diffusion model on mRNA 5' untranslated regions (5'-UTRs) and optimize
sequences for high translation efficiencies. Our guided diffusion model
effectively generates diverse 5'-UTRs with high Mean Ribosome Loading (MRL) and
Translation Efficiency (TE), outperforming baselines in balancing rewards and
structural stability trade-off. Our findings hold potential for advancing RNA
sequence-function research and therapeutic RNA design.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Test Time Learning for Time Series Forecasting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.14012v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.14012v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Panayiotis Christou, Shichu Chen, Xupeng Chen, Parijat Dube
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Time-series forecasting has seen significant advancements with the
introduction of token prediction mechanisms such as multi-head attention.
However, these methods often struggle to achieve the same performance as in
language modeling, primarily due to the quadratic computational cost and the
complexity of capturing long-range dependencies in time-series data.
State-space models (SSMs), such as Mamba, have shown promise in addressing
these challenges by offering efficient solutions with linear RNNs capable of
modeling long sequences with larger context windows. However, there remains
room for improvement in accuracy and scalability.
  We propose the use of Test-Time Training (TTT) modules in a parallel
architecture to enhance performance in long-term time series forecasting.
Through extensive experiments on standard benchmark datasets, we demonstrate
that TTT modules consistently outperform state-of-the-art models, including the
Mamba-based TimeMachine, particularly in scenarios involving extended sequence
and prediction lengths. Our results show significant improvements in Mean
Squared Error (MSE) and Mean Absolute Error (MAE), especially on larger
datasets such as Electricity, Traffic, and Weather, underscoring the
effectiveness of TTT in capturing long-range dependencies. Additionally, we
explore various convolutional architectures within the TTT framework, showing
that even simple configurations like 1D convolution with small filters can
achieve competitive results. This work sets a new benchmark for time-series
forecasting and lays the groundwork for future research in scalable,
high-performance forecasting models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LogicAsker: Evaluating and Improving the Logical Reasoning Ability of
  Large Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.00757v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.00757v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxuan Wan, Wenxuan Wang, Yiliu Yang, Youliang Yuan, Jen-tse Huang, Pinjia He, Wenxiang Jiao, Michael R. Lyu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce LogicAsker, a novel approach for evaluating and enhancing the
logical reasoning capabilities of large language models (LLMs) such as ChatGPT
and GPT-4. Despite LLMs' prowess in tasks like writing assistance, code
generation, and machine translation, assessing their ability to reason has been
challenging. Traditional evaluations often prioritize accuracy on downstream
tasks over direct assessments of reasoning processes. LogicAsker addresses this
gap by employing a set of atomic reasoning skills grounded in propositional and
predicate logic to systematically examine and improve the reasoning prowess of
LLMs. Our methodology reveals significant gaps in LLMs' learning of logical
rules, with identified reasoning failures ranging from 29\% to 90\% across
different models. Moreover, we leverage these findings to construct targeted
demonstration examples and fine-tune data, notably enhancing logical reasoning
in models like GPT-4o by up to 5\%. To our knowledge, this is the first effort
to utilize test case outcomes to effectively refine LLMs' formal reasoning
capabilities. We make our code, data, and results publicly available
(https://github.com/yxwan123/LogicAsker) to facilitate further research and
replication of our findings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tool-Planner: Task Planning with Clusters across Multiple Tools 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.03807v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.03807v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanming Liu, Xinyue Peng, Jiannan Cao, Shi Bo, Yuwei Zhang, Xuhong Zhang, Sheng Cheng, Xun Wang, Jianwei Yin, Tianyu Du
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have demonstrated exceptional reasoning
capabilities, enabling them to solve various complex problems. Recently, this
ability has been applied to the paradigm of tool learning. Tool learning
involves providing examples of tool usage and their corresponding functions,
allowing LLMs to formulate plans and demonstrate the process of invoking and
executing each tool. LLMs can address tasks that they cannot complete
independently, thereby enhancing their potential across different tasks.
However, this approach faces two key challenges. First, redundant error
correction leads to unstable planning and long execution time. Additionally,
designing a correct plan among multiple tools is also a challenge in tool
learning. To address these issues, we propose Tool-Planner, a task-processing
framework based on toolkits. Tool-Planner groups tools based on the API
functions with the same function into a toolkit and allows LLMs to implement
planning across the various toolkits. When a tool error occurs, the language
model can reselect and adjust tools based on the toolkit. Experiments show that
our approach demonstrates a high pass and win rate across different datasets
and optimizes the planning scheme for tool learning in models such as GPT-4 and
Claude 3, showcasing the potential of our method. Our code is public at
\url{https://github.com/OceannTwT/Tool-Planner}
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>48pages second version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Almost Sure Convergence of Average Reward Temporal Difference Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19546v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19546v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ethan Blaser, Shangtong Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tabular average reward Temporal Difference (TD) learning is perhaps the
simplest and the most fundamental policy evaluation algorithm in average reward
reinforcement learning. After at least 25 years since its discovery, we are
finally able to provide a long-awaited almost sure convergence analysis.
Namely, we are the first to prove that, under very mild conditions, tabular
average reward TD converges almost surely to a sample path dependent fixed
point. Key to this success is a new general stochastic approximation result
concerning nonexpansive mappings with Markovian and additive noise, built on
recent advances in stochastic Krasnoselskii-Mann iterations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Gemma 2: Improving Open Language Models at a Practical Size 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.00118v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.00118v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                         Gemma Team, Morgane Riviere, Shreya Pathak, Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupatiraju, Léonard Hussenot, Thomas Mesnard, Bobak Shahriari, Alexandre Ramé, Johan Ferret, Peter Liu, Pouya Tafti, Abe Friesen, Michelle Casbon, Sabela Ramos, Ravin Kumar, Charline Le Lan, Sammy Jerome, Anton Tsitsulin, Nino Vieillard, Piotr Stanczyk, Sertan Girgin, Nikola Momchev, Matt Hoffman, Shantanu Thakoor, Jean-Bastien Grill, Behnam Neyshabur, Olivier Bachem, Alanna Walton, Aliaksei Severyn, Alicia Parrish, Aliya Ahmad, Allen Hutchison, Alvin Abdagic, Amanda Carl, Amy Shen, Andy Brock, Andy Coenen, Anthony Laforge, Antonia Paterson, Ben Bastian, Bilal Piot, Bo Wu, Brandon Royal, Charlie Chen, Chintu Kumar, Chris Perry, Chris Welty, Christopher A. Choquette-Choo, Danila Sinopalnikov, David Weinberger, Dimple Vijaykumar, Dominika Rogozińska, Dustin Herbison, Elisa Bandy, Emma Wang, Eric Noland, Erica Moreira, Evan Senter, Evgenii Eltyshev, Francesco Visin, Gabriel Rasskin, Gary Wei, Glenn Cameron, Gus Martins, Hadi Hashemi, Hanna Klimczak-Plucińska, Harleen Batra, Harsh Dhand, Ivan Nardini, Jacinda Mein, Jack Zhou, James Svensson, Jeff Stanway, Jetha Chan, Jin Peng Zhou, Joana Carrasqueira, Joana Iljazi, Jocelyn Becker, Joe Fernandez, Joost van Amersfoort, Josh Gordon, Josh Lipschultz, Josh Newlan, Ju-yeong Ji, Kareem Mohamed, Kartikeya Badola, Kat Black, Katie Millican, Keelin McDonell, Kelvin Nguyen, Kiranbir Sodhia, Kish Greene, Lars Lowe Sjoesund, Lauren Usui, Laurent Sifre, Lena Heuermann, Leticia Lago, Lilly McNealus, Livio Baldini Soares, Logan Kilpatrick, Lucas Dixon, Luciano Martins, Machel Reid, Manvinder Singh, Mark Iverson, Martin Görner, Mat Velloso, Mateo Wirth, Matt Davidow, Matt Miller, Matthew Rahtz, Matthew Watson, Meg Risdal, Mehran Kazemi, Michael Moynihan, Ming Zhang, Minsuk Kahng, Minwoo Park, Mofi Rahman, Mohit Khatwani, Natalie Dao, Nenshad Bardoliwalla, Nesh Devanathan, Neta Dumai, Nilay Chauhan, Oscar Wahltinez, Pankil Botarda, Parker Barnes, Paul Barham, Paul Michel, Pengchong Jin, Petko Georgiev, Phil Culliton, Pradeep Kuppala, Ramona Comanescu, Ramona Merhej, Reena Jana, Reza Ardeshir Rokni, Rishabh Agarwal, Ryan Mullins, Samaneh Saadat, Sara Mc Carthy, Sarah Cogan, Sarah Perrin, Sébastien M. R. Arnold, Sebastian Krause, Shengyang Dai, Shruti Garg, Shruti Sheth, Sue Ronstrom, Susan Chan, Timothy Jordan, Ting Yu, Tom Eccles, Tom Hennigan, Tomas Kocisky, Tulsee Doshi, Vihan Jain, Vikas Yadav, Vilobh Meshram, Vishal Dharmadhikari, Warren Barkley, Wei Wei, Wenming Ye, Woohyun Han, Woosuk Kwon, Xiang Xu, Zhe Shen, Zhitao Gong, Zichuan Wei, Victor Cotruta, Phoebe Kirk, Anand Rao, Minh Giang, Ludovic Peran, Tris Warkentin, Eli Collins, Joelle Barral, Zoubin Ghahramani, Raia Hadsell, D. Sculley, Jeanine Banks, Anca Dragan, Slav Petrov, Oriol Vinyals, Jeff Dean, Demis Hassabis, Koray Kavukcuoglu, Clement Farabet, Elena Buchatskaya, Sebastian Borgeaud, Noah Fiedel, Armand Joulin, Kathleen Kenealy, Robert Dadashi, Alek Andreev
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we introduce Gemma 2, a new addition to the Gemma family of
lightweight, state-of-the-art open models, ranging in scale from 2 billion to
27 billion parameters. In this new version, we apply several known technical
modifications to the Transformer architecture, such as interleaving
local-global attentions (Beltagy et al., 2020a) and group-query attention
(Ainslie et al., 2023). We also train the 2B and 9B models with knowledge
distillation (Hinton et al., 2015) instead of next token prediction. The
resulting models deliver the best performance for their size, and even offer
competitive alternatives to models that are 2-3 times bigger. We release all
our models to the community.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Reliable and diverse evaluation of LLM medical knowledge mastery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.14302v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.14302v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxuan Zhou, Xien Liu, Chen Ning, Xiao Zhang, Ji Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mastering medical knowledge is crucial for medical-specific LLMs. However,
despite the existence of medical benchmarks like MedQA, a unified framework
that fully leverages existing knowledge bases to evaluate LLMs' mastery of
medical knowledge is still lacking. In the study, we propose a novel framework
PretexEval that dynamically generates reliable and diverse test samples to
evaluate LLMs for any given medical knowledge base. We notice that test samples
produced directly from knowledge bases by templates or LLMs may introduce
factual errors and also lack diversity. To address these issues, we introduce a
novel schema into our proposed evaluation framework that employs predicate
equivalence transformations to produce a series of variants for any given
medical knowledge point. Finally, these produced predicate variants are
converted into textual language, resulting in a series of reliable and diverse
test samples to evaluate whether LLMs fully master the given medical factual
knowledge point. Here, we use our proposed framework to systematically
investigate the mastery of medical factual knowledge of 12 well-known LLMs,
based on two knowledge bases that are crucial for clinical diagnosis and
treatment. The evaluation results illustrate that current LLMs still exhibit
significant deficiencies in fully mastering medical knowledge, despite
achieving considerable success on some famous public benchmarks. These new
findings provide valuable insights for developing medical-specific LLMs,
highlighting that current LLMs urgently need to strengthen their comprehensive
and in-depth mastery of medical knowledge before being applied to real-world
medical scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ EEG-Language Modeling for Pathology Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.07480v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.07480v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sam Gijsen, Kerstin Ritter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal language modeling constitutes a recent breakthrough which
leverages advances in large language models to pretrain capable multimodal
models. The integration of natural language during pretraining has been shown
to significantly improve learned representations, particularly in computer
vision. However, the efficacy of multimodal language modeling in the realm of
functional brain data, specifically for advancing pathology detection, remains
unexplored. This study pioneers EEG-language models trained on clinical reports
and 15000 EEGs. We extend methods for multimodal alignment to this novel domain
and investigate which textual information in reports is useful for training
EEG-language models. Our results indicate that models learn richer
representations from being exposed to a variety of report segments, including
the patient's clinical history, description of the EEG, and the physician's
interpretation. Compared to models exposed to narrower clinical text
information, we find such models to retrieve EEGs based on clinical reports
(and vice versa) with substantially higher accuracy. Yet, this is only observed
when using a contrastive learning approach. Particularly in regimes with few
annotations, we observe that representations of EEG-language models can
significantly improve pathology detection compared to those of EEG-only models,
as demonstrated by both zero-shot classification and linear probes. In sum,
these results highlight the potential of integrating brain activity data with
clinical text, suggesting that EEG-language models represent significant
progress for clinical applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MallowsPO: Fine-Tune Your LLM with Preference Dispersions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.14953v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.14953v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoxian Chen, Hanyang Zhao, Henry Lam, David Yao, Wenpin Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Direct Preference Optimization (DPO) has recently emerged as a popular
approach to improve reinforcement learning with human feedback (RLHF), leading
to better techniques to fine-tune large language models (LLM). A weakness of
DPO, however, lies in its lack of capability to characterize the diversity of
human preferences. Inspired by Mallows' theory of preference ranking, we
develop in this paper a new approach, the MallowsPO. A distinct feature of this
approach is a dispersion index, which reflects the dispersion of human
preference to prompts. We show that existing DPO models can be reduced to
special cases of this dispersion index, thus unified with MallowsPO. More
importantly, we demonstrate (empirically) how to use this dispersion index to
enhance the performance of DPO in a broad array of benchmark tasks, from
synthetic bandit selection to controllable generations and dialogues, while
maintaining great generalization capabilities. MallowsPO is also compatible
with other SOTA offline preference optimization methods, boosting nearly 2\%
extra LC win rate when used as a plugin for fine-tuning Llama3-Instruct.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Heterogeneous Multi-Agent Reinforcement Learning for Zero-Shot Scalable
  Collaboration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.03869v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.03869v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xudong Guo, Daming Shi, Junjie Yu, Wenhui Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The emergence of multi-agent reinforcement learning (MARL) is significantly
transforming various fields like autonomous vehicle networks. However,
real-world multi-agent systems typically contain multiple roles, and the scale
of these systems dynamically fluctuates. Consequently, in order to achieve
zero-shot scalable collaboration, it is essential that strategies for different
roles can be updated flexibly according to the scales, which is still a
challenge for current MARL frameworks. To address this, we propose a novel MARL
framework named Scalable and Heterogeneous Proximal Policy Optimization
(SHPPO), integrating heterogeneity into parameter-shared PPO-based MARL
networks. We first leverage a latent network to learn strategy patterns for
each agent adaptively. Second, we introduce a heterogeneous layer to be
inserted into decision-making networks, whose parameters are specifically
generated by the learned latent variables. Our approach is scalable as all the
parameters are shared except for the heterogeneous layer, and gains both
inter-individual and temporal heterogeneity, allowing SHPPO to adapt
effectively to varying scales. SHPPO exhibits superior performance in classic
MARL environments like Starcraft Multi-Agent Challenge (SMAC) and Google
Research Football (GRF), showcasing enhanced zero-shot scalability, and
offering insights into the learned latent variables' impact on team performance
by visualization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multiple Heads are Better than One: Mixture of Modality Knowledge
  Experts for Entity Representation Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.16869v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.16869v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yichi Zhang, Zhuo Chen, Lingbing Guo, Yajing Xu, Binbin Hu, Ziqi Liu, Wen Zhang, Huajun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning high-quality multi-modal entity representations is an important goal
of multi-modal knowledge graph (MMKG) representation learning, which can
enhance reasoning tasks within the MMKGs, such as MMKG completion (MMKGC). The
main challenge is to collaboratively model the structural information concealed
in massive triples and the multi-modal features of the entities. Existing
methods focus on crafting elegant entity-wise multi-modal fusion strategies,
yet they overlook the utilization of multi-perspective features concealed
within the modalities under diverse relational contexts. To address this issue,
we introduce a novel framework with Mixture of Modality Knowledge experts
(MoMoK for short) to learn adaptive multi-modal entity representations for
better MMKGC. We design relation-guided modality knowledge experts to acquire
relation-aware modality embeddings and integrate the predictions from
multi-modalities to achieve joint decisions. Additionally, we disentangle the
experts by minimizing their mutual information. Experiments on four public MMKG
benchmarks demonstrate the outstanding performance of MoMoK under complex
scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress. Code and data will be released at
  https://github.com/zjukg/MoMoK</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CodeGRAG: Bridging the Gap between Natural Language and Programming
  Language via Graphical Retrieval Augmented Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.02355v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.02355v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kounianhua Du, Jizheng Chen, Renting Rui, Huacan Chai, Lingyue Fu, Wei Xia, Yasheng Wang, Ruiming Tang, Yong Yu, Weinan Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Utilizing large language models to generate codes has shown promising meaning
in software development revolution. Despite the intelligence shown by the
general large language models, their specificity in code generation can still
be improved due to the syntactic gap and mismatched vocabulary existing among
natural language and different programming languages. In this paper, we propose
CodeGRAG, a Graphical Retrieval Augmented Code Generation framework to enhance
the performance of LLMs. CodeGRAG builds the graphical view of code blocks
based on the control flow and data flow of them to fill the gap between
programming languages and natural language, which can facilitate natural
language based LLMs for better understanding of code syntax and serve as a
bridge among different programming languages. To take the extracted structural
knowledge into the foundation models, we propose 1) a hard meta-graph prompt
template to transform the challenging graphical representation into informative
knowledge for tuning-free models and 2) a soft prompting technique that injects
the domain knowledge of programming languages into the model parameters via
finetuning the models with the help of a pretrained GNN expert model. Various
experiments and ablations are done on four datasets including both the C++ and
python languages to validate the hard meta-graph prompt, the soft prompting
technique, and the effectiveness of the objectives for pretrained GNN expert.
CodeGRAG improves the code generation ability of LLMs and can even offer
performance gain for cross-lingual code generation. The implementation is
available at https://anonymous.4open.science/r/Code-5970/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ NuwaTS: a Foundation Model Mending Every Incomplete Time Series 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.15317v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.15317v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinguo Cheng, Chunwei Yang, Wanlin Cai, Yuxuan Liang, Qingsong Wen, Yuankai Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Time series imputation is critical for many real-world applications and has
been widely studied. However, existing models often require specialized designs
tailored to specific missing patterns, variables, or domains which limits their
generalizability. In addition, current evaluation frameworks primarily focus on
domain-specific tasks and often rely on time-wise train/validation/test data
splits, which fail to rigorously assess a model's ability to generalize across
unseen variables or domains. In this paper, we present \textbf{NuwaTS}, a novel
framework that repurposes Pre-trained Language Models (PLMs) for general time
series imputation. Once trained, NuwaTS can be applied to impute missing data
across any domain. We introduce specialized embeddings for each sub-series
patch, capturing information about the patch, its missing data patterns, and
its statistical characteristics. By combining contrastive learning with the
imputation task, we train PLMs to create a versatile, one-for-all imputation
model. Additionally, we employ a plug-and-play fine-tuning approach, enabling
efficient adaptation to domain-specific tasks with minimal adjustments. To
evaluate cross-variable and cross-domain generalization, we propose a new
benchmarking protocol that partitions the datasets along the variable
dimension. Experimental results on over seventeen million time series samples
from diverse domains demonstrate that NuwaTS outperforms state-of-the-art
domain-specific models across various datasets under the proposed benchmarking
protocol. Furthermore, we show that NuwaTS generalizes to other time series
tasks, such as forecasting. Our codes are available at
https://github.com/Chengyui/NuwaTS.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages, 14 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Comprehensive Graph Pooling Benchmark: Effectiveness, Robustness and
  Generalizability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.09031v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.09031v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pengyun Wang, Junyu Luo, Yanxin Shen, Ming Zhang, Siyu Heng, Xiao Luo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph pooling has gained attention for its ability to obtain effective node
and graph representations for various downstream tasks. Despite the recent
surge in graph pooling approaches, there is a lack of standardized experimental
settings and fair benchmarks to evaluate their performance. To address this
issue, we have constructed a comprehensive benchmark that includes 17 graph
pooling methods and 28 different graph datasets. This benchmark systematically
assesses the performance of graph pooling methods in three dimensions, i.e.,
effectiveness, robustness, and generalizability. We first evaluate the
performance of these graph pooling approaches across different tasks including
graph classification, graph regression and node classification. Then, we
investigate their performance under potential noise attacks and
out-of-distribution shifts in real-world scenarios. We also involve detailed
efficiency analysis, backbone analysis, parameter analysis and visualization to
provide more evidence. Extensive experiments validate the strong capability and
applicability of graph pooling approaches in various scenarios, which can
provide valuable insights and guidance for deep geometric learning research.
The source code of our benchmark is available at
https://github.com/goose315/Graph_Pooling_Benchmark.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ KnowTuning: Knowledge-aware Fine-tuning for Large Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.11176v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.11176v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yougang Lyu, Lingyong Yan, Shuaiqiang Wang, Haibo Shi, Dawei Yin, Pengjie Ren, Zhumin Chen, Maarten de Rijke, Zhaochun Ren
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite their success at many natural language processing (NLP) tasks, large
language models still struggle to effectively leverage knowledge for
knowledge-intensive tasks, manifesting limitations such as generating
incomplete, non-factual, or illogical answers. These limitations stem from
inadequate knowledge awareness of LLMs during vanilla fine-tuning. To address
these problems, we propose a knowledge-aware fine-tuning (KnowTuning) method to
improve fine-grained and coarse-grained knowledge awareness of LLMs. We devise
a fine-grained knowledge augmentation stage to train LLMs to identify difficult
fine-grained knowledge in answers. We also propose a coarse-grained knowledge
comparison stage to train LLMs to distinguish between reliable and unreliable
knowledge, in three aspects: completeness, factuality, and logicality.
Extensive experiments on both generic and medical question answering (QA)
datasets confirm the effectiveness of KnowTuning, through automatic and human
evaluations, across various sizes of LLMs. We further verify that KnowTuning
generates more facts with less factual error rate under fine-grained facts
evaluation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 main paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AutoPal: Autonomous Adaptation to Users for Personal AI Companisonship 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.13960v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.13960v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi Cheng, Wenge Liu, Kaishuai Xu, Wenjun Hou, Yi Ouyang, Chak Tou Leong, Xian Wu, Yefeng Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Previous research has demonstrated the potential of AI agents to act as
companions that can provide constant emotional support for humans. In this
paper, we emphasize the necessity of autonomous adaptation in personal AI
companionship, an underexplored yet promising direction. Such adaptability is
crucial as it can facilitate more tailored interactions with users and allow
the agent to evolve in response to users' changing needs. However, imbuing
agents with autonomous adaptability presents unique challenges, including
identifying optimal adaptations to meet users' expectations and ensuring a
smooth transition during the adaptation process. To address them, we devise a
hierarchical framework, AutoPal, that enables controllable and authentic
adjustments to the agent's persona based on user interactions. A
personamatching dataset is constructed to facilitate the learning of optimal
persona adaptations. Extensive experiments demonstrate the effectiveness of
AutoPal and highlight the importance of autonomous adaptability in AI
companionship.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Impact of Scanner Domain Shift on Deep Learning Performance in
  Medical Imaging: an Experimental Study 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04368v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04368v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Brian Guo, Darui Lu, Gregory Szumel, Rongze Gui, Tingyu Wang, Nicholas Konz, Maciej A. Mazurowski
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Purpose: Medical images acquired using different scanners and protocols can
differ substantially in their appearance. This phenomenon, scanner domain
shift, can result in a drop in the performance of deep neural networks which
are trained on data acquired by one scanner and tested on another. This
significant practical issue is well-acknowledged, however, no systematic study
of the issue is available across different modalities and diagnostic tasks.
Materials and Methods: In this paper, we present a broad experimental study
evaluating the impact of scanner domain shift on convolutional neural network
performance for different automated diagnostic tasks. We evaluate this
phenomenon in common radiological modalities, including X-ray, CT, and MRI.
Results: We find that network performance on data from a different scanner is
almost always worse than on same-scanner data, and we quantify the degree of
performance drop across different datasets. Notably, we find that this drop is
most severe for MRI, moderate for X-ray, and quite small for CT, on average,
which we attribute to the standardized nature of CT acquisition systems which
is not present in MRI or X-ray. We also study how injecting varying amounts of
target domain data into the training set, as well as adding noise to the
training data, helps with generalization. Conclusion: Our results provide
extensive experimental evidence and quantification of the extent of performance
drop caused by scanner domain shift in deep learning across different
modalities, with the goal of guiding the future development of robust deep
learning models for medical image analysis.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Opponent Shaping for Antibody Development 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.10588v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.10588v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sebastian Towers, Aleksandra Kalisz, Philippe A. Robert, Alicia Higueruelo, Francesca Vianello, Ming-Han Chloe Tsai, Harrison Steel, Jakob N. Foerster
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Anti-viral therapies are typically designed to target only the current
strains of a virus. Game theoretically, this corresponds to a short-sighted, or
myopic, response. However, therapy-induced selective pressures act on viruses
to drive the emergence of mutated strains, against which initial therapies have
reduced efficacy. Building on a computational model of binding between
antibodies and viral antigens (the Absolut! framework), we design and implement
a genetic simulation of viral evolutionary escape. Crucially, this allows our
antibody optimisation algorithm to consider and influence the entire escape
curve of the virus, i.e. to guide (or "shape") the viral evolution. This is
inspired by opponent shaping which, in general-sum learning, accounts for the
adaptation of the co-player rather than playing a myopic best response. Hence
we call the optimised antibodies shapers. Within our simulations, we
demonstrate that our shapers target both current and simulated future viral
variants, outperforming the antibodies chosen in a myopic way. Furthermore, we
show that shapers exert specific evolutionary pressure on the virus compared to
myopic antibodies. Altogether, shapers modify the evolutionary trajectories of
viral strains and minimise the viral escape compared to their myopic
counterparts. While this is a simplified model, we hope that our proposed
paradigm will facilitate the discovery of better long-lived vaccines and
antibody therapies in the future, enabled by rapid advancements in the
capabilities of simulation tools. Our code is available at
https://github.com/olakalisz/antibody-shapers.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ EfficientQAT: Efficient Quantization-Aware Training for Large Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11062v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11062v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mengzhao Chen, Wenqi Shao, Peng Xu, Jiahao Wang, Peng Gao, Kaipeng Zhang, Ping Luo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) are crucial in modern natural language
processing and artificial intelligence. However, they face challenges in
managing their significant memory requirements. Although quantization-aware
training (QAT) offers a solution by reducing memory consumption through low-bit
representations with minimal accuracy loss, it is impractical due to
substantial training resources. To address this, we propose Efficient
Quantization-Aware Training (EfficientQAT), a more feasible QAT algorithm.
EfficientQAT involves two consecutive phases: Block-wise training of all
parameters (Block-AP) and end-to-end training of quantization parameters
(E2E-QP). To the best of our knowledge, Block-AP is the first method to enable
direct training of all parameters in a block-wise manner, reducing accuracy
loss in low-bit scenarios by enhancing the solution space during optimization.
E2E-QP then trains only the quantization parameters (step sizes) end-to-end,
further improving the performance of quantized models by considering
interactions among all sub-modules. Extensive experiments demonstrate that
EfficientQAT outperforms previous quantization methods across a range of
models, including base LLMs, instruction-tuned LLMs, and multimodal LLMs, with
scales from 7B to 70B parameters at various quantization bits. For instance,
EfficientQAT obtains a 2-bit Llama-2-70B model on a single A100-80GB GPU in 41
hours, with less than 3 points accuracy degradation compared to the full
precision (69.48 vs. 72.41). Code is available at
https://github.com/OpenGVLab/EfficientQAT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>An efficient and effective quantization technical to improve the
  performance of low-bits LMMs and LVLMs</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unveiling the Invisible: Captioning Videos with Metaphors 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.04886v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.04886v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Abisek Rajakumar Kalarani, Pushpak Bhattacharyya, Sumit Shekhar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Metaphors are a common communication tool used in our day-to-day life. The
detection and generation of metaphors in textual form have been studied
extensively but metaphors in other forms have been under-explored. Recent
studies have shown that Vision-Language (VL) models cannot understand visual
metaphors in memes and adverts. As of now, no probing studies have been done
that involve complex language phenomena like metaphors with videos. Hence, we
introduce a new VL task of describing the metaphors present in the videos in
our work. To facilitate this novel task, we construct and release a manually
created dataset with 705 videos and 2115 human-written captions, along with a
new metric called Average Concept Distance (ACD), to automatically evaluate the
creativity of the metaphors generated. We also propose a novel low-resource
video metaphor captioning system: GIT-LLaVA, which obtains comparable
performance to SoTA video language models on the proposed task. We perform a
comprehensive analysis of existing video language models on this task and
publish our dataset, models, and benchmark results to enable further research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Motion meets Attention: Video Motion <span class="highlight-title">Prompt</span>s <span class="chip">ACML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.03179v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.03179v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qixiang Chen, Lei Wang, Piotr Koniusz, Tom Gedeon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Videos contain rich spatio-temporal information. Traditional methods for
extracting motion, used in tasks such as action recognition, often rely on
visual contents rather than precise motion features. This phenomenon is
referred to as 'blind motion extraction' behavior, which proves inefficient in
capturing motions of interest due to a lack of motion-guided cues. Recently,
attention mechanisms have enhanced many computer vision tasks by effectively
highlighting salient visual areas. Inspired by this, we propose a modified
Sigmoid function with learnable slope and shift parameters as an attention
mechanism to modulate motion signals from frame differencing maps. This
approach generates a sequence of attention maps that enhance the processing of
motion-related video content. To ensure temporal continuity and smoothness of
the attention maps, we apply pair-wise temporal attention variation
regularization to remove unwanted motions (e.g., noise) while preserving
important ones. We then perform Hadamard product between each pair of attention
maps and the original video frames to highlight the evolving motions of
interest over time. These highlighted motions, termed video motion prompts, are
subsequently used as inputs to the model instead of the original video frames.
We formalize this process as a motion prompt layer and incorporate the
regularization term into the loss function to learn better motion prompts. This
layer serves as an adapter between the model and the video data, bridging the
gap between traditional 'blind motion extraction' and the extraction of
relevant motions of interest. We show that our lightweight, plug-and-play
motion prompt layer seamlessly integrates into models like SlowFast, X3D, and
TimeSformer, enhancing performance on benchmarks such as FineGym and MPII
Cooking 2.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at the 16th Asian Conference on Machine Learning (ACML 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Cost-Effective Online Multi-LLM Selection with Versatile Reward Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.16587v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.16587v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangxiang Dai, Jin Li, Xutong Liu, Anqi Yu, John C. S. Lui
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid advancement of large language models (LLMs), the diversity of
multi-LLM tasks and the variability in their pricing structures have become
increasingly important, as costs can vary greatly between different LLMs. To
tackle these challenges, we introduce the \textit{C2MAB-V}, a
\underline{C}ost-effective \underline{C}ombinatorial \underline{M}ulti-armed
\underline{B}andit with \underline{V}ersatile reward models for optimal LLM
selection and usage. This online model differs from traditional static
approaches or those reliant on a single LLM without cost consideration. With
multiple LLMs deployed on a scheduling cloud and a local server dedicated to
handling user queries, \textit{C2MAB-V} facilitates the selection of multiple
LLMs over a combinatorial search space, specifically tailored for various
collaborative task types with different reward models. Based on our designed
online feedback mechanism and confidence bound technique, \textit{C2MAB-V} can
effectively address the multi-LLM selection challenge by managing the
exploration-exploitation trade-off across different models, while also
balancing cost and reward for diverse tasks. The NP-hard integer linear
programming problem for selecting multiple LLMs with trade-off dilemmas is
addressed by: i) decomposing the integer problem into a relaxed form by the
local server, ii) utilizing a discretization rounding scheme that provides
optimal LLM combinations by the scheduling cloud, and iii) continual online
updates based on feedback. Theoretically, we prove that \textit{C2MAB-V} offers
strict guarantees over versatile reward models, matching state-of-the-art
results for regret and violations in some degenerate cases. Empirically, we
show that \textit{C2MAB-V} effectively balances performance and cost-efficiency
with nine LLMs for three application scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>32 pages, 14 figures, conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DeTPP: Leveraging Object Detection for Robust Long-Horizon Event
  Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.13131v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.13131v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ivan Karpukhin, Andrey Savchenko
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Long-horizon event forecasting is critical across various domains, including
retail, finance, healthcare, and social networks. Traditional methods, such as
Marked Temporal Point Processes (MTPP), often rely on autoregressive models to
predict multiple future events. However, these models frequently suffer from
issues like converging to constant or repetitive outputs, which limits their
effectiveness and general applicability. To address these challenges, we
introduce DeTPP (Detection-based Temporal Point Processes), a novel approach
inspired by object detection techniques from computer vision. DeTPP employs a
unique matching-based loss function that selectively prioritizes reliably
predictable events, improving the accuracy and diversity of predictions during
inference. Our method establishes a new state-of-the-art in long-horizon event
forecasting, achieving up to a 77% relative improvement over existing MTPP and
next-K methods. The proposed hybrid approach enhances the accuracy of next
event prediction by up to 2.7% on a large transactional dataset. Notably, DeTPP
is also among the fastest methods for inference. The implementation of DeTPP is
publicly available on GitHub.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Judging the Judges: A Systematic Investigation of Position Bias in
  Pairwise Comparative Assessments by LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.07791v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.07791v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lin Shi, Chiyu Ma, Wenhua Liang, Weicheng Ma, Soroush Vosoughi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLM-as-a-Judge presents a promising alternative to human evaluators across
various tasks, but inherent biases, especially position bias - a tendency to
favor solutions based on their position in the prompt - have compromised its
effectiveness. Our study introduces a systematic framework to examine position
bias in pairwise comparisons, focusing on repetition stability, position
consistency, and preference fairness. This research significantly contributes
to the field by introducing new concepts for understanding position bias and
providing a multi-dimensional framework for evaluations. We conducted
experiments with 12 LLM judges across MTBench and DevBench, covering 22 tasks
and approximately 40 solution-generating models - candidates, resulting in over
100,000 evaluation instances. Our findings confirm that position bias in
capable LLM judges is not due to random chances, along with notable variations
observed across judges and tasks. Moreover, position bias is weakly influenced
by the length of prompt components but significantly impacted by the quality
gap between solutions. These insights can help optimize judge model selections,
improve benchmark design, and inform future research on debiasing strategies,
ultimately enhancing the reliability of LLM judges.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Optimal Causal Representations and the Causal Information Bottleneck <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00535v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00535v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Francisco N. F. Q. Simoes, Mehdi Dastani, Thijs van Ommen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To effectively study complex causal systems, it is often useful to construct
representations that simplify parts of the system by discarding irrelevant
details while preserving key features. The Information Bottleneck (IB) method
is a widely used approach in representation learning that compresses random
variables while retaining information about a target variable. Traditional
methods like IB are purely statistical and ignore underlying causal structures,
making them ill-suited for causal tasks. We propose the Causal Information
Bottleneck (CIB), a causal extension of the IB, which compresses a set of
chosen variables while maintaining causal control over a target variable. This
method produces representations which are causally interpretable, and which can
be used when reasoning about interventions. We present experimental results
demonstrating that the learned representations accurately capture causality as
intended.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to ICLR 2025. Code available at
  github.com/francisco-simoes/cib-optimization-psagd</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Training-Free Message Passing for Learning on Hypergraphs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.05569v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.05569v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bohan Tang, Zexi Liu, Keyue Jiang, Siheng Chen, Xiaowen Dong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Hypergraphs are crucial for modelling higher-order interactions in real-world
data. Hypergraph neural networks (HNNs) effectively utilise these structures by
message passing to generate informative node features for various downstream
tasks like node classification. However, the message passing module in existing
HNNs typically requires a computationally intensive training process, which
limits their practical use. To tackle this challenge, we propose an alternative
approach by decoupling the usage of hypergraph structural information from the
model learning stage. This leads to a novel training-free message passing
module, named TF-MP-Module, which can be precomputed in the data preprocessing
stage, thereby reducing the computational burden. We refer to the hypergraph
neural network equipped with our TF-MP-Module as TF-HNN. We theoretically
support the efficiency and effectiveness of TF-HNN by showing that: 1) It is
more training-efficient compared to existing HNNs; 2) It utilises as much
information as existing HNNs for node feature generation; and 3) It is robust
against the oversmoothing issue while using long-range interactions.
Experiments based on seven real-world hypergraph benchmarks in node
classification and hyperlink prediction show that, compared to state-of-the-art
HNNs, TF-HNN exhibits both competitive performance and superior training
efficiency. Specifically, on the large-scale benchmark, Trivago, TF-HNN
outperforms the node classification accuracy of the best baseline by 10% with
just 1% of the training time of that baseline.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Rapid Gyroscope Calibration: A Deep Learning Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.00488v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.00488v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yair Stolero, Itzik Klein
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low-cost gyroscope calibration is essential for ensuring the accuracy and
reliability of gyroscope measurements. Stationary calibration estimates the
deterministic parts of measurement errors. To this end, a common practice is to
average the gyroscope readings during a predefined period and estimate the
gyroscope bias. Calibration duration plays a crucial role in performance,
therefore, longer periods are preferred. However, some applications require
quick startup times and calibration is therefore allowed only for a short time.
In this work, we focus on reducing low-cost gyroscope calibration time using
deep learning methods. We propose a deep-learning framework and explore the
possibilities of using multiple real and virtual gyroscopes to improve the
calibration performance of single gyroscopes. To train and validate our
approach, we recorded a dataset consisting of 169 hours of gyroscope readings,
using 24 gyroscopes of two different brands. We also created a virtual dataset
consisting of simulated gyroscope readings. The two datasets were used to
evaluate our proposed approach. One of our key achievements in this work is
reducing gyroscope calibration time by up to 89% using three low-cost
gyroscopes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 Pages, 14 Figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Large Language Model Confidence Estimation via Black-Box Access 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.04370v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.04370v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tejaswini Pedapati, Amit Dhurandhar, Soumya Ghosh, Soham Dan, Prasanna Sattigeri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Estimating uncertainty or confidence in the responses of a model can be
significant in evaluating trust not only in the responses, but also in the
model as a whole. In this paper, we explore the problem of estimating
confidence for responses of large language models (LLMs) with simply black-box
or query access to them. We propose a simple and extensible framework where, we
engineer novel features and train a (interpretable) model (viz. logistic
regression) on these features to estimate the confidence. We empirically
demonstrate that our simple framework is effective in estimating confidence of
Flan-ul2, Llama-13b and Mistral-7b on four benchmark Q\&A tasks as well as of
Pegasus-large and BART-large on two benchmark summarization tasks with it
surpassing baselines by even over $10\%$ (on AUROC) in some cases.
Additionally, our interpretable approach provides insight into features that
are predictive of confidence, leading to the interesting and useful discovery
that our confidence models built for one LLM generalize zero-shot across others
on a given dataset.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ArtVLM: Attribute Recognition Through Vision-Based Prefix Language
  Modeling <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.04102v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.04102v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        William Yicheng Zhu, Keren Ye, Junjie Ke, Jiahui Yu, Leonidas Guibas, Peyman Milanfar, Feng Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recognizing and disentangling visual attributes from objects is a foundation
to many computer vision applications. While large vision language
representations like CLIP had largely resolved the task of zero-shot object
recognition, zero-shot visual attribute recognition remains a challenge because
CLIP's contrastively-learned vision-language representation cannot effectively
capture object-attribute dependencies. In this paper, we target this weakness
and propose a sentence generation-based retrieval formulation for attribute
recognition that is novel in 1) explicitly modeling a to-be-measured and
retrieved object-attribute relation as a conditional probability graph, which
converts the recognition problem into a dependency-sensitive language-modeling
problem, and 2) applying a large pretrained Vision-Language Model (VLM) on this
reformulation and naturally distilling its knowledge of image-object-attribute
relations to use towards attribute recognition. Specifically, for each
attribute to be recognized on an image, we measure the visual-conditioned
probability of generating a short sentence encoding the attribute's relation to
objects on the image. Unlike contrastive retrieval, which measures likelihood
by globally aligning elements of the sentence to the image, generative
retrieval is sensitive to the order and dependency of objects and attributes in
the sentence. We demonstrate through experiments that generative retrieval
consistently outperforms contrastive retrieval on two visual reasoning
datasets, Visual Attribute in the Wild (VAW), and our newly-proposed Visual
Genome Attribute Ranking (VGARank).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ECCV 2024. Contact: zhuwilliam[at]google[dot]com. GitHub:
  https://github.com/google-research/google-research/tree/master/attribute_with_prefixlm</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Understanding the Training and Generalization of <span class="highlight-title">Pretrain</span>ed <span class="highlight-title">Transformer</span>
  for Sequential Decision Making 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.14219v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.14219v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hanzhao Wang, Yu Pan, Fupeng Sun, Shang Liu, Kalyan Talluri, Guanting Chen, Xiaocheng Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we consider the supervised pre-trained transformer for a class
of sequential decision-making problems. The class of considered problems is a
subset of the general formulation of reinforcement learning in that there is no
transition probability matrix; though seemingly restrictive, the subset class
of problems covers bandits, dynamic pricing, and newsvendor problems as special
cases. Such a structure enables the use of optimal actions/decisions in the
pre-training phase, and the usage also provides new insights for the training
and generalization of the pre-trained transformer. We first note the training
of the transformer model can be viewed as a performative prediction problem,
and the existing methods and theories largely ignore or cannot resolve an
out-of-distribution issue. We propose a natural solution that includes the
transformer-generated action sequences in the training procedure, and it enjoys
better properties both numerically and theoretically. The availability of the
optimal actions in the considered tasks also allows us to analyze the
properties of the pre-trained transformer as an algorithm and explains why it
may lack exploration and how this can be automatically resolved. Numerically,
we categorize the advantages of pre-trained transformers over the structured
algorithms such as UCB and Thompson sampling into three cases: (i) it better
utilizes the prior knowledge in the pre-training data; (ii) it can elegantly
handle the misspecification issue suffered by the structured algorithms; (iii)
for short time horizon such as $T\le50$, it behaves more greedy and enjoys much
better regret than the structured algorithms designed for asymptotic
optimality.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">GPT</span> vs RETRO: Exploring the Intersection of Retrieval and
  Parameter-Efficient Fine-Tuning <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.04528v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.04528v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aleksander Ficek, Jiaqi Zeng, Oleksii Kuchaiev
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Parameter-Efficient Fine-Tuning (PEFT) and Retrieval-Augmented Generation
(RAG) have become popular methods for adapting large language models while
minimizing compute requirements. In this paper, we apply PEFT methods
(P-tuning, Adapters, and LoRA) to a modified Retrieval-Enhanced Transformer
(RETRO) and a baseline GPT model across several sizes, ranging from 823 million
to 48 billion parameters. We show that RETRO models outperform GPT models in
zero-shot settings due to their unique pre-training process but GPT models have
higher performance potential with PEFT. Additionally, our study indicates that
8B parameter models strike an optimal balance between cost and performance and
P-tuning lags behind other PEFT techniques. We further provide a comparative
analysis between applying PEFT to an Instruction-tuned RETRO model and base
RETRO model. This work presents the first comprehensive comparison of various
PEFT methods integrated with RAG, applied to both GPT and RETRO models,
highlighting their relative performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evaluating Large Language Models Using Contrast Sets: An Experimental
  Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.01569v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.01569v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manish Sanwal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the domain of Natural Language Inference (NLI), especially in tasks
involving the classification of multiple input texts, the Cross-Entropy Loss
metric is widely employed as a standard for error measurement. However, this
metric falls short in effectively evaluating a model's capacity to understand
language entailments. In this study, we introduce an innovative technique for
generating a contrast set for the Stanford Natural Language Inference (SNLI)
dataset. Our strategy involves the automated substitution of verbs, adverbs,
and adjectives with their synonyms to preserve the original meaning of
sentences. This method aims to assess whether a model's performance is based on
genuine language comprehension or simply on pattern recognition. We conducted
our analysis using the ELECTRA-small model. The model achieved an accuracy of
89.9% on the conventional SNLI dataset but showed a reduced accuracy of 72.5%
on our contrast set, indicating a substantial 17% decline. This outcome led us
to conduct a detailed examination of the model's learning behaviors. Following
this, we improved the model's resilience by fine-tuning it with a
contrast-enhanced training dataset specifically designed for SNLI, which
increased its accuracy to 85.5% on the contrast sets. Our findings highlight
the importance of incorporating diverse linguistic expressions into datasets
for NLI tasks. We hope that our research will encourage the creation of more
inclusive datasets, thereby contributing to the development of NLI models that
are both more sophisticated and effective.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning Explainable and Better Performing Representations of POMDP
  Strategies 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.07656v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.07656v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexander Bork, Debraj Chakraborty, Kush Grover, Jan Kretinsky, Stefanie Mohr
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Strategies for partially observable Markov decision processes (POMDP)
typically require memory. One way to represent this memory is via automata. We
present a method to learn an automaton representation of a strategy using a
modification of the L*-algorithm. Compared to the tabular representation of a
strategy, the resulting automaton is dramatically smaller and thus also more
explainable. Moreover, in the learning process, our heuristics may even improve
the strategy's performance. In contrast to approaches that synthesize an
automaton directly from the POMDP thereby solving it, our approach is
incomparably more scalable.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical report for the submission to TACAS 24</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SAAS: Solving Ability Amplification Strategy for Enhanced Mathematical
  Reasoning in Large Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.03887v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.03887v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hyeonwoo Kim, Gyoungjin Gim, Yungi Kim, Jihoo Kim, Byungju Kim, Wonseok Lee, Chanjun Park
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study presents a novel learning approach designed to enhance both
mathematical reasoning and problem-solving abilities of Large Language Models
(LLMs). We focus on integrating the Chain-of-Thought (CoT) and the
Program-of-Thought (PoT) learning, hypothesizing that prioritizing the learning
of mathematical reasoning ability is helpful for the amplification of
problem-solving ability. Thus, the initial learning with CoT is essential for
solving challenging mathematical problems. To this end, we propose a sequential
learning approach, named SAAS (Solving Ability Amplification Strategy), which
strategically transitions from CoT learning to PoT learning. Our empirical
study, involving an extensive performance comparison using several benchmarks,
demonstrates that our SAAS achieves state-of-the-art (SOTA) performance. The
results underscore the effectiveness of our sequential learning approach,
marking a significant advancement in the field of mathematical reasoning in
LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Industry Track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Document-Level In-Context Few-Shot Relation Extraction via <span class="highlight-title">Pre-Train</span>ed
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.11085v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.11085v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yilmazcan Ozyurt, Stefan Feuerriegel, Ce Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Document-level relation extraction aims at inferring structured human
knowledge from textual documents. State-of-the-art methods for this task use
pre-trained language models (LMs) via fine-tuning, yet fine-tuning is
computationally expensive and cannot adapt to new relation types or new LMs. As
a remedy, we leverage the generalization capabilities of pre-trained LMs and
present a novel framework for document-level in-context few-shot relation
extraction. Our framework has three strengths: it eliminates the need (1) for
named entity recognition and (2) for human annotations of documents, and (3) it
can be updated to new LMs without re-training. We evaluate our framework using
DocRED, the largest publicly available dataset for document-level relation
extraction, and demonstrate that our framework achieves state-of-the-art
performance. We further show that our framework actually performs much better
than the original labels from the development set of DocRED. Finally, we
conduct an extensive benchmark demonstrating the effectiveness of our
framework, achieving state-of-the-art results across six relation extraction
datasets and outperforming more than 30 baseline methods. Unlike our framework,
the baseline methods have large computational overhead (e.g., from
fine-tuning). To the best of our knowledge, we are the first to reformulate the
document-level relation extraction task as a tailored in-context few-shot
learning paradigm.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Open-Set Graph Anomaly Detection via Normal Structure Regularisation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.06835v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.06835v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qizhou Wang, Guansong Pang, Mahsa Salehi, Xiaokun Xia, Christopher Leckie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper considers an important Graph Anomaly Detection (GAD) task, namely
open-set GAD, which aims to train a detection model using a small number of
normal and anomaly nodes (referred to as seen anomalies) to detect both seen
anomalies and unseen anomalies (i.e., anomalies that cannot be illustrated the
training anomalies). Those labelled training data provide crucial prior
knowledge about abnormalities for GAD models, enabling substantially reduced
detection errors. However, current supervised GAD methods tend to
over-emphasise fitting the seen anomalies, leading to many errors of detecting
the unseen anomalies as normal nodes. Further, existing open-set AD models were
introduced to handle Euclidean data, failing to effectively capture
discriminative features from graph structure and node attributes for GAD. In
this work, we propose a novel open-set GAD approach, namely normal structure
regularisation (NSReg), to achieve generalised detection ability to unseen
anomalies, while maintaining its effectiveness on detecting seen anomalies. The
key idea in NSReg is to introduce a regularisation term that enforces the
learning of compact, semantically-rich representations of normal nodes based on
their structural relations to other nodes. When being optimised with supervised
anomaly detection losses, the regularisation term helps incorporate strong
normality into the modelling, and thus, it effectively avoids over-fitting the
seen anomalies and learns a better normality decision boundary, largely
reducing the false negatives of detecting unseen anomalies as normal. Extensive
empirical results on seven real-world datasets show that NSReg significantly
outperforms state-of-the-art competing methods by at least 14% AUC-ROC on the
unseen anomaly classes and by 10% AUC-ROC on all anomaly classes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CyberCortex.AI: An AI-based Operating System for Autonomous Robotics and
  Complex Automation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.01241v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.01241v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sorin Grigorescu, Mihai Zaha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The underlying framework for controlling autonomous robots and complex
automation applications are Operating Systems (OS) capable of scheduling
perception-and-control tasks, as well as providing real-time data communication
to other robotic peers and remote cloud computers. In this paper, we introduce
CyberCortex AI, a robotics OS designed to enable heterogeneous AI-based
robotics and complex automation applications. CyberCortex AI is a decentralized
distributed OS which enables robots to talk to each other, as well as to High
Performance Computers (HPC) in the cloud. Sensory and control data from the
robots is streamed towards HPC systems with the purpose of training AI
algorithms, which are afterwards deployed on the robots. Each functionality of
a robot (e.g. sensory data acquisition, path planning, motion control, etc.) is
executed within a so-called DataBlock of Filters shared through the internet,
where each filter is computed either locally on the robot itself, or remotely
on a different robotic system. The data is stored and accessed via a so-called
Temporal Addressable Memory (TAM), which acts as a gateway between each
filter's input and output. CyberCortex.AI has two main components: i) the
CyberCortex AI inference system, which is a real-time implementation of the
DataBlock running on the robots' embedded hardware, and ii) the CyberCortex AI
dojo, which runs on an HPC computer in the cloud, and it is used to design,
train and deploy AI algorithms. We present a quantitative and qualitative
performance analysis of the proposed approach using two collaborative robotics
applications: i) a forest fires prevention system based on an Unitree A1 legged
robot and an Anafi Parrot 4K drone, as well as ii) an autonomous driving system
which uses CyberCortex.AI for collaborative perception and motion control.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Model-based Preference Optimization in Abstractive Summarization without
  Human Feedback <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18618v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18618v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jaepill Choi, Kyubyung Chae, Jiwoo Song, Yohan Jo, Taesup Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In abstractive summarization, the challenge of producing concise and accurate
summaries arises from the vast amount of information contained in the source
document. Consequently, although Large Language Models (LLMs) can generate
fluent text, they often introduce inaccuracies by hallucinating content not
found in the original source. While supervised fine-tuning methods that
maximize likelihood contribute to this issue, they do not consistently enhance
the faithfulness of the summaries. Preference-based optimization methods, such
as Direct Preference Optimization (DPO), can further refine the model to align
with human preferences. However, these methods still heavily depend on costly
human feedback. In this work, we introduce a novel and straightforward approach
called Model-based Preference Optimization (MPO) to fine-tune LLMs for improved
summarization abilities without any human feedback. By leveraging the model's
inherent summarization capabilities, we create a preference dataset that is
fully generated by the model using different decoding strategies. Our
experiments on standard summarization datasets and various metrics demonstrate
that our proposed MPO significantly enhances the quality of generated summaries
without relying on human feedback.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ An LLM Feature-based Framework for Dialogue Constructiveness Assessment <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14760v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14760v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lexin Zhou, Youmna Farag, Andreas Vlachos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Research on dialogue constructiveness assessment focuses on (i) analysing
conversational factors that influence individuals to take specific actions, win
debates, change their perspectives or broaden their open-mindedness and (ii)
predicting constructiveness outcomes following dialogues for such use cases.
These objectives can be achieved by training either interpretable feature-based
models (which often involve costly human annotations) or neural models such as
pre-trained language models (which have empirically shown higher task accuracy
but lack interpretability). In this paper we propose an LLM feature-based
framework for dialogue constructiveness assessment that combines the strengths
of feature-based and neural approaches, while mitigating their downsides. The
framework first defines a set of dataset-independent and interpretable
linguistic features, which can be extracted by both prompting an LLM and simple
heuristics. Such features are then used to train LLM feature-based models. We
apply this framework to three datasets of dialogue constructiveness and find
that our LLM feature-based models outperform or performs at least as well as
standard feature-based models and neural models. We also find that the LLM
feature-based model learns more robust prediction rules instead of relying on
superficial shortcuts, which often trouble neural models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Paper accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Leveraging the Context through Multi-Round Interactions for Jailbreaking
  Attacks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.09177v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.09177v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yixin Cheng, Markos Georgopoulos, Volkan Cevher, Grigorios G. Chrysos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are susceptible to Jailbreaking attacks, which
aim to extract harmful information by subtly modifying the attack query. As
defense mechanisms evolve, directly obtaining harmful information becomes
increasingly challenging for Jailbreaking attacks. In this work, inspired from
Chomsky's transformational-generative grammar theory and human practices of
indirect context to elicit harmful information, we focus on a new attack form,
called Contextual Interaction Attack. We contend that the prior
context\u2014the information preceding the attack query\u2014plays a pivotal
role in enabling strong Jailbreaking attacks. Specifically, we propose a first
multi-turn approach that leverages benign preliminary questions to interact
with the LLM. Due to the autoregressive nature of LLMs, which use previous
conversation rounds as context during generation, we guide the model's
question-response pair to construct a context that is semantically aligned with
the attack query to execute the attack. We conduct experiments on seven
different LLMs and demonstrate the efficacy of this attack, which is black-box
and can also transfer across LLMs. We believe this can lead to further
developments and understanding of security in LLMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>29 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring Scalability of Self-Training for Open-Vocabulary Temporal
  Action Localization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.07024v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.07024v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jeongseok Hyun, Su Ho Han, Hyolim Kang, Joon-Young Lee, Seon Joo Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The vocabulary size in temporal action localization (TAL) is limited by the
scarcity of large-scale annotated datasets. To overcome this, recent works
integrate vision-language models (VLMs), such as CLIP, for open-vocabulary TAL
(OV-TAL). However, despite the success of VLMs trained on extensive datasets,
existing OV-TAL methods still rely on human-labeled TAL datasets of limited
size to train action localizers, limiting their generalizability. In this
paper, we explore the scalability of self-training with unlabeled YouTube
videos for OV-TAL. Our approach consists of two stages: (1) a class-agnostic
action localizer is trained on a human-labeled TAL dataset to generate
pseudo-labels for unlabeled videos, and (2) the large-scale pseudo-labeled
dataset is then used to train the localizer. Extensive experiments demonstrate
that leveraging web-scale videos in self-training significantly enhances the
generalizability of an action localizer. Additionally, we identify limitations
in existing OV-TAL evaluation schemes and propose a new benchmark for thorough
assessment. Finally, we showcase the TAL performance of the large multimodal
model Gemini-1.5 on our new benchmark. Code is released at
https://github.com/HYUNJS/STOV-TAL.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Conditional Diffusion on Web-Scale Image Pairs leads to Diverse Image
  Variations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.14857v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.14857v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manoj Kumar, Neil Houlsby, Emiel Hoogeboom
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating image variations, where a model produces variations of an input
image while preserving the semantic context has gained increasing attention.
Current image variation techniques involve adapting a text-to-image model to
reconstruct an input image conditioned on the same image. We first demonstrate
that a diffusion model trained to reconstruct an input image from frozen
embeddings, can reconstruct the image with minor variations. Second, inspired
by how text-to-image models learn from web-scale text-image pairs, we explore a
new pretraining strategy to generate image variations using a large collection
of image pairs. Our diffusion model \textit{Semantica} receives a random
(encoded) image from a webpage as conditional input and denoises another noisy
random image from the same webpage. We carefully examine various design choices
for the image encoder, given its crucial role in extracting relevant context
from the input image. Once trained, \textit{Semantica} can adaptively generate
new images from a dataset by simply using images from that dataset as input.
Finally, we identify limitations in standard image consistency metrics for
evaluating image variations and propose alternative metrics based on few-shot
generation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DreamCatalyst: Fast and High-Quality 3D Editing via Controlling
  Editability and Identity Preservation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11394v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11394v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiwook Kim, Seonho Lee, Jaeyo Shin, Jiho Choi, Hyunjung Shim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Score distillation sampling (SDS) has emerged as an effective framework in
text-driven 3D editing tasks, leveraging diffusion models for 3D consistent
editing. However, existing SDS-based 3D editing methods suffer from long
training times and produce low-quality results. We identify that the root cause
of this performance degradation is their conflict with the sampling dynamics of
diffusion models. Addressing this conflict allows us to treat SDS as a
diffusion reverse process for 3D editing via sampling from data space. In
contrast, existing methods naively distill the score function using diffusion
models. From these insights, we propose DreamCatalyst, a novel framework that
considers these sampling dynamics in the SDS framework. Specifically, we devise
the optimization process of our DreamCatalyst to approximate the diffusion
reverse process in editing tasks, thereby aligning with diffusion sampling
dynamics. As a result, DreamCatalyst successfully reduces training time and
improves editing quality. Our method offers two modes: (1) a fast mode that
edits Neural Radiance Fields (NeRF) scenes approximately 23 times faster than
current state-of-the-art NeRF editing methods, and (2) a high-quality mode that
produces superior results about 8 times faster than these methods. Notably, our
high-quality mode outperforms current state-of-the-art NeRF editing methods in
terms of both speed and quality. DreamCatalyst also surpasses the
state-of-the-art 3D Gaussian Splatting (3DGS) editing methods, establishing
itself as an effective and model-agnostic 3D editing solution. See more
extensive results on our project page: https://dream-catalyst.github.io.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ProjectPage: https://dream-catalyst.github.io Code:
  https://github.com/kaist-cvml/DreamCatalyst (Appendix included)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Cross-Domain Content Generation with Domain-Specific Small Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.17171v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.17171v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ankit Maloo, Abhinav Garg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generating domain-specific content using small language models poses
challenges, especially when dealing with multiple distinct datasets with
minimal overlap. In this study, we explore methods to enable a small language
model to produce coherent and relevant outputs for two different domains:
stories (Dataset A) and recipes (Dataset B). Our initial experiments show that
training individual models on each dataset yields satisfactory results, with
each model generating appropriate content within its domain. We find that
utilizing custom tokenizers tailored to each dataset significantly enhances
generation quality compared to using a generic tokenizer. Attempts to adapt a
single model to both domains using Low-Rank Adaptation (LoRA) or standard
fine-tuning do not yield substantial results, often failing to produce
meaningful outputs. Moreover, full fine-tuning without freezing the model's
existing weights leads to catastrophic forgetting, where the model loses
previously learned information and only retains knowledge from the new data. To
overcome these challenges, we employ a knowledge expansion strategy: training
only with additional parameters. This approach enables the model to generate
both stories and recipes upon request, effectively handling multiple domains
without suffering from catastrophic forgetting. Our findings demonstrate that
knowledge expansion with frozen layers is an effective method for small
language models to generate domain-specific content across distinct datasets.
This work contributes to the development of efficient multi-domain language
models and provides insights into managing catastrophic forgetting in
small-scale architectures.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Conditional Independence Test in the Presence of Discretization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.17644v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.17644v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Boyang Sun, Yu Yao, Huangyuan Hao, Yumou Qiu, Kun Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Testing conditional independence has many applications, such as in Bayesian
network learning and causal discovery. Different test methods have been
proposed. However, existing methods generally can not work when only
discretized observations are available. Specifically, consider $X_1$,
$\tilde{X}_2$ and $X_3$ are observed variables, where $\tilde{X}_2$ is a
discretization of latent variables $X_2$. Applying existing test methods to the
observations of $X_1$, $\tilde{X}_2$ and $X_3$ can lead to a false conclusion
about the underlying conditional independence of variables $X_1$, $X_2$ and
$X_3$. Motivated by this, we propose a conditional independence test
specifically designed to accommodate the presence of such discretization. To
achieve this, we design the bridge equations to recover the parameter
reflecting the statistical information of the underlying latent continuous
variables. An appropriate test statistic and its asymptotic distribution under
the null hypothesis of conditional independence have also been derived. Both
theoretical results and empirical validation have been provided, demonstrating
the effectiveness of our test methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RMLR: Extending Multinomial Logistic Regression into General Geometries <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19433v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19433v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziheng Chen, Yue Song, Rui Wang, Xiaojun Wu, Nicu Sebe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Riemannian neural networks, which extend deep learning techniques to
Riemannian spaces, have gained significant attention in machine learning. To
better classify the manifold-valued features, researchers have started
extending Euclidean multinomial logistic regression (MLR) into Riemannian
manifolds. However, existing approaches suffer from limited applicability due
to their strong reliance on specific geometric properties. This paper proposes
a framework for designing Riemannian MLR over general geometries, referred to
as RMLR. Our framework only requires minimal geometric properties, thus
exhibiting broad applicability and enabling its use with a wide range of
geometries. Specifically, we showcase our framework on the Symmetric Positive
Definite (SPD) manifold and special orthogonal group, i.e., the set of rotation
matrices. On the SPD manifold, we develop five families of SPD MLRs under five
types of power-deformed metrics. On rotation matrices we propose Lie MLR based
on the popular bi-invariant metric. Extensive experiments on different
Riemannian backbone networks validate the effectiveness of our framework.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Scrutinize What We Ignore: Reining In Task Representation Shift Of
  Context-Based Offline Meta Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.12001v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.12001v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hai Zhang, Boyuan Zheng, Tianying Ji, Jinhang Liu, Anqi Guo, Junqiao Zhao, Lanqing Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Offline meta reinforcement learning (OMRL) has emerged as a promising
approach for interaction avoidance and strong generalization performance by
leveraging pre-collected data and meta-learning techniques. Previous
context-based approaches predominantly rely on the intuition that alternating
optimization between the context encoder and the policy can lead to performance
improvements, as long as the context encoder follows the principle of
maximizing the mutual information between the task variable $M$ and its latent
representation $Z$ ($I(Z;M)$) while the policy adopts the standard offline
reinforcement learning (RL) algorithms conditioning on the learned task
representation.Despite promising results, the theoretical justification of
performance improvements for such intuition remains underexplored.Inspired by
the return discrepancy scheme in the model-based RL field, we find that the
previous optimization framework can be linked with the general RL objective of
maximizing the expected return, thereby explaining performance improvements.
Furthermore, after scrutinizing this optimization framework, we find it ignores
the variation of the task representation in the alternating optimization
process, which weakens the condition necessary for monotonic performance
improvements, and may therefore violate the monotonicity.We name this issue
\underline{task representation shift} and theoretically prove that the
monotonic performance improvements can be guaranteed with appropriate context
encoder updates.We use different settings to rein in the task representation
shift on three widely adopted training objectives concerning maximizing
$I(Z;M)$ across different data qualities.Empirical results show that reining in
the task representation shift can indeed improve performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ How Reliable Are Automatic Evaluation Methods for Instruction-Tuned
  LLMs? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.10770v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.10770v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ehsan Doostmohammadi, Oskar Holmström, Marco Kuhlmann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Work on instruction-tuned Large Language Models (LLMs) has used automatic
methods based on text overlap and LLM judgments as cost-effective alternatives
to human evaluation. In this paper, we perform a meta-evaluation of such
methods and assess their reliability across a broad range of tasks. In
evaluating how well automatic methods align with human evaluations, correlation
metrics are the most commonly employed method despite their inherent
limitations when dealing with ties and different scales. To address these
shortcomings, we use Pairwise Accuracy as an alternative to standard
correlation measures. We observe that while automatic evaluation methods can
approximate human ratings under specific conditions, their validity is highly
context-dependent. Specifically, the simple ROUGE-L metric correlates very well
with human ratings for short-answer English tasks but is unreliable in
free-form generation tasks and cross-lingual scenarios. The effectiveness of
the more advanced method of using GPT-4 as a judge diminishes significantly if
reference answers are not included in the prompt, which is the scenario where
this method has the potential to provide the most value compared to other
metrics. Our findings enhance the understanding of how automatic methods should
be applied and interpreted when developing and evaluating instruction-tuned
LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Moshi: a speech-text foundation model for real-time dialogue 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00037v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00037v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexandre Défossez, Laurent Mazaré, Manu Orsini, Amélie Royer, Patrick Pérez, Hervé Jégou, Edouard Grave, Neil Zeghidour
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Moshi, a speech-text foundation model and full-duplex spoken
dialogue framework. Current systems for spoken dialogue rely on pipelines of
independent components, namely voice activity detection, speech recognition,
textual dialogue and text-to-speech. Such frameworks cannot emulate the
experience of real conversations. First, their complexity induces a latency of
several seconds between interactions. Second, text being the intermediate
modality for dialogue, non-linguistic information that modifies meaning -- such
as emotion or non-speech sounds -- is lost in the interaction. Finally, they
rely on a segmentation into speaker turns, which does not take into account
overlapping speech, interruptions and interjections. Moshi solves these
independent issues altogether by casting spoken dialogue as speech-to-speech
generation. Starting from a text language model backbone, Moshi generates
speech as tokens from the residual quantizer of a neural audio codec, while
modeling separately its own speech and that of the user into parallel streams.
This allows for the removal of explicit speaker turns, and the modeling of
arbitrary conversational dynamics. We moreover extend the hierarchical
semantic-to-acoustic token generation of previous work to first predict
time-aligned text tokens as a prefix to audio tokens. Not only this "Inner
Monologue" method significantly improves the linguistic quality of generated
speech, but we also illustrate how it can provide streaming speech recognition
and text-to-speech. Our resulting model is the first real-time full-duplex
spoken large language model, with a theoretical latency of 160ms, 200ms in
practice, and is available at https://github.com/kyutai-labs/moshi.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Time-MoE: Billion-Scale Time Series Foundation Models with Mixture of
  Experts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.16040v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.16040v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoming Shi, Shiyu Wang, Yuqi Nie, Dianqi Li, Zhou Ye, Qingsong Wen, Ming Jin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep learning for time series forecasting has seen significant advancements
over the past decades. However, despite the success of large-scale pre-training
in language and vision domains, pre-trained time series models remain limited
in scale and operate at a high cost, hindering the development of larger
capable forecasting models in real-world applications. In response, we
introduce Time-MoE, a scalable and unified architecture designed to pre-train
larger, more capable forecasting foundation models while reducing inference
costs. By leveraging a sparse mixture-of-experts (MoE) design, Time-MoE
enhances computational efficiency by activating only a subset of networks for
each prediction, reducing computational load while maintaining high model
capacity. This allows Time-MoE to scale effectively without a corresponding
increase in inference costs. Time-MoE comprises a family of decoder-only
transformer models that operate in an auto-regressive manner and support
flexible forecasting horizons with varying input context lengths. We
pre-trained these models on our newly introduced large-scale data Time-300B,
which spans over 9 domains and encompassing over 300 billion time points. For
the first time, we scaled a time series foundation model up to 2.4 billion
parameters, achieving significantly improved forecasting precision. Our results
validate the applicability of scaling laws for training tokens and model size
in the context of time series forecasting. Compared to dense models with the
same number of activated parameters or equivalent computation budgets, our
models consistently outperform them by large margin. These advancements
position Time-MoE as a state-of-the-art solution for tackling real-world time
series forecasting challenges with superior capability, efficiency, and
flexibility.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>30 pages, 10 figures, 13 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mini-batch Submodular Maximization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.12478v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.12478v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gregory Schwartzman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present the first mini-batch algorithm for maximizing a non-negative
monotone decomposable submodular function, $F=\sum_{i=1}^N f^i$, under a set of
constraints. We consider two sampling approaches: uniform and weighted. We
first show that mini-batch with weighted sampling improves over the state of
the art sparsifier based approach both in theory and in practice.
  Surprisingly, our experimental results show that uniform sampling is superior
to weighted sampling. However, it is impossible to explain this using
worst-case analysis. Our main contribution is using smoothed analysis to
provide a theoretical foundation for our experimental results. We show that,
under very mild assumptions, uniform sampling is superior for both the
mini-batch and the sparsifier approaches. We empirically verify that these
assumptions hold for our datasets. Uniform sampling is simple to implement and
has complexity independent of $N$, making it the perfect candidate to tackle
massive real-world datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Routoo: Learning to Route to Large Language Models Effectively 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.13979v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.13979v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alireza Mohammadshahi, Arshad Rafiq Shaikh, Majid Yazdani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  LLMs with superior response quality--particularly larger or closed-source
models--often come with higher inference costs, making their deployment
inefficient and costly. Meanwhile, developing foundational LLMs from scratch is
becoming increasingly resource-intensive and impractical for many applications.
To address the challenge of balancing quality and cost, we introduce Routoo, an
architecture designed to optimize the selection of LLMs for specific prompts
based on performance, cost, and efficiency. Routoo provides controllability
over the trade-off between inference cost and quality, enabling significant
reductions in inference costs for a given quality requirement. Routoo comprises
two key components: a performance predictor and cost-aware selector. The
performance predictor is a lightweight LLM that estimates the expected
performance of various underlying LLMs on a given prompt without executing
them. The cost-aware selector module then selects the most suitable model based
on these predictions and constraints such as cost and latency, significantly
reducing inference costs for the same quality. We evaluated Routoo using the
MMLU benchmark across 57 domains employing open-source models. Our results show
that Routoo matches the performance of the Mixtral 8x7b model while reducing
inference costs by one-third. Additionally, by allowing increased costs, Routoo
surpasses Mixtral's accuracy by over 5% at equivalent costs, achieving an
accuracy of 75.9%. When integrating GPT4 into our model pool, Routoo nearly
matches GPT4's performance at half the cost and exceeds it with a 25% cost
reduction. These outcomes highlight Routoo's potential to significantly reduce
inference costs without compromising quality, and even to establish new
state-of-the-art results by leveraging the collective capabilities of multiple
LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Bayesian WeakS-to-Strong from Text Classification to Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.03199v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.03199v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziyun Cui, Ziyang Zhang, Wen Wu, Guangzhi Sun, Chao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Advances in large language models raise the question of how alignment
techniques will adapt as models become increasingly complex and humans will
only be able to supervise them weakly. Weak-to-Strong mimics such a scenario
where weak model supervision attempts to harness the full capabilities of a
much stronger model. This work extends Weak-to-Strong to WeakS-to-Strong by
exploring an ensemble of weak models which simulate the variability in human
opinions. Confidence scores are estimated using a Bayesian approach to guide
the WeakS-to-Strong generalization. Furthermore, we extend the application of
WeakS-to-Strong from text classification tasks to text generation tasks where
more advanced strategies are investigated for supervision. Moreover, direct
preference optimization is applied to advance the student model's preference
learning, beyond the basic learning framework of teacher forcing. Results
demonstrate the effectiveness of the proposed approach for the reliability of a
strong student model, showing potential for superalignment.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Are LLMs Effective Negotiators? Systematic Evaluation of the
  Multifaceted Capabilities of LLMs in Negotiation Dialogues <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.13550v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.13550v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Deuksin Kwon, Emily Weiss, Tara Kulshrestha, Kushal Chawla, Gale M. Lucas, Jonathan Gratch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A successful negotiation requires a range of capabilities, including
comprehension of the conversation context, Theory-of-Mind (ToM) skills to infer
the partner's motives, strategic reasoning, and effective communication, making
it challenging for automated systems. Despite the remarkable performance of
LLMs in various NLP tasks, there is no systematic evaluation of their
capabilities in negotiation. Such an evaluation is critical for advancing AI
negotiation agents and negotiation research, ranging from designing dialogue
systems to providing pedagogical feedback and scaling up data collection
practices. This work aims to systematically analyze the multifaceted
capabilities of LLMs across diverse dialogue scenarios throughout the stages of
a typical negotiation interaction. Our analysis highlights GPT-4's superior
performance in many tasks while identifying specific challenges, such as making
subjective assessments and generating contextually appropriate, strategically
advantageous responses.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to Findings of EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fine-Tuning is Fine, if Calibrated <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.16223v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.16223v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zheda Mai, Arpita Chowdhury, Ping Zhang, Cheng-Hao Tu, Hong-You Chen, Vardaan Pahuja, Tanya Berger-Wolf, Song Gao, Charles Stewart, Yu Su, Wei-Lun Chao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Fine-tuning is arguably the most straightforward way to tailor a pre-trained
model (e.g., a foundation model) to downstream applications, but it also comes
with the risk of losing valuable knowledge the model had learned in
pre-training. For example, fine-tuning a pre-trained classifier capable of
recognizing a large number of classes to master a subset of classes at hand is
shown to drastically degrade the model's accuracy in the other classes it had
previously learned. As such, it is hard to further use the fine-tuned model
when it encounters classes beyond the fine-tuning data. In this paper, we
systematically dissect the issue, aiming to answer the fundamental question,
"What has been damaged in the fine-tuned model?" To our surprise, we find that
the fine-tuned model neither forgets the relationship among the other classes
nor degrades the features to recognize these classes. Instead, the fine-tuned
model often produces more discriminative features for these other classes, even
if they were missing during fine-tuning! {What really hurts the accuracy is the
discrepant logit scales between the fine-tuning classes and the other classes},
implying that a simple post-processing calibration would bring back the
pre-trained model's capability and at the same time unveil the feature
improvement over all classes. We conduct an extensive empirical study to
demonstrate the robustness of our findings and provide preliminary explanations
underlying them, suggesting new directions for future theoretical analysis. Our
code is available at
https://github.com/OSU-MLB/Fine-Tuning-Is-Fine-If-Calibrated.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The first three authors contribute equally. The paper has been
  accepted to NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Crafting Heavy-Tails in Weight Matrix Spectrum without Gradient Noise 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.04657v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.04657v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vignesh Kothapalli, Tianyu Pang, Shenyang Deng, Zongmin Liu, Yaoqing Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Training strategies for modern deep neural networks (NNs) tend to induce a
heavy-tailed (HT) empirical spectral density (ESD) in the layer weights. While
previous efforts have shown that the HT phenomenon correlates with good
generalization in large NNs, a theoretical explanation of its occurrence is
still lacking. Especially, understanding the conditions which lead to this
phenomenon can shed light on the interplay between generalization and weight
spectra. Our work aims to bridge this gap by presenting a simple, rich setting
to model the emergence of HT ESD. In particular, we present a theory-informed
analysis for 'crafting' heavy tails in the ESD of two-layer NNs without any
gradient noise. This is the first work to analyze a noise-free setting and
incorporate optimizer (GD/Adam) dependent (large) learning rates into the HT
ESD analysis. Our results highlight the role of learning rates on the
Bulk+Spike and HT shape of the ESDs in the early phase of training, which can
facilitate generalization in the two-layer NN. These observations shed light on
the behavior of large-scale NNs, albeit in a much simpler setting. Last but not
least, we present a novel perspective on the ESD evolution dynamics by
analyzing the singular vectors of weight matrices and optimizer updates.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>34 pages, 32 figures, 4 tables</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Machine Learning <span class="chip" style="font-size: 60%">150</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PROXI: Challenging the GNNs for Link Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01802v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01802v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Astrit Tola, Jack Myrick, Baris Coskunuzer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Over the past decade, Graph Neural Networks (GNNs) have transformed graph
representation learning. In the widely adopted message-passing GNN framework,
nodes refine their representations by aggregating information from neighboring
nodes iteratively. While GNNs excel in various domains, recent theoretical
studies have raised concerns about their capabilities. GNNs aim to address
various graph-related tasks by utilizing such node representations, however,
this one-size-fits-all approach proves suboptimal for diverse tasks.
  Motivated by these observations, we conduct empirical tests to compare the
performance of current GNN models with more conventional and direct methods in
link prediction tasks. Introducing our model, PROXI, which leverages proximity
information of node pairs in both graph and attribute spaces, we find that
standard machine learning (ML) models perform competitively, even outperforming
cutting-edge GNN models when applied to these proximity metrics derived from
node neighborhoods and attributes. This holds true across both homophilic and
heterophilic networks, as well as small and large benchmark datasets, including
those from the Open Graph Benchmark (OGB). Moreover, we show that augmenting
traditional GNNs with PROXI significantly boosts their link prediction
performance. Our empirical findings corroborate the previously mentioned
theoretical observations and imply that there exists ample room for enhancement
in current GNN models to reach their potential.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On the expressiveness and spectral bias of KANs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01803v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01803v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yixuan Wang, Jonathan W. Siegel, Ziming Liu, Thomas Y. Hou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Kolmogorov-Arnold Networks (KAN) \cite{liu2024kan} were very recently
proposed as a potential alternative to the prevalent architectural backbone of
many deep learning models, the multi-layer perceptron (MLP). KANs have seen
success in various tasks of AI for science, with their empirical efficiency and
accuracy demostrated in function regression, PDE solving, and many more
scientific problems.
  In this article, we revisit the comparison of KANs and MLPs, with emphasis on
a theoretical perspective. On the one hand, we compare the representation and
approximation capabilities of KANs and MLPs. We establish that MLPs can be
represented using KANs of a comparable size. This shows that the approximation
and representation capabilities of KANs are at least as good as MLPs.
Conversely, we show that KANs can be represented using MLPs, but that in this
representation the number of parameters increases by a factor of the KAN grid
size. This suggests that KANs with a large grid size may be more efficient than
MLPs at approximating certain functions. On the other hand, from the
perspective of learning and optimization, we study the spectral bias of KANs
compared with MLPs. We demonstrate that KANs are less biased toward low
frequencies than MLPs. We highlight that the multi-level learning feature
specific to KANs, i.e. grid extension of splines, improves the learning process
for high-frequency components. Detailed comparisons with different choices of
depth, width, and grid sizes of KANs are made, shedding some light on how to
choose the hyperparameters in practice.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient $1$-bit tensor approximations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01799v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01799v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alex W. Neal Riasanovsky, Sarah El Kazdadi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a spatially efficient decomposition of matrices and
arbitrary-order tensors as linear combinations of tensor products of $\{-1,
1\}$-valued vectors. For any matrix $A \in \mathbb{R}^{m \times n}$, $$A - R_w
= S_w C_w T_w^\top = \sum_{j=1}^w c_j \cdot \mathbf{s}_j \mathbf{t}_j^\top$$ is
a {\it $w$-width signed cut decomposition of $A$}. Here $C_w =
"diag"(\mathbf{c}_w)$ for some $\mathbf{c}_w \in \mathbb{R}^w,$ and $S_w, T_w$,
and the vectors $\mathbf{s}_j, \mathbf{t}_j$ are $\{-1, 1\}$-valued. To store
$(S_w, T_w, C_w)$, we may pack $w \cdot (m + n)$ bits, and require only $w$
floating point numbers. As a function of $w$, $\|R_w\|_F$ exhibits exponential
decay when applied to #f32 matrices with i.i.d. $\mathcal N (0, 1)$ entries.
Choosing $w$ so that $(S_w, T_w, C_w)$ has the same memory footprint as a
\textit{f16} or \textit{bf16} matrix, the relative error is comparable. Our
algorithm yields efficient signed cut decompositions in $20$ lines of
pseudocode. It reflects a simple modification from a celebrated 1999 paper [1]
of Frieze and Kannan. As a first application, we approximate the weight
matrices in the open \textit{Mistral-7B-v0.1} Large Language Model to a $50\%$
spatial compression. Remarkably, all $226$ remainder matrices have a relative
error $<6\%$ and the expanded model closely matches \textit{Mistral-7B-v0.1} on
the {\it huggingface} leaderboard [2]. Benchmark performance degrades slowly as
we reduce the spatial compression from $50\%$ to $25\%$. We optimize our open
source \textit{rust} implementation [3] with \textit{simd} instructions on
\textit{avx2} and \textit{avx512} architectures. We also extend our algorithm
from matrices to tensors of arbitrary order and use it to compress a picture of
the first author's cat Angus.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, one cat picture reused a lot</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bellman Diffusion: Generative Modeling as Learning a Linear Operator in
  the Distribution Space 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01796v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01796v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yangming Li, Chieh-Hsin Lai, Carola-Bibiane Schönlieb, Yuki Mitsufuji, Stefano Ermon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep Generative Models (DGMs), including Energy-Based Models (EBMs) and
Score-based Generative Models (SGMs), have advanced high-fidelity data
generation and complex continuous distribution approximation. However, their
application in Markov Decision Processes (MDPs), particularly in distributional
Reinforcement Learning (RL), remains underexplored, with conventional
histogram-based methods dominating the field. This paper rigorously highlights
that this application gap is caused by the nonlinearity of modern DGMs, which
conflicts with the linearity required by the Bellman equation in MDPs. For
instance, EBMs involve nonlinear operations such as exponentiating energy
functions and normalizing constants. To address this, we introduce Bellman
Diffusion, a novel DGM framework that maintains linearity in MDPs through
gradient and scalar field modeling. With divergence-based training techniques
to optimize neural network proxies and a new type of stochastic differential
equation (SDE) for sampling, Bellman Diffusion is guaranteed to converge to the
target distribution. Our empirical results show that Bellman Diffusion achieves
accurate field estimations and is a capable image generator, converging 1.5x
faster than the traditional histogram-based baseline in distributional RL
tasks. This work enables the effective integration of DGMs into MDP
applications, unlocking new avenues for advanced decision-making frameworks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Paper under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Knowledge-Driven Feature Selection and Engineering for Genotype Data
  with Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01795v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01795v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joseph Lee, Shu Yang, Jae Young Baik, Xiaoxi Liu, Zhen Tan, Dawei Li, Zixuan Wen, Bojian Hou, Duy Duong-Tran, Tianlong Chen, Li Shen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Predicting phenotypes with complex genetic bases based on a small,
interpretable set of variant features remains a challenging task.
Conventionally, data-driven approaches are utilized for this task, yet the high
dimensional nature of genotype data makes the analysis and prediction
difficult. Motivated by the extensive knowledge encoded in pre-trained LLMs and
their success in processing complex biomedical concepts, we set to examine the
ability of LLMs in feature selection and engineering for tabular genotype data,
with a novel knowledge-driven framework. We develop FREEFORM, Free-flow
Reasoning and Ensembling for Enhanced Feature Output and Robust Modeling,
designed with chain-of-thought and ensembling principles, to select and
engineer features with the intrinsic knowledge of LLMs. Evaluated on two
distinct genotype-phenotype datasets, genetic ancestry and hereditary hearing
loss, we find this framework outperforms several data-driven methods,
particularly on low-shot regimes. FREEFORM is available as open-source
framework at GitHub: https://github.com/PennShenLab/FREEFORM.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Thermodynamic Bayesian Inference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01793v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01793v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maxwell Aifer, Samuel Duffield, Kaelan Donatella, Denis Melanson, Phoebe Klett, Zach Belateche, Gavin Crooks, Antonio J. Martinez, Patrick J. Coles
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A fully Bayesian treatment of complicated predictive models (such as deep
neural networks) would enable rigorous uncertainty quantification and the
automation of higher-level tasks including model selection. However, the
intractability of sampling Bayesian posteriors over many parameters inhibits
the use of Bayesian methods where they are most needed. Thermodynamic computing
has emerged as a paradigm for accelerating operations used in machine learning,
such as matrix inversion, and is based on the mapping of Langevin equations to
the dynamics of noisy physical systems. Hence, it is natural to consider the
implementation of Langevin sampling algorithms on thermodynamic devices. In
this work we propose electronic analog devices that sample from Bayesian
posteriors by realizing Langevin dynamics physically. Circuit designs are given
for sampling the posterior of a Gaussian-Gaussian model and for Bayesian
logistic regression, and are validated by simulations. It is shown, under
reasonable assumptions, that the Bayesian posteriors for these models can be
sampled in time scaling with $\ln(d)$, where $d$ is dimension. For the
Gaussian-Gaussian model, the energy cost is shown to scale with $ d \ln(d)$.
These results highlight the potential for fast, energy-efficient Bayesian
inference using thermodynamic computing.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Investigating on RLHF methodology 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01789v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01789v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexey Kutalev, Sergei Markoff
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this article, we investigate the alignment of Large Language Models
according to human preferences. We discuss the features of training a
Preference Model, which simulates human preferences, and the methods and
details we found essential for achieving the best results. We also discuss
using Reinforcement Learning to fine-tune Large Language Models and describe
the challenges we faced and the ways to overcome them. Additionally, we present
our experience with the Direct Preference Optimization method, which enables us
to align a Large Language Model with human preferences without creating a
separate Preference Model. As our contribution, we introduce the approach for
collecting a preference dataset through perplexity filtering, which makes the
process of creating such a dataset for a specific Language Model much easier
and more cost-effective.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages, 6 figures, 6 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning To Solve Differential Equation Constrained Optimization
  Problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01786v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01786v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vincenzo Di Vito, Mostafa Mohammadian, Kyri Baker, Ferdinando Fioretto
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Differential equations (DE) constrained optimization plays a critical role in
numerous scientific and engineering fields, including energy systems, aerospace
engineering, ecology, and finance, where optimal configurations or control
strategies must be determined for systems governed by ordinary or stochastic
differential equations. Despite its significance, the computational challenges
associated with these problems have limited their practical use. To address
these limitations, this paper introduces a learning-based approach to
DE-constrained optimization that combines techniques from proxy optimization
and neural differential equations. The proposed approach uses a dual-network
architecture, with one approximating the control strategies, focusing on
steady-state constraints, and another solving the associated DEs. This
combination enables the approximation of optimal strategies while accounting
for dynamic constraints in near real-time. Experiments across problems in
energy optimization and finance modeling show that this method provides full
compliance with dynamic constraints and it produces results up to 25 times more
precise than other methods which do not explicitly model the system's dynamic
equations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Open-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large
  Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01782v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01782v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shayekh Bin Islam, Md Asib Rahman, K S M Tozammel Hossain, Enamul Hoque, Shafiq Joty, Md Rizwan Parvez
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) has been shown to enhance the factual
accuracy of Large Language Models (LLMs), but existing methods often suffer
from limited reasoning capabilities in effectively using the retrieved
evidence, particularly when using open-source LLMs. To mitigate this gap, we
introduce a novel framework, Open-RAG, designed to enhance reasoning
capabilities in RAG with open-source LLMs. Our framework transforms an
arbitrary dense LLM into a parameter-efficient sparse mixture of experts (MoE)
model capable of handling complex reasoning tasks, including both single- and
multi-hop queries. Open-RAG uniquely trains the model to navigate challenging
distractors that appear relevant but are misleading. As a result, Open-RAG
leverages latent learning, dynamically selecting relevant experts and
integrating external knowledge effectively for more accurate and contextually
relevant responses. In addition, we propose a hybrid adaptive retrieval method
to determine retrieval necessity and balance the trade-off between performance
gain and inference speed. Experimental results show that the Llama2-7B-based
Open-RAG outperforms state-of-the-art LLMs and RAG models such as ChatGPT,
Self-RAG, and Command R+ in various knowledge-intensive tasks. We open-source
our code and models at https://openragmoe.github.io/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Findings. Website:
  https://openragmoe.github.io/. 14 pages, 7 figures, 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Composing Global Optimizers to Reasoning Tasks via Algebraic Objects in
  Neural Nets 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01779v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01779v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuandong Tian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We prove rich algebraic structures of the solution space for 2-layer neural
networks with quadratic activation and $L_2$ loss, trained on reasoning tasks
in Abelian group (e.g., modular addition). Such a rich structure enables
analytical construction of global optimal solutions from partial solutions that
only satisfy part of the loss, despite its high nonlinearity. We coin the
framework as CoGO (Composing Global Optimizers). Specifically, we show that the
weight space over different numbers of hidden nodes of the 2-layer network is
equipped with a semi-ring algebraic structure, and the loss function to be
optimized consists of monomial potentials, which are ring homomorphism,
allowing partial solutions to be composed into global ones by ring addition and
multiplication. Our experiments show that around $95\%$ of the solutions
obtained by gradient descent match exactly our theoretical constructions.
Although the global optimizers constructed only required a small number of
hidden nodes, our analysis on gradient dynamics shows that
over-parameterization asymptotically decouples training dynamics and is
beneficial. We further show that training dynamics favors simpler solutions
under weight decay, and thus high-order global optimizers such as perfect
memorization are unfavorable.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TopER: Topological Embeddings in Graph Representation Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01778v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01778v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Astrit Tola, Funmilola Mary Taiwom, Cuneyt Gurcan Akcora, Baris Coskunuzer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph embeddings play a critical role in graph representation learning,
allowing machine learning models to explore and interpret graph-structured
data. However, existing methods often rely on opaque, high-dimensional
embeddings, limiting interpretability and practical visualization.
  In this work, we introduce Topological Evolution Rate (TopER), a novel,
low-dimensional embedding approach grounded in topological data analysis. TopER
simplifies a key topological approach, Persistent Homology, by calculating the
evolution rate of graph substructures, resulting in intuitive and interpretable
visualizations of graph data. This approach not only enhances the exploration
of graph datasets but also delivers competitive performance in graph clustering
and classification tasks. Our TopER-based models achieve or surpass
state-of-the-art results across molecular, biological, and social network
datasets in tasks such as classification, clustering, and visualization.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dynamical-generative downscaling of climate model ensembles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01776v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01776v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ignacio Lopez-Gomez, Zhong Yi Wan, Leonardo Zepeda-Núñez, Tapio Schneider, John Anderson, Fei Sha
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Regional high-resolution climate projections are crucial for many
applications, such as agriculture, hydrology, and natural hazard risk
assessment. Dynamical downscaling, the state-of-the-art method to produce
localized future climate information, involves running a regional climate model
(RCM) driven by an Earth System Model (ESM), but it is too computationally
expensive to apply to large climate projection ensembles. We propose a novel
approach combining dynamical downscaling with generative artificial
intelligence to reduce the cost and improve the uncertainty estimates of
downscaled climate projections. In our framework, an RCM dynamically downscales
ESM output to an intermediate resolution, followed by a generative diffusion
model that further refines the resolution to the target scale. This approach
leverages the generalizability of physics-based models and the sampling
efficiency of diffusion models, enabling the downscaling of large multi-model
ensembles. We evaluate our method against dynamically-downscaled climate
projections from the CMIP6 ensemble. Our results demonstrate its ability to
provide more accurate uncertainty bounds on future regional climate than
alternatives such as dynamical downscaling of smaller ensembles, or traditional
empirical statistical downscaling methods. We also show that
dynamical-generative downscaling results in significantly lower errors than
bias correction and spatial disaggregation (BCSD), and captures more accurately
the spectra and multivariate correlations of meteorological fields. These
characteristics make the dynamical-generative framework a flexible, accurate,
and efficient way to downscale large ensembles of climate projections,
currently out of reach for pure dynamical downscaling.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Trained <span class="highlight-title">Transformer</span> Classifiers Generalize and Exhibit Benign
  Overfitting In-Context 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01774v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01774v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Spencer Frei, Gal Vardi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformers have the capacity to act as supervised learning algorithms: by
properly encoding a set of labeled training ("in-context") examples and an
unlabeled test example into an input sequence of vectors of the same dimension,
the forward pass of the transformer can produce predictions for that unlabeled
test example. A line of recent work has shown that when linear transformers are
pre-trained on random instances for linear regression tasks, these trained
transformers make predictions using an algorithm similar to that of ordinary
least squares. In this work, we investigate the behavior of linear transformers
trained on random linear classification tasks. Via an analysis of the implicit
regularization of gradient descent, we characterize how many pre-training tasks
and in-context examples are needed for the trained transformer to generalize
well at test-time. We further show that in some settings, these trained
transformers can exhibit "benign overfitting in-context": when in-context
examples are corrupted by label flipping noise, the transformer memorizes all
of its in-context examples (including those with noisy labels) yet still
generalizes near-optimally for clean test examples.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>34 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bayesian Binary Search 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01771v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01771v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vikash Singh, Matthew Khanzadeh, Vincent Davis, Harrison Rush, Emanuele Rossi, Jesse Shrader, Pietro Lio
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present Bayesian Binary Search (BBS), a novel probabilistic variant of the
classical binary search/bisection algorithm. BBS leverages machine
learning/statistical techniques to estimate the probability density of the
search space and modifies the bisection step to split based on probability
density rather than the traditional midpoint, allowing for the learned
distribution of the search space to guide the search algorithm. Search space
density estimation can flexibly be performed using supervised probabilistic
machine learning techniques (e.g., Gaussian process regression, Bayesian neural
networks, quantile regression) or unsupervised learning algorithms (e.g.,
Gaussian mixture models, kernel density estimation (KDE), maximum likelihood
estimation (MLE)). We demonstrate significant efficiency gains of using BBS on
both simulated data across a variety of distributions and in a real-world
binary search use case of probing channel balances in the Bitcoin Lightning
Network, for which we have deployed the BBS algorithm in a production setting.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Explainable Earth Surface Forecasting under Extreme Events 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01770v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01770v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Oscar J. Pellicer-Valero, Miguel-Ángel Fernández-Torres, Chaonan Ji, Miguel D. Mahecha, Gustau Camps-Valls
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With climate change-related extreme events on the rise, high dimensional
Earth observation data presents a unique opportunity for forecasting and
understanding impacts on ecosystems. This is, however, impeded by the
complexity of processing, visualizing, modeling, and explaining this data. To
showcase how this challenge can be met, here we train a convolutional long
short-term memory-based architecture on the novel DeepExtremeCubes dataset.
DeepExtremeCubes includes around 40,000 long-term Sentinel-2 minicubes (January
2016-October 2022) worldwide, along with labeled extreme events, meteorological
data, vegetation land cover, and topography map, sampled from locations
affected by extreme climate events and surrounding areas. When predicting
future reflectances and vegetation impacts through kernel normalized difference
vegetation index, the model achieved an R$^2$ score of 0.9055 in the test set.
Explainable artificial intelligence was used to analyze the model's predictions
during the October 2020 Central South America compound heatwave and drought
event. We chose the same area exactly one year before the event as
counterfactual, finding that the average temperature and surface pressure are
generally the best predictors under normal conditions. In contrast, minimum
anomalies of evaporation and surface latent heat flux take the lead during the
event. A change of regime is also observed in the attributions before the
event, which might help assess how long the event was brewing before happening.
The code to replicate all experiments and figures in this paper is publicly
available at https://github.com/DeepExtremes/txyXAI
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Decision-Focused Uncertainty Quantification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01767v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01767v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Santiago Cortes-Gomez, Carlos Patiño, Yewon Byun, Steven Wu, Eric Horvitz, Bryan Wilder
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  There is increasing interest in ''decision-focused'' machine learning methods
which train models to account for how their predictions are used in downstream
optimization problems. Doing so can often improve performance on subsequent
decision problems. However, current methods for uncertainty quantification do
not incorporate any information at all about downstream decisions. We develop a
framework based on conformal prediction to produce prediction sets that account
for a downstream decision loss function, making them more appropriate to inform
high-stakes decision-making. Our approach harnesses the strengths of conformal
methods--modularity, model-agnosticism, and statistical coverage
guarantees--while incorporating downstream decisions and user-specified utility
functions. We prove that our methods retain standard coverage guarantees.
Empirical evaluation across a range of datasets and utility metrics
demonstrates that our methods achieve significantly lower decision loss
compared to standard conformal methods. Additionally, we present a real-world
use case in healthcare diagnosis, where our method effectively incorporates the
hierarchical structure of dermatological diseases. It successfully generates
sets with coherent diagnostic meaning, aiding the triage process during
dermatology diagnosis and illustrating how our method can ground high-stakes
decision-making on external domain knowledge.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SegHeD: Segmentation of Heterogeneous Data for Multiple Sclerosis
  Lesions with Anatomical Constraints <span class="chip">MICCAI</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01766v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01766v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Berke Doga Basaran, Xinru Zhang, Paul M. Matthews, Wenjia Bai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Assessment of lesions and their longitudinal progression from brain magnetic
resonance (MR) images plays a crucial role in diagnosing and monitoring
multiple sclerosis (MS). Machine learning models have demonstrated a great
potential for automated MS lesion segmentation. Training such models typically
requires large-scale high-quality datasets that are consistently annotated.
However, MS imaging datasets are often small, segregated across multiple sites,
with different formats (cross-sectional or longitudinal), and diverse
annotation styles. This poses a significant challenge to train a unified MS
lesion segmentation model. To tackle this challenge, we present SegHeD, a novel
multi-dataset multi-task segmentation model that can incorporate heterogeneous
data as input and perform all-lesion, new-lesion, as well as vanishing-lesion
segmentation. Furthermore, we account for domain knowledge about MS lesions,
incorporating longitudinal, spatial, and volumetric constraints into the
segmentation model. SegHeD is assessed on five MS datasets and achieves a high
performance in all, new, and vanishing-lesion segmentation, outperforming
several state-of-the-art methods in this field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 4 figures, MICCAI, LDTM Workshop</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Integrating Protein Sequence and Expression Level to Analysis Molecular
  Characterization of Breast Cancer Subtypes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01755v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01755v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hossein Sholehrasa
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Breast cancer's complexity and variability pose significant challenges in
understanding its progression and guiding effective treatment. This study aims
to integrate protein sequence data with expression levels to improve the
molecular characterization of breast cancer subtypes and predict clinical
outcomes. Using ProtGPT2, a language model designed for protein sequences, we
generated embeddings that capture the functional and structural properties of
proteins sequence. These embeddings were integrated with protein expression
level to form enriched biological representations, which were analyzed using
machine learning methods like ensemble K-means for clustering and XGBoost for
classification. Our approach enabled successful clustering of patients into
biologically distinct groups and accurately predicted clinical outcomes such as
survival and biomarkers status, achieving high performance metrics, notably an
F1 score of 0.88 for survival and 0.87 for biomarkers status prediction.
Analysis of feature importance highlighted key proteins like KMT2C, GCN1, and
CLASP2, linked to hormone receptor and Human Epidermal Growth Factor Receptor 2
(HER2) expression, which play a role in tumor progression and patient outcomes,
respectively. Furthermore, protein-protein interaction networks and correlation
analyses revealed the interdependence of proteins that may influence breast
cancer subtype behaviors. These findings suggest that integrating protein
sequence and expression data provides valuable insights into tumor biology and
has significant potential to enhance personalized treatment strategies in
breast cancer care.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TorchSISSO: A PyTorch-Based Implementation of the Sure Independence
  Screening and Sparsifying Operator for Efficient and Interpretable Model
  Discovery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01752v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01752v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Madhav Muthyala, Farshud Sorourifar, Joel A. Paulson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Symbolic regression (SR) is a powerful machine learning approach that
searches for both the structure and parameters of algebraic models, offering
interpretable and compact representations of complex data. Unlike traditional
regression methods, SR explores progressively complex feature spaces, which can
uncover simple models that generalize well, even from small datasets. Among SR
algorithms, the Sure Independence Screening and Sparsifying Operator (SISSO)
has proven particularly effective in the natural sciences, helping to
rediscover fundamental physical laws as well as discover new interpretable
equations for materials property modeling. However, its widespread adoption has
been limited by performance inefficiencies and the challenges posed by its
FORTRAN-based implementation, especially in modern computing environments. In
this work, we introduce TorchSISSO, a native Python implementation built in the
PyTorch framework. TorchSISSO leverages GPU acceleration, easy integration, and
extensibility, offering a significant speed-up and improved accuracy over the
original. We demonstrate that TorchSISSO matches or exceeds the performance of
the original SISSO across a range of tasks, while dramatically reducing
computational time and improving accessibility for broader scientific
applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Not All LLM Reasoners Are Created Equal 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01748v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01748v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arian Hosseini, Alessandro Sordoni, Daniel Toyama, Aaron Courville, Rishabh Agarwal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study the depth of grade-school math (GSM) problem-solving capabilities of
LLMs. To this end, we evaluate their performance on pairs of existing math word
problems together so that the answer to the second problem depends on correctly
answering the first problem. Our findings reveal a significant reasoning gap in
most LLMs, that is performance difference between solving the compositional
pairs and solving each question independently. This gap is more pronounced in
smaller, more cost-efficient, and math-specialized models. Moreover,
instruction-tuning recipes and code generation have varying effects across LLM
sizes, while finetuning on GSM can lead to task overfitting. Our analysis
indicates that large reasoning gaps are not because of test-set leakage, but
due to distraction from additional context and poor second-hop reasoning.
Overall, LLMs exhibit systematic differences in their reasoning abilities,
despite what their performance on standard benchmarks indicates.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Leray-Schauder Mappings for Operator Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01746v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01746v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Emanuele Zappala
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present an algorithm for learning operators between Banach spaces, based
on the use of Leray-Schauder mappings to learn a finite-dimensional
approximation of compact subspaces. We show that the resulting method is a
universal approximator of (possibly nonlinear) operators. We demonstrate the
efficiency of the approach on two benchmark datasets showing it achieves
results comparable to state of the art models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 2 figures, 1 table. Comments are welcome!</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PreND: Enhancing Intrinsic Motivation in Reinforcement Learning through
  <span class="highlight-title">Pre-train</span>ed Network Distillation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01745v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01745v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammadamin Davoodabadi, Negin Hashemi Dijujin, Mahdieh Soleymani Baghshah
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Intrinsic motivation, inspired by the psychology of developmental learning in
infants, stimulates exploration in agents without relying solely on sparse
external rewards. Existing methods in reinforcement learning like Random
Network Distillation (RND) face significant limitations, including (1) relying
on raw visual inputs, leading to a lack of meaningful representations, (2) the
inability to build a robust latent space, (3) poor target network
initialization and (4) rapid degradation of intrinsic rewards. In this paper,
we introduce Pre-trained Network Distillation (PreND), a novel approach to
enhance intrinsic motivation in reinforcement learning (RL) by improving upon
the widely used prediction-based method, RND. PreND addresses these challenges
by incorporating pre-trained representation models into both the target and
predictor networks, resulting in more meaningful and stable intrinsic rewards,
while enhancing the representation learned by the model. We also tried simple
but effective variants of the predictor network optimization by controlling the
learning rate. Through experiments on the Atari domain, we demonstrate that
PreND significantly outperforms RND, offering a more robust intrinsic
motivation signal that leads to better exploration, improving overall
performance and sample efficiency. This research highlights the importance of
target and predictor networks representation in prediction-based intrinsic
motivation, setting a new direction for improving RL agents' learning
efficiency in sparse reward environments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mimicking Human Intuition: Cognitive Belief-Driven Q-Learning <span class="chip">ICLR 25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01739v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01739v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingrui Gu, Guanren Qiao, Chuyi Jiang, Tianqing Xia, Hangyu Mao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement learning encounters challenges in various environments related
to robustness and explainability. Traditional Q-learning algorithms cannot
effectively make decisions and utilize the historical learning experience. To
overcome these limitations, we propose Cognitive Belief-Driven Q-Learning
(CBDQ), which integrates subjective belief modeling into the Q-learning
framework, enhancing decision-making accuracy by endowing agents with
human-like learning and reasoning capabilities. Drawing inspiration from
cognitive science, our method maintains a subjective belief distribution over
the expectation of actions, leveraging a cluster-based subjective belief model
that enables agents to reason about the potential probability associated with
each decision. CBDQ effectively mitigates overestimated phenomena and optimizes
decision-making policies by integrating historical experiences with current
contextual information, mimicking the dynamics of human decision-making. We
evaluate the proposed method on discrete control benchmark tasks in various
complicate environments. The results demonstrate that CBDQ exhibits stronger
adaptability, robustness, and human-like characteristics in handling these
environments, outperforming other baselines. We hope this work will give
researchers a fresh perspective on understanding and explaining Q-learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review by ICLR 25</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Recursive Abstractive Processing for Retrieval in Dynamic <span class="highlight-title">Dataset</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01736v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01736v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Charbel Chucri, Rami Azouz, Joachim Ott
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent retrieval-augmented models enhance basic methods by building a
hierarchical structure over retrieved text chunks through recursive embedding,
clustering, and summarization. The most relevant information is then retrieved
from both the original text and generated summaries. However, such approaches
face limitations with dynamic datasets, where adding or removing documents over
time complicates the updating of hierarchical representations formed through
clustering. We propose a new algorithm to efficiently maintain the
recursive-abstractive tree structure in dynamic datasets, without compromising
performance. Additionally, we introduce a novel post-retrieval method that
applies query-focused recursive abstractive processing to substantially improve
context quality. Our method overcomes the limitations of other approaches by
functioning as a black-box post-retrieval layer compatible with any retrieval
algorithm. Both algorithms are validated through extensive experiments on
real-world datasets, demonstrating their effectiveness in handling dynamic data
and improving retrieval performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LASeR: Learning to Adaptively Select Reward Models with Multi-Armed
  Bandits 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01735v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01735v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Duy Nguyen, Archiki Prasad, Elias Stengel-Eskin, Mohit Bansal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reward Models (RMs) play a crucial role in aligning LLMs with human
preferences, enhancing their performance by ranking outputs during inference or
iterative training. However, the degree to which an RM generalizes to new tasks
is often not known a priori (e.g. some RMs may excel at scoring creative
writing vs. math reasoning). Therefore, using only one fixed RM while training
LLMs can be suboptimal. Moreover, optimizing LLMs with multiple RMs
simultaneously can be prohibitively computationally-intensive and challenging
due to conflicting signals from different RMs, potentially degrading
performance. To address these challenges, we introduce LASeR (Learning to
Adaptively Select Rewards), which iteratively trains LLMs using multiple RMs,
selecting and utilizing the most well-suited RM for each instance to rank
outputs and generate preference data, framed as a multi-armed bandit problem.
Our results on commonsense and math reasoning tasks demonstrate that LASeR can
boost iterative LLM optimization by optimizing for multiple RMs, improving the
absolute average accuracy of Llama-3-8B over three datasets by 2.67% over
training with ensemble RM scores while also showing superior training
efficiency (e.g., a 2x speedup). Moreover, on WildChat, a benchmark of
instruction-following prompts, we find that using Llama-3-8B LASeR leads to a
71.45% AlpacaEval win rate over sequentially optimizing multiple RMs. Extending
to long-context generation tasks, we find that on Llama-3-8B, LASeR achieves an
average improvement of 2.64 F1 and 2.42 F1 on single- and multi-document QA
over random RM selection when used with best-of-n sampling. LASeR is robust to
noisy rewards and generalizes to multiple settings. Finally, LASeR's RM
selection changes depending on the underlying task or instance and we verify
the presence of conflicting preferences from multiple RMs that can be mitigated
using LASeR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages; First two authors contributed equally. Code:
  https://github.com/duykhuongnguyen/LASeR-MAB</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluating Robustness of Reward Models for Mathematical Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01729v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01729v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sunghwan Kim, Dongjin Kang, Taeyoon Kwon, Hyungjoo Chae, Jungsoo Won, Dongha Lee, Jinyoung Yeo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reward models are key in reinforcement learning from human feedback (RLHF)
systems, aligning the model behavior with human preferences. Particularly in
the math domain, there have been plenty of studies using reward models to align
policies for improving reasoning capabilities. Recently, as the importance of
reward models has been emphasized, RewardBench is proposed to understand their
behavior. However, we figure out that the math subset of RewardBench has
different representations between chosen and rejected completions, and relies
on a single comparison, which may lead to unreliable results as it only see an
isolated case. Therefore, it fails to accurately present the robustness of
reward models, leading to a misunderstanding of its performance and potentially
resulting in reward hacking. In this work, we introduce a new design for
reliable evaluation of reward models, and to validate this, we construct
RewardMATH, a benchmark that effectively represents the robustness of reward
models in mathematical reasoning tasks. We demonstrate that the scores on
RewardMATH strongly correlate with the results of optimized policy and
effectively estimate reward overoptimization, whereas the existing benchmark
shows almost no correlation. The results underscore the potential of our design
to enhance the reliability of evaluation, and represent the robustness of
reward model. We make our code and data publicly available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Automated Knowledge Concept Annotation and Question Representation
  Learning for Knowledge Tracing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01727v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01727v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yilmazcan Ozyurt, Stefan Feuerriegel, Mrinmaya Sachan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge tracing (KT) is a popular approach for modeling students' learning
progress over time, which can enable more personalized and adaptive learning.
However, existing KT approaches face two major limitations: (1) they rely
heavily on expert-defined knowledge concepts (KCs) in questions, which is
time-consuming and prone to errors; and (2) KT methods tend to overlook the
semantics of both questions and the given KCs. In this work, we address these
challenges and present KCQRL, a framework for automated knowledge concept
annotation and question representation learning that can improve the
effectiveness of any existing KT model. First, we propose an automated KC
annotation process using large language models (LLMs), which generates question
solutions and then annotates KCs in each solution step of the questions.
Second, we introduce a contrastive learning approach to generate semantically
rich embeddings for questions and solution steps, aligning them with their
associated KCs via a tailored false negative elimination approach. These
embeddings can be readily integrated into existing KT models, replacing their
randomly initialized embeddings. We demonstrate the effectiveness of KCQRL
across 15 KT algorithms on two large real-world Math learning datasets, where
we achieve consistent performance improvements.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards a Theoretical Understanding of Synthetic Data in LLM
  Post-Training: A Reverse-Bottleneck Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01720v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01720v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zeyu Gan, Yong Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Synthetic data has become a pivotal resource in post-training tasks for large
language models (LLMs) due to the scarcity of high-quality, specific data.
While various methods have been developed to generate synthetic data, there
remains a discernible gap between the practical effects of synthetic data and
our theoretical comprehension. To address this challenge, we commence by
presenting a detailed modeling of the prevalent synthetic data generation
process. Building upon this modeling, we demonstrate that the generalization
capability of the post-trained model is critically determined by the
information gain derived from the generative model, as analyzed from a novel
reverse-bottleneck perspective. Moreover, we introduce the concept of
Generalization Gain via Mutual Information (GGMI) and elucidate the
relationship between generalization gain and information gain. This analysis
serves as a theoretical foundation for synthetic data generation and further
highlights its connection with the generalization capability of post-trained
models, offering an understanding about the design of synthetic data generation
techniques and the optimization of the post-training process. We open source
our code through an anonymous GitHub repository at
https://anonymous.4open.science/r/Understanding-Synthetic.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Meta-TTT: A Meta-learning Minimax Framework For Test-Time Training 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01709v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01709v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chen Tao, Li Shen, Soumik Mondal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Test-time domain adaptation is a challenging task that aims to adapt a
pre-trained model to limited, unlabeled target data during inference. Current
methods that rely on self-supervision and entropy minimization underperform
when the self-supervised learning (SSL) task does not align well with the
primary objective. Additionally, minimizing entropy can lead to suboptimal
solutions when there is limited diversity within minibatches. This paper
introduces a meta-learning minimax framework for test-time training on batch
normalization (BN) layers, ensuring that the SSL task aligns with the primary
task while addressing minibatch overfitting. We adopt a mixed-BN approach that
interpolates current test batch statistics with the statistics from source
domains and propose a stochastic domain synthesizing method to improve model
generalization and robustness to domain shifts. Extensive experiments
demonstrate that our method surpasses state-of-the-art techniques across
various domain adaptation and generalization benchmarks, significantly
enhancing the pre-trained model's robustness on unseen domains.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 7 tables, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Performant, Memory Efficient and Scalable Multi-Agent Reinforcement
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01706v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01706v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Omayma Mahjoub, Sasha Abramowitz, Ruan de Kock, Wiem Khlifi, Simon du Toit, Jemma Daniel, Louay Ben Nessir, Louise Beyers, Claude Formanek, Liam Clark, Arnu Pretorius
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As the field of multi-agent reinforcement learning (MARL) progresses towards
larger and more complex environments, achieving strong performance while
maintaining memory efficiency and scalability to many agents becomes
increasingly important. Although recent research has led to several advanced
algorithms, to date, none fully address all of these key properties
simultaneously. In this work, we introduce Sable, a novel and theoretically
sound algorithm that adapts the retention mechanism from Retentive Networks to
MARL. Sable's retention-based sequence modelling architecture allows for
computationally efficient scaling to a large number of agents, as well as
maintaining a long temporal context, making it well-suited for large-scale
partially observable environments. Through extensive evaluations across six
diverse environments, we demonstrate how Sable is able to significantly
outperform existing state-of-the-art methods in the majority of tasks (34 out
of 45, roughly 75\%). Furthermore, Sable demonstrates stable performance as we
scale the number of agents, handling environments with more than a thousand
agents while exhibiting a linear increase in memory usage. Finally, we conduct
ablation studies to isolate the source of Sable's performance gains and confirm
its efficient computational memory usage. Our results highlight Sable's
performance and efficiency, positioning it as a leading approach to MARL at
scale.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MOREL: Enhancing Adversarial Robustness through Multi-Objective
  Representation Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01697v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01697v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sedjro Salomon Hotegni, Sebastian Peitz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Extensive research has shown that deep neural networks (DNNs) are vulnerable
to slight adversarial perturbations$-$small changes to the input data that
appear insignificant but cause the model to produce drastically different
outputs. In addition to augmenting training data with adversarial examples
generated from a specific attack method, most of the current defense strategies
necessitate modifying the original model architecture components to improve
robustness or performing test-time data purification to handle adversarial
attacks. In this work, we demonstrate that strong feature representation
learning during training can significantly enhance the original model's
robustness. We propose MOREL, a multi-objective feature representation learning
approach, encouraging classification models to produce similar features for
inputs within the same class, despite perturbations. Our training method
involves an embedding space where cosine similarity loss and multi-positive
contrastive loss are used to align natural and adversarial features from the
model encoder and ensure tight clustering. Concurrently, the classifier is
motivated to achieve accurate predictions. Through extensive experiments, we
demonstrate that our approach significantly enhances the robustness of DNNs
against white-box and black-box adversarial attacks, outperforming other
methods that similarly require no architectural changes or test-time data
purification. Our code is available at https://github.com/salomonhotegni/MOREL
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Uncertainty Quantification with Bayesian Higher Order ReLU KANs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01687v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01687v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        James Giroux, Cristiano Fanelli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce the first method of uncertainty quantification in the domain of
Kolmogorov-Arnold Networks, specifically focusing on (Higher Order) ReLUKANs to
enhance computational efficiency given the computational demands of Bayesian
methods. The method we propose is general in nature, providing access to both
epistemic and aleatoric uncertainties. It is also capable of generalization to
other various basis functions. We validate our method through a series of
closure tests, including simple one-dimensional functions and application to
the domain of (Stochastic) Partial Differential Equations. Referring to the
latter, we demonstrate the method's ability to correctly identify functional
dependencies introduced through the inclusion of a stochastic term. The code
supporting this work can be found at
https://github.com/wmdataphys/Bayesian-HR-KAN
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 7 Figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Positional Attention: Out-of-Distribution Generalization and
  Expressivity for Neural Algorithmic Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01686v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01686v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Artur Back de Luca, George Giapitzakis, Shenghao Yang, Petar Veličković, Kimon Fountoulakis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  There has been a growing interest in the ability of neural networks to solve
algorithmic tasks, such as arithmetic, summary statistics, and sorting. While
state-of-the-art models like Transformers have demonstrated good generalization
performance on in-distribution tasks, their out-of-distribution (OOD)
performance is poor when trained end-to-end. In this paper, we focus on value
generalization, a common instance of OOD generalization where the test
distribution has the same input sequence length as the training distribution,
but the value ranges in the training and test distributions do not necessarily
overlap. To address this issue, we propose that using fixed positional
encodings to determine attention weights-referred to as positional
attention-enhances empirical OOD performance while maintaining expressivity. We
support our claim about expressivity by proving that Transformers with
positional attention can effectively simulate parallel algorithms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>37 pages, 22 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PHI-S: Distribution Balancing for Label-Free Multi-Teacher Distillation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01680v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01680v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mike Ranzinger, Jon Barker, Greg Heinrich, Pavlo Molchanov, Bryan Catanzaro, Andrew Tao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Various visual foundation models have distinct strengths and weaknesses, both
of which can be improved through heterogeneous multi-teacher knowledge
distillation without labels, termed "agglomerative models." We build upon this
body of work by studying the effect of the teachers' activation statistics,
particularly the impact of the loss function on the resulting student model
quality. We explore a standard toolkit of statistical normalization techniques
to better align the different distributions and assess their effects. Further,
we examine the impact on downstream teacher-matching metrics, which motivates
the use of Hadamard matrices. With these matrices, we demonstrate useful
properties, showing how they can be used for isotropic standardization, where
each dimension of a multivariate distribution is standardized using the same
scale. We call this technique "PHI Standardization" (PHI-S) and empirically
demonstrate that it produces the best student model across the suite of methods
studied.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VinePPO: Unlocking RL Potential For LLM Reasoning Through Refined Credit
  Assignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01679v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01679v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amirhossein Kazemnejad, Milad Aghajohari, Eva Portelance, Alessandro Sordoni, Siva Reddy, Aaron Courville, Nicolas Le Roux
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) are increasingly applied to complex reasoning
tasks that require executing several complex steps before receiving any reward.
Properly assigning credit to these steps is essential for enhancing model
performance. Proximal Policy Optimization (PPO), a state-of-the-art
reinforcement learning (RL) algorithm used for LLM finetuning, employs value
networks to tackle credit assignment. However, value networks face challenges
in predicting the expected cumulative rewards accurately in complex reasoning
tasks, often leading to high-variance updates and suboptimal performance. In
this work, we systematically evaluate the efficacy of value networks and reveal
their significant shortcomings in reasoning-heavy LLM tasks, showing that they
barely outperform a random baseline when comparing alternative steps. To
address this, we propose VinePPO, a straightforward approach that leverages the
flexibility of language environments to compute unbiased Monte Carlo-based
estimates, bypassing the need for large value networks. Our method consistently
outperforms PPO and other RL-free baselines across MATH and GSM8K datasets with
fewer gradient updates (up to 9x), less wall-clock time (up to 3.0x). These
results emphasize the importance of accurate credit assignment in RL finetuning
of LLM and demonstrate VinePPO's potential as a superior alternative.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Sparse Covariance Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01669v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01669v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrea Cavallo, Zhan Gao, Elvin Isufi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Covariance Neural Networks (VNNs) perform graph convolutions on the
covariance matrix of tabular data and achieve success in a variety of
applications. However, the empirical covariance matrix on which the VNNs
operate may contain many spurious correlations, making VNNs' performance
inconsistent due to these noisy estimates and decreasing their computational
efficiency. To tackle this issue, we put forth Sparse coVariance Neural
Networks (S-VNNs), a framework that applies sparsification techniques on the
sample covariance matrix before convolution. When the true covariance matrix is
sparse, we propose hard and soft thresholding to improve covariance estimation
and reduce computational cost. Instead, when the true covariance is dense, we
propose stochastic sparsification where data correlations are dropped in
probability according to principled strategies. We show that S-VNNs are more
stable than nominal VNNs as well as sparse principal component analysis. By
analyzing the impact of sparsification on their behavior, we provide novel
connections between S-VNN stability and data distribution. We support our
theoretical findings with experimental results on various application
scenarios, ranging from brain data to human action recognition, and show an
improved task performance, stability, and computational efficiency of S-VNNs
compared with nominal VNNs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Conformal Generative Modeling with Improved Sample Efficiency through
  Sequential Greedy Filtering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01660v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01660v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Klaus-Rudolf Kladny, Bernhard Schölkopf, Michael Muehlebach
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative models lack rigorous statistical guarantees for their outputs and
are therefore unreliable in safety-critical applications. In this work, we
propose Sequential Conformal Prediction for Generative Models (SCOPE-Gen), a
sequential conformal prediction method producing prediction sets that satisfy a
rigorous statistical guarantee called conformal admissibility control. This
guarantee states that with high probability, the prediction sets contain at
least one admissible (or valid) example. To this end, our method first samples
an initial set of i.i.d. examples from a black box generative model. Then, this
set is iteratively pruned via so-called greedy filters. As a consequence of the
iterative generation procedure, admissibility of the final prediction set
factorizes as a Markov chain. This factorization is crucial, because it allows
to control each factor separately, using conformal prediction. In comparison to
prior work, our method demonstrates a large reduction in the number of
admissibility evaluations during calibration. This reduction is important in
safety-critical applications, where these evaluations must be conducted
manually by domain experts and are therefore costly and time consuming. We
highlight the advantages of our method in terms of admissibility evaluations
and cardinality of the prediction sets through experiments in natural language
generation and molecular graph extension tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Smaller Confidence Intervals From IPW Estimators via Data-Dependent
  Coarsening <span class="chip">COLT</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01658v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01658v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alkis Kalavasis, Anay Mehrotra, Manolis Zampetakis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Inverse propensity-score weighted (IPW) estimators are prevalent in causal
inference for estimating average treatment effects in observational studies.
Under unconfoundedness, given accurate propensity scores and $n$ samples, the
size of confidence intervals of IPW estimators scales down with $n$, and,
several of their variants improve the rate of scaling. However, neither IPW
estimators nor their variants are robust to inaccuracies: even if a single
covariate has an $\varepsilon>0$ additive error in the propensity score, the
size of confidence intervals of these estimators can increase arbitrarily.
Moreover, even without errors, the rate with which the confidence intervals of
these estimators go to zero with $n$ can be arbitrarily slow in the presence of
extreme propensity scores (those close to 0 or 1).
  We introduce a family of Coarse IPW (CIPW) estimators that captures existing
IPW estimators and their variants. Each CIPW estimator is an IPW estimator on a
coarsened covariate space, where certain covariates are merged. Under mild
assumptions, e.g., Lipschitzness in expected outcomes and sparsity of extreme
propensity scores, we give an efficient algorithm to find a robust estimator:
given $\varepsilon$-inaccurate propensity scores and $n$ samples, its
confidence interval size scales with $\varepsilon+1/\sqrt{n}$. In contrast,
under the same assumptions, existing estimators' confidence interval sizes are
$\Omega(1)$ irrespective of $\varepsilon$ and $n$. Crucially, our estimator is
data-dependent and we show that no data-independent CIPW estimator can be
robust to inaccuracies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for presentation at the 37th Conference on Learning Theory
  (COLT) 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Scalable and Consistent Graph Neural Networks for Distributed Mesh-based
  Data-driven Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01657v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01657v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shivam Barwey, Riccardo Balin, Bethany Lusch, Saumil Patel, Ramesh Balakrishnan, Pinaki Pal, Romit Maulik, Venkatram Vishwanath
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work develops a distributed graph neural network (GNN) methodology for
mesh-based modeling applications using a consistent neural message passing
layer. As the name implies, the focus is on enabling scalable operations that
satisfy physical consistency via halo nodes at sub-graph boundaries. Here,
consistency refers to the fact that a GNN trained and evaluated on one rank
(one large graph) is arithmetically equivalent to evaluations on multiple ranks
(a partitioned graph). This concept is demonstrated by interfacing GNNs with
NekRS, a GPU-capable exascale CFD solver developed at Argonne National
Laboratory. It is shown how the NekRS mesh partitioning can be linked to the
distributed GNN training and inference routines, resulting in a scalable
mesh-based data-driven modeling workflow. We study the impact of consistency on
the scalability of mesh-based GNNs, demonstrating efficient scaling in
consistent GNNs for up to O(1B) graph nodes on the Frontier exascale
supercomputer.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient Statistics With Unknown Truncation, Polynomial Time
  Algorithms, Beyond Gaussians 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01656v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01656v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jane H. Lee, Anay Mehrotra, Manolis Zampetakis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study the estimation of distributional parameters when samples are shown
only if they fall in some unknown set $S \subseteq \mathbb{R}^d$. Kontonis,
Tzamos, and Zampetakis (FOCS'19) gave a $d^{\mathrm{poly}(1/\varepsilon)}$ time
algorithm for finding $\varepsilon$-accurate parameters for the special case of
Gaussian distributions with diagonal covariance matrix. Recently, Diakonikolas,
Kane, Pittas, and Zarifis (COLT'24) showed that this exponential dependence on
$1/\varepsilon$ is necessary even when $S$ belongs to some well-behaved
classes. These works leave the following open problems which we address in this
work: Can we estimate the parameters of any Gaussian or even extend beyond
Gaussians? Can we design $\mathrm{poly}(d/\varepsilon)$ time algorithms when
$S$ is a simple set such as a halfspace?
  We make progress on both of these questions by providing the following
results:
  1. Toward the first question, we give a $d^{\mathrm{poly}(\ell/\varepsilon)}$
time algorithm for any exponential family that satisfies some structural
assumptions and any unknown set $S$ that is $\varepsilon$-approximable by
degree-$\ell$ polynomials. This result has two important applications:
  1a) The first algorithm for estimating arbitrary Gaussian distributions from
samples truncated to an unknown $S$; and
  1b) The first algorithm for linear regression with unknown truncation and
Gaussian features.
  2. To address the second question, we provide an algorithm with runtime
$\mathrm{poly}(d/\varepsilon)$ that works for a set of exponential families
(containing all Gaussians) when $S$ is a halfspace or an axis-aligned
rectangle.
  Along the way, we develop tools that may be of independent interest,
including, a reduction from PAC learning with positive and unlabeled samples to
PAC learning with positive and negative samples that is robust to certain
covariate shifts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for presentation at the 65th IEEE Symposium on Foundations
  of Computer Science (FOCS), 2024; abstract shortened for arXiv</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Extending Contextual Self-Modulation: Meta-Learning Across Modalities,
  Task Dimensionalities, and Data Regimes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01655v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01655v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Roussel Desmond Nzoyem, David A. W. Barton, Tom Deakin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Contextual Self-Modulation (CSM) is a potent regularization mechanism for the
Neural Context Flow (NCF) framework which demonstrates powerful meta-learning
of physical systems. However, CSM has limitations in its applicability across
different modalities and in high-data regimes. In this work, we introduce two
extensions: $i$CSM, which expands CSM to infinite-dimensional tasks, and
StochasticNCF, which improves scalability. These extensions are demonstrated
through comprehensive experimentation on a range of tasks, including dynamical
systems with parameter variations, computer vision challenges, and curve
fitting problems. $i$CSM embeds the contexts into an infinite-dimensional
function space, as opposed to CSM which uses finite-dimensional context
vectors. StochasticNCF enables the application of both CSM and $i$CSM to
high-data scenarios by providing an unbiased approximation of meta-gradient
updates through a sampled set of nearest environments. Additionally, we
incorporate higher-order Taylor expansions via Taylor-Mode automatic
differentiation, revealing that higher-order approximations do not necessarily
enhance generalization. Finally, we demonstrate how CSM can be integrated into
other meta-learning frameworks with FlashCAVIA, a computationally efficient
extension of the CAVIA meta-learning framework (Zintgraf et al. 2019).
FlashCAVIA outperforms its predecessor across various benchmarks and reinforces
the utility of bi-level optimization techniques. Together, these contributions
establish a robust framework for tackling an expanded spectrum of meta-learning
tasks, offering practical insights for out-of-distribution generalization. Our
open-sourced library, designed for flexible integration of self-modulation into
contextual meta-learning workflows, is available at
\url{github.com/ddrous/self-mod}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages, 11 figures, 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ shapiq: Shapley Interactions for Machine Learning <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01649v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01649v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maximilian Muschalik, Hubert Baniecki, Fabian Fumagalli, Patrick Kolpaczki, Barbara Hammer, Eyke Hüllermeier
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Originally rooted in game theory, the Shapley Value (SV) has recently become
an important tool in machine learning research. Perhaps most notably, it is
used for feature attribution and data valuation in explainable artificial
intelligence. Shapley Interactions (SIs) naturally extend the SV and address
its limitations by assigning joint contributions to groups of entities, which
enhance understanding of black box machine learning models. Due to the
exponential complexity of computing SVs and SIs, various methods have been
proposed that exploit structural assumptions or yield probabilistic estimates
given limited resources. In this work, we introduce shapiq, an open-source
Python package that unifies state-of-the-art algorithms to efficiently compute
SVs and any-order SIs in an application-agnostic framework. Moreover, it
includes a benchmarking suite containing 11 machine learning applications of
SIs with pre-computed games and ground-truth values to systematically assess
computational performance across domains. For practitioners, shapiq is able to
explain and visualize any-order feature interactions in predictions of models,
including vision transformers, language models, as well as XGBoost and LightGBM
with TreeSHAP-IQ. With shapiq, we extend shap beyond feature attributions and
consolidate the application of SVs and SIs in machine learning that facilitates
future research. The source code and documentation are available at
https://github.com/mmschlk/shapiq.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Novel Framework of Horizontal-Vertical Hybrid Federated Learning for
  EdgeIoT 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01644v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01644v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kai Li, Yilei Liang, Xin Yuan, Wei Ni, Jon Crowcroft, Chau Yuen, Ozgur B. Akan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This letter puts forth a new hybrid horizontal-vertical federated learning
(HoVeFL) for mobile edge computing-enabled Internet of Things (EdgeIoT). In
this framework, certain EdgeIoT devices train local models using the same data
samples but analyze disparate data features, while the others focus on the same
features using non-independent and identically distributed (non-IID) data
samples. Thus, even though the data features are consistent, the data samples
vary across devices. The proposed HoVeFL formulates the training of local and
global models to minimize the global loss function. Performance evaluations on
CIFAR-10 and SVHN datasets reveal that the testing loss of HoVeFL with 12
horizontal FL devices and six vertical FL devices is 5.5% and 25.2% higher,
respectively, compared to a setup with six horizontal FL devices and 12
vertical FL devices.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Stable Offline Value Function Learning with Bisimulation-based
  Representations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01643v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01643v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Brahma S. Pavse, Yudong Chen, Qiaomin Xie, Josiah P. Hanna
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In reinforcement learning, offline value function learning is the procedure
of using an offline dataset to estimate the expected discounted return from
each state when taking actions according to a fixed target policy. The
stability of this procedure, i.e., whether it converges to its fixed-point,
critically depends on the representations of the state-action pairs. Poorly
learned representations can make value function learning unstable, or even
divergent. Therefore, it is critical to stabilize value function learning by
explicitly shaping the state-action representations. Recently, the class of
bisimulation-based algorithms have shown promise in shaping representations for
control. However, it is still unclear if this class of methods can stabilize
value function learning. In this work, we investigate this question and answer
it affirmatively. We introduce a bisimulation-based algorithm called kernel
representations for offline policy evaluation (KROPE). KROPE uses a kernel to
shape state-action representations such that state-action pairs that have
similar immediate rewards and lead to similar next state-action pairs under the
target policy also have similar representations. We show that KROPE: 1) learns
stable representations and 2) leads to lower value error than baselines. Our
analysis provides new theoretical insight into the stability properties of
bisimulation-based methods and suggests that practitioners can use these
methods for stable and accurate evaluation of offline reinforcement learning
agents.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Moral Alignment for LLM Agents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01639v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01639v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elizaveta Tennant, Stephen Hailes, Mirco Musolesi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Decision-making agents based on pre-trained Large Language Models (LLMs) are
increasingly being deployed across various domains of human activity. While
their applications are currently rather specialized, several research efforts
are under way to develop more generalist agents. As LLM-based systems become
more agentic, their influence on human activity will grow and the transparency
of this will decrease. Consequently, developing effective methods for aligning
them to human values is vital.
  The prevailing practice in alignment often relies on human preference data
(e.g., in RLHF or DPO), in which values are implicit and are essentially
deduced from relative preferences over different model outputs. In this work,
instead of relying on human feedback, we introduce the design of reward
functions that explicitly encode core human values for Reinforcement
Learning-based fine-tuning of foundation agent models. Specifically, we use
intrinsic rewards for the moral alignment of LLM agents.
  We evaluate our approach using the traditional philosophical frameworks of
Deontological Ethics and Utilitarianism, quantifying moral rewards for agents
in terms of actions and consequences on the Iterated Prisoner's Dilemma (IPD)
environment. We also show how moral fine-tuning can be deployed to enable an
agent to unlearn a previously developed selfish strategy. Finally, we find that
certain moral strategies learned on the IPD game generalize to several other
matrix game environments. In summary, we demonstrate that fine-tuning with
intrinsic rewards is a promising general solution for aligning LLM agents to
human values, and it might represent a more transparent and cost-effective
alternative to currently predominant alignment techniques.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Does Graph <span class="highlight-title">Prompt</span> Work? A Data Operation Perspective with Theoretical
  Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01635v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01635v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qunzhong Wang, Xiangguo Sun, Hong Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, graph prompting has emerged as a promising research
direction, enabling the learning of additional tokens or subgraphs appended to
the original graphs without requiring retraining of pre-trained graph models
across various applications. This novel paradigm, shifting from the traditional
pretraining and finetuning to pretraining and prompting has shown significant
empirical success in simulating graph data operations, with applications
ranging from recommendation systems to biological networks and graph
transferring. However, despite its potential, the theoretical underpinnings of
graph prompting remain underexplored, raising critical questions about its
fundamental effectiveness. The lack of rigorous theoretical proof of why and
how much it works is more like a dark cloud over the graph prompt area to go
further. To fill this gap, this paper introduces a theoretical framework that
rigorously analyzes graph prompting from a data operation perspective. Our
contributions are threefold: First, we provide a formal guarantee theorem,
demonstrating graph prompts capacity to approximate graph transformation
operators, effectively linking upstream and downstream tasks. Second, we derive
upper bounds on the error of these data operations by graph prompts for a
single graph and extend this discussion to batches of graphs, which are common
in graph model training. Third, we analyze the distribution of data operation
errors, extending our theoretical findings from linear graph models (e.g., GCN)
to non-linear graph models (e.g., GAT). Extensive experiments support our
theoretical results and confirm the practical implications of these guarantees.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fira: Can We Achieve Full-rank Training of LLMs Under Low-rank
  Constraint? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01623v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01623v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xi Chen, Kaituo Feng, Changsheng Li, Xunhao Lai, Xiangyu Yue, Ye Yuan, Guoren Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low-rank training has emerged as a promising approach for reducing memory
usage in training Large Language Models (LLMs). Previous methods either rely on
decomposing weight matrices (e.g., LoRA), or seek to decompose gradient
matrices (e.g., GaLore) to ensure reduced memory consumption. However, both of
them constrain the training in a low-rank subspace, thus inevitably leading to
sub-optimal performance. This raises a question: whether it is possible to
consistently preserve the low-rank constraint for memory efficiency, while
achieving full-rank training (i.e., training with full-rank gradients of
full-rank weights) to avoid inferior outcomes? In this paper, we propose a new
plug-and-play training framework for LLMs called Fira, as the first attempt to
achieve this goal. First, we observe an interesting phenomenon during LLM
training: the scaling impact of adaptive optimizers (e.g., Adam) on the
gradient norm remains similar from low-rank to full-rank training. Based on
this observation, we propose a norm-based scaling method, which utilizes the
scaling impact of low-rank optimizers as substitutes for that of original
full-rank optimizers to enable full-rank training. In this way, we can preserve
the low-rank constraint in the optimizer while achieving full-rank training for
better performance. Moreover, we find that there are sudden gradient rises
during the optimization process, potentially causing loss spikes. To address
this, we further put forward a norm-growth limiter to smooth the gradient via
regulating the relative increase of gradient norms. Extensive experiments on
the pre-training and fine-tuning of LLMs show that Fira outperforms both LoRA
and GaLore, achieving performance that is comparable to or even better than
full-rank training.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code is available at: https://github.com/xichen-fy/Fira</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On Using Certified Training towards Empirical Robustness 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01617v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01617v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alessandro De Palma, Serge Durand, Zakaria Chihani, François Terrier, Caterina Urban
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Adversarial training is arguably the most popular way to provide empirical
robustness against specific adversarial examples. While variants based on
multi-step attacks incur significant computational overhead, single-step
variants are vulnerable to a failure mode known as catastrophic overfitting,
which hinders their practical utility for large perturbations. A parallel line
of work, certified training, has focused on producing networks amenable to
formal guarantees of robustness against any possible attack. However, the wide
gap between the best-performing empirical and certified defenses has severely
limited the applicability of the latter. Inspired by recent developments in
certified training, which rely on a combination of adversarial attacks with
network over-approximations, and by the connections between local linearity and
catastrophic overfitting, we present experimental evidence on the practical
utility and limitations of using certified training towards empirical
robustness. We show that, when tuned for the purpose, a recent certified
training algorithm can prevent catastrophic overfitting on single-step attacks,
and that it can bridge the gap to multi-step baselines under appropriate
experimental settings. Finally, we present a novel regularizer for network
over-approximations that can achieve similar effects while markedly reducing
runtime.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DRUPI: <span class="highlight-title">Dataset</span> Reduction Using Privileged Information 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01611v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01611v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shaobo Wang, Yantai Yang, Shuaiyu Zhang, Chenghao Sun, Weiya Li, Xuming Hu, Linfeng Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dataset reduction (DR) seeks to select or distill samples from large datasets
into smaller subsets while preserving performance on target tasks. Existing
methods primarily focus on pruning or synthesizing data in the same format as
the original dataset, typically the input data and corresponding labels.
However, in DR settings, we find it is possible to synthesize more information
beyond the data-label pair as an additional learning target to facilitate model
training. In this paper, we introduce Dataset Reduction Using Privileged
Information (DRUPI), which enriches DR by synthesizing privileged information
alongside the reduced dataset. This privileged information can take the form of
feature labels or attention labels, providing auxiliary supervision to improve
model learning. Our findings reveal that effective feature labels must balance
between being overly discriminative and excessively diverse, with a moderate
level proving optimal for improving the reduced dataset's efficacy. Extensive
experiments on ImageNet, CIFAR-10/100, and Tiny ImageNet demonstrate that DRUPI
integrates seamlessly with existing dataset reduction methods, offering
significant performance gains.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Automated Red Teaming with GOAT: the Generative Offensive Agent Tester 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01606v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01606v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maya Pavlova, Erik Brinkman, Krithika Iyer, Vitor Albiero, Joanna Bitton, Hailey Nguyen, Joe Li, Cristian Canton Ferrer, Ivan Evtimov, Aaron Grattafiori
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Red teaming assesses how large language models (LLMs) can produce content
that violates norms, policies, and rules set during their safety training.
However, most existing automated methods in the literature are not
representative of the way humans tend to interact with AI models. Common users
of AI models may not have advanced knowledge of adversarial machine learning
methods or access to model internals, and they do not spend a lot of time
crafting a single highly effective adversarial prompt. Instead, they are likely
to make use of techniques commonly shared online and exploit the multiturn
conversational nature of LLMs. While manual testing addresses this gap, it is
an inefficient and often expensive process. To address these limitations, we
introduce the Generative Offensive Agent Tester (GOAT), an automated agentic
red teaming system that simulates plain language adversarial conversations
while leveraging multiple adversarial prompting techniques to identify
vulnerabilities in LLMs. We instantiate GOAT with 7 red teaming attacks by
prompting a general-purpose model in a way that encourages reasoning through
the choices of methods available, the current target model's response, and the
next steps. Our approach is designed to be extensible and efficient, allowing
human testers to focus on exploring new areas of risk while automation covers
the scaled adversarial stress-testing of known risk territory. We present the
design and evaluation of GOAT, demonstrating its effectiveness in identifying
vulnerabilities in state-of-the-art LLMs, with an ASR@10 of 97% against Llama
3.1 and 88% against GPT-4 on the JailbreakBench dataset.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ENTP: Encoder-only Next Token Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01600v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01600v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ethan Ewer, Daewon Chae, Thomas Zeng, Jinkyu Kim, Kangwook Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Next-token prediction models have predominantly relied on decoder-only
Transformers with causal attention, driven by the common belief that causal
attention is essential to prevent "cheating" by masking future tokens. We
challenge this widely accepted notion and argue that this design choice is
about efficiency rather than necessity. While decoder-only Transformers are
still a good choice for practical reasons, they are not the only viable option.
In this work, we introduce Encoder-only Next Token Prediction (ENTP). We
explore the differences between ENTP and decoder-only Transformers in
expressive power and complexity, highlighting potential advantages of ENTP. We
introduce the Triplet-Counting task and show, both theoretically and
experimentally, that while ENTP can perform this task easily, a decoder-only
Transformer cannot. Finally, we empirically demonstrate ENTP's superior
performance across various realistic tasks, such as length generalization and
in-context learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Model Discovery Using Domain Decomposition and PINNs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01599v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01599v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tirtho S. Saha, Alexander Heinlein, Cordula Reisch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We enhance machine learning algorithms for learning model parameters in
complex systems represented by ordinary differential equations (ODEs) with
domain decomposition methods. The study evaluates the performance of two
approaches, namely (vanilla) Physics-Informed Neural Networks (PINNs) and
Finite Basis Physics-Informed Neural Networks (FBPINNs), in learning the
dynamics of test models with a quasi-stationary longtime behavior. We test the
approaches for data sets in different dynamical regions and with varying noise
level. As results, we find a better performance for the FBPINN approach
compared to the vanilla PINN approach, even in cases with data from only a
quasi-stationary time domain with few dynamics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SAFE: Semantic Adaptive Feature Extraction with Rate Control for 6G
  Wireless Communications 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01597v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01597v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuna Yan, Lixin Li, Xin Zhang, Wensheng Lin, Wenchi Cheng, Zhu Han
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Most current Deep Learning-based Semantic Communication (DeepSC) systems are
designed and trained exclusively for particular single-channel conditions,
which restricts their adaptability and overall bandwidth utilization. To
address this, we propose an innovative Semantic Adaptive Feature Extraction
(SAFE) framework, which significantly improves bandwidth efficiency by allowing
users to select different sub-semantic combinations based on their channel
conditions. This paper also introduces three advanced learning algorithms to
optimize the performance of SAFE framework as a whole. Through a series of
simulation experiments, we demonstrate that the SAFE framework can effectively
and adaptively extract and transmit semantics under different channel bandwidth
conditions, of which effectiveness is verified through objective and subjective
quality evaluations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DynFrs: An Efficient Framework for Machine Unlearning in Random Forest 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01588v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01588v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shurong Wang, Zhuoyang Shen, Xinbao Qiao, Tongning Zhang, Meng Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Random Forests are widely recognized for establishing efficacy in
classification and regression tasks, standing out in various domains such as
medical diagnosis, finance, and personalized recommendations. These domains,
however, are inherently sensitive to privacy concerns, as personal and
confidential data are involved. With increasing demand for the right to be
forgotten, particularly under regulations such as GDPR and CCPA, the ability to
perform machine unlearning has become crucial for Random Forests. However,
insufficient attention was paid to this topic, and existing approaches face
difficulties in being applied to real-world scenarios. Addressing this gap, we
propose the DynFrs framework designed to enable efficient machine unlearning in
Random Forests while preserving predictive accuracy. Dynfrs leverages
subsampling method Occ(q) and a lazy tag strategy Lzy, and is still adaptable
to any Random Forest variant. In essence, Occ(q) ensures that each sample in
the training set occurs only in a proportion of trees so that the impact of
deleting samples is limited, and Lzy delays the reconstruction of a tree node
until necessary, thereby avoiding unnecessary modifications on tree structures.
In experiments, applying Dynfrs on Extremely Randomized Trees yields
substantial improvements, achieving orders of magnitude faster unlearning
performance and better predictive accuracy than existing machine unlearning
methods for Random Forests.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning-Augmented Robust Algorithmic Recourse 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01580v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01580v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kshitij Kayastha, Vasilis Gkatzelis, Shahin Jabbari
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The widespread use of machine learning models in high-stakes domains can have
a major negative impact, especially on individuals who receive undesirable
outcomes. Algorithmic recourse provides such individuals with suggestions of
minimum-cost improvements they can make to achieve a desirable outcome in the
future. However, machine learning models often get updated over time and this
can cause a recourse to become invalid (i.e., not lead to the desirable
outcome). The robust recourse literature aims to choose recourses that are less
sensitive, even against adversarial model changes, but this comes at a higher
cost. To overcome this obstacle, we initiate the study of algorithmic recourse
through the learning-augmented framework and evaluate the extent to which a
designer equipped with a prediction regarding future model changes can reduce
the cost of recourse when the prediction is accurate (consistency) while also
limiting the cost even when the prediction is inaccurate (robustness). We
propose a novel algorithm for this problem, study the robustness-consistency
trade-off, and analyze how prediction accuracy affects performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Coordinate-Based Neural Representation Enabling Zero-Shot Learning for
  3D Multiparametric Quantitative MRI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01577v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01577v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guoyan Lao, Ruimin Feng, Haikun Qi, Zhenfeng Lv, Qiangqiang Liu, Chunlei Liu, Yuyao Zhang, Hongjiang Wei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Quantitative magnetic resonance imaging (qMRI) offers tissue-specific
physical parameters with significant potential for neuroscience research and
clinical practice. However, lengthy scan times for 3D multiparametric qMRI
acquisition limit its clinical utility. Here, we propose SUMMIT, an innovative
imaging methodology that includes data acquisition and an unsupervised
reconstruction for simultaneous multiparametric qMRI. SUMMIT first encodes
multiple important quantitative properties into highly undersampled k-space. It
further leverages implicit neural representation incorporated with a dedicated
physics model to reconstruct the desired multiparametric maps without needing
external training datasets. SUMMIT delivers co-registered T1, T2, T2*, and
quantitative susceptibility mapping. Extensive simulations and phantom imaging
demonstrate SUMMIT's high accuracy. Additionally, the proposed unsupervised
approach for qMRI reconstruction also introduces a novel zero-shot learning
paradigm for multiparametric imaging applicable to various medical imaging
modalities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fake It Until You Break It: On the Adversarial Robustness of
  AI-generated Image Detectors 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01574v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01574v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sina Mavali, Jonas Ricker, David Pape, Yash Sharma, Asja Fischer, Lea Schoenherr
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While generative AI (GenAI) offers countless possibilities for creative and
productive tasks, artificially generated media can be misused for fraud,
manipulation, scams, misinformation campaigns, and more. To mitigate the risks
associated with maliciously generated media, forensic classifiers are employed
to identify AI-generated content. However, current forensic classifiers are
often not evaluated in practically relevant scenarios, such as the presence of
an attacker or when real-world artifacts like social media degradations affect
images. In this paper, we evaluate state-of-the-art AI-generated image (AIGI)
detectors under different attack scenarios. We demonstrate that forensic
classifiers can be effectively attacked in realistic settings, even when the
attacker does not have access to the target model and post-processing occurs
after the adversarial examples are created, which is standard on social media
platforms. These attacks can significantly reduce detection accuracy to the
extent that the risks of relying on detectors outweigh their benefits. Finally,
we propose a simple defense mechanism to make CLIP-based detectors, which are
currently the best-performing detectors, robust against these attacks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Truncated Kernel Stochastic Gradient Descent on Spheres 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01570v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01570v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        JinHui Bai, Lei Shi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Inspired by the structure of spherical harmonics, we propose the truncated
kernel stochastic gradient descent (T-kernel SGD) algorithm with a least-square
loss function for spherical data fitting. T-kernel SGD employs a "truncation"
operation, enabling the application of a series-based kernel function in
stochastic gradient descent, thereby avoiding the difficulties of finding
suitable closed-form kernel functions in high-dimensional spaces. In contrast
to traditional kernel SGD, T-kernel SGD is more effective in balancing bias and
variance by dynamically adjusting the hypothesis space during iterations. The
most significant advantage of the proposed algorithm is that it can achieve
theoretically optimal convergence rates using a constant step size (independent
of the sample size) while overcoming the inherent saturation problem of kernel
SGD. Additionally, we leverage the structure of spherical polynomials to derive
an equivalent T-kernel SGD, significantly reducing storage and computational
costs compared to kernel SGD. Typically, T-kernel SGD requires only
$\mathcal{O}(n^{1+\frac{d}{d-1}\epsilon})$ computational complexity and
$\mathcal{O}(n^{\frac{d}{d-1}\epsilon})$ storage to achieve optimal rates for
the d-dimensional sphere, where $0<\epsilon<\frac{1}{2}$ can be arbitrarily
small if the optimal fitting or the underlying space possesses sufficient
regularity. This regularity is determined by the smoothness parameter of the
objective function and the decaying rate of the eigenvalues of the integral
operator associated with the kernel function, both of which reflect the
difficulty of the estimation problem. Our main results quantitatively
characterize how this prior information influences the convergence of T-kernel
SGD. The numerical experiments further validate the theoretical findings
presented in this paper.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>57 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bayes' Power for Explaining In-Context Learning Generalizations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01565v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01565v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Samuel Müller, Noah Hollmann, Frank Hutter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Traditionally, neural network training has been primarily viewed as an
approximation of maximum likelihood estimation (MLE). This interpretation
originated in a time when training for multiple epochs on small datasets was
common and performance was data bound; but it falls short in the era of
large-scale single-epoch trainings ushered in by large self-supervised setups,
like language models. In this new setup, performance is compute-bound, but data
is readily available. As models became more powerful, in-context learning
(ICL), i.e., learning in a single forward-pass based on the context, emerged as
one of the dominant paradigms. In this paper, we argue that a more useful
interpretation of neural network behavior in this era is as an approximation of
the true posterior, as defined by the data-generating process. We demonstrate
this interpretations' power for ICL and its usefulness to predict
generalizations to previously unseen tasks. We show how models become robust
in-context learners by effectively composing knowledge from their training
data. We illustrate this with experiments that reveal surprising
generalizations, all explicable through the exact posterior. Finally, we show
the inherent constraints of the generalization capabilities of posteriors and
the limitations of neural networks in approximating these posteriors.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HRTF Estimation using a Score-based Prior 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01562v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01562v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Etienne Thuillier, Jean-Marie Lemercier, Eloi Moliner, Timo Gerkmann, Vesa Välimäki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a head-related transfer function (HRTF) estimation method which
relies on a data-driven prior given by a score-based diffusion model. The HRTF
is estimated in reverberant environments using natural excitation signals, e.g.
human speech. The impulse response of the room is estimated along with the HRTF
by optimizing a parametric model of reverberation based on the statistical
behaviour of room acoustics. The posterior distribution of HRTF given the
reverberant measurement and excitation signal is modelled using the score-based
HRTF prior and a log-likelihood approximation. We show that the resulting
method outperforms several baselines, including an oracle recommender system
that assigns the optimal HRTF in our training set based on the smallest
distance to the true HRTF at the given direction of arrival. In particular, we
show that the diffusion prior can account for the large variability of
high-frequency content in HRTFs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ OpenMathInstruct-2: Accelerating AI for Math with Massive Open-Source
  Instruction Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01560v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01560v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shubham Toshniwal, Wei Du, Ivan Moshkov, Branislav Kisacanin, Alexan Ayrapetyan, Igor Gitman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mathematical reasoning continues to be a critical challenge in large language
model (LLM) development with significant interest. However, most of the
cutting-edge progress in mathematical reasoning with LLMs has become
\emph{closed-source} due to lack of access to training data. This lack of data
access limits researchers from understanding the impact of different choices
for synthesizing and utilizing the data. With the goal of creating a
high-quality finetuning (SFT) dataset for math reasoning, we conduct careful
ablation experiments on data synthesis using the recently released
\texttt{Llama3.1} family of models. Our experiments show that: (a) solution
format matters, with excessively verbose solutions proving detrimental to SFT
performance, (b) data generated by a strong teacher outperforms
\emph{on-policy} data generated by a weak student model, (c) SFT is robust to
low-quality solutions, allowing for imprecise data filtering, and (d) question
diversity is crucial for achieving data scaling gains. Based on these insights,
we create the OpenMathInstruct-2 dataset, which consists of 14M
question-solution pairs ($\approx$ 600K unique questions), making it nearly
eight times larger than the previous largest open-source math reasoning
dataset. Finetuning the \texttt{Llama-3.1-8B-Base} using OpenMathInstruct-2
outperforms \texttt{Llama3.1-8B-Instruct} on MATH by an absolute 15.9\% (51.9\%
$\rightarrow$ 67.8\%). Finally, to accelerate the open-source efforts, we
release the code, the finetuned models, and the OpenMathInstruct-2 dataset
under a commercially permissive license.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Integrative Decoding: Improve Factuality via Implicit Self-consistency 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01556v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01556v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi Cheng, Xiao Liang, Yeyun Gong, Wen Xiao, Song Wang, Yuji Zhang, Wenjun Hou, Kaishuai Xu, Wenge Liu, Wenjie Li, Jian Jiao, Qi Chen, Peng Cheng, Wayne Xiong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Self-consistency-based approaches, which involve repeatedly sampling multiple
outputs and selecting the most consistent one as the final response, prove to
be remarkably effective in improving the factual accuracy of large language
models. Nonetheless, existing methods usually have strict constraints on the
task format, largely limiting their applicability. In this paper, we present
Integrative Decoding (ID), to unlock the potential of self-consistency in
open-ended generation tasks. ID operates by constructing a set of inputs, each
prepended with a previously sampled response, and then processes them
concurrently, with the next token being selected by aggregating of all their
corresponding predictions at each decoding step. In essence, this simple
approach implicitly incorporates self-consistency in the decoding objective.
Extensive evaluation shows that ID consistently enhances factuality over a wide
range of language models, with substantial improvements on the TruthfulQA
(+11.2%), Biographies (+15.4%) and LongFact (+8.5%) benchmarks. The performance
gains amplify progressively as the number of sampled responses increases,
indicating the potential of ID to scale up with repeated sampling.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Lines of Thought in Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01545v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01545v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Raphaël Sarfati, Toni J. B. Liu, Nicolas Boullé, Christopher J. Earls
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models achieve next-token prediction by transporting a
vectorized piece of text (prompt) across an accompanying embedding space under
the action of successive transformer layers. The resulting high-dimensional
trajectories realize different contextualization, or 'thinking', steps, and
fully determine the output probability distribution. We aim to characterize the
statistical properties of ensembles of these 'lines of thought.' We observe
that independent trajectories cluster along a low-dimensional, non-Euclidean
manifold, and that their path can be well approximated by a stochastic equation
with few parameters extracted from data. We find it remarkable that the vast
complexity of such large models can be reduced to a much simpler form, and we
reflect on implications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Edge-preserving noise for diffusion models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01540v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01540v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jente Vandersanden, Sascha Holl, Xingchang Huang, Gurprit Singh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Classical generative diffusion models learn an isotropic Gaussian denoising
process, treating all spatial regions uniformly, thus neglecting potentially
valuable structural information in the data. Inspired by the long-established
work on anisotropic diffusion in image processing, we present a novel
edge-preserving diffusion model that is a generalization of denoising diffusion
probablistic models (DDPM). In particular, we introduce an edge-aware noise
scheduler that varies between edge-preserving and isotropic Gaussian noise. We
show that our model's generative process converges faster to results that more
closely match the target distribution. We demonstrate its capability to better
learn the low-to-mid frequencies within the dataset, which plays a crucial role
in representing shapes and structural information. Our edge-preserving
diffusion process consistently outperforms state-of-the-art baselines in
unconditional image generation. It is also more robust for generative tasks
guided by a shape-based prior, such as stroke-to-image generation. We present
qualitative and quantitative results showing consistent improvements (FID
score) of up to 30% for both tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Attention layers provably solve single-location regression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01537v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01537v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pierre Marion, Raphaël Berthier, Gérard Biau, Claire Boyer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Attention-based models, such as Transformer, excel across various tasks but
lack a comprehensive theoretical understanding, especially regarding token-wise
sparsity and internal linear representations. To address this gap, we introduce
the single-location regression task, where only one token in a sequence
determines the output, and its position is a latent random variable,
retrievable via a linear projection of the input. To solve this task, we
propose a dedicated predictor, which turns out to be a simplified version of a
non-linear self-attention layer. We study its theoretical properties, by
showing its asymptotic Bayes optimality and analyzing its training dynamics. In
particular, despite the non-convex nature of the problem, the predictor
effectively learns the underlying structure. This work highlights the capacity
of attention mechanisms to handle sparse token information and internal linear
structures.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>41 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ TiVaT: Joint-Axis Attention for Time Series Forecasting with Lead-Lag
  Dynamics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01531v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01531v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junwoo Ha, Hyukjae Kwon, Sungsoo Kim, Kisu Lee, Ha Young Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multivariate time series (MTS) forecasting plays a crucial role in various
real-world applications, yet simultaneously capturing both temporal and
inter-variable dependencies remains a challenge. Conventional Channel-Dependent
(CD) models handle these dependencies separately, limiting their ability to
model complex interactions such as lead-lag dynamics. To address these
limitations, we propose TiVaT (Time-Variable Transformer), a novel architecture
that integrates temporal and variate dependencies through its Joint-Axis (JA)
attention mechanism. TiVaT's ability to capture intricate variate-temporal
dependencies, including asynchronous interactions, is further enhanced by the
incorporation of Distance-aware Time-Variable (DTV) Sampling, which reduces
noise and improves accuracy through a learned 2D map that focuses on key
interactions. TiVaT effectively models both temporal and variate dependencies,
consistently delivering strong performance across diverse datasets. Notably, it
excels in capturing complex patterns within multivariate time series, enabling
it to surpass or remain competitive with state-of-the-art methods. This
positions TiVaT as a new benchmark in MTS forecasting, particularly in handling
datasets characterized by intricate and challenging dependencies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bounds on $L_p$ Errors in Density Ratio Estimation via $f$-Divergence
  Loss Functions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01516v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01516v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yoshiaki Kitazawa
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Density ratio estimation (DRE) is a fundamental machine learning technique
for identifying relationships between two probability distributions.
$f$-divergence loss functions, derived from variational representations of
$f$-divergence, are commonly employed in DRE to achieve state-of-the-art
results. This study presents a novel perspective on DRE using $f$-divergence
loss functions by deriving the upper and lower bounds on $L_p$ errors. These
bounds apply to any estimator within a class of Lipschitz continuous
estimators, irrespective of the specific $f$-divergence loss functions
utilized. The bounds are formulated as a product of terms that include the data
dimension and the expected value of the density ratio raised to the power of
$p$. Notably, the lower bound incorporates an exponential term dependent on the
Kullback--Leibler divergence, indicating that the $L_p$ error significantly
increases with the Kullback--Leibler divergence for $p > 1$, and this increase
becomes more pronounced as $p$ increases. Furthermore, these theoretical
findings are substantiated through numerical experiments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LEGO: Learnable Expansion of Graph Operators for Multi-Modal Feature
  Fusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01506v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01506v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dexuan Ding, Lei Wang, Liyun Zhu, Tom Gedeon, Piotr Koniusz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In computer vision tasks, features often come from diverse representations,
domains, and modalities, such as text, images, and videos. Effectively fusing
these features is essential for robust performance, especially with the
availability of powerful pre-trained models like vision-language models.
However, common fusion methods, such as concatenation, element-wise operations,
and non-linear techniques, often fail to capture structural relationships, deep
feature interactions, and suffer from inefficiency or misalignment of features
across domains. In this paper, we shift from high-dimensional feature space to
a lower-dimensional, interpretable graph space by constructing similarity
graphs that encode feature relationships at different levels, e.g., clip,
frame, patch, token, etc. To capture deeper interactions, we use graph power
expansions and introduce a learnable graph fusion operator to combine these
graph powers for more effective fusion. Our approach is relationship-centric,
operates in a homogeneous space, and is mathematically principled, resembling
element-wise similarity score aggregation via multilinear polynomials. We
demonstrate the effectiveness of our graph-based fusion method on video anomaly
detection, showing strong performance across multi-representational,
multi-modal, and multi-domain feature fusion tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Research paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Discrete Diffusion Schrödinger Bridge Matching for Graph
  Transformation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01500v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01500v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jun Hyeong Kim, Seonghwan Kim, Seokhyun Moon, Hyeongwoo Kim, Jeheon Woo, Woo Youn Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transporting between arbitrary distributions is a fundamental goal in
generative modeling. Recently proposed diffusion bridge models provide a
potential solution, but they rely on a joint distribution that is difficult to
obtain in practice. Furthermore, formulations based on continuous domains limit
their applicability to discrete domains such as graphs. To overcome these
limitations, we propose Discrete Diffusion Schr\"odinger Bridge Matching
(DDSBM), a novel framework that utilizes continuous-time Markov chains to solve
the SB problem in a high-dimensional discrete state space. Our approach extends
Iterative Markovian Fitting to discrete domains, and we have proved its
convergence to the SB. Furthermore, we adapt our framework for the graph
transformation and show that our design choice of underlying dynamics
characterized by independent modifications of nodes and edges can be
interpreted as the entropy-regularized version of optimal transport with a cost
function described by the graph edit distance. To demonstrate the effectiveness
of our framework, we have applied DDSBM to molecular optimization in the field
of chemistry. Experimental results demonstrate that DDSBM effectively optimizes
molecules' property-of-interest with minimal graph transformation, successfully
retaining other features.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DLP-LoRA: Efficient Task-Specific LoRA Fusion with a Dynamic,
  Lightweight Plugin for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01497v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01497v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxuan Zhang, Ruizhe Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in Large Language Models (LLMs) have achieved robust
performance across diverse tasks, but fine-tuning these models for specific
domains remains resource-intensive. Parameter-Efficient Fine-Tuning (PEFT)
methods like Low-Rank Adaptation (LoRA) address this challenge by fine-tuning a
small subset of parameters. However, existing methods for fusing multiple LoRAs
lack dynamic fusion based on contextual inputs and often increase inference
time due to token-level operations. We propose DLP-LoRA, a Dynamic Lightweight
Plugin that employs a mini-MLP module with only 5M parameters to dynamically
fuse multiple LoRAs at the sentence level using top-p sampling strategies. This
approach reduces inference time to less than twice that of single LoRA
inference by leveraging parallel computation. Evaluations across 26
tasks-including multiple-choice questions and question answering-demonstrate
that DLP-LoRA achieves an average accuracy of 92.34% on multiple-choice
datasets and significant improvements in BLEU and ROUGE scores on QA datasets,
outperforming different LLMs backbones under composite task settings. DLP-LoRA
effectively balances performance and efficiency, making it a practical solution
for dynamic multi-task adaptation in LLMs. Our code is available at
https://github.com/MeCuping/DLP-LoRA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint under review, 18 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Foldable SuperNets: Scalable Merging of <span class="highlight-title">Transformer</span>s with Different
  Initializations and Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01483v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01483v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Edan Kinderman, Itay Hubara, Haggai Maron, Daniel Soudry
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many recent methods aim to merge neural networks (NNs) with identical
architectures trained on different tasks to obtain a single multi-task model.
Most existing works tackle the simpler setup of merging NNs initialized from a
common pre-trained network, where simple heuristics like weight averaging work
well. This work targets a more challenging goal: merging large transformers
trained on different tasks from distinct initializations. First, we demonstrate
that traditional merging methods fail catastrophically in this setup. To
overcome this challenge, we propose Foldable SuperNet Merge (FS-Merge), a
method that optimizes a SuperNet to fuse the original models using a feature
reconstruction loss. FS-Merge is simple, data-efficient, and capable of merging
models of varying widths. We test FS-Merge against existing methods, including
knowledge distillation, on MLPs and transformers across various settings,
sizes, tasks, and modalities. FS-Merge consistently outperforms them, achieving
SOTA results, particularly in limited data scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ One Wave to Explain Them All: A Unifying Perspective on Post-hoc
  Explainability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01482v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01482v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gabriel Kasmi, Amandine Brunetto, Thomas Fel, Jayneel Parekh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the growing use of deep neural networks in safety-critical
decision-making, their inherent black-box nature hinders transparency and
interpretability. Explainable AI (XAI) methods have thus emerged to understand
a model's internal workings, and notably attribution methods also called
saliency maps. Conventional attribution methods typically identify the
locations -- the where -- of significant regions within an input. However,
because they overlook the inherent structure of the input data, these methods
often fail to interpret what these regions represent in terms of structural
components (e.g., textures in images or transients in sounds). Furthermore,
existing methods are usually tailored to a single data modality, limiting their
generalizability. In this paper, we propose leveraging the wavelet domain as a
robust mathematical foundation for attribution. Our approach, the Wavelet
Attribution Method (WAM) extends the existing gradient-based feature
attributions into the wavelet domain, providing a unified framework for
explaining classifiers across images, audio, and 3D shapes. Empirical
evaluations demonstrate that WAM matches or surpasses state-of-the-art methods
across faithfulness metrics and models in image, audio, and 3D explainability.
Finally, we show how our method explains not only the where -- the important
parts of the input -- but also the what -- the relevant patterns in terms of
structural components.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>main: 10 pages, appendix: 14 pages, 5 Tables, 25 Figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Introducing Flexible Monotone Multiple Choice Item Response Theory
  Models and Bit Scales 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01480v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01480v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joakim Wallmark, Maria Josefsson, Marie Wiberg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Item Response Theory (IRT) is a powerful statistical approach for evaluating
test items and determining test taker abilities through response analysis. An
IRT model that better fits the data leads to more accurate latent trait
estimates. In this study, we present a new model for multiple choice data, the
monotone multiple choice (MMC) model, which we fit using autoencoders. Using
both simulated scenarios and real data from the Swedish Scholastic Aptitude
Test, we demonstrate empirically that the MMC model outperforms the traditional
nominal response IRT model in terms of fit. Furthermore, we illustrate how the
latent trait scale from any fitted IRT model can be transformed into a ratio
scale, aiding in score interpretation and making it easier to compare different
types of IRT models. We refer to these new scales as bit scales. Bit scales are
especially useful for models for which minimal or no assumptions are made for
the latent trait scale distributions, such as for the autoencoder fitted models
in this study.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reducing Variance in Meta-Learning via Laplace Approximation for
  Regression Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01476v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01476v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alfredo Reichlin, Gustaf Tegnér, Miguel Vasco, Hang Yin, Mårten Björkman, Danica Kragic
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Given a finite set of sample points, meta-learning algorithms aim to learn an
optimal adaptation strategy for new, unseen tasks. Often, this data can be
ambiguous as it might belong to different tasks concurrently. This is
particularly the case in meta-regression tasks. In such cases, the estimated
adaptation strategy is subject to high variance due to the limited amount of
support data for each task, which often leads to sub-optimal generalization
performance. In this work, we address the problem of variance reduction in
gradient-based meta-learning and formalize the class of problems prone to this,
a condition we refer to as \emph{task overlap}. Specifically, we propose a
novel approach that reduces the variance of the gradient estimate by weighing
each support point individually by the variance of its posterior over the
parameters. To estimate the posterior, we utilize the Laplace approximation,
which allows us to express the variance in terms of the curvature of the loss
landscape of our meta-learner. Experimental results demonstrate the
effectiveness of the proposed method and highlight the importance of variance
reduction in meta-learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Flow Matching for Accelerated Simulation of Atomic Transport in
  Materials 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01464v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01464v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Juno Nam, Sulin Liu, Gavin Winter, KyuJung Jun, Soojung Yang, Rafael Gómez-Bombarelli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce LiFlow, a generative framework to accelerate molecular dynamics
(MD) simulations for crystalline materials that formulates the task as
conditional generation of atomic displacements. The model uses flow matching,
with a Propagator submodel to generate atomic displacements and a Corrector to
locally correct unphysical geometries, and incorporates an adaptive prior based
on the Maxwell-Boltzmann distribution to account for chemical and thermal
conditions. We benchmark LiFlow on a dataset comprising 25-ps trajectories of
lithium diffusion across 4,186 solid-state electrolyte (SSE) candidates at four
temperatures. The model obtains a consistent Spearman rank correlation of
0.7-0.8 for lithium mean squared displacement (MSD) predictions on unseen
compositions. Furthermore, LiFlow generalizes from short training trajectories
to larger supercells and longer simulations while maintaining high accuracy.
With speed-ups of up to 600,000$\times$ compared to first-principles methods,
LiFlow enables scalable simulations at significantly larger length and time
scales.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Selective Aggregation for Low-Rank Adaptation in Federated Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01463v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01463v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pengxin Guo, Shuang Zeng, Yanran Wang, Huijie Fan, Feifei Wang, Liangqiong Qu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We investigate LoRA in federated learning through the lens of the asymmetry
analysis of the learned $A$ and $B$ matrices. In doing so, we uncover that $A$
matrices are responsible for learning general knowledge, while $B$ matrices
focus on capturing client-specific knowledge. Based on this finding, we
introduce Federated Share-A Low-Rank Adaptation (FedSA-LoRA), which employs two
low-rank trainable matrices $A$ and $B$ to model the weight update, but only
$A$ matrices are shared with the server for aggregation. Moreover, we delve
into the relationship between the learned $A$ and $B$ matrices in other LoRA
variants, such as rsLoRA and VeRA, revealing a consistent pattern.
Consequently, we extend our FedSA-LoRA method to these LoRA variants, resulting
in FedSA-rsLoRA and FedSA-VeRA. In this way, we establish a general paradigm
for integrating LoRA with FL, offering guidance for future work on subsequent
LoRA variants combined with FL. Extensive experimental results on natural
language understanding and generation tasks demonstrate the effectiveness of
the proposed method.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ From Reward Shaping to Q-Shaping: Achieving Unbiased Learning with
  LLM-Guided Knowledge 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01458v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01458v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiefeng Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Q-shaping is an extension of Q-value initialization and serves as an
alternative to reward shaping for incorporating domain knowledge to accelerate
agent training, thereby improving sample efficiency by directly shaping
Q-values. This approach is both general and robust across diverse tasks,
allowing for immediate impact assessment while guaranteeing optimality. We
evaluated Q-shaping across 20 different environments using a large language
model (LLM) as the heuristic provider. The results demonstrate that Q-shaping
significantly enhances sample efficiency, achieving a \textbf{16.87\%}
improvement over the best baseline in each environment and a \textbf{253.80\%}
improvement compared to LLM-based reward shaping methods. These findings
establish Q-shaping as a superior and unbiased alternative to conventional
reward shaping in reinforcement learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>q-shaping, reinforcement learning, reward shaping</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Verbalized Graph Representation Learning: A Fully Interpretable Graph
  Model Based on Large Language Models Throughout the Entire Process 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01457v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01457v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingyu Ji, Jiale Liu, Lu Li, Maojun Wang, Zeyu Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Representation learning on text-attributed graphs (TAGs) has attracted
significant interest due to its wide-ranging real-world applications,
particularly through Graph Neural Networks (GNNs). Traditional GNN methods
focus on encoding the structural information of graphs, often using shallow
text embeddings for node or edge attributes. This limits the model to
understand the rich semantic information in the data and its reasoning ability
for complex downstream tasks, while also lacking interpretability. With the
rise of large language models (LLMs), an increasing number of studies are
combining them with GNNs for graph representation learning and downstream
tasks. While these approaches effectively leverage the rich semantic
information in TAGs datasets, their main drawback is that they are only
partially interpretable, which limits their application in critical fields. In
this paper, we propose a verbalized graph representation learning (VGRL) method
which is fully interpretable. In contrast to traditional graph machine learning
models, which are usually optimized within a continuous parameter space, VGRL
constrains this parameter space to be text description which ensures complete
interpretability throughout the entire process, making it easier for users to
understand and trust the decisions of the model. We conduct several studies to
empirically evaluate the effectiveness of VGRL and we believe these method can
serve as a stepping stone in graph representation learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>under review. corresponding author: Zeyu Zhang</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Ensembles provably learn equivariance through data augmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01452v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01452v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Oskar Nordenfors, Axel Flinth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, it was proved that group equivariance emerges in ensembles of
neural networks as the result of full augmentation in the limit of infinitely
wide neural networks (neural tangent kernel limit). In this paper, we extend
this result significantly. We provide a proof that this emergence does not
depend on the neural tangent kernel limit at all. We also consider stochastic
settings, and furthermore general architectures. For the latter, we provide a
simple sufficient condition on the relation between the architecture and the
action of the group for our results to hold. We validate our findings through
simple numeric experiments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         <span class="highlight-title">★</span> Geometric Signatures of Compositionality Across a Language Model's
  Lifetime <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01444v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01444v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jin Hwa Lee, Thomas Jiralerspong, Lei Yu, <span class="highlight-author">Yoshua Bengio</span>, Emily Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Compositionality, the notion that the meaning of an expression is constructed
from the meaning of its parts and syntactic rules, permits the infinite
productivity of human language. For the first time, artificial language models
(LMs) are able to match human performance in a number of compositional
generalization tasks. However, much remains to be understood about the
representational mechanisms underlying these abilities. We take a high-level
geometric approach to this problem by relating the degree of compositionality
in a dataset to the intrinsic dimensionality of its representations under an
LM, a measure of feature complexity. We find not only that the degree of
dataset compositionality is reflected in representations' intrinsic
dimensionality, but that the relationship between compositionality and
geometric complexity arises due to learned linguistic features over training.
Finally, our analyses reveal a striking contrast between linear and nonlinear
dimensionality, showing that they respectively encode formal and semantic
aspects of linguistic composition.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review as a conference paper at ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Closed-loop Long-horizon Robotic Planning via Equilibrium Sequence
  Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01440v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01440v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinghan Li, Zhicheng Sun, Fei Li, Cao Sheng, Jiazhong Yu, Yadong Mu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the endeavor to make autonomous robots take actions, task planning is a
major challenge that requires translating high-level task descriptions into
long-horizon action sequences. Despite recent advances in language model
agents, they remain prone to planning errors and limited in their ability to
plan ahead. To address these limitations in robotic planning, we advocate a
self-refining scheme that iteratively refines a draft plan until an equilibrium
is reached. Remarkably, this process can be optimized end-to-end from an
analytical perspective without the need to curate additional verifiers or
reward models, allowing us to train self-refining planners in a simple
supervised learning fashion. Meanwhile, a nested equilibrium sequence modeling
procedure is devised for efficient closed-loop planning that incorporates
useful feedback from the environment (or an internal world model). Our method
is evaluated on the VirtualHome-Env benchmark, showing advanced performance
with better scaling for inference computation. Code is available at
https://github.com/Singularity0104/equilibrium-planner.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Information-Theoretical Principled Trade-off between Jailbreakability
  and Stealthiness on Vision Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01438v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01438v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ching-Chia Kao, Chia-Mu Yu, Chun-Shien Lu, Chu-Song Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, Vision-Language Models (VLMs) have demonstrated significant
advancements in artificial intelligence, transforming tasks across various
domains. Despite their capabilities, these models are susceptible to jailbreak
attacks, which can compromise their safety and reliability. This paper explores
the trade-off between jailbreakability and stealthiness in VLMs, presenting a
novel algorithm to detect non-stealthy jailbreak attacks and enhance model
robustness. We introduce a stealthiness-aware jailbreak attack using diffusion
models, highlighting the challenge of detecting AI-generated content. Our
approach leverages Fano's inequality to elucidate the relationship between
attack success rates and stealthiness scores, providing an explainable
framework for evaluating these threats. Our contributions aim to fortify AI
systems against sophisticated attacks, ensuring their outputs remain aligned
with ethical standards and user expectations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Circuit Compositions: Exploring Modular Structures in <span class="highlight-title">Transformer</span>-Based
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01434v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01434v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Philipp Mondorf, Sondre Wold, Barbara Plank
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A fundamental question in interpretability research is to what extent neural
networks, particularly language models, implement reusable functions via
subnetworks that can be composed to perform more complex tasks. Recent
developments in mechanistic interpretability have made progress in identifying
subnetworks, often referred to as circuits, which represent the minimal
computational subgraph responsible for a model's behavior on specific tasks.
However, most studies focus on identifying circuits for individual tasks
without investigating how functionally similar circuits relate to each other.
To address this gap, we examine the modularity of neural networks by analyzing
circuits for highly compositional subtasks within a transformer-based language
model. Specifically, given a probabilistic context-free grammar, we identify
and compare circuits responsible for ten modular string-edit operations. Our
results indicate that functionally similar circuits exhibit both notable node
overlap and cross-task faithfulness. Moreover, we demonstrate that the circuits
identified can be reused and combined through subnetwork set operations to
represent more complex functional capabilities of the model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>24 pages, 17 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         <span class="highlight-title">★</span> Adaptive teachers for amortized samplers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01432v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01432v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minsu Kim, Sanghyeok Choi, Taeyoung Yun, Emmanuel Bengio, Leo Feng, Jarrid Rector-Brooks, Sungsoo Ahn, Jinkyoo Park, Nikolay Malkin, <span class="highlight-author">Yoshua Bengio</span>
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Amortized inference is the task of training a parametric model, such as a
neural network, to approximate a distribution with a given unnormalized density
where exact sampling is intractable. When sampling is implemented as a
sequential decision-making process, reinforcement learning (RL) methods, such
as generative flow networks, can be used to train the sampling policy.
Off-policy RL training facilitates the discovery of diverse, high-reward
candidates, but existing methods still face challenges in efficient
exploration. We propose to use an adaptive training distribution (the Teacher)
to guide the training of the primary amortized sampler (the Student) by
prioritizing high-loss regions. The Teacher, an auxiliary behavior model, is
trained to sample high-error regions of the Student and can generalize across
unexplored modes, thereby enhancing mode coverage by providing an efficient
training curriculum. We validate the effectiveness of this approach in a
synthetic environment designed to present an exploration challenge, two
diffusion-based sampling tasks, and four biochemical discovery tasks
demonstrating its ability to improve sample efficiency and mode coverage.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages, 12 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Scalable Reinforcement Learning-based Neural Architecture Search 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01431v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01431v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amber Cassimon, Siegfried Mercelis, Kevin Mets
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this publication, we assess the ability of a novel Reinforcement
Learning-based solution to the problem of Neural Architecture Search, where a
Reinforcement Learning (RL) agent learns to search for good architectures,
rather than to return a single optimal architecture. We consider both the
NAS-Bench-101 and NAS- Bench-301 settings, and compare against various known
strong baselines, such as local search and random search. We conclude that our
Reinforcement Learning agent displays strong scalability with regards to the
size of the search space, but limited robustness to hyperparameter changes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>33 Pages, 19 Figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Approximation by Steklov Neural Network Operators 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01426v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01426v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        S. N. Karaman, M. Turgay, T. Acar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The present paper deals with construction of newly family of Neural Network
operators, that is,Steklov Neural Network operators. By using Steklov type
integral, we introduce a new version of Neural Network operators and we obtain
some convergence theorems for the family, such as, pointwise and uniform
convergence,rate of convergence via moduli of smoothness of order $r$.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fair4Free: Generating High-fidelity Fair Synthetic Samples using Data
  Free Distillation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01423v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01423v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Md Fahim Sikder, Daniel de Leng, Fredrik Heintz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work presents Fair4Free, a novel generative model to generate synthetic
fair data using data-free distillation in the latent space. Fair4Free can work
on the situation when the data is private or inaccessible. In our approach, we
first train a teacher model to create fair representation and then distil the
knowledge to a student model (using a smaller architecture). The process of
distilling the student model is data-free, i.e. the student model does not have
access to the training dataset while distilling. After the distillation, we use
the distilled model to generate fair synthetic samples. Our extensive
experiments show that our synthetic samples outperform state-of-the-art models
in all three criteria (fairness, utility and synthetic quality) with a
performance increase of 5% for fairness, 8% for utility and 12% in synthetic
quality for both tabular and image datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CASE: Efficient Curricular Data <span class="highlight-title">Pre-train</span>ing for Building Assistive
  Psychology Expert Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.00314v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.00314v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sarthak Harne, Monjoy Narayan Choudhury, Madhav Rao, TK Srikanth, Seema Mehrotra, Apoorva Vashisht, Aarushi Basu, Manjit Sodhi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The limited availability of psychologists necessitates efficient
identification of individuals requiring urgent mental healthcare. This study
explores the use of Natural Language Processing (NLP) pipelines to analyze text
data from online mental health forums used for consultations. By analyzing
forum posts, these pipelines can flag users who may require immediate
professional attention. A crucial challenge in this domain is data privacy and
scarcity. To address this, we propose utilizing readily available curricular
texts used in institutes specializing in mental health for pre-training the NLP
pipelines. This helps us mimic the training process of a psychologist. Our work
presents CASE-BERT that flags potential mental health disorders based on forum
text. CASE-BERT demonstrates superior performance compared to existing methods,
achieving an f1 score of 0.91 for Depression and 0.88 for Anxiety, two of the
most commonly reported mental health disorders. Our code and data are publicly
available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FastCLIP: A Suite of Optimization Techniques to Accelerate CLIP Training
  with Limited Resources 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.01445v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.01445v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiyuan Wei, Fanjiang Ye, Ori Yonay, Xingyu Chen, Baixi Sun, Dingwen Tao, Tianbao Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing studies of training state-of-the-art Contrastive Language-Image
Pretraining (CLIP) models on large-scale data involve hundreds of or even
thousands of GPUs due to the requirement of a large batch size. However, such a
large amount of resources is not accessible to most people. While advanced
compositional optimization techniques for optimizing global contrastive losses
have been demonstrated effective for removing the requirement of large batch
size, their performance on large-scale data remains underexplored and not
optimized. To bridge the gap, this paper explores several aspects of CLIP
training with limited resources (e.g., up to tens of GPUs). First, we introduce
FastCLIP, a general CLIP training framework built on advanced compositional
optimization techniques while designed and optimized for the distributed
setting. Our framework is equipped with an efficient gradient reduction
strategy to reduce communication overhead. Second, to further boost training
efficiency, we investigate three components of the framework from an
optimization perspective: the schedule of the inner learning rate, the update
rules of the temperature parameter and the model parameters, respectively.
Experiments on different strategies for each component shed light on how to
conduct CLIP training more efficiently. Finally, we benchmark the performance
of FastCLIP and the state-of-the-art training baseline (OpenCLIP) on different
compute scales up to 32 GPUs on 8 nodes, and three data scales ranging from 2.7
million, 9.1 million to 315 million image-text pairs to demonstrate the
significant improvement of FastCLIP in the resource-limited setting. We release
the code of FastCLIP at https://github.com/Optimization-AI/fast_clip .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>29 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Temporal Test-Time Adaptation with State-Space Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12492v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12492v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mona Schirmer, Dan Zhang, Eric Nalisnick
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Distribution shifts between training and test data are inevitable over the
lifecycle of a deployed model, leading to performance decay. Adapting a model
on test samples can help mitigate this drop in performance. However, most
test-time adaptation methods have focused on synthetic corruption shifts,
leaving a variety of distribution shifts underexplored. In this paper, we focus
on distribution shifts that evolve gradually over time, which are common in the
wild but challenging for existing methods, as we show. To address this, we
propose STAD, a probabilistic state-space model that adapts a deployed model to
temporal distribution shifts by learning the time-varying dynamics in the last
set of hidden features. Without requiring labels, our model infers
time-evolving class prototypes that act as a dynamic classification head.
Through experiments on real-world temporal distribution shifts, we show that
our method excels in handling small batch sizes and label shift.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VisionTS: Visual Masked Autoencoders Are Free-Lunch Zero-Shot Time
  Series Forecasters 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.17253v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.17253v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mouxiang Chen, Lefei Shen, Zhuo Li, Xiaoyun Joy Wang, Jianling Sun, Chenghao Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Foundation models have emerged as a promising approach in time series
forecasting (TSF). Existing approaches either repurpose large language models
(LLMs) or build large-scale time series datasets to develop TSF foundation
models for universal forecasting. However, these methods face challenges due to
the severe cross-domain gap or in-domain heterogeneity. This paper explores a
new road to building a TSF foundation model from rich, high-quality natural
images. Our key insight is that a visual masked autoencoder, pre-trained on the
ImageNet dataset, can naturally be a numeric series forecaster. By
reformulating TSF as an image reconstruction task, we bridge the gap between
image pre-training and TSF downstream tasks. Surprisingly, without further
adaptation in the time-series domain, the proposed VisionTS could achieve
superior zero-shot forecasting performance compared to existing TSF foundation
models. With fine-tuning for one epoch, VisionTS could further improve the
forecasting and achieve state-of-the-art performance in most cases. Extensive
experiments reveal intrinsic similarities between images and real-world time
series, suggesting visual models may offer a ``free lunch'' for TSF and
highlight the potential for future cross-modality research. Our code is
publicly available at https://github.com/Keytoyze/VisionTS.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>v2: add more experiments</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Concept-skill Transferability-based Data Selection for Large
  Vision-Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.10995v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.10995v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jaewoo Lee, Boyang Li, Sung Ju Hwang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Instruction tuning, or supervised finetuning on extensive task-specific data,
is necessary for Large Vision-Language Models (LVLMs) to generalize well across
a broad range of vision-language (VL) tasks. However, training on large VL
datasets can become prohibitively expensive. In this work, we introduce
COINCIDE, an effective and scalable data selection technique that uses a small
model as a reference model to select visual instruction tuning data for
efficient finetuning of a target LVLM, focusing on diversity and
transferability. Specifically, we cluster the training data using internal
activations from a small model, which identifies VL concept-skill compositions
needed by a target LVLM. We then sample data from these diverse clusters by
considering their density and transferability, or the ability to transfer well
to other concept-skill compositions. This approach ensures the diversity of
these compositions, which is vital for LVLM generalization. Extensive
experiments demonstrate that COINCIDE achieves superior performance and data
selection efficiency against 8 strong baselines on two distinct datasets:
LLaVA-1.5 and Vision-Flan. Using only 20% of the LLaVA-1.5 dataset, COINCIDE
achieves performance comparable to the LVLM finetuned on the whole dataset,
with 70% reduction of the wall-clock running time. On the Vision-Flan dataset,
our method achieves superior results with only 16.7% of the training data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Eliminating Position Bias of Language Models: A Mechanistic Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.01100v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.01100v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziqi Wang, Hanlin Zhang, Xiner Li, Kuan-Hao Huang, Chi Han, Shuiwang Ji, Sham M. Kakade, Hao Peng, Heng Ji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Position bias has proven to be a prevalent issue of modern language models
(LMs), where the models prioritize content based on its position within the
given context. This bias often leads to unexpected model failures and hurts
performance, robustness, and reliability across various applications. Our
mechanistic analysis attributes the position bias to two components employed in
nearly all state-of-the-art LMs: causal attention and relative positional
encodings. Based on the analyses, we propose to eliminate position bias (e.g.,
different retrieved documents' orders in QA affect performance) with a
training-free zero-shot approach. Our method changes the causal attention to
bidirectional attention between documents and utilizes model attention values
to decide the relative orders of documents instead of using the order provided
in input prompts, therefore enabling Position-INvariant inferencE (PINE) at the
document level. By eliminating position bias, models achieve better performance
and reliability in downstream tasks, including LM-as-a-judge,
retrieval-augmented QA, molecule generation, and math reasoning. Notably, PINE
is especially useful when adapting LMs for evaluating reasoning pairs: it
consistently provides 8 to 10 percentage points performance gains, making
Llama-3-70B-Instruct perform even better than GPT-4-0125-preview and
GPT-4o-2024-08-06 on the RewardBench reasoning set.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages, 6 figures, 15 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Scaling Optimal LR Across Token Horizons 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19913v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19913v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Johan Bjorck, Alon Benhaim, Vishrav Chaudhary, Furu Wei, Xia Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  State-of-the-art LLMs are powered by scaling -- scaling model size, dataset
size and cluster size. It is economically infeasible to extensively tune
hyperparameter for the largest runs. Instead, approximately optimal
hyperparameters must be inferred or \textit{transferred} from smaller
experiments. Hyperparameter transfer across model sizes has been studied in
Yang et al. However, hyperparameter transfer across dataset size -- or token
horizon -- has not been studied yet. To remedy this we conduct a large scale
empirical study on how optimal learning rate (LR) depends on token horizon in
LLM training. We first demonstrate that the optimal LR changes significantly
with token horizon -- longer training necessitates smaller LR. Secondly we
demonstrate the the optimal LR follows a scaling law, and that the optimal LR
for longer horizons can be accurately estimated from shorter horizons via such
scaling laws. We also provide a rule-of-thumb for transferring LR across token
horizons with zero overhead over current practices. Lastly we provide evidence
that LLama-1 used too high LR, and estimate the performance hit from this. We
thus argue that hyperparameter transfer across data size is an important and
overlooked component of LLM training.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Privacy-Preserving Relational Data Synthesis via Probabilistic
  Relational Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04194v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04194v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Malte Luttermann, Ralf Möller, Mattis Hartwig
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Probabilistic relational models provide a well-established formalism to
combine first-order logic and probabilistic models, thereby allowing to
represent relationships between objects in a relational domain. At the same
time, the field of artificial intelligence requires increasingly large amounts
of relational training data for various machine learning tasks. Collecting
real-world data, however, is often challenging due to privacy concerns, data
protection regulations, high costs, and so on. To mitigate these challenges,
the generation of synthetic data is a promising approach. In this paper, we
solve the problem of generating synthetic relational data via probabilistic
relational models. In particular, we propose a fully-fledged pipeline to go
from relational database to probabilistic relational model, which can then be
used to sample new synthetic relational data points from its underlying
probability distribution. As part of our proposed pipeline, we introduce a
learning algorithm to construct a probabilistic relational model from a given
relational database.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the Proceedings of the 47th German Conference on
  Artificial Intelligence (KI 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Transformer</span>s are Minimax Optimal Nonparametric In-Context Learners <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.12186v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.12186v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Juno Kim, Tai Nakamaki, Taiji Suzuki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In-context learning (ICL) of large language models has proven to be a
surprisingly effective method of learning a new task from only a few
demonstrative examples. In this paper, we study the efficacy of ICL from the
viewpoint of statistical learning theory. We develop approximation and
generalization error bounds for a transformer composed of a deep neural network
and one linear attention layer, pretrained on nonparametric regression tasks
sampled from general function spaces including the Besov space and piecewise
$\gamma$-smooth class. We show that sufficiently trained transformers can
achieve -- and even improve upon -- the minimax optimal estimation risk in
context by encoding the most relevant basis representations during pretraining.
Our analysis extends to high-dimensional or sequential data and distinguishes
the \emph{pretraining} and \emph{in-context} generalization gaps. Furthermore,
we establish information-theoretic lower bounds for meta-learners w.r.t. both
the number of tasks and in-context examples. These findings shed light on the
roles of task diversity and representation learning for ICL.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS 2024; 40 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HOPE for a Robust Parameterization of Long-memory State Space Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.13975v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.13975v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Annan Yu, Michael W. Mahoney, N. Benjamin Erichson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  State-space models (SSMs) that utilize linear, time-invariant (LTI) systems
are known for their effectiveness in learning long sequences. To achieve
state-of-the-art performance, an SSM often needs a specifically designed
initialization, and the training of state matrices is on a logarithmic scale
with a very small learning rate. To understand these choices from a unified
perspective, we view SSMs through the lens of Hankel operator theory. Building
upon it, we develop a new parameterization scheme, called HOPE, for LTI systems
that utilizes Markov parameters within Hankel operators. Our approach helps
improve the initialization and training stability, leading to a more robust
parameterization. We efficiently implement these innovations by nonuniformly
sampling the transfer functions of LTI systems, and they require fewer
parameters compared to canonical SSMs. When benchmarked against
HiPPO-initialized models such as S4 and S4D, an SSM parameterized by Hankel
operators demonstrates improved performance on Long-Range Arena (LRA) tasks.
Moreover, our new parameterization endows the SSM with non-decaying memory
within a fixed time window, which is empirically corroborated by a sequential
CIFAR-10 task with padded noise.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning Dynamics of LLM Finetuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10490v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10490v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yi Ren, Danica J. Sutherland
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning dynamics, which describes how the learning of specific training
examples influences the model's predictions on other examples, gives us a
powerful tool for understanding the behavior of deep learning systems. We study
the learning dynamics of large language models during different types of
finetuning, by analyzing the step-wise decomposition of how influence
accumulates among different potential responses. Our framework allows a uniform
interpretation of many interesting observations about the training of popular
algorithms for both instruction tuning and preference tuning. In particular, we
propose a hypothetical explanation of why specific types of hallucination are
strengthened after finetuning, e.g., the model might use phrases or facts in
the response for question B to answer question A, or the model might keep
repeating similar simple phrases when generating responses. We also extend our
framework and highlight a unique "squeezing effect" to explain a previously
observed phenomenon in off-policy direct preference optimization (DPO), where
running DPO for too long makes even the desired outputs less likely. This
framework also provides insights into where the benefits of on-policy DPO and
other variants come from. The analysis not only provides a novel perspective of
understanding LLM's finetuning but also inspires a simple, effective method to
improve alignment performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Latent Diffusion Models for Controllable RNA Sequence Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.09828v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.09828v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaixuan Huang, Yukang Yang, Kaidi Fu, Yanyi Chu, Le Cong, Mengdi Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work presents RNAdiffusion, a latent diffusion model for generating and
optimizing discrete RNA sequences of variable lengths. RNA is a key
intermediary between DNA and protein, exhibiting high sequence diversity and
complex three-dimensional structures to support a wide range of functions. We
utilize pretrained BERT-type models to encode raw RNA sequences into
token-level, biologically meaningful representations. A Query Transformer is
employed to compress such representations into a set of fixed-length latent
vectors, with an autoregressive decoder trained to reconstruct RNA sequences
from these latent variables. We then develop a continuous diffusion model
within this latent space. To enable optimization, we integrate the gradients of
reward models--surrogates for RNA functional properties--into the backward
diffusion process, thereby generating RNAs with high reward scores. Empirical
results confirm that RNAdiffusion generates non-coding RNAs that align with
natural distributions across various biological metrics. Further, we fine-tune
the diffusion model on mRNA 5' untranslated regions (5'-UTRs) and optimize
sequences for high translation efficiencies. Our guided diffusion model
effectively generates diverse 5'-UTRs with high Mean Ribosome Loading (MRL) and
Translation Efficiency (TE), outperforming baselines in balancing rewards and
structural stability trade-off. Our findings hold potential for advancing RNA
sequence-function research and therapeutic RNA design.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Deep Separable Spatiotemporal Learning for Fast Dynamic Cardiac MRI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.15939v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.15939v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zi Wang, Min Xiao, Yirong Zhou, Chengyan Wang, Naiming Wu, Yi Li, Yiwen Gong, Shufu Chang, Yinyin Chen, Liuhong Zhu, Jianjun Zhou, Congbo Cai, He Wang, Di Guo, Guang Yang, Xiaobo Qu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dynamic magnetic resonance imaging (MRI) plays an indispensable role in
cardiac diagnosis. To enable fast imaging, the k-space data can be undersampled
but the image reconstruction poses a great challenge of high-dimensional
processing. This challenge necessitates extensive training data in deep
learning reconstruction methods. In this work, we propose a novel and efficient
approach, leveraging a dimension-reduced separable learning scheme that can
perform exceptionally well even with highly limited training data. We design
this new approach by incorporating spatiotemporal priors into the development
of a Deep Separable Spatiotemporal Learning network (DeepSSL), which unrolls an
iteration process of a 2D spatiotemporal reconstruction model with both
temporal low-rankness and spatial sparsity. Intermediate outputs can also be
visualized to provide insights into the network behavior and enhance
interpretability. Extensive results on cardiac cine datasets demonstrate that
the proposed DeepSSL surpasses state-of-the-art methods both visually and
quantitatively, while reducing the demand for training cases by up to 75%.
Additionally, its preliminary adaptability to unseen cardiac patients has been
verified through a blind reader study conducted by experienced radiologists and
cardiologists. Furthermore, DeepSSL enhances the accuracy of the downstream
task of cardiac segmentation and exhibits robustness in prospectively
undersampled real-time cardiac MRI.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 14 figures, 4 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Test Time Learning for Time Series Forecasting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.14012v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.14012v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Panayiotis Christou, Shichu Chen, Xupeng Chen, Parijat Dube
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Time-series forecasting has seen significant advancements with the
introduction of token prediction mechanisms such as multi-head attention.
However, these methods often struggle to achieve the same performance as in
language modeling, primarily due to the quadratic computational cost and the
complexity of capturing long-range dependencies in time-series data.
State-space models (SSMs), such as Mamba, have shown promise in addressing
these challenges by offering efficient solutions with linear RNNs capable of
modeling long sequences with larger context windows. However, there remains
room for improvement in accuracy and scalability.
  We propose the use of Test-Time Training (TTT) modules in a parallel
architecture to enhance performance in long-term time series forecasting.
Through extensive experiments on standard benchmark datasets, we demonstrate
that TTT modules consistently outperform state-of-the-art models, including the
Mamba-based TimeMachine, particularly in scenarios involving extended sequence
and prediction lengths. Our results show significant improvements in Mean
Squared Error (MSE) and Mean Absolute Error (MAE), especially on larger
datasets such as Electricity, Traffic, and Weather, underscoring the
effectiveness of TTT in capturing long-range dependencies. Additionally, we
explore various convolutional architectures within the TTT framework, showing
that even simple configurations like 1D convolution with small filters can
achieve competitive results. This work sets a new benchmark for time-series
forecasting and lays the groundwork for future research in scalable,
high-performance forecasting models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Strategies for <span class="highlight-title">Pretrain</span>ing Neural Operators 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.08473v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.08473v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anthony Zhou, Cooper Lorsung, AmirPouya Hemmasian, Amir Barati Farimani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pretraining for partial differential equation (PDE) modeling has recently
shown promise in scaling neural operators across datasets to improve
generalizability and performance. Despite these advances, our understanding of
how pretraining affects neural operators is still limited; studies generally
propose tailored architectures and datasets that make it challenging to compare
or examine different pretraining frameworks. To address this, we compare
various pretraining methods without optimizing architecture choices to
characterize pretraining dynamics on different models and datasets as well as
to understand its scaling and generalization behavior. We find that pretraining
is highly dependent on model and dataset choices, but in general transfer
learning or physics-based pretraining strategies work best. In addition,
pretraining performance can be further improved by using data augmentations.
Lastly, pretraining can be additionally beneficial when fine-tuning in scarce
data regimes or when generalizing to downstream data similar to the pretraining
distribution. Through providing insights into pretraining neural operators for
physics prediction, we hope to motivate future work in developing and
evaluating pretraining methods for PDEs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>29 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SysCaps: Language Interfaces for Simulation Surrogates of Complex
  Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.19653v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.19653v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Patrick Emami, Zhaonan Li, Saumya Sinha, Truc Nguyen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Surrogate models are used to predict the behavior of complex energy systems
that are too expensive to simulate with traditional numerical methods. Our work
introduces the use of language descriptions, which we call "system captions" or
SysCaps, to interface with such surrogates. We argue that interacting with
surrogates through text, particularly natural language, makes these models more
accessible for both experts and non-experts. We introduce a lightweight
multimodal text and timeseries regression model and a training pipeline that
uses large language models (LLMs) to synthesize high-quality captions from
simulation metadata. Our experiments on two real-world simulators of buildings
and wind farms show that our SysCaps-augmented surrogates have better accuracy
on held-out systems than traditional methods while enjoying new generalization
abilities, such as handling semantically related descriptions of the same test
system. Additional experiments also highlight the potential of SysCaps to
unlock language-driven design space exploration and to regularize training
through prompt augmentation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages. Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Optimized Multi-Token Joint Decoding with Auxiliary Model for LLM
  Inference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.09722v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.09722v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zongyue Qin, Ziniu Hu, Zifan He, Neha Prakriya, Jason Cong, Yizhou Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have achieved remarkable success across diverse
tasks, yet their inference processes are hindered by substantial time and
energy demands due to single-token generation at each decoding step. While
previous methods such as speculative decoding mitigate these inefficiencies by
producing multiple tokens per step, each token is still generated by its
single-token distribution, thereby enhancing speed without improving
effectiveness. In contrast, our work simultaneously enhances inference speed
and improves the output effectiveness. We consider multi-token joint decoding
(MTJD), which generates multiple tokens from their joint distribution at each
iteration, theoretically reducing perplexity and enhancing task performance.
However, MTJD suffers from the high cost of sampling from the joint
distribution of multiple tokens. Inspired by speculative decoding, we introduce
multi-token assisted decoding (MTAD), a novel framework designed to accelerate
MTJD. MTAD leverages a smaller auxiliary model to approximate the joint
distribution of a larger model, incorporating a verification mechanism that not
only ensures the accuracy of this approximation, but also improves the decoding
efficiency over conventional speculative decoding. Theoretically, we
demonstrate that MTAD closely approximates exact MTJD with bounded error.
Empirical evaluations using Llama-2 and OPT models ranging from 13B to 70B
parameters across various tasks reveal that MTAD reduces perplexity by 21.2%
and improves downstream performance compared to standard single-token sampling.
Furthermore, MTAD achieves a 1.42x speed-up and consumes 1.54x less energy than
conventional speculative decoding methods. These results highlight MTAD's
ability to make multi-token joint decoding both effective and efficient,
promoting more sustainable and high-performance deployment of LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Dimensionality Reduction and Nearest Neighbors for Improving
  Out-of-Distribution Detection in Medical Image Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.02761v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.02761v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        McKell Woodland, Nihil Patel, Austin Castelo, Mais Al Taie, Mohamed Eltaher, Joshua P. Yung, Tucker J. Netherton, Tiffany L. Calderone, Jessica I. Sanchez, Darrel W. Cleere, Ahmed Elsaiey, Nakul Gupta, David Victor, Laura Beretta, Ankit B. Patel, Kristy K. Brock
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Clinically deployed deep learning-based segmentation models are known to fail
on data outside of their training distributions. While clinicians review the
segmentations, these models tend to perform well in most instances, which could
exacerbate automation bias. Therefore, detecting out-of-distribution images at
inference is critical to warn the clinicians that the model likely failed. This
work applied the Mahalanobis distance (MD) post hoc to the bottleneck features
of four Swin UNETR and nnU-net models that segmented the liver on T1-weighted
magnetic resonance imaging and computed tomography. By reducing the dimensions
of the bottleneck features with either principal component analysis or uniform
manifold approximation and projection, images the models failed on were
detected with high performance and minimal computational load. In addition,
this work explored a non-parametric alternative to the MD, a k-th nearest
neighbors distance (KNN). KNN drastically improved scalability and performance
over MD when both were applied to raw and average-pooled bottleneck features.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication at the Journal of Machine Learning for
  Biomedical Imaging (MELBA) https://melba-journal.org/2024:020. Expansion of
  "Dimensionality Reduction for Improving Out-of-Distribution Detection in
  Medical Image Segmentation" arXiv:2308.03723. Code available at
  https://github.com/mckellwoodland/dimen_reduce_mahal
  (https://zenodo.org/records/13881989)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Almost Sure Convergence of Average Reward Temporal Difference Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19546v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19546v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ethan Blaser, Shangtong Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tabular average reward Temporal Difference (TD) learning is perhaps the
simplest and the most fundamental policy evaluation algorithm in average reward
reinforcement learning. After at least 25 years since its discovery, we are
finally able to provide a long-awaited almost sure convergence analysis.
Namely, we are the first to prove that, under very mild conditions, tabular
average reward TD converges almost surely to a sample path dependent fixed
point. Key to this success is a new general stochastic approximation result
concerning nonexpansive mappings with Markovian and additive noise, built on
recent advances in stochastic Krasnoselskii-Mann iterations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Differentially Private Bootstrap: New Privacy Analysis and Inference
  Strategies 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2210.06140v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2210.06140v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhanyu Wang, Guang Cheng, Jordan Awan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Differentially private (DP) mechanisms protect individual-level information
by introducing randomness into the statistical analysis procedure. Despite the
availability of numerous DP tools, there remains a lack of general techniques
for conducting statistical inference under DP. We examine a DP bootstrap
procedure that releases multiple private bootstrap estimates to infer the
sampling distribution and construct confidence intervals (CIs). Our privacy
analysis presents new results on the privacy cost of a single DP bootstrap
estimate, applicable to any DP mechanism, and identifies some misapplications
of the bootstrap in the existing literature. For the composition of the DP
bootstrap, we present a numerical method to compute the exact privacy cost of
releasing multiple DP bootstrap estimates, and using the Gaussian-DP (GDP)
framework (Dong et al., 2022), we show that the release of $B$ DP bootstrap
estimates from mechanisms satisfying $(\mu/\sqrt{(2-2/\mathrm{e})B})$-GDP
asymptotically satisfies $\mu$-GDP as $B$ goes to infinity. Then, we perform
private statistical inference by post-processing the DP bootstrap estimates. We
prove that our point estimates are consistent, our standard CIs are
asymptotically valid, and both enjoy optimal convergence rates. To further
improve the finite performance, we use deconvolution with DP bootstrap
estimates to accurately infer the sampling distribution. We derive CIs for
tasks such as population mean estimation, logistic regression, and quantile
regression, and we compare them to existing methods using simulations and
real-world experiments on 2016 Canada Census data. Our private CIs achieve the
nominal coverage level and offer the first approach to private inference for
quantile regression.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Neural Context Flows for Meta-Learning of Dynamical Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.02154v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.02154v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Roussel Desmond Nzoyem, David A. W. Barton, Tom Deakin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural Ordinary Differential Equations (NODEs) often struggle to adapt to new
dynamic behaviors caused by parameter changes in the underlying system, even
when these dynamics are similar to previously observed behaviors. This problem
becomes more challenging when the changing parameters are unobserved, meaning
their value or influence cannot be directly measured when collecting data. To
address this issue, we introduce Neural Context Flow (NCF), a robust and
interpretable Meta-Learning framework that includes uncertainty estimation. NCF
uses higher-order Taylor expansion to enable contextual self-modulation,
allowing context vectors to influence dynamics from other domains while also
modulating themselves. After establishing convergence guarantees, we
empirically test NCF and compare it to related adaptation methods. Our results
show that NCF achieves state-of-the-art Out-of-Distribution performance on 5
out of 6 linear and non-linear benchmark problems. Through extensive
experiments, we explore the flexible model architecture of NCF and the encoded
representations within the learned context vectors. Our findings highlight the
potential implications of NCF for foundational models in the physical sciences,
offering a promising approach to improving the adaptability and generalization
of NODEs in various scientific applications. Our code is openly available at
\url{https://github.com/ddrous/ncflow}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>31 pages, 19 figures, 8 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Futuristic Autonomous Experimentation--A Surprise-Reacting
  Sequential Experiment Policy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2112.00600v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2112.00600v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Imtiaz Ahmed, Satish Bukkapatnam, Bhaskar Botcha, Yu Ding
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  An autonomous experimentation platform in manufacturing is supposedly capable
of conducting a sequential search for finding suitable manufacturing conditions
by itself or even for discovering new materials with minimal human
intervention. The core of the intelligent control of such platforms is a policy
to decide where to conduct the next experiment based on what has been done thus
far. Such policy inevitably trades off between exploitation and exploration.
Currently, the prevailing approach is to use various acquisition functions in
the Bayesian optimization framework. We discuss whether it is beneficial to
trade off exploitation versus exploration by measuring the element and degree
of surprise associated with the immediate past observation. We devise a
surprise-reacting policy using two existing surprise metrics, known as the
Shannon surprise and Bayesian surprise. Our analysis shows that the
surprise-reacting policy appears to be better suited for quickly characterizing
the overall landscape of a response surface under resource constraints. We do
not claim that we have a fully autonomous experimentation system but believe
that the surprise-reacting capability benefits the automation of sequential
decisions in autonomous experimentation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fitting an ellipsoid to a quadratic number of random points 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2307.01181v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2307.01181v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Afonso S. Bandeira, Antoine Maillard, Shahar Mendelson, Elliot Paquette
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider the problem $(\mathrm{P})$ of fitting $n$ standard Gaussian
random vectors in $\mathbb{R}^d$ to the boundary of a centered ellipsoid, as
$n, d \to \infty$. This problem is conjectured to have a sharp feasibility
transition: for any $\varepsilon > 0$, if $n \leq (1 - \varepsilon) d^2 / 4$
then $(\mathrm{P})$ has a solution with high probability, while $(\mathrm{P})$
has no solutions with high probability if $n \geq (1 + \varepsilon) d^2 /4$. So
far, only a trivial bound $n \geq d^2 / 2$ is known on the negative side, while
the best results on the positive side assume $n \leq d^2 /
\mathrm{polylog}(d)$. In this work, we improve over previous approaches using a
key result of Bartl & Mendelson (2022) on the concentration of Gram matrices of
random vectors under mild assumptions on their tail behavior. This allows us to
give a simple proof that $(\mathrm{P})$ is feasible with high probability when
$n \leq d^2 / C$, for a (possibly large) constant $C > 0$.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages; Update (v2) to match the published version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ EEG-Language Modeling for Pathology Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.07480v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.07480v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sam Gijsen, Kerstin Ritter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal language modeling constitutes a recent breakthrough which
leverages advances in large language models to pretrain capable multimodal
models. The integration of natural language during pretraining has been shown
to significantly improve learned representations, particularly in computer
vision. However, the efficacy of multimodal language modeling in the realm of
functional brain data, specifically for advancing pathology detection, remains
unexplored. This study pioneers EEG-language models trained on clinical reports
and 15000 EEGs. We extend methods for multimodal alignment to this novel domain
and investigate which textual information in reports is useful for training
EEG-language models. Our results indicate that models learn richer
representations from being exposed to a variety of report segments, including
the patient's clinical history, description of the EEG, and the physician's
interpretation. Compared to models exposed to narrower clinical text
information, we find such models to retrieve EEGs based on clinical reports
(and vice versa) with substantially higher accuracy. Yet, this is only observed
when using a contrastive learning approach. Particularly in regimes with few
annotations, we observe that representations of EEG-language models can
significantly improve pathology detection compared to those of EEG-only models,
as demonstrated by both zero-shot classification and linear probes. In sum,
these results highlight the potential of integrating brain activity data with
clinical text, suggesting that EEG-language models represent significant
progress for clinical applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MallowsPO: Fine-Tune Your LLM with Preference Dispersions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.14953v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.14953v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoxian Chen, Hanyang Zhao, Henry Lam, David Yao, Wenpin Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Direct Preference Optimization (DPO) has recently emerged as a popular
approach to improve reinforcement learning with human feedback (RLHF), leading
to better techniques to fine-tune large language models (LLM). A weakness of
DPO, however, lies in its lack of capability to characterize the diversity of
human preferences. Inspired by Mallows' theory of preference ranking, we
develop in this paper a new approach, the MallowsPO. A distinct feature of this
approach is a dispersion index, which reflects the dispersion of human
preference to prompts. We show that existing DPO models can be reduced to
special cases of this dispersion index, thus unified with MallowsPO. More
importantly, we demonstrate (empirically) how to use this dispersion index to
enhance the performance of DPO in a broad array of benchmark tasks, from
synthetic bandit selection to controllable generations and dialogues, while
maintaining great generalization capabilities. MallowsPO is also compatible
with other SOTA offline preference optimization methods, boosting nearly 2\%
extra LC win rate when used as a plugin for fine-tuning Llama3-Instruct.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Heterogeneous Multi-Agent Reinforcement Learning for Zero-Shot Scalable
  Collaboration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.03869v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.03869v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xudong Guo, Daming Shi, Junjie Yu, Wenhui Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The emergence of multi-agent reinforcement learning (MARL) is significantly
transforming various fields like autonomous vehicle networks. However,
real-world multi-agent systems typically contain multiple roles, and the scale
of these systems dynamically fluctuates. Consequently, in order to achieve
zero-shot scalable collaboration, it is essential that strategies for different
roles can be updated flexibly according to the scales, which is still a
challenge for current MARL frameworks. To address this, we propose a novel MARL
framework named Scalable and Heterogeneous Proximal Policy Optimization
(SHPPO), integrating heterogeneity into parameter-shared PPO-based MARL
networks. We first leverage a latent network to learn strategy patterns for
each agent adaptively. Second, we introduce a heterogeneous layer to be
inserted into decision-making networks, whose parameters are specifically
generated by the learned latent variables. Our approach is scalable as all the
parameters are shared except for the heterogeneous layer, and gains both
inter-individual and temporal heterogeneity, allowing SHPPO to adapt
effectively to varying scales. SHPPO exhibits superior performance in classic
MARL environments like Starcraft Multi-Agent Challenge (SMAC) and Google
Research Football (GRF), showcasing enhanced zero-shot scalability, and
offering insights into the learned latent variables' impact on team performance
by visualization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Sequential transport maps using SoS density estimation and
  $α$-divergences 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.17943v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.17943v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Benjamin Zanger, Olivier Zahm, Tiangang Cui, Martin Schreiber
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transport-based density estimation methods are receiving growing interest
because of their ability to efficiently generate samples from the approximated
density. We further invertigate the sequential transport maps framework
proposed from arXiv:2106.04170 arXiv:2303.02554, which builds on a sequence of
composed Knothe-Rosenblatt (KR) maps. Each of those maps are built by first
estimating an intermediate density of moderate complexity, and then by
computing the exact KR map from a reference density to the precomputed
approximate density. In our work, we explore the use of Sum-of-Squares (SoS)
densities and $\alpha$-divergences for approximating the intermediate
densities. Combining SoS densities with $\alpha$-divergence interestingly
yields convex optimization problems which can be efficiently solved using
semidefinite programming. The main advantage of $\alpha$-divergences is to
enable working with unnormalized densities, which provides benefits both
numerically and theoretically. In particular, we provide a new convergence
analyses of the sequential transport maps based on information geometric
properties of $\alpha$-divergences. The choice of intermediate densities is
also crucial for the efficiency of the method. While tempered (or annealed)
densities are the state-of-the-art, we introduce diffusion-based intermediate
densities which permits to approximate densities known from samples only. Such
intermediate densities are well-established in machine learning for generative
modeling. Finally we propose low-dimensional maps (or lazy maps) for dealing
with high-dimensional problems and numerically demonstrate our methods on
Bayesian inference problems and unsupervised learning tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ NuwaTS: a Foundation Model Mending Every Incomplete Time Series 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.15317v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.15317v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinguo Cheng, Chunwei Yang, Wanlin Cai, Yuxuan Liang, Qingsong Wen, Yuankai Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Time series imputation is critical for many real-world applications and has
been widely studied. However, existing models often require specialized designs
tailored to specific missing patterns, variables, or domains which limits their
generalizability. In addition, current evaluation frameworks primarily focus on
domain-specific tasks and often rely on time-wise train/validation/test data
splits, which fail to rigorously assess a model's ability to generalize across
unseen variables or domains. In this paper, we present \textbf{NuwaTS}, a novel
framework that repurposes Pre-trained Language Models (PLMs) for general time
series imputation. Once trained, NuwaTS can be applied to impute missing data
across any domain. We introduce specialized embeddings for each sub-series
patch, capturing information about the patch, its missing data patterns, and
its statistical characteristics. By combining contrastive learning with the
imputation task, we train PLMs to create a versatile, one-for-all imputation
model. Additionally, we employ a plug-and-play fine-tuning approach, enabling
efficient adaptation to domain-specific tasks with minimal adjustments. To
evaluate cross-variable and cross-domain generalization, we propose a new
benchmarking protocol that partitions the datasets along the variable
dimension. Experimental results on over seventeen million time series samples
from diverse domains demonstrate that NuwaTS outperforms state-of-the-art
domain-specific models across various datasets under the proposed benchmarking
protocol. Furthermore, we show that NuwaTS generalizes to other time series
tasks, such as forecasting. Our codes are available at
https://github.com/Chengyui/NuwaTS.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages, 14 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Longhorn: State Space Models are Amortized Online Learners 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.14207v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.14207v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bo Liu, Rui Wang, Lemeng Wu, Yihao Feng, Peter Stone, Qiang Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modern large language models are built on sequence modeling via next-token
prediction. While the Transformer remains the dominant architecture for
sequence modeling, its quadratic decoding complexity in sequence length poses a
major limitation. State-space models (SSMs) present a competitive alternative,
offering linear decoding efficiency while maintaining parallelism during
training. However, most existing SSMs rely on linear recurrence designs that
appear somewhat ad hoc. In this work, we explore SSM design through the lens of
online learning, conceptualizing SSMs as meta-modules for specific online
learning problems. This approach links SSM design to formulating precise online
learning objectives, with state transition rules derived from solving these
objectives. Based on this insight, we introduce a novel deep SSM architecture,
Longhorn, whose update resembles the closed-form solution for solving the
online associative recall problem. Our experimental results show that Longhorn
outperforms state-of-the-art SSMs, including the Mamba model, on standard
sequence modeling benchmarks, language modeling, and vision tasks.
Specifically, Longhorn achieves a 1.8x improvement in sample efficiency
compared to Mamba, and can extrapolate over contexts that are up to 16x longer
during inference.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HAMLET: Graph <span class="highlight-title">Transformer</span> Neural Operator for Partial Differential
  Equations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.03541v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.03541v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrey Bryutkin, Jiahao Huang, Zhongying Deng, Guang Yang, Carola-Bibiane Schönlieb, Angelica Aviles-Rivero
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a novel graph transformer framework, HAMLET, designed to address
the challenges in solving partial differential equations (PDEs) using neural
networks. The framework uses graph transformers with modular input encoders to
directly incorporate differential equation information into the solution
process. This modularity enhances parameter correspondence control, making
HAMLET adaptable to PDEs of arbitrary geometries and varied input formats.
Notably, HAMLET scales effectively with increasing data complexity and noise,
showcasing its robustness. HAMLET is not just tailored to a single type of
physical simulation, but can be applied across various domains. Moreover, it
boosts model resilience and performance, especially in scenarios with limited
data. We demonstrate, through extensive experiments, that our framework is
capable of outperforming current techniques for PDEs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 7 figures, 6 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Comprehensive Graph Pooling Benchmark: Effectiveness, Robustness and
  Generalizability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.09031v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.09031v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pengyun Wang, Junyu Luo, Yanxin Shen, Ming Zhang, Siyu Heng, Xiao Luo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph pooling has gained attention for its ability to obtain effective node
and graph representations for various downstream tasks. Despite the recent
surge in graph pooling approaches, there is a lack of standardized experimental
settings and fair benchmarks to evaluate their performance. To address this
issue, we have constructed a comprehensive benchmark that includes 17 graph
pooling methods and 28 different graph datasets. This benchmark systematically
assesses the performance of graph pooling methods in three dimensions, i.e.,
effectiveness, robustness, and generalizability. We first evaluate the
performance of these graph pooling approaches across different tasks including
graph classification, graph regression and node classification. Then, we
investigate their performance under potential noise attacks and
out-of-distribution shifts in real-world scenarios. We also involve detailed
efficiency analysis, backbone analysis, parameter analysis and visualization to
provide more evidence. Extensive experiments validate the strong capability and
applicability of graph pooling approaches in various scenarios, which can
provide valuable insights and guidance for deep geometric learning research.
The source code of our benchmark is available at
https://github.com/goose315/Graph_Pooling_Benchmark.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving Fairness and Mitigating MADness in Generative Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.13977v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.13977v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Paul Mayer, Lorenzo Luzi, Ali Siahkoohi, Don H. Johnson, Richard G. Baraniuk
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative models unfairly penalize data belonging to minority classes,
suffer from model autophagy disorder (MADness), and learn biased estimates of
the underlying distribution parameters. Our theoretical and empirical results
show that training generative models with intentionally designed hypernetworks
leads to models that 1) are more fair when generating datapoints belonging to
minority classes 2) are more stable in a self-consumed (i.e., MAD) setting, and
3) learn parameters that are less statistically biased. To further mitigate
unfairness, MADness, and bias, we introduce a regularization term that
penalizes discrepancies between a generative model's estimated weights when
trained on real data versus its own synthetic data. To facilitate training
existing deep generative models within our framework, we offer a scalable
implementation of hypernetworks that automatically generates a hypernetwork
architecture for any given generative model.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Joint Graph Rewiring and Feature Denoising via Spectral Resonance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.07191v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.07191v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jonas Linkerhägner, Cheng Shi, Ivan Dokmanić
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In graph learning the graph and the node features both contain noisy
information about the node labels. In this paper we propose joint denoising and
rewiring (JDR)--an algorithm to jointly rewire the graph and denoise the
features, which improves the performance of downstream node classification
graph neural nets (GNNs). JDR improves the alignment between the leading
eigenspaces of graph and feature matrices. To approximately solve the
associated non-convex optimization problem we propose a heuristic that
efficiently handles real-world graph datasets with multiple classes and
different levels of homophily or heterophily. We theoretically justify JDR in a
stylized setting and verify the effectiveness of our approach through extensive
experiments on synthetic and real-world graph datasets. The results show that
JDR consistently outperforms existing rewiring methods on node classification
using GNNs as downstream models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Closed-loop Diffusion Control of Complex Physical Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.03124v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.03124v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Long Wei, Haodong Feng, Yuchen Yang, Ruiqi Feng, Peiyan Hu, Xiang Zheng, Tao Zhang, Dixia Fan, Tailin Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The control problems of complex physical systems have broad applications in
science and engineering. Previous studies have shown that generative control
methods based on diffusion models offer significant advantages for solving
these problems. However, existing generative control approaches face challenges
in both performance and efficiency when extended to the closed-loop setting,
which is essential for effective control. In this paper, we propose an
efficient Closed-Loop Diffusion method for Physical systems Control
(CL-DiffPhyCon). By employing an asynchronous denoising framework for different
physical time steps, CL-DiffPhyCon generates control signals conditioned on
real-time feedback from the environment with significantly reduced
computational cost during sampling. Additionally, the control process could be
further accelerated by incorporating fast sampling techniques, such as DDIM. We
evaluate CL-DiffPhyCon on two tasks: 1D Burgers' equation control and 2D
incompressible fluid control. The results demonstrate that CL-DiffPhyCon
achieves superior control performance with significant improvements in sampling
efficiency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ EfficientQAT: Efficient Quantization-Aware Training for Large Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11062v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11062v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mengzhao Chen, Wenqi Shao, Peng Xu, Jiahao Wang, Peng Gao, Kaipeng Zhang, Ping Luo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) are crucial in modern natural language
processing and artificial intelligence. However, they face challenges in
managing their significant memory requirements. Although quantization-aware
training (QAT) offers a solution by reducing memory consumption through low-bit
representations with minimal accuracy loss, it is impractical due to
substantial training resources. To address this, we propose Efficient
Quantization-Aware Training (EfficientQAT), a more feasible QAT algorithm.
EfficientQAT involves two consecutive phases: Block-wise training of all
parameters (Block-AP) and end-to-end training of quantization parameters
(E2E-QP). To the best of our knowledge, Block-AP is the first method to enable
direct training of all parameters in a block-wise manner, reducing accuracy
loss in low-bit scenarios by enhancing the solution space during optimization.
E2E-QP then trains only the quantization parameters (step sizes) end-to-end,
further improving the performance of quantized models by considering
interactions among all sub-modules. Extensive experiments demonstrate that
EfficientQAT outperforms previous quantization methods across a range of
models, including base LLMs, instruction-tuned LLMs, and multimodal LLMs, with
scales from 7B to 70B parameters at various quantization bits. For instance,
EfficientQAT obtains a 2-bit Llama-2-70B model on a single A100-80GB GPU in 41
hours, with less than 3 points accuracy degradation compared to the full
precision (69.48 vs. 72.41). Code is available at
https://github.com/OpenGVLab/EfficientQAT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>An efficient and effective quantization technical to improve the
  performance of low-bits LMMs and LVLMs</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Synthesis of Green Architectural Tactics for ML-Enabled Systems <span class="chip">ICSE</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.09610v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.09610v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Heli Järvenpää, Patricia Lago, Justus Bogner, Grace Lewis, Henry Muccini, Ipek Ozkaya
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid adoption of artificial intelligence (AI) and machine learning (ML)
has generated growing interest in understanding their environmental impact and
the challenges associated with designing environmentally friendly ML-enabled
systems. While Green AI research, i.e., research that tries to minimize the
energy footprint of AI, is receiving increasing attention, very few concrete
guidelines are available on how ML-enabled systems can be designed to be more
environmentally sustainable. In this paper, we provide a catalog of 30 green
architectural tactics for ML-enabled systems to fill this gap. An architectural
tactic is a high-level design technique to improve software quality, in our
case environmental sustainability. We derived the tactics from the analysis of
51 peer-reviewed publications that primarily explore Green AI, and validated
them using a focus group approach with three experts. The 30 tactics we
identified are aimed to serve as an initial reference guide for further
exploration into Green AI from a software engineering perspective, and assist
in designing sustainable ML-enabled systems. To enhance transparency and
facilitate their widespread use and extension, we make the tactics available
online in easily consumable formats. Wide-spread adoption of these tactics has
the potential to substantially reduce the societal impact of ML-enabled systems
regarding their energy and carbon footprint.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication at the 2024 International Conference on
  Software Engineering - Software Engineering in Society (ICSE-SEIS'2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Comparing and Contrasting Deep Learning Weather Prediction Backbones on
  Navier-Stokes and Atmospheric Dynamics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.14129v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.14129v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matthias Karlbauer, Danielle C. Maddix, Abdul Fatir Ansari, Boran Han, Gaurav Gupta, Yuyang Wang, Andrew Stuart, Michael W. Mahoney
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Remarkable progress in the development of Deep Learning Weather Prediction
(DLWP) models positions them to become competitive with traditional numerical
weather prediction (NWP) models. Indeed, a wide number of DLWP architectures --
based on various backbones, including U-Net, Transformer, Graph Neural Network
(GNN), and Fourier Neural Operator (FNO) -- have demonstrated their potential
at forecasting atmospheric states. However, due to differences in training
protocols, forecast horizons, and data choices, it remains unclear which (if
any) of these methods and architectures are most suitable for weather
forecasting and for future model development. Here, we step back and provide a
detailed empirical analysis, under controlled conditions, comparing and
contrasting the most prominent DLWP models, along with their backbones. We
accomplish this by predicting synthetic two-dimensional incompressible
Navier-Stokes and real-world global weather dynamics. In terms of accuracy,
memory consumption, and runtime, our results illustrate various tradeoffs. For
example, on synthetic data, we observe favorable performance of FNO; and on the
real-world WeatherBench dataset, our results demonstrate the suitability of
ConvLSTM and SwinTransformer for short-to-mid-ranged forecasts. For long-ranged
weather rollouts of up to 365 days, we observe superior stability and physical
soundness in architectures that formulate a spherical data representation,
i.e., GraphCast and Spherical FNO. In addition, we observe that all of these
model backbones "saturate," i.e., none of them exhibit so-called neural
scaling, which highlights an important direction for future work on these and
related models. The code is available at
https://github.com/amazon-science/dlwp-benchmark.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Dynamic Graph Representation Learning via Edge Temporal States Modeling
  and Structure-reinforced <span class="highlight-title">Transformer</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2304.10079v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2304.10079v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shengxiang Hu, Guobing Zou, Song Yang, Shiyi Lin, Yanglan Gan, Bofeng Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dynamic graph representation learning has emerged as a crucial research area,
driven by the growing need for analyzing time-evolving graph data in real-world
applications. While recent approaches leveraging recurrent neural networks
(RNNs) and graph neural networks (GNNs) have shown promise, they often fail to
adequately capture the impact of temporal edge states on inter-node
relationships, consequently overlooking the dynamic changes in node features
induced by these evolving relationships. Furthermore, these methods suffer from
GNNs' inherent over-smoothing problem, which hinders the extraction of global
structural features. To address these challenges, we introduce the Recurrent
Structure-reinforced Graph Transformer (RSGT), a novel framework for dynamic
graph representation learning. It first designs a heuristic method to
explicitly model edge temporal states by employing different edge types and
weights based on the differences between consecutive snapshots, thereby
integrating varying edge temporal states into the graph's topological
structure. We then propose a structure-reinforced graph transformer that
captures temporal node representations encoding both graph topology and
evolving dynamics through a recurrent learning paradigm, enabling the
extraction of both local and global structural features. Comprehensive
experiments on four real-world datasets demonstrate RSGT's superior performance
in discrete dynamic graph representation learning, consistently outperforming
existing methods in dynamic link prediction tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work has been submitted to the Elsevier for possible
  publication. Copyright may be transferred without notice, after which this
  version may no longer be accessible</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Agnostic Sharpness-Aware Minimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.07107v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.07107v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Van-Anh Nguyen, Quyen Tran, Tuan Truong, Thanh-Toan Do, Dinh Phung, Trung Le
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sharpness-aware minimization (SAM) has been instrumental in improving deep
neural network training by minimizing both the training loss and the sharpness
of the loss landscape, leading the model into flatter minima that are
associated with better generalization properties. In another aspect,
Model-Agnostic Meta-Learning (MAML) is a framework designed to improve the
adaptability of models. MAML optimizes a set of meta-models that are
specifically tailored for quick adaptation to multiple tasks with minimal
fine-tuning steps and can generalize well with limited data. In this work, we
explore the connection between SAM and MAML in enhancing model generalization.
We introduce Agnostic-SAM, a novel approach that combines the principles of
both SAM and MAML. Agnostic-SAM adapts the core idea of SAM by optimizing the
model toward wider local minima using training data, while concurrently
maintaining low loss values on validation data. By doing so, it seeks flatter
minima that are not only robust to small perturbations but also less vulnerable
to data distributional shift problems. Our experimental results demonstrate
that Agnostic-SAM significantly improves generalization over baselines across a
range of datasets and under challenging conditions such as noisy labels or data
limitation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Motion meets Attention: Video Motion <span class="highlight-title">Prompt</span>s <span class="chip">ACML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.03179v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.03179v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qixiang Chen, Lei Wang, Piotr Koniusz, Tom Gedeon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Videos contain rich spatio-temporal information. Traditional methods for
extracting motion, used in tasks such as action recognition, often rely on
visual contents rather than precise motion features. This phenomenon is
referred to as 'blind motion extraction' behavior, which proves inefficient in
capturing motions of interest due to a lack of motion-guided cues. Recently,
attention mechanisms have enhanced many computer vision tasks by effectively
highlighting salient visual areas. Inspired by this, we propose a modified
Sigmoid function with learnable slope and shift parameters as an attention
mechanism to modulate motion signals from frame differencing maps. This
approach generates a sequence of attention maps that enhance the processing of
motion-related video content. To ensure temporal continuity and smoothness of
the attention maps, we apply pair-wise temporal attention variation
regularization to remove unwanted motions (e.g., noise) while preserving
important ones. We then perform Hadamard product between each pair of attention
maps and the original video frames to highlight the evolving motions of
interest over time. These highlighted motions, termed video motion prompts, are
subsequently used as inputs to the model instead of the original video frames.
We formalize this process as a motion prompt layer and incorporate the
regularization term into the loss function to learn better motion prompts. This
layer serves as an adapter between the model and the video data, bridging the
gap between traditional 'blind motion extraction' and the extraction of
relevant motions of interest. We show that our lightweight, plug-and-play
motion prompt layer seamlessly integrates into models like SlowFast, X3D, and
TimeSformer, enhancing performance on benchmarks such as FineGym and MPII
Cooking 2.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at the 16th Asian Conference on Machine Learning (ACML 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HoTPP Benchmark: Are We Good at the Long Horizon Events Forecasting? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.14341v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.14341v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ivan Karpukhin, Foma Shipilov, Andrey Savchenko
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurately forecasting multiple future events within a given time horizon is
crucial for finance, retail, social networks, and healthcare applications.
Event timing and labels are typically modeled using Marked Temporal Point
Processes (MTPP), with evaluations often focused on next-event prediction
quality. While some studies have extended evaluations to a fixed number of
future events, we demonstrate that this approach leads to inaccuracies in
handling false positives and false negatives. To address these issues, we
propose a novel evaluation method inspired by object detection techniques from
computer vision. Specifically, we introduce Temporal mean Average Precision
(T-mAP), a temporal variant of mAP, which overcomes the limitations of existing
long-horizon evaluation metrics. Our extensive experiments demonstrate that
models with strong next-event prediction accuracy can yield poor long-horizon
forecasts and vice versa, indicating that specialized methods are needed for
each task. To support further research, we release HoTPP, the first benchmark
designed explicitly for evaluating long-horizon MTPP predictions. HoTPP
includes large-scale datasets with up to 43 million events and provides
optimized procedures for both autoregressive and parallel inference, paving the
way for future advancements in the field.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Cost-Effective Online Multi-LLM Selection with Versatile Reward Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.16587v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.16587v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangxiang Dai, Jin Li, Xutong Liu, Anqi Yu, John C. S. Lui
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid advancement of large language models (LLMs), the diversity of
multi-LLM tasks and the variability in their pricing structures have become
increasingly important, as costs can vary greatly between different LLMs. To
tackle these challenges, we introduce the \textit{C2MAB-V}, a
\underline{C}ost-effective \underline{C}ombinatorial \underline{M}ulti-armed
\underline{B}andit with \underline{V}ersatile reward models for optimal LLM
selection and usage. This online model differs from traditional static
approaches or those reliant on a single LLM without cost consideration. With
multiple LLMs deployed on a scheduling cloud and a local server dedicated to
handling user queries, \textit{C2MAB-V} facilitates the selection of multiple
LLMs over a combinatorial search space, specifically tailored for various
collaborative task types with different reward models. Based on our designed
online feedback mechanism and confidence bound technique, \textit{C2MAB-V} can
effectively address the multi-LLM selection challenge by managing the
exploration-exploitation trade-off across different models, while also
balancing cost and reward for diverse tasks. The NP-hard integer linear
programming problem for selecting multiple LLMs with trade-off dilemmas is
addressed by: i) decomposing the integer problem into a relaxed form by the
local server, ii) utilizing a discretization rounding scheme that provides
optimal LLM combinations by the scheduling cloud, and iii) continual online
updates based on feedback. Theoretically, we prove that \textit{C2MAB-V} offers
strict guarantees over versatile reward models, matching state-of-the-art
results for regret and violations in some degenerate cases. Empirically, we
show that \textit{C2MAB-V} effectively balances performance and cost-efficiency
with nine LLMs for three application scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>32 pages, 14 figures, conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DeTPP: Leveraging Object Detection for Robust Long-Horizon Event
  Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.13131v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.13131v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ivan Karpukhin, Andrey Savchenko
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Long-horizon event forecasting is critical across various domains, including
retail, finance, healthcare, and social networks. Traditional methods, such as
Marked Temporal Point Processes (MTPP), often rely on autoregressive models to
predict multiple future events. However, these models frequently suffer from
issues like converging to constant or repetitive outputs, which limits their
effectiveness and general applicability. To address these challenges, we
introduce DeTPP (Detection-based Temporal Point Processes), a novel approach
inspired by object detection techniques from computer vision. DeTPP employs a
unique matching-based loss function that selectively prioritizes reliably
predictable events, improving the accuracy and diversity of predictions during
inference. Our method establishes a new state-of-the-art in long-horizon event
forecasting, achieving up to a 77% relative improvement over existing MTPP and
next-K methods. The proposed hybrid approach enhances the accuracy of next
event prediction by up to 2.7% on a large transactional dataset. Notably, DeTPP
is also among the fastest methods for inference. The implementation of DeTPP is
publicly available on GitHub.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploratory Optimal Stopping: A Singular Control Formulation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.09335v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.09335v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jodi Dianetti, Giorgio Ferrari, Renyuan Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper explores continuous-time and state-space optimal stopping problems
from a reinforcement learning perspective. We begin by formulating the stopping
problem using randomized stopping times, where the decision maker's control is
represented by the probability of stopping within a given time--specifically, a
bounded, non-decreasing, c\`adl\`ag control process. To encourage exploration
and facilitate learning, we introduce a regularized version of the problem by
penalizing it with the cumulative residual entropy of the randomized stopping
time. The regularized problem takes the form of an (n+1)-dimensional degenerate
singular stochastic control with finite-fuel. We address this through the
dynamic programming principle, which enables us to identify the unique optimal
exploratory strategy. For the specific case of a real option problem, we derive
a semi-explicit solution to the regularized problem, allowing us to assess the
impact of entropy regularization and analyze the vanishing entropy limit.
Finally, we propose a reinforcement learning algorithm based on policy
iteration. We show both policy improvement and policy convergence results for
our proposed algorithm.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>49 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Optimization by Parallel Quasi-Quantum Annealing with Gradient-Based
  Sampling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.02135v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.02135v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuma Ichikawa, Yamato Arai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning-based methods have gained attention as general-purpose solvers due
to their ability to automatically learn problem-specific heuristics, reducing
the need for manually crafted heuristics. However, these methods often face
scalability challenges. To address these issues, the improved Sampling
algorithm for Combinatorial Optimization (iSCO), using discrete Langevin
dynamics, has been proposed, demonstrating better performance than several
learning-based solvers. This study proposes a different approach that
integrates gradient-based update through continuous relaxation, combined with
Quasi-Quantum Annealing (QQA). QQA smoothly transitions the objective function,
starting from a simple convex function, minimized at half-integral values, to
the original objective function, where the relaxed variables are minimized only
in the discrete space. Furthermore, we incorporate parallel run communication
leveraging GPUs to enhance exploration capabilities and accelerate convergence.
Numerical experiments demonstrate that our method is a competitive
general-purpose solver, achieving performance comparable to iSCO and
learning-based solvers across various benchmark problems. Notably, our method
exhibits superior speed-quality trade-offs for large-scale instances compared
to iSCO, learning-based solvers, commercial solvers, and specialized
algorithms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Optimal Causal Representations and the Causal Information Bottleneck <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00535v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00535v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Francisco N. F. Q. Simoes, Mehdi Dastani, Thijs van Ommen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To effectively study complex causal systems, it is often useful to construct
representations that simplify parts of the system by discarding irrelevant
details while preserving key features. The Information Bottleneck (IB) method
is a widely used approach in representation learning that compresses random
variables while retaining information about a target variable. Traditional
methods like IB are purely statistical and ignore underlying causal structures,
making them ill-suited for causal tasks. We propose the Causal Information
Bottleneck (CIB), a causal extension of the IB, which compresses a set of
chosen variables while maintaining causal control over a target variable. This
method produces representations which are causally interpretable, and which can
be used when reasoning about interventions. We present experimental results
demonstrating that the learned representations accurately capture causality as
intended.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to ICLR 2025. Code available at
  github.com/francisco-simoes/cib-optimization-psagd</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ $α$-Divergence Loss Function for Neural Density Ratio Estimation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.02041v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.02041v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yoshiaki Kitazawa
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Density ratio estimation (DRE) is a fundamental machine learning technique
for capturing relationships between two probability distributions.
State-of-the-art DRE methods estimate the density ratio using neural networks
trained with loss functions derived from variational representations of
$f$-divergence. However, existing methods face optimization challenges, such as
overfitting due to lower-unbounded loss functions, biased mini-batch gradients,
vanishing training loss gradients, and high sample requirements for
Kullback-Leibler (KL) divergence loss functions. To address these issues, we
focus on $\alpha$-divergence, which provides a suitable variational
representation of $f$-divergence. Subsequently, a novel loss function for DRE,
the $\alpha$-divergence loss function ($\alpha$-Div), is derived. $\alpha$-Div
is concise but offers stable and effective optimization for DRE. The
boundedness of $\alpha$-divergence provides the potential for successful DRE
with data exhibiting high KL-divergence. Our numerical experiments demonstrate
the effectiveness in optimization using $\alpha$-Div. However, the experiments
also show that the proposed loss function offers no significant advantage over
the KL-divergence loss function in terms of RMSE for DRE. This indicates that
the accuracy of DRE is primarily determined by the amount of KL-divergence in
the data and is less dependent on $\alpha$-divergence.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>$\mathcal{T}_{\text{Lip}}$ in Theorem 7.1 (Theorem B.15.) was changed
  to the set of all locally Lipschitz continuous functions. In the previous
  version, $\mathcal{T}_{\text{Lip}}$ was defined as the set of all Lipschitz
  continuous functions, which is unsuitable for the statement of case (ii) in
  the theorem</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Training-Free Message Passing for Learning on Hypergraphs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.05569v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.05569v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bohan Tang, Zexi Liu, Keyue Jiang, Siheng Chen, Xiaowen Dong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Hypergraphs are crucial for modelling higher-order interactions in real-world
data. Hypergraph neural networks (HNNs) effectively utilise these structures by
message passing to generate informative node features for various downstream
tasks like node classification. However, the message passing module in existing
HNNs typically requires a computationally intensive training process, which
limits their practical use. To tackle this challenge, we propose an alternative
approach by decoupling the usage of hypergraph structural information from the
model learning stage. This leads to a novel training-free message passing
module, named TF-MP-Module, which can be precomputed in the data preprocessing
stage, thereby reducing the computational burden. We refer to the hypergraph
neural network equipped with our TF-MP-Module as TF-HNN. We theoretically
support the efficiency and effectiveness of TF-HNN by showing that: 1) It is
more training-efficient compared to existing HNNs; 2) It utilises as much
information as existing HNNs for node feature generation; and 3) It is robust
against the oversmoothing issue while using long-range interactions.
Experiments based on seven real-world hypergraph benchmarks in node
classification and hyperlink prediction show that, compared to state-of-the-art
HNNs, TF-HNN exhibits both competitive performance and superior training
efficiency. Specifically, on the large-scale benchmark, Trivago, TF-HNN
outperforms the node classification accuracy of the best baseline by 10% with
just 1% of the training time of that baseline.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Rapid Gyroscope Calibration: A Deep Learning Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.00488v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.00488v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yair Stolero, Itzik Klein
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low-cost gyroscope calibration is essential for ensuring the accuracy and
reliability of gyroscope measurements. Stationary calibration estimates the
deterministic parts of measurement errors. To this end, a common practice is to
average the gyroscope readings during a predefined period and estimate the
gyroscope bias. Calibration duration plays a crucial role in performance,
therefore, longer periods are preferred. However, some applications require
quick startup times and calibration is therefore allowed only for a short time.
In this work, we focus on reducing low-cost gyroscope calibration time using
deep learning methods. We propose a deep-learning framework and explore the
possibilities of using multiple real and virtual gyroscopes to improve the
calibration performance of single gyroscopes. To train and validate our
approach, we recorded a dataset consisting of 169 hours of gyroscope readings,
using 24 gyroscopes of two different brands. We also created a virtual dataset
consisting of simulated gyroscope readings. The two datasets were used to
evaluate our proposed approach. One of our key achievements in this work is
reducing gyroscope calibration time by up to 89% using three low-cost
gyroscopes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 Pages, 14 Figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Large Language Model Confidence Estimation via Black-Box Access 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.04370v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.04370v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tejaswini Pedapati, Amit Dhurandhar, Soumya Ghosh, Soham Dan, Prasanna Sattigeri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Estimating uncertainty or confidence in the responses of a model can be
significant in evaluating trust not only in the responses, but also in the
model as a whole. In this paper, we explore the problem of estimating
confidence for responses of large language models (LLMs) with simply black-box
or query access to them. We propose a simple and extensible framework where, we
engineer novel features and train a (interpretable) model (viz. logistic
regression) on these features to estimate the confidence. We empirically
demonstrate that our simple framework is effective in estimating confidence of
Flan-ul2, Llama-13b and Mistral-7b on four benchmark Q\&A tasks as well as of
Pegasus-large and BART-large on two benchmark summarization tasks with it
surpassing baselines by even over $10\%$ (on AUROC) in some cases.
Additionally, our interpretable approach provides insight into features that
are predictive of confidence, leading to the interesting and useful discovery
that our confidence models built for one LLM generalize zero-shot across others
on a given dataset.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Understanding the Training and Generalization of <span class="highlight-title">Pretrain</span>ed <span class="highlight-title">Transformer</span>
  for Sequential Decision Making 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.14219v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.14219v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hanzhao Wang, Yu Pan, Fupeng Sun, Shang Liu, Kalyan Talluri, Guanting Chen, Xiaocheng Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we consider the supervised pre-trained transformer for a class
of sequential decision-making problems. The class of considered problems is a
subset of the general formulation of reinforcement learning in that there is no
transition probability matrix; though seemingly restrictive, the subset class
of problems covers bandits, dynamic pricing, and newsvendor problems as special
cases. Such a structure enables the use of optimal actions/decisions in the
pre-training phase, and the usage also provides new insights for the training
and generalization of the pre-trained transformer. We first note the training
of the transformer model can be viewed as a performative prediction problem,
and the existing methods and theories largely ignore or cannot resolve an
out-of-distribution issue. We propose a natural solution that includes the
transformer-generated action sequences in the training procedure, and it enjoys
better properties both numerically and theoretically. The availability of the
optimal actions in the considered tasks also allows us to analyze the
properties of the pre-trained transformer as an algorithm and explains why it
may lack exploration and how this can be automatically resolved. Numerically,
we categorize the advantages of pre-trained transformers over the structured
algorithms such as UCB and Thompson sampling into three cases: (i) it better
utilizes the prior knowledge in the pre-training data; (ii) it can elegantly
handle the misspecification issue suffered by the structured algorithms; (iii)
for short time horizon such as $T\le50$, it behaves more greedy and enjoys much
better regret than the structured algorithms designed for asymptotic
optimality.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ $σ$-zero: Gradient-based Optimization of $\ell_0$-norm Adversarial
  Examples 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.01879v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.01879v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Antonio Emanuele Cinà, Francesco Villani, Maura Pintor, Lea Schönherr, Battista Biggio, Marcello Pelillo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Evaluating the adversarial robustness of deep networks to gradient-based
attacks is challenging. While most attacks consider $\ell_2$- and
$\ell_\infty$-norm constraints to craft input perturbations, only a few
investigate sparse $\ell_1$- and $\ell_0$-norm attacks. In particular,
$\ell_0$-norm attacks remain the least studied due to the inherent complexity
of optimizing over a non-convex and non-differentiable constraint. However,
evaluating adversarial robustness under these attacks could reveal weaknesses
otherwise left untested with more conventional $\ell_2$- and $\ell_\infty$-norm
attacks. In this work, we propose a novel $\ell_0$-norm attack, called
$\sigma$-zero, which leverages a differentiable approximation of the $\ell_0$
norm to facilitate gradient-based optimization, and an adaptive projection
operator to dynamically adjust the trade-off between loss minimization and
perturbation sparsity. Extensive evaluations using MNIST, CIFAR10, and ImageNet
datasets, involving robust and non-robust models, show that $\sigma$-zero finds
minimum $\ell_0$-norm adversarial examples without requiring any time-consuming
hyperparameter tuning, and that it outperforms all competing sparse attacks in
terms of success rate, perturbation size, and efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Code available at
  https://github.com/Cinofix/sigma-zero-adversarial-attack</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">GPT</span> vs RETRO: Exploring the Intersection of Retrieval and
  Parameter-Efficient Fine-Tuning <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.04528v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.04528v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aleksander Ficek, Jiaqi Zeng, Oleksii Kuchaiev
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Parameter-Efficient Fine-Tuning (PEFT) and Retrieval-Augmented Generation
(RAG) have become popular methods for adapting large language models while
minimizing compute requirements. In this paper, we apply PEFT methods
(P-tuning, Adapters, and LoRA) to a modified Retrieval-Enhanced Transformer
(RETRO) and a baseline GPT model across several sizes, ranging from 823 million
to 48 billion parameters. We show that RETRO models outperform GPT models in
zero-shot settings due to their unique pre-training process but GPT models have
higher performance potential with PEFT. Additionally, our study indicates that
8B parameter models strike an optimal balance between cost and performance and
P-tuning lags behind other PEFT techniques. We further provide a comparative
analysis between applying PEFT to an Instruction-tuned RETRO model and base
RETRO model. This work presents the first comprehensive comparison of various
PEFT methods integrated with RAG, applied to both GPT and RETRO models,
highlighting their relative performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evaluating Large Language Models Using Contrast Sets: An Experimental
  Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.01569v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.01569v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manish Sanwal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the domain of Natural Language Inference (NLI), especially in tasks
involving the classification of multiple input texts, the Cross-Entropy Loss
metric is widely employed as a standard for error measurement. However, this
metric falls short in effectively evaluating a model's capacity to understand
language entailments. In this study, we introduce an innovative technique for
generating a contrast set for the Stanford Natural Language Inference (SNLI)
dataset. Our strategy involves the automated substitution of verbs, adverbs,
and adjectives with their synonyms to preserve the original meaning of
sentences. This method aims to assess whether a model's performance is based on
genuine language comprehension or simply on pattern recognition. We conducted
our analysis using the ELECTRA-small model. The model achieved an accuracy of
89.9% on the conventional SNLI dataset but showed a reduced accuracy of 72.5%
on our contrast set, indicating a substantial 17% decline. This outcome led us
to conduct a detailed examination of the model's learning behaviors. Following
this, we improved the model's resilience by fine-tuning it with a
contrast-enhanced training dataset specifically designed for SNLI, which
increased its accuracy to 85.5% on the contrast sets. Our findings highlight
the importance of incorporating diverse linguistic expressions into datasets
for NLI tasks. We hope that our research will encourage the creation of more
inclusive datasets, thereby contributing to the development of NLI models that
are both more sophisticated and effective.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Correlations Are Ruining Your Gradient Descent 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10780v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10780v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nasir Ahmad
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Herein the topics of (natural) gradient descent, data decorrelation, and
approximate methods for backpropagation are brought into a common discussion.
Natural gradient descent illuminates how gradient vectors, pointing at
directions of steepest descent, can be improved by considering the local
curvature of loss landscapes. We extend this perspective and show that to fully
solve the problem illuminated by natural gradients in neural networks, one must
recognise that correlations in the data at any linear transformation, including
node responses at every layer of a neural network, cause a non-orthonormal
relationship between the model's parameters. To solve this requires a method
for decorrelating inputs at each individual layer of a neural network. We
describe a range of methods which have been proposed for decorrelation and
whitening of node output, and expand on these to provide a novel method
specifically useful for distributed computing and computational neuroscience.
Implementing decorrelation within multi-layer neural networks, we can show that
not only is training via backpropagation sped up significantly but also
existing approximations of backpropagation, which have failed catastrophically
in the past, benefit significantly in their accuracy and convergence speed.
This has the potential to provide a route forward for approximate gradient
descent methods which have previously been discarded, training approaches for
analogue and neuromorphic hardware, and potentially insights as to the efficacy
and utility of decorrelation processes in the brain.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Off-policy Evaluation with Deeply-abstracted States 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19531v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19531v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Meiling Hao, Pingfan Su, Liyuan Hu, Zoltan Szabo, Qingyuan Zhao, Chengchun Shi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Off-policy evaluation (OPE) is crucial for assessing a target policy's impact
offline before its deployment. However, achieving accurate OPE in large state
spaces remains challenging. This paper studies state abstractions -- originally
designed for policy learning -- in the context of OPE. Our contributions are
three-fold: (i) We define a set of irrelevance conditions central to learning
state abstractions for OPE, and derive a backward-model-irrelevance condition
for achieving irrelevance in %sequential and (marginalized) importance sampling
ratios by constructing a time-reversed Markov decision process (MDP). (ii) We
propose a novel iterative procedure that sequentially projects the original
state space into a smaller space, resulting in a deeply-abstracted state, which
substantially simplifies the sample complexity of OPE arising from high
cardinality. (iii) We prove the Fisher consistencies of various OPE estimators
when applied to our proposed abstract state spaces.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>56 pages, 5 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ShortCircuit: AlphaZero-Driven Circuit Design 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.09858v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.09858v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dimitrios Tsaras, Antoine Grosnit, Lei Chen, Zhiyao Xie, Haitham Bou-Ammar, Mingxuan Yuan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Chip design relies heavily on generating Boolean circuits, such as
AND-Inverter Graphs (AIGs), from functional descriptions like truth tables.
This generation operation is a key process in logic synthesis, a primary chip
design stage. While recent advances in deep learning have aimed to accelerate
circuit design, these efforts have mostly focused on tasks other than
synthesis, and traditional heuristic methods have plateaued. In this paper, we
introduce ShortCircuit, a novel transformer-based architecture that leverages
the structural properties of AIGs and performs efficient space exploration.
Contrary to prior approaches attempting end-to-end generation of logic circuits
using deep networks, ShortCircuit employs a two-phase process combining
supervised with reinforcement learning to enhance generalization to unseen
truth tables. We also propose an AlphaZero variant to handle the double
exponentially large state space and the reward sparsity, enabling the discovery
of near-optimal designs. To evaluate the generative performance of our model ,
we extract 500 truth tables from a set of 20 real-world circuits. ShortCircuit
successfully generates AIGs for $98\%$ of the 8-input test truth tables, and
outperforms the state-of-the-art logic synthesis tool, ABC, by $18.62\%$ in
terms of circuits size.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning Explainable and Better Performing Representations of POMDP
  Strategies 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.07656v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.07656v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexander Bork, Debraj Chakraborty, Kush Grover, Jan Kretinsky, Stefanie Mohr
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Strategies for partially observable Markov decision processes (POMDP)
typically require memory. One way to represent this memory is via automata. We
present a method to learn an automaton representation of a strategy using a
modification of the L*-algorithm. Compared to the tabular representation of a
strategy, the resulting automaton is dramatically smaller and thus also more
explainable. Moreover, in the learning process, our heuristics may even improve
the strategy's performance. In contrast to approaches that synthesize an
automaton directly from the POMDP thereby solving it, our approach is
incomparably more scalable.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Technical report for the submission to TACAS 24</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multiple-Input Fourier Neural Operator (MIFNO) for source-dependent 3D
  elastodynamics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.10115v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.10115v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fanny Lehmann, Filippo Gatti, Didier Clouteau
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Numerical simulations are essential tools to evaluate the solution of the
wave equation in complex settings, such as three-dimensional (3D) domains with
heterogeneous properties. However, their application is limited by high
computational costs and existing surrogate models lack the flexibility of
numerical solvers. This work introduces the Multiple-Input Fourier Neural
Operator (MIFNO) to deal with structured 3D fields representing material
properties as well as vectors describing the source characteristics. The MIFNO
is applied to the problem of elastic wave propagation in the Earth's crust. It
is trained on the HEMEW^S-3D database containing 30000 earthquake simulations
in different heterogeneous domains with random source positions and
orientations. Outputs are time- and space-dependent surface wavefields. The
MIFNO predictions are assessed as good to excellent based on Goodness-Of-Fit
(GOF) criteria. Wave arrival times and wave fronts' propagation are very
accurate since 80% of the predictions have an excellent phase GOF. The
fluctuations amplitudes are good for 87% of the predictions. The envelope score
is hindered by the small-scale fluctuations that are challenging to capture due
to the complex physical phenomena associated with high-frequency features.
Nevertheless, the MIFNO can generalize to sources located outside the training
domain and it shows good generalization ability to a real complex overthrust
geology. When focusing on a region of interest, transfer learning improves the
accuracy with limited additional costs, since GOF scores improved by more than
1 GOF unit with only 500 additional specific samples. The MIFNO is the first
surrogate model offering the flexibility of an earthquake simulator with
varying sources and material properties. Its good accuracy and massive speed-up
offer new perspectives to replace numerical simulations in many-query problems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Urdu Dependency Parsing and Treebank Development: A Syntactic and
  Morphological Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.09549v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.09549v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nudrat Habib
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Parsing is the process of analyzing a sentence's syntactic structure by
breaking it down into its grammatical components. and is critical for various
linguistic applications. Urdu is a low-resource, free word-order language and
exhibits complex morphology. Literature suggests that dependency parsing is
well-suited for such languages. Our approach begins with a basic feature model
encompassing word location, head word identification, and dependency relations,
followed by a more advanced model integrating part-of-speech (POS) tags and
morphological attributes (e.g., suffixes, gender). We manually annotated a
corpus of news articles of varying complexity. Using Maltparser and the
NivreEager algorithm, we achieved a best-labeled accuracy (LA) of 70% and an
unlabeled attachment score (UAS) of 84%, demonstrating the feasibility of
dependency parsing for Urdu.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Document-Level In-Context Few-Shot Relation Extraction via <span class="highlight-title">Pre-Train</span>ed
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.11085v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.11085v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yilmazcan Ozyurt, Stefan Feuerriegel, Ce Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Document-level relation extraction aims at inferring structured human
knowledge from textual documents. State-of-the-art methods for this task use
pre-trained language models (LMs) via fine-tuning, yet fine-tuning is
computationally expensive and cannot adapt to new relation types or new LMs. As
a remedy, we leverage the generalization capabilities of pre-trained LMs and
present a novel framework for document-level in-context few-shot relation
extraction. Our framework has three strengths: it eliminates the need (1) for
named entity recognition and (2) for human annotations of documents, and (3) it
can be updated to new LMs without re-training. We evaluate our framework using
DocRED, the largest publicly available dataset for document-level relation
extraction, and demonstrate that our framework achieves state-of-the-art
performance. We further show that our framework actually performs much better
than the original labels from the development set of DocRED. Finally, we
conduct an extensive benchmark demonstrating the effectiveness of our
framework, achieving state-of-the-art results across six relation extraction
datasets and outperforming more than 30 baseline methods. Unlike our framework,
the baseline methods have large computational overhead (e.g., from
fine-tuning). To the best of our knowledge, we are the first to reformulate the
document-level relation extraction task as a tailored in-context few-shot
learning paradigm.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On exploring the potential of quantum auto-encoder for learning quantum
  systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2106.15432v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2106.15432v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxuan Du, Dacheng Tao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The frequent interactions between quantum computing and machine learning
revolutionize both fields. One prototypical achievement is the quantum
auto-encoder (QAE), as the leading strategy to relieve the curse of
dimensionality ubiquitous in the quantum world. Despite its attractive
capabilities, practical applications of QAE have yet largely unexplored. To
narrow this knowledge gap, here we devise three effective QAE-based learning
protocols to address three classically computational hard learning problems
when learning quantum systems, which are low-rank state fidelity estimation,
quantum Fisher information estimation, and Gibbs state preparation. Attributed
to the versatility of QAE, our proposals can be readily executed on near-term
quantum machines. Besides, we analyze the error bounds of the trained protocols
and showcase the necessary conditions to provide practical utility from the
perspective of complexity theory. We conduct numerical simulations to confirm
the effectiveness of the proposed three protocols. Our work sheds new light on
developing advanced quantum learning algorithms to accomplish hard quantum
physics and quantum information processing tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to IEEE Transactions on Neural Networks and Learning Systems</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Open-Set Graph Anomaly Detection via Normal Structure Regularisation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.06835v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.06835v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qizhou Wang, Guansong Pang, Mahsa Salehi, Xiaokun Xia, Christopher Leckie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper considers an important Graph Anomaly Detection (GAD) task, namely
open-set GAD, which aims to train a detection model using a small number of
normal and anomaly nodes (referred to as seen anomalies) to detect both seen
anomalies and unseen anomalies (i.e., anomalies that cannot be illustrated the
training anomalies). Those labelled training data provide crucial prior
knowledge about abnormalities for GAD models, enabling substantially reduced
detection errors. However, current supervised GAD methods tend to
over-emphasise fitting the seen anomalies, leading to many errors of detecting
the unseen anomalies as normal nodes. Further, existing open-set AD models were
introduced to handle Euclidean data, failing to effectively capture
discriminative features from graph structure and node attributes for GAD. In
this work, we propose a novel open-set GAD approach, namely normal structure
regularisation (NSReg), to achieve generalised detection ability to unseen
anomalies, while maintaining its effectiveness on detecting seen anomalies. The
key idea in NSReg is to introduce a regularisation term that enforces the
learning of compact, semantically-rich representations of normal nodes based on
their structural relations to other nodes. When being optimised with supervised
anomaly detection losses, the regularisation term helps incorporate strong
normality into the modelling, and thus, it effectively avoids over-fitting the
seen anomalies and learns a better normality decision boundary, largely
reducing the false negatives of detecting unseen anomalies as normal. Extensive
empirical results on seven real-world datasets show that NSReg significantly
outperforms state-of-the-art competing methods by at least 14% AUC-ROC on the
unseen anomaly classes and by 10% AUC-ROC on all anomaly classes.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2024-10-01T00:00:00Z">2024-10-01</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language <span class="chip" style="font-size: 60%">55</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Characterizing Online Toxicity During the 2022 Mpox Outbreak: A
  Computational Analysis of Topical and Network Dynamics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.11962v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.11962v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lizhou Fan, Lingyao Li, Libby Hemphill
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Background: Online toxicity, encompassing behaviors such as harassment,
bullying, hate speech, and the dissemination of misinformation, has become a
pressing social concern in the digital age. The 2022 Mpox outbreak, initially
termed "Monkeypox" but subsequently renamed to mitigate associated stigmas and
societal concerns, serves as a poignant backdrop to this issue. Objective: In
this research, we undertake a comprehensive analysis of the toxic online
discourse surrounding the 2022 Mpox outbreak. Our objective is to dissect its
origins, characterize its nature and content, trace its dissemination patterns,
and assess its broader societal implications, with the goal of providing
insights that can inform strategies to mitigate such toxicity in future crises.
Methods: We collected more than 1.6 million unique tweets and analyzed them
from five dimensions, including context, extent, content, speaker, and intent.
Utilizing BERT-based topic modeling and social network community clustering, we
delineated the toxic dynamics on Twitter. Results: We identified five
high-level topic categories in the toxic online discourse on Twitter, including
disease (46.6%), health policy and healthcare (19.3%), homophobia (23.9%),
politics (6.0%), and racism (4.1%). Through the toxicity diffusion networks of
mentions, retweets, and the top users, we found that retweets of toxic content
were widespread, while influential users rarely engaged with or countered this
toxicity through retweets. Conclusions: By tracking topical dynamics, we can
track the changing popularity of toxic content online, providing a better
understanding of societal challenges. Network dynamics spotlight key social
media influencers and their intents, indicating that addressing these central
figures in toxic discourse can enhance crisis communication and inform
policy-making.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>36 pages, 8 figure, and 12 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Iteration of Thought: Leveraging Inner Dialogue for Autonomous Large
  Language Model Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.12618v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.12618v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Santosh Kumar Radha, Yasamin Nouri Jelyani, Ara Ghukasyan, Oktay Goktas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Iterative human engagement is a common and effective means of leveraging the
advanced language processing power of large language models (LLMs). Using
well-structured prompts in a conversational manner, human users can effectively
influence an LLM to develop more thoughtful and accurate responses. Motivated
by this insight, we propose the Iteration of Thought (IoT) framework for
enhancing LLM responses by generating "thought"-provoking prompts vis a vis an
input query and the current iteration of an LLM's response. Unlike static or
semi-static approaches, e.g. Chain of Thought (CoT) or Tree of Thoughts (ToT),
IoT adapts its reasoning path dynamically, based on evolving context, and
without generating alternate explorative thoughts which are ultimately
discarded. The three components of the IoT framework are (1) an Inner Dialogue
Agent (IDA) responsible for generating instructive, context-specific prompts;
(2) an LLM Agent (LLMA) that processes these prompts to refine its responses;
and (3) an iterative prompting loop that implements a conversation between the
former two components. We introduce two variants of our framework: Autonomous
Iteration of Thought (AIoT), where an LLM decides when to stop iterating, and
Guided Iteration of Thought (GIoT), which always forces a fixed number
iterations. We investigate the performance of IoT across various datasets,
spanning complex reasoning tasks from the GPQA dataset, explorative
problem-solving in Game of 24, puzzle solving in Mini Crosswords, and multi-hop
question answering from the HotpotQA dataset. Our results show that IoT
represents a viable paradigm for autonomous response refinement in LLMs,
showcasing significant improvements over CoT and thereby enabling more adaptive
and efficient reasoning systems that minimize human intervention.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AIPatient: Simulating Patients with EHRs and LLM Powered Agentic
  Workflow 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18924v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18924v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huizi Yu, Jiayan Zhou, Lingyao Li, Shan Chen, Jack Gallifant, Anye Shi, Xiang Li, Wenyue Hua, Mingyu Jin, Guang Chen, Yang Zhou, Zhao Li, Trisha Gupte, Ming-Li Chen, Zahra Azizi, Yongfeng Zhang, Themistocles L. Assimes, Xin Ma, Danielle S. Bitterman, Lin Lu, Lizhou Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Simulated patient systems play a crucial role in modern medical education and
research, providing safe, integrative learning environments and enabling
clinical decision-making simulations. Large Language Models (LLM) could advance
simulated patient systems by replicating medical conditions and patient-doctor
interactions with high fidelity and low cost. However, ensuring the
effectiveness and trustworthiness of these systems remains a challenge, as they
require a large, diverse, and precise patient knowledgebase, along with a
robust and stable knowledge diffusion to users. Here, we developed AIPatient,
an advanced simulated patient system with AIPatient Knowledge Graph (AIPatient
KG) as the input and the Reasoning Retrieval-Augmented Generation (Reasoning
RAG) agentic workflow as the generation backbone. AIPatient KG samples data
from Electronic Health Records (EHRs) in the Medical Information Mart for
Intensive Care (MIMIC)-III database, producing a clinically diverse and
relevant cohort of 1,495 patients with high knowledgebase validity (F1 0.89).
Reasoning RAG leverages six LLM powered agents spanning tasks including
retrieval, KG query generation, abstraction, checker, rewrite, and
summarization. This agentic framework reaches an overall accuracy of 94.15% in
EHR-based medical Question Answering (QA), outperforming benchmarks that use
either no agent or only partial agent integration. Our system also presents
high readability (median Flesch Reading Ease 77.23; median Flesch Kincaid Grade
5.6), robustness (ANOVA F-value 0.6126, p>0.1), and stability (ANOVA F-value
0.782, p>0.1). The promising performance of the AIPatient system highlights its
potential to support a wide range of applications, including medical education,
model evaluation, and system integration.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>42 pages, 6 figures, 7 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FLRT: Fluent Student-Teacher Redteaming 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.17447v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.17447v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        T. Ben Thompson, Michael Sklar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many publicly available language models have been safety tuned to reduce the
likelihood of toxic or liability-inducing text. To redteam or jailbreak these
models for compliance with toxic requests, users and security analysts have
developed adversarial prompting techniques. One attack method is to apply
discrete optimization techniques to the prompt. However, the resulting attack
strings are often gibberish text, easily filtered by defenders due to high
measured perplexity, and may fail for unseen tasks and/or well-tuned models. In
this work, we improve existing algorithms (primarily GCG and BEAST) to develop
powerful and fluent attacks on safety-tuned models like Llama-2 and Phi-3. Our
technique centers around a new distillation-based approach that encourages the
victim model to emulate a toxified finetune, either in terms of output
probabilities or internal activations. To encourage human-fluent attacks, we
add a multi-model perplexity penalty and a repetition penalty to the objective.
We also enhance optimizer strength by allowing token insertions, token swaps,
and token deletions and by using longer attack sequences. The resulting process
is able to reliably jailbreak the most difficult target models with prompts
that appear similar to human-written prompts. On Advbench we achieve attack
success rates $>93$% for Llama-2-7B, Llama-3-8B, and Vicuna-7B, while
maintaining model-measured perplexity $<33$; we achieve $95$% attack success
for Phi-3, though with higher perplexity. We also find a universally-optimized
single fluent prompt that induces $>88$% compliance on previously unseen tasks
across Llama-2-7B, Phi-3-mini and Vicuna-7B and transfers to other black-box
models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Conversational Complexity for Assessing Risk in Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.01247v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.01247v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        John Burden, Manuel Cebrian, Jose Hernandez-Orallo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) present a dual-use dilemma: they enable
beneficial applications while harboring potential for harm, particularly
through conversational interactions. Despite various safeguards, advanced LLMs
remain vulnerable. A watershed case was Kevin Roose's notable conversation with
Bing, which elicited harmful outputs after extended interaction. This contrasts
with simpler early jailbreaks that produced similar content more easily,
raising the question: How much conversational effort is needed to elicit
harmful information from LLMs? We propose two measures: Conversational Length
(CL), which quantifies the conversation length used to obtain a specific
response, and Conversational Complexity (CC), defined as the Kolmogorov
complexity of the user's instruction sequence leading to the response. To
address the incomputability of Kolmogorov complexity, we approximate CC using a
reference LLM to estimate the compressibility of user instructions. Applying
this approach to a large red-teaming dataset, we perform a quantitative
analysis examining the statistical distribution of harmful and harmless
conversational lengths and complexities. Our empirical findings suggest that
this distributional analysis and the minimisation of CC serve as valuable tools
for understanding AI safety, offering insights into the accessibility of
harmful information. This work establishes a foundation for a new perspective
on LLM safety, centered around the algorithmic complexity of pathways to harm.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Automated Peer <span class="highlight-title">Review</span>ing in Paper SEA: Standardization, Evaluation, and
  Analysis <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12857v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12857v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jianxiang Yu, Zichen Ding, Jiaqi Tan, Kangyang Luo, Zhenmin Weng, Chenghua Gong, Long Zeng, Renjing Cui, Chengcheng Han, Qiushi Sun, Zhiyong Wu, Yunshi Lan, Xiang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, the rapid increase in scientific papers has overwhelmed
traditional review mechanisms, resulting in varying quality of publications.
Although existing methods have explored the capabilities of Large Language
Models (LLMs) for automated scientific reviewing, their generated contents are
often generic or partial. To address the issues above, we introduce an
automated paper reviewing framework SEA. It comprises of three modules:
Standardization, Evaluation, and Analysis, which are represented by models
SEA-S, SEA-E, and SEA-A, respectively. Initially, SEA-S distills data
standardization capabilities of GPT-4 for integrating multiple reviews for a
paper. Then, SEA-E utilizes standardized data for fine-tuning, enabling it to
generate constructive reviews. Finally, SEA-A introduces a new evaluation
metric called mismatch score to assess the consistency between paper contents
and reviews. Moreover, we design a self-correction strategy to enhance the
consistency. Extensive experimental results on datasets collected from eight
venues show that SEA can generate valuable insights for authors to improve
their papers.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MMNeuron: Discovering Neuron-Level Domain-Specific Interpretation in
  Multimodal Large Language Model <span class="chip">EMNLP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11193v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11193v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiahao Huo, Yibo Yan, Boren Hu, Yutao Yue, Xuming Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Projecting visual features into word embedding space has become a significant
fusion strategy adopted by Multimodal Large Language Models (MLLMs). However,
its internal mechanisms have yet to be explored. Inspired by multilingual
research, we identify domain-specific neurons in multimodal large language
models. Specifically, we investigate the distribution of domain-specific
neurons and the mechanism of how MLLMs process features from diverse domains.
Furthermore, we propose a three-stage mechanism for language model modules in
MLLMs when handling projected image features, and verify this hypothesis using
logit lens. Extensive experiments indicate that while current MLLMs exhibit
Visual Question Answering (VQA) capability, they may not fully utilize
domain-specific information. Manipulating domain-specific neurons properly will
result in a 10% change of accuracy at most, shedding light on the development
of cross-domain, all-encompassing MLLMs in the future. The source code is
available at https://github.com/Z1zs/MMNeuron.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by the Main Conference of Empirical Methods in Natural
  Language Processing (EMNLP) 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Dual-Space Knowledge Distillation for Large Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17328v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17328v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Songming Zhang, Xue Zhang, Zengkui Sun, Yufeng Chen, Jinan Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge distillation (KD) is known as a promising solution to compress
large language models (LLMs) via transferring their knowledge to smaller
models. During this process, white-box KD methods usually minimize the distance
between the output distributions of the two models so that more knowledge can
be transferred. However, in the current white-box KD framework, the output
distributions are from the respective output spaces of the two models, using
their own prediction heads. We argue that the space discrepancy will lead to
low similarity between the teacher model and the student model on both
representation and distribution levels. Furthermore, this discrepancy also
hinders the KD process between models with different vocabularies, which is
common for current LLMs. To address these issues, we propose a dual-space
knowledge distillation (DSKD) framework that unifies the output spaces of the
two models for KD. On the basis of DSKD, we further develop a cross-model
attention mechanism, which can automatically align the representations of the
two models with different vocabularies. Thus, our framework is not only
compatible with various distance functions for KD (e.g., KL divergence) like
the current framework, but also supports KD between any two LLMs regardless of
their vocabularies. Experiments on task-agnostic instruction-following
benchmarks show that DSKD significantly outperforms the current white-box KD
framework with various distance functions, and also surpasses existing KD
methods for LLMs with different vocabularies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The camera-ready version for EMNLP 2024 main conference. 17 pages, 11
  figures, code available at: https://github.com/songmzhang/DSKD</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Does Vision Accelerate Hierarchical Generalization in Neural Language
  Learners? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2302.00667v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2302.00667v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tatsuki Kuribayashi, Timothy Baldwin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural language models (LMs) are arguably less data-efficient than humans
from a language acquisition perspective. One fundamental question is why this
human-LM gap arises. This study explores the advantage of grounded language
acquisition, specifically the impact of visual information -- which humans can
usually rely on but LMs largely do not have access to during language
acquisition -- on syntactic generalization in LMs. Our experiments, following
the poverty of stimulus paradigm under two scenarios (using artificial vs.
naturalistic images), demonstrate that if the alignments between the linguistic
and visual components are clear in the input, access to vision data does help
with the syntactic generalization of LMs, but if not, visual input does not
help. This highlights the need for additional biases or signals, such as mutual
gaze, to enhance cross-modal alignment and enable efficient syntactic
generalization in multimodal LMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Who is better at math, Jenny or Jingzhen? Uncovering Stereotypes in
  Large Language Models <span class="chip">EMNLP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.06917v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.06917v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zara Siddique, Liam D. Turner, Luis Espinosa-Anke
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have been shown to propagate and amplify harmful
stereotypes, particularly those that disproportionately affect marginalised
communities. To understand the effect of these stereotypes more
comprehensively, we introduce GlobalBias, a dataset of 876k sentences
incorporating 40 distinct gender-by-ethnicity groups alongside descriptors
typically used in bias literature, which enables us to study a broad set of
stereotypes from around the world. We use GlobalBias to directly probe a suite
of LMs via perplexity, which we use as a proxy to determine how certain
stereotypes are represented in the model's internal representations. Following
this, we generate character profiles based on given names and evaluate the
prevalence of stereotypes in model outputs. We find that the demographic groups
associated with various stereotypes remain consistent across model likelihoods
and model outputs. Furthermore, larger models consistently display higher
levels of stereotypical outputs, even when explicitly instructed not to.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP Main 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Atomic Inference for NLI with Generated Facts as Atoms <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.13214v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.13214v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joe Stacey, Pasquale Minervini, Haim Dubossarsky, Oana-Maria Camburu, Marek Rei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With recent advances, neural models can achieve human-level performance on
various natural language tasks. However, there are no guarantees that any
explanations from these models are faithful, i.e. that they reflect the inner
workings of the model. Atomic inference overcomes this issue, providing
interpretable and faithful model decisions. This approach involves making
predictions for different components (or atoms) of an instance, before using
interpretable and deterministic rules to derive the overall prediction based on
the individual atom-level predictions. We investigate the effectiveness of
using LLM-generated facts as atoms, decomposing Natural Language Inference
premises into lists of facts. While directly using generated facts in atomic
inference systems can result in worse performance, with 1) a multi-stage fact
generation process, and 2) a training regime that incorporates the facts, our
fact-based method outperforms other approaches.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Use of Large Language Models (LLM) for Cyber Threat Intelligence
  (CTI) in Cybercrime Forums 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.03354v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.03354v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vanessa Clairoux-Trepanier, Isa-May Beauchamp, Estelle Ruellan, Masarah Paquet-Clouston, Serge-Olivier Paquette, Eric Clay
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) can be used to analyze cyber threat intelligence
(CTI) data from cybercrime forums, which contain extensive information and key
discussions about emerging cyber threats. However, to date, the level of
accuracy and efficiency of LLMs for such critical tasks has yet to be
thoroughly evaluated. Hence, this study assesses the performance of an LLM
system built on the OpenAI GPT-3.5-turbo model [8] to extract CTI information.
To do so, a random sample of more than 700 daily conversations from three
cybercrime forums - XSS, Exploit_in, and RAMP - was extracted, and the LLM
system was instructed to summarize the conversations and predict 10 key CTI
variables, such as whether a large organization and/or a critical
infrastructure is being targeted, with only simple human-language instructions.
Then, two coders reviewed each conversation and evaluated whether the
information extracted by the LLM was accurate. The LLM system performed well,
with an average accuracy score of 96.23%, an average precision of 90% and an
average recall of 88.2%. Various ways to enhance the model were uncovered, such
as the need to help the LLM distinguish between stories and past events, as
well as being careful with verb tenses in prompts. Nevertheless, the results of
this study highlight the relevance of using LLMs for cyber threat intelligence.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.10774v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.10774v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liyan Tang, Philippe Laban, Greg Durrett
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recognizing if LLM output can be grounded in evidence is central to many
tasks in NLP: retrieval-augmented generation, summarization, document-grounded
dialogue, and more. Current approaches to this kind of fact-checking are based
on verifying each piece of a model generation against potential evidence using
an LLM. However, this process can be very computationally expensive, requiring
many calls to a model to check a single response. In this work, we show how to
build small fact-checking models that have GPT-4-level performance but for 400x
lower cost. We do this by constructing synthetic training data with GPT-4,
which involves creating realistic yet challenging instances of factual errors
via a structured generation procedure. Training on this data teaches models to
check each fact in the claim and recognize synthesis of information across
sentences. For evaluation, we unify datasets from recent work on fact-checking
and grounding LLM generations into a new benchmark, LLM-AggreFact. Our best
system MiniCheck-FT5 (770M parameters) outperforms all systems of comparable
size and reaches GPT-4 accuracy. We release LLM-AggreFact, code for data
synthesis, and models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Large Language Models Are Unconscious of Unreasonability in Math
  Problems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.19346v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.19346v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingyuan Ma, Damai Dai, Lei Sha, Zhifang Sui
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) demonstrate substantial capabilities in solving
math problems. However, they tend to produce hallucinations when given
questions containing unreasonable errors. In this paper, we study the behavior
of LLMs when faced with unreasonable math problems and further explore their
potential to address these problems. We construct the Unreasonable Math Problem
(UMP) benchmark to examine the error detection ability of LLMs. Experiments
show that LLMs are able to detect unreasonable errors, but still fail in
generating non-hallucinatory content. In order to improve their ability of
error detection and correction, we further design a strategic prompt template
called Critical Calculation and Conclusion(CCC). With CCC, LLMs can better
self-evaluate and detect unreasonable errors in math questions, making them
more reliable and safe in practical application scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ OLAPH: Improving Factuality in Biomedical Long-form Question Answering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.12701v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.12701v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minbyul Jeong, Hyeon Hwang, Chanwoong Yoon, Taewhoo Lee, Jaewoo Kang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the medical domain, numerous scenarios necessitate the long-form
generation ability of large language models (LLMs). Specifically, when
addressing patients' questions, it is essential that the model's response
conveys factual claims, highlighting the need for an automated method to
evaluate those claims. Thus, we introduce MedLFQA, a benchmark dataset
reconstructed using long-form question-answering datasets related to the
biomedical domain. We use MedLFQA to facilitate a cost-effective automatic
evaluations of factuality. We also propose OLAPH, a simple and novel framework
that utilizes cost-effective and multifaceted automatic evaluation to construct
a synthetic preference set and answers questions in our preferred manner. Our
framework leads us to train LLMs step-by-step to reduce hallucinations and
include crucial medical claims. We highlight that, even on evaluation metrics
not used during training, LLMs trained with our OLAPH framework demonstrate
significant performance improvement in factuality. Our findings reveal that a
7B LLM trained with our OLAPH framework can provide long answers comparable to
the medical experts' answers in terms of factuality. We believe that our work
could shed light on gauging the long-text generation ability of LLMs in the
medical domain. Our code and datasets are available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evidence Is All You Need: Ordering Imaging Studies via Language Model
  Alignment with the ACR Appropriateness Criteria 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19177v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19177v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michael S. Yao, Allison Chae, Charles E. Kahn Jr., Walter R. Witschey, James C. Gee, Hersh Sagreiya, Osbert Bastani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diagnostic imaging studies are an increasingly important component of the
workup and management of acutely presenting patients. However, ordering
appropriate imaging studies according to evidence-based medical guidelines is a
challenging task with a high degree of variability between healthcare
providers. To address this issue, recent work has investigated if generative AI
and large language models can be leveraged to help clinicians order relevant
imaging studies for patients. However, it is challenging to ensure that these
tools are correctly aligned with medical guidelines, such as the American
College of Radiology's Appropriateness Criteria (ACR AC). In this study, we
introduce a framework to intelligently leverage language models by recommending
imaging studies for patient cases that are aligned with evidence-based
guidelines. We make available a novel dataset of patient "one-liner" scenarios
to power our experiments, and optimize state-of-the-art language models to
achieve an accuracy on par with clinicians in image ordering. Finally, we
demonstrate that our language model-based pipeline can be used as intelligent
assistants by clinicians to support image ordering workflows and improve the
accuracy of imaging study ordering according to the ACR AC. Our work
demonstrates and validates a strategy to leverage AI-based software to improve
trustworthy clinical decision making in alignment with expert evidence-based
guidelines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages main text, 4 figures, 1 table</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LePaRD: A Large-Scale <span class="highlight-title">Dataset</span> of Judges Citing Precedents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.09356v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.09356v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Robert Mahari, Dominik Stammbach, Elliott Ash, Alex `Sandy' Pentland
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present the Legal Passage Retrieval Dataset LePaRD. LePaRD is a massive
collection of U.S. federal judicial citations to precedent in context. The
dataset aims to facilitate work on legal passage prediction, a challenging
practice-oriented legal retrieval and reasoning task. Legal passage prediction
seeks to predict relevant passages from precedential court decisions given the
context of a legal argument. We extensively evaluate various retrieval
approaches on LePaRD, and find that classification appears to work best.
However, we note that legal precedent prediction is a difficult task, and there
remains significant room for improvement. We hope that by publishing LePaRD, we
will encourage others to engage with a legal NLP task that promises to help
expand access to justice by reducing the burden associated with legal research.
A subset of the LePaRD dataset is freely available and the whole dataset will
be released upon publication.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Design as Desired: Utilizing Visual Question Answering for Multimodal
  <span class="highlight-title">Pre-train</span>ing <span class="chip">MICCAI2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.00226v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.00226v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tongkun Su, Jun Li, Xi Zhang, Haibo Jin, Hao Chen, Qiong Wang, Faqin Lv, Baoliang Zhao, Yin Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal pre-training demonstrates its potential in the medical domain,
which learns medical visual representations from paired medical reports.
However, many pre-training tasks require extra annotations from clinicians, and
most of them fail to explicitly guide the model to learn the desired features
of different pathologies. In this paper, we utilize Visual Question Answering
(VQA) for multimodal pre-training to guide the framework focusing on targeted
pathological features. We leverage descriptions in medical reports to design
multi-granular question-answer pairs associated with different diseases, which
assist the framework in pre-training without requiring extra annotations from
experts. We also propose a novel pre-training framework with a quasi-textual
feature transformer, a module designed to transform visual features into a
quasi-textual space closer to the textual domain via a contrastive learning
strategy. This narrows the vision-language gap and facilitates modality
alignment. Our framework is applied to four downstream tasks: report
generation, classification, segmentation, and detection across five datasets.
Extensive experiments demonstrate the superiority of our framework compared to
other state-of-the-art methods. Our code is available at
https://github.com/MoramiSu/QFT-MICCAI2024.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by MICCAI2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Merging LoRAs like Playing LEGO: Pushing the Modularity of LoRA to
  Extremes Through Rank-Wise Clustering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.16167v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.16167v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziyu Zhao, Tao Shen, Didi Zhu, Zexi Li, Jing Su, Xuwu Wang, Kun Kuang, Fei Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low-Rank Adaptation (LoRA) has emerged as a popular technique for fine-tuning
large language models (LLMs) to various domains due to its modular design and
widespread availability on platforms like Huggingface. This modularity has
sparked interest in combining multiple LoRAs to enhance LLM capabilities.
However, existing methods for LoRA composition primarily focus on task-specific
adaptations that require additional training, and current model merging
techniques often fail to fully leverage LoRA's modular nature, leading to
parameter interference and performance degradation. In this paper, we
investigate the feasibility of disassembling and reassembling multiple LoRAs at
a finer granularity, analogous to assembling LEGO blocks. We introduce the
concept of Minimal Semantic Units (MSUs), where the parameters corresponding to
each rank in LoRA function as independent units. These MSUs demonstrate
permutation invariance and concatenation-summation equivalence properties,
enabling flexible combinations to create new LoRAs. Building on these insights,
we propose the LoRA-LEGO framework. This framework conducts rank-wise parameter
clustering by grouping MSUs from different LoRAs into $k$ clusters. The
centroid of each cluster serves as a representative MSU, enabling the assembly
of a merged LoRA with an adjusted rank of $k$. Additionally, we apply a dual
reweighting strategy to optimize the scale of the merged LoRA. Experiments
across various benchmarks demonstrate that our method outperforms existing
approaches in LoRA merging.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LUMA: A Benchmark <span class="highlight-title">Dataset</span> for Learning from Uncertain and Multimodal
  Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.09864v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.09864v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Grigor Bezirganyan, Sana Sellami, Laure Berti-Équille, Sébastien Fournier
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Deep Learning enhances decision-making by integrating diverse
information sources, such as texts, images, audio, and videos. To develop
trustworthy multimodal approaches, it is essential to understand how
uncertainty impacts these models. We propose LUMA, a unique benchmark dataset,
featuring audio, image, and textual data from 50 classes, for learning from
uncertain and multimodal data. It extends the well-known CIFAR 10/100 dataset
with audio samples extracted from three audio corpora, and text data generated
using the Gemma-7B Large Language Model (LLM). The LUMA dataset enables the
controlled injection of varying types and degrees of uncertainty to achieve and
tailor specific experiments and benchmarking initiatives. LUMA is also
available as a Python package including the functions for generating multiple
variants of the dataset with controlling the diversity of the data, the amount
of noise for each modality, and adding out-of-distribution samples. A baseline
pre-trained model is also provided alongside three uncertainty quantification
methods: Monte-Carlo Dropout, Deep Ensemble, and Reliable Conflictive
Multi-View Learning. This comprehensive dataset and its benchmarking tools are
intended to promote and support the development, evaluation, and benchmarking
of trustworthy and robust multimodal deep learning approaches. We anticipate
that the LUMA dataset will help the ICLR community to design more trustworthy
and robust machine learning approaches for safety critical applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Optimizing Rare Word Accuracy in Direct Speech Translation with a
  Retrieval-and-Demonstration Approach <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.09009v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.09009v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siqi Li, Danni Liu, Jan Niehues
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Direct speech translation (ST) models often struggle with rare words.
Incorrect translation of these words can have severe consequences, impacting
translation quality and user trust. While rare word translation is inherently
challenging for neural models due to sparse learning signals, real-world
scenarios often allow access to translations of past recordings on similar
topics. To leverage these valuable resources, we propose a
retrieval-and-demonstration approach to enhance rare word translation accuracy
in direct ST models. First, we adapt existing ST models to incorporate
retrieved examples for rare word translation, which allows the model to benefit
from prepended examples, similar to in-context learning. We then develop a
cross-modal (speech-to-speech, speech-to-text, text-to-text) retriever to
locate suitable examples. We demonstrate that standard ST models can be
effectively adapted to leverage examples for rare word translation, improving
rare word translation accuracy over the baseline by 17.6% with gold examples
and 8.5% with retrieved examples. Moreover, our speech-to-speech retrieval
approach outperforms other modalities and exhibits higher robustness to unseen
speakers. Our code is publicly available
(https://github.com/SiqiLii/Retrieve-and-Demonstration-ST).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing High-order Interaction Awareness in LLM-based Recommender
  Model <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19979v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19979v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinfeng Wang, Jin Cui, Fumiyo Fukumoto, Yoshimi Suzuki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have demonstrated prominent reasoning
capabilities in recommendation tasks by transforming them into text-generation
tasks. However, existing approaches either disregard or ineffectively model the
user-item high-order interactions. To this end, this paper presents an enhanced
LLM-based recommender (ELMRec). We enhance whole-word embeddings to
substantially enhance LLMs' interpretation of graph-constructed interactions
for recommendations, without requiring graph pre-training. This finding may
inspire endeavors to incorporate rich knowledge graphs into LLM-based
recommenders via whole-word embedding. We also found that LLMs often recommend
items based on users' earlier interactions rather than recent ones, and present
a reranking solution. Our ELMRec outperforms state-of-the-art (SOTA) methods in
both direct and sequential recommendations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Long paper accepted to EMNLP 2024 Main. 16 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Backdoor Attacks for LLMs with Weak-To-Strong Knowledge Distillation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.17946v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.17946v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuai Zhao, Leilei Gan, Zhongliang Guo, Xiaobao Wu, Luwei Xiao, Xiaoyu Xu, Cong-Duy Nguyen, Luu Anh Tuan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite being widely applied due to their exceptional capabilities, Large
Language Models (LLMs) have been proven to be vulnerable to backdoor attacks.
These attacks introduce targeted vulnerabilities into LLMs by poisoning
training samples and full-parameter fine-tuning. However, this kind of backdoor
attack is limited since they require significant computational resources,
especially as the size of LLMs increases. Besides, parameter-efficient
fine-tuning (PEFT) offers an alternative but the restricted parameter updating
may impede the alignment of triggers with target labels. In this study, we
first verify that backdoor attacks with PEFT may encounter challenges in
achieving feasible performance. To address these issues and improve the
effectiveness of backdoor attacks with PEFT, we propose a novel backdoor attack
algorithm from weak to strong based on feature alignment-enhanced knowledge
distillation (W2SAttack). Specifically, we poison small-scale language models
through full-parameter fine-tuning to serve as the teacher model. The teacher
model then covertly transfers the backdoor to the large-scale student model
through feature alignment-enhanced knowledge distillation, which employs PEFT.
Theoretical analysis reveals that W2SAttack has the potential to augment the
effectiveness of backdoor attacks. We demonstrate the superior performance of
W2SAttack on classification tasks across four language models, four backdoor
attack algorithms, and two different architectures of teacher models.
Experimental results indicate success rates close to 100% for backdoor attacks
targeting PEFT.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Universal Vulnerabilities in Large Language Models: Backdoor Attacks for
  In-context Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.05949v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.05949v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuai Zhao, Meihuizi Jia, Luu Anh Tuan, Fengjun Pan, Jinming Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In-context learning, a paradigm bridging the gap between pre-training and
fine-tuning, has demonstrated high efficacy in several NLP tasks, especially in
few-shot settings. Despite being widely applied, in-context learning is
vulnerable to malicious attacks. In this work, we raise security concerns
regarding this paradigm. Our studies demonstrate that an attacker can
manipulate the behavior of large language models by poisoning the demonstration
context, without the need for fine-tuning the model. Specifically, we design a
new backdoor attack method, named ICLAttack, to target large language models
based on in-context learning. Our method encompasses two types of attacks:
poisoning demonstration examples and poisoning demonstration prompts, which can
make models behave in alignment with predefined intentions. ICLAttack does not
require additional fine-tuning to implant a backdoor, thus preserving the
model's generality. Furthermore, the poisoned examples are correctly labeled,
enhancing the natural stealth of our attack method. Extensive experimental
results across several language models, ranging in size from 1.3B to 180B
parameters, demonstrate the effectiveness of our attack method, exemplified by
a high average attack success rate of 95.0% across the three datasets on OPT
models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations? <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.05904v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.05904v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zorik Gekhman, Gal Yona, Roee Aharoni, Matan Eyal, Amir Feder, Roi Reichart, Jonathan Herzig
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  When large language models are aligned via supervised fine-tuning, they may
encounter new factual information that was not acquired through pre-training.
It is often conjectured that this can teach the model the behavior of
hallucinating factually incorrect responses, as the model is trained to
generate facts that are not grounded in its pre-existing knowledge. In this
work, we study the impact of such exposure to new knowledge on the capability
of the fine-tuned model to utilize its pre-existing knowledge. To this end, we
design a controlled setup, focused on closed-book QA, where we vary the
proportion of the fine-tuning examples that introduce new knowledge. We
demonstrate that large language models struggle to acquire new factual
knowledge through fine-tuning, as fine-tuning examples that introduce new
knowledge are learned significantly slower than those consistent with the
model's knowledge. However, we also find that as the examples with new
knowledge are eventually learned, they linearly increase the model's tendency
to hallucinate. Taken together, our results highlight the risk in introducing
new factual knowledge through fine-tuning, and support the view that large
language models mostly acquire factual knowledge through pre-training, whereas
fine-tuning teaches them to use it more efficiently.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted as a long paper at EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unveiling Implicit Table Knowledge with Question-Then-Pinpoint Reasoner
  for Insightful Table Summarization <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12269v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12269v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kwangwook Seo, Jinyoung Yeo, Dongha Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Implicit knowledge hidden within the explicit table cells, such as data
insights, is the key to generating a high-quality table summary. However,
unveiling such implicit knowledge is a non-trivial task. Due to the complex
nature of structured tables, it is challenging even for large language models
(LLMs) to mine the implicit knowledge in an insightful and faithful manner. To
address this challenge, we propose a novel table reasoning framework
Question-then-Pinpoint. Our work focuses on building a plug-and-play table
reasoner that can self-question the insightful knowledge and answer it by
faithfully pinpointing evidence on the table to provide explainable guidance
for the summarizer. To train a reliable reasoner, we collect table knowledge by
guiding a teacher LLM to follow the coarse-to-fine reasoning paths and refine
it through two quality enhancement strategies to selectively distill the
high-quality knowledge to the reasoner. Extensive experiments on two table
summarization datasets, including our newly proposed InsTaSumm, validate the
general effectiveness of our framework.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DiffuCOMET: Contextual Commonsense Knowledge Diffusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.17011v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.17011v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Silin Gao, Mete Ismayilzada, Mengjie Zhao, Hiromi Wakaki, Yuki Mitsufuji, Antoine Bosselut
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Inferring contextually-relevant and diverse commonsense to understand
narratives remains challenging for knowledge models. In this work, we develop a
series of knowledge models, DiffuCOMET, that leverage diffusion to learn to
reconstruct the implicit semantic connections between narrative contexts and
relevant commonsense knowledge. Across multiple diffusion steps, our method
progressively refines a representation of commonsense facts that is anchored to
a narrative, producing contextually-relevant and diverse commonsense inferences
for an input context. To evaluate DiffuCOMET, we introduce new metrics for
commonsense inference that more closely measure knowledge diversity and
contextual relevance. Our results on two different benchmarks, ComFact and
WebNLG+, show that knowledge generated by DiffuCOMET achieves a better
trade-off between commonsense diversity, contextual relevance and alignment to
known gold references, compared to baseline knowledge models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Think Twice: A Human-like Two-stage Conversational Agent for Emotional
  Response Generation <span class="chip">AAMAS 2023</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2301.04907v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2301.04907v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yushan Qian, Bo Wang, Shangzhao Ma, Wu Bin, Shuo Zhang, Dongming Zhao, Kun Huang, Yuexian Hou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Towards human-like dialogue systems, current emotional dialogue approaches
jointly model emotion and semantics with a unified neural network. This
strategy tends to generate safe responses due to the mutual restriction between
emotion and semantics, and requires rare emotion-annotated large-scale dialogue
corpus. Inspired by the "think twice" behavior in human dialogue, we propose a
two-stage conversational agent for the generation of emotional dialogue.
Firstly, a dialogue model trained without the emotion-annotated dialogue corpus
generates a prototype response that meets the contextual semantics. Secondly,
the first-stage prototype is modified by a controllable emotion refiner with
the empathy hypothesis. Experimental results on the DailyDialog and
EmpatheticDialogues datasets demonstrate that the proposed conversational
outperforms the comparison models in emotion generation and maintains the
semantic performance in automatic and human evaluations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to AAMAS 2023</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Zero-Shot Multi-Hop Question Answering via Monte-Carlo Tree Search with
  Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19382v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19382v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seongmin Lee, Jaewook Shin, Youngjin Ahn, Seokin Seo, Ohjoon Kwon, Kee-Eung Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in large language models (LLMs) have significantly impacted
the domain of multi-hop question answering (MHQA), where systems are required
to aggregate information and infer answers from disparate pieces of text.
However, the autoregressive nature of LLMs inherently poses a challenge as
errors may accumulate if mistakes are made in the intermediate reasoning steps.
This paper introduces Monte-Carlo tree search for Zero-shot multi-hop Question
Answering (MZQA), a framework based on Monte-Carlo tree search (MCTS) to
identify optimal reasoning paths in MHQA tasks, mitigating the error
propagation from sequential reasoning processes. Unlike previous works, we
propose a zero-shot prompting method, which relies solely on instructions
without the support of hand-crafted few-shot examples that typically require
domain expertise. We also introduce a behavioral cloning approach (MZQA-BC)
trained on self-generated MCTS inference trajectories, achieving an over
10-fold increase in reasoning speed with bare compromise in performance. The
efficacy of our method is validated on standard benchmarks such as HotpotQA,
2WikiMultihopQA, and MuSiQue, demonstrating that it outperforms existing
frameworks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in Progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Bone: Block Affine Transformation as Parameter Efficient Fine-tuning
  Methods for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15371v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15371v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiale Kang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low-Rank Adaptation (LoRA) has achieved remarkable training results by
freezing the original weights and training only low-rank matrices, establishing
itself as the predominant fine-tuning method for LLMs. In pursuit of
performance closer to full-parameter training, a series of LoRA variants have
emerged, such as LoRA+, PISSA, Olora, and LoRA-GA. However, these improvements
complicate the initial setup of model training and increase initialization
time. More importantly, they overlook the internal interactions of the original
weight information. To address these issues, we introduce a novel theory,
``Weight Guide'' aimed at continuously guiding trainable matrices through the
original weights during training to enhance the utilization of weight
information. Based on this theory, we designed a new PEFT technique called Bone
(\textbf{B}l\textbf{o}ck Affi\textbf{ne}), which not only enhances the
utilization of original weight information but also emphasizes the internal
connections between weights, leading to faster convergence and better data
fitting. Experimental comparisons across two different LLM architectures
(LLaMA2, RWKV6) and various parameter scales demonstrate that the Bone
structure can achieve rapid convergence and superior data fitting without the
need for complex initialization. For example, when fine-tuning LLaMA2-7B on the
MetaMathQA dataset and validating on GSM8k and math benchmarks, Bone achieved
fine-tuning scores of 49.36 and 8.8, respectively, outperforming PISSA by
5.84\% and 1.96\%.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Developments in Sheaf-Theoretic Models of Natural Language Ambiguities 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.04505v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.04505v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kin Ian Lo, Mehrnoosh Sadrzadeh, Shane Mansfield
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sheaves are mathematical objects consisting of a base which constitutes a
topological space and the data associated with each open set thereof, e.g.
continuous functions defined on the open sets. Sheaves have originally been
used in algebraic topology and logic. Recently, they have also modelled events
such as physical experiments and natural language disambiguation processes. We
extend the latter models from lexical ambiguities to discourse ambiguities
arising from anaphora. To begin, we calculated a new measure of contextuality
for a dataset of basic anaphoric discourses, resulting in a higher proportion
of contextual models-82.9%-compared to previous work which only yielded 3.17%
contextual models. Then, we show how an extension of the natural language
processing challenge, known as the Winograd Schema, which involves anaphoric
ambiguities can be modelled on the Bell-CHSH scenario with a contextual
fraction of 0.096.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>In Proceedings DCM 2023, arXiv:2409.19298</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Efficient Controlled Language Generation with Low-Rank Autoregressive
  Reward Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.04615v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.04615v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sergey Troshin, Vlad Niculae, Antske Fokkens
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language models trained on large amounts of data are known to produce
inappropriate content in some cases and require careful tuning to be used in
the real world. We revisit the reward augmented decoding (RAD) approach to
control the generation from a language model using the scores from a
task-specific reward model. We investigate the training objective of RAD, and
reformulate it as a task of learning a reward matrix. We show that RAD is
designed to support high flexibility when representing the reward matrices,
which leads to a higher computational costs during decoding. However, we
demonstrate that RAD does not use its full flexibility. Motivated by this, we
propose a simpler but more efficient low-rank parametrization of the reward
model enabling fast and effective guided decoding. For the detoxification and
sentiment control tasks, we show that our low-rank reward model performs on par
with the more flexible RAD parametrization, while requiring only a single
reward model call per generated token.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Ruler: A Model-Agnostic Method to Control Generated Length for Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18943v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18943v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaming Li, Lei Zhang, Yunshui Li, Ziqiang Liu, yuelin bai, Run Luo, Longze Chen, Min Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The instruction-following ability of large language models enables humans to
interact with AI agents in a natural way. However, when required to generate
responses of a specific length, large language models often struggle to meet
users' needs due to their inherent difficulty in accurately perceiving
numerical constraints. To explore the ability of large language models to
control the length of generated responses, we propose the Target Length
Generation Task (TLG) and design two metrics, Precise Match (PM) and Flexible
Match (FM) to evaluate the model's performance in adhering to specified
response lengths. Furthermore, we introduce a novel, model-agnostic approach
called Ruler, which employs Meta Length Tokens (MLTs) to enhance the
instruction-following ability of large language models under length-constrained
instructions. Specifically, Ruler equips LLMs with the ability to generate
responses of a specified length based on length constraints within the
instructions. Moreover, Ruler can automatically generate appropriate MLT when
length constraints are not explicitly provided, demonstrating excellent
versatility and generalization. Comprehensive experiments show the
effectiveness of Ruler across different LLMs on Target Length Generation Task,
e.g., at All Level 27.97 average gain on PM, 29.57 average gain on FM. In
addition, we conduct extensive ablation experiments to further substantiate the
efficacy and generalization of Ruler. Our code and data is available at
https://github.com/Geaming2002/Ruler.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Read Over the Lines: Attacking LLMs and Toxicity Detection Systems with
  ASCII Art to Mask Profanity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18708v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18708v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sergey Berezin, Reza Farahbakhsh, Noel Crespi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a novel family of adversarial attacks that exploit the inability
of language models to interpret ASCII art. To evaluate these attacks, we
propose the ToxASCII benchmark and develop two custom ASCII art fonts: one
leveraging special tokens and another using text-filled letter shapes. Our
attacks achieve a perfect 1.0 Attack Success Rate across ten models, including
OpenAI's o1-preview and LLaMA 3.1.
  Warning: this paper contains examples of toxic language used for research
purposes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unlabeled Debiasing in Downstream Tasks via Class-wise Low Variance
  Regularization <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19541v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19541v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shahed Masoudian, Markus Frohman, Navid Rekabsaz, Markus Schedl
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language models frequently inherit societal biases from their training data.
Numerous techniques have been proposed to mitigate these biases during both the
pre-training and fine-tuning stages. However, fine-tuning a pre-trained
debiased language model on a downstream task can reintroduce biases into the
model. Additionally, existing debiasing methods for downstream tasks either (i)
require labels of protected attributes (e.g., age, race, or political views)
that are often not available or (ii) rely on indicators of bias, which
restricts their applicability to gender debiasing since they rely on
gender-specific words. To address this, we introduce a novel debiasing
regularization technique based on the class-wise variance of embeddings.
Crucially, our method does not require attribute labels and targets any
attribute, thus addressing the shortcomings of existing debiasing methods. Our
experiments on encoder language models and three datasets demonstrate that our
method outperforms existing strong debiasing baselines that rely on target
attribute labels while maintaining performance on the target task.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Model-based Preference Optimization in Abstractive Summarization without
  Human Feedback <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18618v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18618v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jaepill Choi, Kyubyung Chae, Jiwoo Song, Yohan Jo, Taesup Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In abstractive summarization, the challenge of producing concise and accurate
summaries arises from the vast amount of information contained in the source
document. Consequently, although Large Language Models (LLMs) can generate
fluent text, they often introduce inaccuracies by hallucinating content not
found in the original source. While supervised fine-tuning methods that
maximize likelihood contribute to this issue, they do not consistently enhance
the faithfulness of the summaries. Preference-based optimization methods, such
as Direct Preference Optimization (DPO), can further refine the model to align
with human preferences. However, these methods still heavily depend on costly
human feedback. In this work, we introduce a novel and straightforward approach
called Model-based Preference Optimization (MPO) to fine-tune LLMs for improved
summarization abilities without any human feedback. By leveraging the model's
inherent summarization capabilities, we create a preference dataset that is
fully generated by the model using different decoding strategies. Our
experiments on standard summarization datasets and various metrics demonstrate
that our proposed MPO significantly enhances the quality of generated summaries
without relying on human feedback.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ UniSumEval: Towards Unified, Fine-Grained, Multi-Dimensional
  Summarization Evaluation for LLMs <span class="chip">EMNLP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19898v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19898v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuho Lee, Taewon Yun, Jason Cai, Hang Su, Hwanjun Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing benchmarks for summarization quality evaluation often lack diverse
input scenarios, focus on narrowly defined dimensions (e.g., faithfulness), and
struggle with subjective and coarse-grained annotation schemes. To address
these shortcomings, we create UniSumEval benchmark, which extends the range of
input context (e.g., domain, length) and provides fine-grained,
multi-dimensional annotations. We use AI assistance in data creation,
identifying potentially hallucinogenic input texts, and also helping human
annotators reduce the difficulty of fine-grained annotation tasks. With
UniSumEval, we benchmark nine latest language models as summarizers, offering
insights into their performance across varying input contexts and evaluation
dimensions. Furthermore, we conduct a thorough comparison of SOTA automated
summary evaluators. Our benchmark data will be available at
https://github.com/DISL-Lab/UniSumEval-v1.0.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP-Findings 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Obliviate: Neutralizing Task-agnostic Backdoors within the
  Parameter-efficient Fine-tuning Paradigm 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.14119v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.14119v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jaehan Kim, Minkyoo Song, Seung Ho Na, Seungwon Shin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Parameter-efficient fine-tuning (PEFT) has become a key training strategy for
large language models. However, its reliance on fewer trainable parameters
poses security risks, such as task-agnostic backdoors. Despite their severe
impact on a wide range of tasks, there is no practical defense solution
available that effectively counters task-agnostic backdoors within the context
of PEFT. In this study, we introduce Obliviate, a PEFT-integrable backdoor
defense. We develop two techniques aimed at amplifying benign neurons within
PEFT layers and penalizing the influence of trigger tokens. Our evaluations
across three major PEFT architectures show that our method can significantly
reduce the attack success rate of the state-of-the-art task-agnostic backdoors
(83.6%$\downarrow$). Furthermore, our method exhibits robust defense
capabilities against both task-specific backdoors and adaptive attacks. Source
code will be obtained at https://github.com/obliviateARR/Obliviate.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Identifying Knowledge Editing Types in Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19663v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19663v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaopeng Li, Shangwen Wang, Shezheng Song, Bin Ji, Huijun Liu, Shasha Li, Jun Ma, Jie Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge editing has emerged as an efficient technology for updating the
knowledge of large language models (LLMs), attracting increasing attention in
recent years. However, there is a lack of effective measures to prevent the
malicious misuse of this technology, which could lead to harmful edits in LLMs.
These malicious modifications could cause LLMs to generate toxic content,
misleading users into inappropriate actions. In front of this risk, we
introduce a new task, Knowledge Editing Type Identification (KETI), aimed at
identifying different types of edits in LLMs, thereby providing timely alerts
to users when encountering illicit edits. As part of this task, we propose
KETIBench, which includes five types of harmful edits covering most popular
toxic types, as well as one benign factual edit. We develop four classical
classification models and three BERT-based models as baseline identifiers for
both open-source and closed-source LLMs. Our experimental results, across 42
trials involving two models and three knowledge editing methods, demonstrate
that all seven baseline identifiers achieve decent identification performance,
highlighting the feasibility of identifying malicious edits in LLMs. Additional
analyses reveal that the performance of the identifiers is independent of the
reliability of the knowledge editing methods and exhibits cross-domain
generalization, enabling the identification of edits from unknown sources. All
data and code are available in https://github.com/xpq-tech/KETI. Warning: This
paper contains examples of toxic text.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring the Limits of Fine-grained LLM-based Physics Inference via
  Premise Removal Interventions <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.18384v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.18384v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jordan Meadows, Tamsin James, Andre Freitas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language models (LMs) can hallucinate when performing complex mathematical
reasoning. Physics provides a rich domain for assessing their mathematical
capabilities, where physical context requires that any symbolic manipulation
satisfies complex semantics (\textit{e.g.,} units, tensorial order). In this
work, we systematically remove crucial context from prompts to force instances
where model inference may be algebraically coherent, yet unphysical. We assess
LM capabilities in this domain using a curated dataset encompassing multiple
notations and Physics subdomains. Further, we improve zero-shot scores using
synthetic in-context examples, and demonstrate non-linear degradation of
derivation quality with perturbation strength via the progressive omission of
supporting premises. We find that the models' mathematical reasoning is not
physics-informed in this setting, where physical context is predominantly
ignored in favour of reverse-engineering solutions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 (Findings)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Instance-adaptive Zero-shot Chain-of-Thought <span class="highlight-title">Prompt</span>ing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.20441v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.20441v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaosong Yuan, Chen Shen, Shaotian Yan, Xiaofeng Zhang, Liang Xie, Wenxiao Wang, Renchu Guan, Ying Wang, Jieping Ye
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Zero-shot Chain-of-Thought (CoT) prompting emerges as a simple and effective
strategy for enhancing the performance of large language models (LLMs) in
real-world reasoning tasks. Nonetheless, the efficacy of a singular, task-level
prompt uniformly applied across the whole of instances is inherently limited
since one prompt cannot be a good partner for all, a more appropriate approach
should consider the interaction between the prompt and each instance
meticulously. This work introduces an instance-adaptive prompting algorithm as
an alternative zero-shot CoT reasoning scheme by adaptively differentiating
good and bad prompts. Concretely, we first employ analysis on LLMs through the
lens of information flow to detect the mechanism under zero-shot CoT reasoning,
in which we discover that information flows from question to prompt and
question to rationale jointly influence the reasoning results most. We notice
that a better zero-shot CoT reasoning needs the prompt to obtain semantic
information from the question then the rationale aggregates sufficient
information from the question directly and via the prompt indirectly. On the
contrary, lacking any of those would probably lead to a bad one. Stem from
that, we further propose an instance-adaptive prompting strategy (IAP) for
zero-shot CoT reasoning. Experiments conducted with LLaMA-2, LLaMA-3, and Qwen
on math, logic, and commonsense reasoning tasks (e.g., GSM8K, MMLU, Causal
Judgement) obtain consistent improvement, demonstrating that the
instance-adaptive zero-shot CoT prompting performs better than other task-level
methods with some curated prompts or sophisticated procedures, showing the
significance of our findings in the zero-shot CoT reasoning mechanism.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FLEX: Expert-level False-Less EXecution Metric for Reliable Text-to-SQL
  Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19014v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19014v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Heegyu Kim, Taeyang Jeon, Seunghwan Choi, Seungtaek Choi, Hyunsouk Cho
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-SQL technology has become crucial for translating natural language
into SQL queries in various industries, enabling non-technical users to perform
complex data operations. The need for accurate evaluation methods has increased
as these systems have grown more sophisticated. However, we found that the
Execution Accuracy (EX), the most promising evaluation metric, still shows a
substantial portion of false positives and negatives compared to human
evaluation. Thus, this paper introduces FLEX (False-Less EXecution), a novel
approach to evaluating text-to-SQL systems using large language models (LLMs)
to emulate human expert-level evaluation of SQL queries. Our method shows
significantly higher agreement with human expert judgments, improving Cohen's
kappa from 61 to 78.17. Re-evaluating top-performing models on the Spider and
BIRD benchmarks using FLEX reveals substantial shifts in performance rankings,
with an average performance decrease of 3.15 due to false positive corrections
and an increase of 6.07 from addressing false negatives. This work contributes
to a more accurate and nuanced evaluation of text-to-SQL systems, potentially
reshaping our understanding of state-of-the-art performance in this field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>preprint, under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Federated Instruction Tuning of LLMs with Domain Coverage Augmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.20135v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.20135v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zezhou Wang, Yaxin Du, Zhuzhong Qian, Siheng Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Federated Domain-specific Instruction Tuning (FedDIT) utilizes limited
cross-client private data alongside server-side public data for instruction
augmentation, ultimately enhancing model performance within specific domains.
While the factors affecting FedDIT remain unclear and existing instruction
augmentation methods mainly focus on the centralized setting without
considering the distributed environment. Our experiments reveal that the
cross-client domain coverage, rather than data heterogeneity, drives model
performance in FedDIT. In response, we propose FedDCA, which optimizes domain
coverage through greedy client center selection and retrieval-based
augmentation. To alleviate client-side computational burdens, FedDCA$^*$ uses
heterogeneous encoders with server-side feature alignment. Extensive
experiments across four distinct domains (code, medical, financial, and
mathematical) substantiate the effectiveness of both methods. Additionally, we
investigate privacy preservation against memory extraction attacks utilizing
varying amounts of public data. Results show no significant correlation between
the volume of public data and the privacy-preserving capability. However, as
the fine-tuning round increases, the risk of privacy leakage reduces or
converges.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Weak-to-Strong Reasoning <span class="chip">EMNLP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13647v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13647v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuqing Yang, Yan Ma, Pengfei Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  When large language models (LLMs) exceed human-level capabilities, it becomes
increasingly challenging to provide full-scale and accurate supervision for
these models. Weak-to-strong learning, which leverages a less capable model to
unlock the latent abilities of a stronger model, proves valuable in this
context. Yet, the efficacy of this approach for complex reasoning tasks is
still untested. Furthermore, tackling reasoning tasks under the weak-to-strong
setting currently lacks efficient methods to avoid blindly imitating the weak
supervisor including its errors. In this paper, we introduce a progressive
learning framework that enables the strong model to autonomously refine its
training data, without requiring input from either a more advanced model or
human-annotated data. This framework begins with supervised fine-tuning on a
selective small but high-quality dataset, followed by preference optimization
on contrastive samples identified by the strong model itself. Extensive
experiments on the GSM8K and MATH datasets demonstrate that our method
significantly enhances the reasoning capabilities of Llama2-70b using three
separate weak models. This method is further validated in a forward-looking
experimental setup, where Llama3-8b-instruct effectively supervises Llama3-70b
on the highly challenging OlympicArena dataset. This work paves the way for a
more scalable and sophisticated strategy to enhance AI reasoning powers. All
relevant code and resources are available in
\url{https://github.com/GAIR-NLP/weak-to-strong-reasoning}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP Findings 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RichRAG: Crafting Rich Responses for Multi-faceted Queries in
  Retrieval-Augmented Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.12566v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.12566v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuting Wang, Xin Yu, Mang Wang, Weipeng Chen, Yutao Zhu, Zhicheng Dou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) effectively addresses issues of static
knowledge and hallucination in large language models. Existing studies mostly
focus on question scenarios with clear user intents and concise answers.
However, it is prevalent that users issue broad, open-ended queries with
diverse sub-intents, for which they desire rich and long-form answers covering
multiple relevant aspects. To tackle this important yet underexplored problem,
we propose a novel RAG framework, namely RichRAG. It includes a sub-aspect
explorer to identify potential sub-aspects of input questions, a multi-faceted
retriever to build a candidate pool of diverse external documents related to
these sub-aspects, and a generative list-wise ranker, which is a key module to
provide the top-k most valuable documents for the final generator. These ranked
documents sufficiently cover various query aspects and are aware of the
generator's preferences, hence incentivizing it to produce rich and
comprehensive responses for users. The training of our ranker involves a
supervised fine-tuning stage to ensure the basic coverage of documents, and a
reinforcement learning stage to align downstream LLM's preferences to the
ranking of documents. Experimental results on two publicly available datasets
prove that our framework effectively and efficiently provides comprehensive and
satisfying responses to users.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ How Far Are We from Intelligent Visual Deductive Reasoning? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.04732v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.04732v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yizhe Zhang, He Bai, Ruixiang Zhang, Jiatao Gu, Shuangfei Zhai, Josh Susskind, Navdeep Jaitly
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-Language Models (VLMs) have recently demonstrated incredible strides
on diverse vision language tasks. We dig into vision-based deductive reasoning,
a more sophisticated but less explored realm, and find previously unexposed
blindspots in the current SOTA VLMs. Specifically, we leverage Raven's
Progressive Matrices (RPMs), to assess VLMs' abilities to perform multi-hop
relational and deductive reasoning relying solely on visual clues. We perform
comprehensive evaluations of several popular VLMs employing standard strategies
such as in-context learning, self-consistency, and Chain-of-thoughts (CoT) on
three diverse datasets, including the Mensa IQ test, IntelligenceTest, and
RAVEN. The results reveal that despite the impressive capabilities of LLMs in
text-based reasoning, we are still far from achieving comparable proficiency in
visual deductive reasoning. We found that certain standard strategies that are
effective when applied to LLMs do not seamlessly translate to the challenges
presented by visual reasoning tasks. A detailed analysis reveals that VLMs
struggle to solve these tasks mainly because they are unable to perceive and
comprehend multiple, confounding abstract patterns in RPM examples.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>COLM 2024. https://github.com/apple/ml-rpm-bench</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs <span class="chip">ICLR
  2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.02262v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.02262v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qingru Zhang, Chandan Singh, Liyuan Liu, Xiaodong Liu, Bin Yu, Jianfeng Gao, Tuo Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In human-written articles, we often leverage the subtleties of text style,
such as bold and italics, to guide the attention of readers. These textual
emphases are vital for the readers to grasp the conveyed information. When
interacting with large language models (LLMs), we have a similar need --
steering the model to pay closer attention to user-specified information, e.g.,
an instruction. Existing methods, however, are constrained to process plain
text and do not support such a mechanism. This motivates us to introduce PASTA
-- Post-hoc Attention STeering Approach, a method that allows LLMs to read text
with user-specified emphasis marks. To this end, PASTA identifies a small
subset of attention heads and applies precise attention reweighting on them,
directing the model attention to user-specified parts. Like prompting, PASTA is
applied at inference time and does not require changing any model parameters.
Experiments demonstrate that PASTA can substantially enhance an LLM's ability
to follow user instructions or integrate new knowledge from user inputs,
leading to a significant performance improvement on a variety of tasks, e.g.,
an average accuracy improvement of 22% for LLAMA-7B. Our code is publicly
available at https://github.com/QingruZhang/PASTA .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The 12th International Conference on Learning Representations (ICLR
  2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Block-Attention for Efficient RAG 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15355v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15355v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        East Sun, Yan Wang, Lan Tian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Block-Attention, an attention mechanism designed to address the
increased inference latency and cost in Retrieval-Augmented Generation (RAG)
scenarios. Traditional approaches often encode the entire context. Instead,
Block-Attention divides retrieved documents into discrete blocks, with each
block independently calculating key-value (KV) states except for the final
block. In RAG scenarios, by defining each passage as a block, Block-Attention
enables us to reuse the KV states of passages that have been seen before,
thereby significantly reducing the latency and the computation overhead during
inference. The implementation of Block-Attention involves block segmentation,
position re-encoding, and fine-tuning the LLM to adapt to the Block-Attention
mechanism. Experiments on four RAG benchmarks demonstrate that after block
fine-tuning, the Block-Attention model achieves performance comparable to
self-attention models (68.4\% vs 67.9\% on Llama3) or even superior performance
(62.8\% vs 59.6\% on Mistral). Notably, Block-Attention significantly reduces
the time to first token (TTFT) and floating point operations (FLOPs) to a very
low level. It only takes 45 ms to output the first token for an input sequence
with a total length of 32K. Compared to the self-attention models, the time
consumption and corresponding FLOPs are reduced by 98.7\% and 99.8\%,
respectively.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Privacy Evaluation Benchmarks for NLP Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15868v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15868v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Huang, Yinggui Wang, Cen Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  By inducing privacy attacks on NLP models, attackers can obtain sensitive
information such as training data and model parameters, etc. Although
researchers have studied, in-depth, several kinds of attacks in NLP models,
they are non-systematic analyses. It lacks a comprehensive understanding of the
impact caused by the attacks. For example, we must consider which scenarios can
apply to which attacks, what the common factors are that affect the performance
of different attacks, the nature of the relationships between different
attacks, and the influence of various datasets and models on the effectiveness
of the attacks, etc. Therefore, we need a benchmark to holistically assess the
privacy risks faced by NLP models. In this paper, we present a privacy attack
and defense evaluation benchmark in the field of NLP, which includes the
conventional/small models and large language models (LLMs). This benchmark
supports a variety of models, datasets, and protocols, along with standardized
modules for comprehensive evaluation of attacks and defense strategies. Based
on the above framework, we present a study on the association between auxiliary
data from different domains and the strength of privacy attacks. And we provide
an improved attack method in this scenario with the help of Knowledge
Distillation (KD). Furthermore, we propose a chained framework for privacy
attacks. Allowing a practitioner to chain multiple attacks to achieve a
higher-level attack objective. Based on this, we provide some defense and
enhanced attack strategies. The code for reproducing the results can be found
at https://github.com/user2311717757/nlp_doctor.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Findings of EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark
  <span class="highlight-title">Dataset</span> for Generative Language Models in Norwegian <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.01314v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.01314v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peng Liu, Lemei Zhang, Terje Farup, Even W. Lauvrak, Jon Espen Ingvaldsen, Simen Eide, Jon Atle Gulla, Zhirong Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Norwegian, spoken by only 5 million population, is under-representative
within the most impressive breakthroughs in NLP tasks. To the best of our
knowledge, there has not yet been a comprehensive evaluation of the existing
language models (LMs) on Norwegian generation tasks during the article writing
process. To fill this gap, we 1) compiled the existing Norwegian dataset and
pre-trained 4 Norwegian Open Language Models varied from parameter scales and
architectures, collectively called NorGLM; 2) introduced a comprehensive
benchmark, NLEBench, for evaluating natural language generation capabilities in
Norwegian, encompassing translation and human annotation. Based on the
investigation, we find that: 1) the mainstream, English-dominated LM GPT-3.5
has limited capability in understanding the Norwegian context; 2) the increase
in model parameter scales demonstrates limited impact on the performance of
downstream tasks when the pre-training dataset is constrained in size; 3)
smaller models also demonstrate the reasoning capability through
Chain-of-Thought; 4) a multi-task dataset that includes synergy tasks can be
used to verify the generalizability of LLMs on natural language understanding
and, meanwhile, test the interconnectedness of these NLP tasks. We share our
resources and code for reproducibility under a CC BY-NC 4.0 license.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024 Main Conference. Code available at
  https://github.com/Smartmedia-AI/NorGLM/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unveiling Factual Recall Behaviors of Large Language Models through
  Knowledge Neurons 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.03247v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.03247v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yifei Wang, Yuheng Chen, Wanting Wen, Yu Sheng, Linjing Li, Daniel Dajun Zeng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we investigate whether Large Language Models (LLMs) actively
recall or retrieve their internal repositories of factual knowledge when faced
with reasoning tasks. Through an analysis of LLMs' internal factual recall at
each reasoning step via Knowledge Neurons, we reveal that LLMs fail to harness
the critical factual associations under certain circumstances. Instead, they
tend to opt for alternative, shortcut-like pathways to answer reasoning
questions. By manually manipulating the recall process of parametric knowledge
in LLMs, we demonstrate that enhancing this recall process directly improves
reasoning performance whereas suppressing it leads to notable degradation.
Furthermore, we assess the effect of Chain-of-Thought (CoT) prompting, a
powerful technique for addressing complex reasoning tasks. Our findings
indicate that CoT can intensify the recall of factual knowledge by encouraging
LLMs to engage in orderly and reliable reasoning. Furthermore, we explored how
contextual conflicts affect the retrieval of facts during the reasoning process
to gain a comprehensive understanding of the factual recall behaviors of LLMs.
Code and data will be available soon.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ See What LLMs Cannot Answer: A Self-Challenge Framework for Uncovering
  LLM Weaknesses 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.08978v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.08978v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yulong Chen, Yang Liu, Jianhao Yan, Xuefeng Bai, Ming Zhong, Yinghao Yang, Ziyi Yang, Chenguang Zhu, Yue Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The impressive performance of Large Language Models (LLMs) has consistently
surpassed numerous human-designed benchmarks, presenting new challenges in
assessing the shortcomings of LLMs. Designing tasks and finding LLMs'
limitations are becoming increasingly important. In this paper, we investigate
the question of whether an LLM can discover its own limitations from the errors
it makes. To this end, we propose a Self-Challenge evaluation framework with
human-in-the-loop. Starting from seed instances that GPT-4 fails to answer, we
prompt GPT-4 to summarize error patterns that can be used to generate new
instances and incorporate human feedback on them to refine these patterns for
generating more challenging data, iteratively. We end up with 8 diverse
patterns, such as text manipulation and questions with assumptions. We then
build a benchmark, SC-G4, consisting of 1,835 instances generated by GPT-4
using these patterns, with human-annotated gold responses. The SC-G4 serves as
a challenging benchmark that allows for a detailed assessment of LLMs'
abilities. Our results show that only 44.96\% of instances in SC-G4 can be
answered correctly by GPT-4. Interestingly, our pilot study indicates that
these error patterns also challenge other LLMs, such as Claude-3 and Llama-3,
and cannot be fully resolved through fine-tuning. Our work takes the first step
to demonstrate that LLMs can autonomously identify their inherent flaws and
provide insights for future dynamic and automatic evaluation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>COLM 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ How You <span class="highlight-title">Prompt</span> Matters! Even Task-Oriented Constraints in Instructions
  Affect LLM-Generated Text Detection <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.08369v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.08369v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ryuto Koike, Masahiro Kaneko, Naoaki Okazaki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To combat the misuse of Large Language Models (LLMs), many recent studies
have presented LLM-generated-text detectors with promising performance. When
users instruct LLMs to generate texts, the instruction can include different
constraints depending on the user's need. However, most recent studies do not
cover such diverse instruction patterns when creating datasets for LLM
detection. In this paper, we reveal that even task-oriented constraints --
constraints that would naturally be included in an instruction and are not
related to detection-evasion -- cause existing powerful detectors to have a
large variance in detection performance. We focus on student essay writing as a
realistic domain and manually create task-oriented constraints based on several
factors for essay quality. Our experiments show that the standard deviation
(SD) of current detector performance on texts generated by an instruction with
such a constraint is significantly larger (up to an SD of 14.4 F1-score) than
that by generating texts multiple times or paraphrasing the instruction. We
also observe an overall trend where the constraints can make LLM detection more
challenging than without them. Finally, our analysis indicates that the high
instruction-following ability of LLMs fosters the large impact of such
constraints on detection performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Findings camera ready. Dataset available at
  https://github.com/ryuryukke/HowYouPromptMatters</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal
  Stories with LLMs <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.17633v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.17633v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jocelyn Shen, Joel Mire, Hae Won Park, Cynthia Breazeal, Maarten Sap
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Empathy serves as a cornerstone in enabling prosocial behaviors, and can be
evoked through sharing of personal experiences in stories. While empathy is
influenced by narrative content, intuitively, people respond to the way a story
is told as well, through narrative style. Yet the relationship between empathy
and narrative style is not fully understood. In this work, we empirically
examine and quantify this relationship between style and empathy using LLMs and
large-scale crowdsourcing studies. We introduce a novel, theory-based taxonomy,
HEART (Human Empathy and Narrative Taxonomy) that delineates elements of
narrative style that can lead to empathy with the narrator of a story. We
establish the performance of LLMs in extracting narrative elements from HEART,
showing that prompting with our taxonomy leads to reasonable, human-level
annotations beyond what prior lexicon-based methods can do. To show empirical
use of our taxonomy, we collect a dataset of empathy judgments of stories via a
large-scale crowdsourcing study with N=2,624 participants. We show that
narrative elements extracted via LLMs, in particular, vividness of emotions and
plot volume, can elucidate the pathways by which narrative style cultivates
empathy towards personal stories. Our work suggests that such models can be
used for narrative analyses that lead to human-centered social and behavioral
insights.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Outcome-Constrained Large Language Models for Countering Hate Speech <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.17146v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.17146v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lingzi Hong, Pengcheng Luo, Eduardo Blanco, Xiaoying Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic counterspeech generation methods have been developed to assist
efforts in combating hate speech. Existing research focuses on generating
counterspeech with linguistic attributes such as being polite, informative, and
intent-driven. However, the real impact of counterspeech in online environments
is seldom considered. This study aims to develop methods for generating
counterspeech constrained by conversation outcomes and evaluate their
effectiveness. We experiment with large language models (LLMs) to incorporate
into the text generation process two desired conversation outcomes: low
conversation incivility and non-hateful hater reentry. Specifically, we
experiment with instruction prompts, LLM finetuning, and LLM reinforcement
learning (RL). Evaluation results show that our methods effectively steer the
generation of counterspeech toward the desired outcomes. Our analyses, however,
show that there are differences in the quality and style depending on the
model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for presentation at the EMNLP 2024 main conference</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Sound <span class="chip" style="font-size: 60%">18</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Augmentation through Laundering Attacks for Audio Spoof Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01108v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01108v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hashim Ali, Surya Subramani, Hafiz Malik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent text-to-speech (TTS) developments have made voice cloning (VC) more
realistic, affordable, and easily accessible. This has given rise to many
potential abuses of this technology, including Joe Biden's New Hampshire
deepfake robocall. Several methodologies have been proposed to detect such
clones. However, these methodologies have been trained and evaluated on
relatively clean databases. Recently, ASVspoof 5 Challenge introduced a new
crowd-sourced database of diverse acoustic conditions including various
spoofing attacks and codec conditions. This paper is our submission to the
ASVspoof 5 Challenge and aims to investigate the performance of Audio Spoof
Detection, trained using data augmentation through laundering attacks, on the
ASVSpoof 5 database. The results demonstrate that our system performs worst on
A18, A19, A20, A26, and A30 spoofing attacks and in the codec and compression
conditions of C08, C09, and C10.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MOSEL: 950,000 Hours of Speech Data for Open-Source Speech Foundation
  Model Training on EU Languages <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01036v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01036v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marco Gaido, Sara Papi, Luisa Bentivogli, Alessio Brutti, Mauro Cettolo, Roberto Gretter, Marco Matassoni, Mohamed Nabih, Matteo Negri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rise of foundation models (FMs), coupled with regulatory efforts
addressing their risks and impacts, has sparked significant interest in
open-source models. However, existing speech FMs (SFMs) fall short of full
compliance with the open-source principles, even if claimed otherwise, as no
existing SFM has model weights, code, and training data publicly available
under open-source terms. In this work, we take the first step toward filling
this gap by focusing on the 24 official languages of the European Union (EU).
We collect suitable training data by surveying automatic speech recognition
datasets and unlabeled speech corpora under open-source compliant licenses, for
a total of 950k hours. Additionally, we release automatic transcripts for 441k
hours of unlabeled data under the permissive CC-BY license, thereby
facilitating the creation of open-source SFMs for the EU languages.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Critical Assessment of Visual Sound Source Localization Models
  Including Negative Audio <span class="chip">ICASSP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01020v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01020v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xavier Juanola, Gloria Haro, Magdalena Fuentes
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The task of Visual Sound Source Localization (VSSL) involves identifying the
location of sound sources in visual scenes, integrating audio-visual data for
enhanced scene understanding. Despite advancements in state-of-the-art (SOTA)
models, we observe three critical flaws: i) The evaluation of the models is
mainly focused in sounds produced by objects that are visible in the image, ii)
The evaluation often assumes a prior knowledge of the size of the sounding
object, and iii) No universal threshold for localization in real-world
scenarios is established, as previous approaches only consider positive
examples without accounting for both positive and negative cases. In this
paper, we introduce a novel test set and metrics designed to complete the
current standard evaluation of VSSL models by testing them in scenarios where
none of the objects in the image corresponds to the audio input, i.e. a
negative audio. We consider three types of negative audio: silence, noise and
offscreen. Our analysis reveals that numerous SOTA models fail to appropriately
adjust their predictions based on audio input, suggesting that these models may
not be leveraging audio information as intended. Additionally, we provide a
comprehensive analysis of the range of maximum values in the estimated
audio-visual similarity maps, in both positive and negative audio cases, and
show that most of the models are not discriminative enough, making them unfit
to choose a universal threshold appropriate to perform sound localization
without any a priori information of the sounding object, that is, object size
and visibility.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to ICASSP 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Heterogeneous sound classification with the Broad Sound Taxonomy and
  <span class="highlight-title">Dataset</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00980v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00980v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Panagiota Anastasopoulou, Jessica Torrey, Xavier Serra, Frederic Font
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic sound classification has a wide range of applications in machine
listening, enabling context-aware sound processing and understanding. This
paper explores methodologies for automatically classifying heterogeneous sounds
characterized by high intra-class variability. Our study evaluates the
classification task using the Broad Sound Taxonomy, a two-level taxonomy
comprising 28 classes designed to cover a heterogeneous range of sounds with
semantic distinctions tailored for practical user applications. We construct a
dataset through manual annotation to ensure accuracy, diverse representation
within each class and relevance in real-world scenarios. We compare a variety
of both traditional and modern machine learning approaches to establish a
baseline for the task of heterogeneous sound classification. We investigate the
role of input features, specifically examining how acoustically derived sound
representations compare to embeddings extracted with pre-trained deep neural
networks that capture both acoustic and semantic information about sounds.
Experimental results illustrate that audio embeddings encoding acoustic and
semantic information achieve higher accuracy in the classification task. After
careful analysis of classification errors, we identify some underlying reasons
for failure and propose actions to mitigate them. The paper highlights the need
for deeper exploration of all stages of classification, understanding the data
and adopting methodologies capable of effectively handling data complexity and
generalizing in real-world sound environments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>DCASE2024, post-print, 5 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Do Music Generation Models Encode Music Theory? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00872v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00872v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Megan Wei, Michael Freeman, Chris Donahue, Chen Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Music foundation models possess impressive music generation capabilities.
When people compose music, they may infuse their understanding of music into
their work, by using notes and intervals to craft melodies, chords to build
progressions, and tempo to create a rhythmic feel. To what extent is this true
of music generation models? More specifically, are fundamental Western music
theory concepts observable within the "inner workings" of these models? Recent
work proposed leveraging latent audio representations from music generation
models towards music information retrieval tasks (e.g. genre classification,
emotion recognition), which suggests that high-level musical characteristics
are encoded within these models. However, probing individual music theory
concepts (e.g. tempo, pitch class, chord quality) remains under-explored. Thus,
we introduce SynTheory, a synthetic MIDI and audio music theory dataset,
consisting of tempos, time signatures, notes, intervals, scales, chords, and
chord progressions concepts. We then propose a framework to probe for these
music theory concepts in music foundation models (Jukebox and MusicGen) and
assess how strongly they encode these concepts within their internal
representations. Our findings suggest that music theory concepts are
discernible within foundation models and that the degree to which they are
detectable varies by model size and layer.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ISMIR 2024. Dataset:
  https://huggingface.co/datasets/meganwei/syntheory Code:
  https://github.com/brown-palm/syntheory Website:
  https://brown-palm.github.io/music-theory</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VHASR: A Multimodal Speech Recognition System With Vision Hotwords <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00822v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00822v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiliang Hu, Zuchao Li, Ping Wang, Haojun Ai, Lefei Zhang, Hai Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The image-based multimodal automatic speech recognition (ASR) model enhances
speech recognition performance by incorporating audio-related image. However,
some works suggest that introducing image information to model does not help
improving ASR performance. In this paper, we propose a novel approach
effectively utilizing audio-related image information and set up VHASR, a
multimodal speech recognition system that uses vision as hotwords to strengthen
the model's speech recognition capability. Our system utilizes a dual-stream
architecture, which firstly transcribes the text on the two streams separately,
and then combines the outputs. We evaluate the proposed model on four datasets:
Flickr8k, ADE20k, COCO, and OpenImages. The experimental results show that
VHASR can effectively utilize key information in images to enhance the model's
speech recognition ability. Its performance not only surpasses unimodal ASR,
but also achieves SOTA among existing image-based multimodal ASR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 6 figures, accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving curriculum learning for target speaker extraction with
  synthetic speakers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00811v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00811v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yun Liu, Xuechen Liu, Junichi Ymagishi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Target speaker extraction (TSE) aims to isolate individual speaker voices
from complex speech environments. The effectiveness of TSE systems is often
compromised when the speaker characteristics are similar to each other. Recent
research has introduced curriculum learning (CL), in which TSE models are
trained incrementally on speech samples of increasing complexity. In CL
training, the model is first trained on samples with low speaker similarity
between the target and interference speakers, and then on samples with high
speaker similarity. To further improve CL, this paper uses a $k$-nearest
neighbor-based voice conversion method to simulate and generate speech of
diverse interference speakers, and then uses the generated data as part of the
CL. Experiments demonstrate that training data based on synthetic speakers can
effectively enhance the model's capabilities and significantly improve the
performance of multiple TSE systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by SLT2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Zero-Shot Text-to-Speech from Continuous Text Streams 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00767v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00767v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Trung Dang, David Aponte, Dung Tran, Tianyi Chen, Kazuhito Koishida
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing zero-shot text-to-speech (TTS) systems are typically designed to
process complete sentences and are constrained by the maximum duration for
which they have been trained. However, in many streaming applications, texts
arrive continuously in short chunks, necessitating instant responses from the
system. We identify the essential capabilities required for chunk-level
streaming and introduce LiveSpeech 2, a stream-aware model that supports
infinitely long speech generation, text-audio stream synchronization, and
seamless transitions between short speech chunks. To achieve these, we propose
(1) adopting Mamba, a class of sequence modeling distinguished by linear-time
decoding, which is augmented by cross-attention mechanisms for conditioning,
(2) utilizing rotary positional embeddings in the computation of
cross-attention, enabling the model to process an infinite text stream by
sliding a window, and (3) decoding with semantic guidance, a technique that
aligns speech with the transcript during inference with minimal overhead.
Experimental results demonstrate that our models are competitive with
state-of-the-art language model-based zero-shot TTS models, while also
providing flexibility to support a wide range of streaming scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Conformer Encoder May Reverse the Time Dimension <span class="chip">ICASSP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00680v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00680v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Robin Schmitt, Albert Zeyer, Mohammad Zeineldeen, Ralf Schlüter, Hermann Ney
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We sometimes observe monotonically decreasing cross-attention weights in our
Conformer-based global attention-based encoder-decoder (AED) models. Further
investigation shows that the Conformer encoder internally reverses the sequence
in the time dimension. We analyze the initial behavior of the decoder
cross-attention mechanism and find that it encourages the Conformer encoder
self-attention to build a connection between the initial frames and all other
informative frames. Furthermore, we show that, at some point in training, the
self-attention module of the Conformer starts dominating the output over the
preceding feed-forward module, which then only allows the reversed information
to pass through. We propose several methods and ideas of how this flipping can
be avoided. Additionally, we investigate a novel method to obtain
label-frame-position alignments by using the gradients of the label log
probabilities w.r.t. the encoder input frames.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to ICASSP 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Contribution of soundscape appropriateness to soundscape quality
  assessment in space: a mediating variable affecting acoustic comfort 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00667v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00667v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinhao Yang, Guangyu Zhang, Xiaodong Lu, Yuan Zhang, Jian Kang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Soundscape appropriateness (SA) provides supplemental information on the
matching degree between auditory information and the surrounding scene in
soundscape perception. This indicator has been integrated into the standard ISO
process for collecting soundscape data, forming a component of the sound
quality assessment questionnaire. However, its role in soundscape quality
assessment has not been fully understood. Herein, we present the findings from
soundscape data collected from Beiling Park in Shenyang, China. A method was
developed that integrates mediation effect models with multiscale
geographically weighted regression (MGWR) models to explore the mediating role
of SA in the impact of sound source types on soundscape quality, as well as the
spatial heterogeneity of this mediation effect. The results confirm that SA
does mediates the influence of sound source types on acoustics comfort (AC).
Specifically, natural sounds (indirect effect / total effect = 0.19 / 0.19),
traffic sounds (indirect effect / total effect = -0.46 / -0.65), and commercial
sounds (indirect effect / total effect = -0.25 / -0.12) impact the perception
of AC by either enhancing or reducing SA. Moreover, the relationships among
variables depicted in this model demonstrate spatial heterogeneity,
demonstrating that in urban open spaces with complex constructures, local
spatial models may be needed for soundscape assessment. The research reaffirms
the significance of SA in urban open spaces. In terms of practical implications
for urban and landscape planners, when sound sources cannot be controlled or
altered, coordinating between the sound and the surrounding environment through
landscape optimisation could also improve the quality of the soundscape through
enhancing SA and help achieve the goal of creating healthy urban open spaces.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Revision submitted to Journal of Environmental Management</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EmoKnob: Enhance Voice Cloning with Fine-Grained Emotion Control <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00316v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00316v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haozhe Chen, Run Chen, Julia Hirschberg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While recent advances in Text-to-Speech (TTS) technology produce natural and
expressive speech, they lack the option for users to select emotion and control
intensity. We propose EmoKnob, a framework that allows fine-grained emotion
control in speech synthesis with few-shot demonstrative samples of arbitrary
emotion. Our framework leverages the expressive speaker representation space
made possible by recent advances in foundation voice cloning models. Based on
the few-shot capability of our emotion control framework, we propose two
methods to apply emotion control on emotions described by open-ended text,
enabling an intuitive interface for controlling a diverse array of nuanced
emotions. To facilitate a more systematic emotional speech synthesis field, we
introduce a set of evaluation metrics designed to rigorously assess the
faithfulness and recognizability of emotion control frameworks. Through
objective and subjective evaluations, we show that our emotion control
framework effectively embeds emotions into speech and surpasses emotion
expressiveness of commercial TTS services.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Recent Advances in Speech Language Models: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03751v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03751v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenqian Cui, Dianzhi Yu, Xiaoqi Jiao, Ziqiao Meng, Guangyan Zhang, Qichao Wang, Yiwen Guo, Irwin King
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have recently garnered significant attention,
primarily for their capabilities in text-based interactions. However, natural
human interaction often relies on speech, necessitating a shift towards
voice-based models. A straightforward approach to achieve this involves a
pipeline of ``Automatic Speech Recognition (ASR) + LLM + Text-to-Speech (TTS)",
where input speech is transcribed to text, processed by an LLM, and then
converted back to speech. Despite being straightforward, this method suffers
from inherent limitations, such as information loss during modality conversion
and error accumulation across the three stages. To address these issues, Speech
Language Models (SpeechLMs) -- end-to-end models that generate speech without
converting from text -- have emerged as a promising alternative. This survey
paper provides the first comprehensive overview of recent methodologies for
constructing SpeechLMs, detailing the key components of their architecture and
the various training recipes integral to their development. Additionally, we
systematically survey the various capabilities of SpeechLMs, categorize the
evaluation metrics for SpeechLMs, and discuss the challenges and future
research directions in this rapidly evolving field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PITCH: AI-assisted Tagging of Deepfake Audio Calls using
  Challenge-Response 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.18085v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.18085v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Govind Mittal, Arthur Jakobsson, Kelly O. Marshall, Chinmay Hegde, Nasir Memon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rise of AI voice-cloning technology, particularly audio Real-time
Deepfakes (RTDFs), has intensified social engineering attacks by enabling
real-time voice impersonation that bypasses conventional enrollment-based
authentication. To address this, we propose PITCH, a robust challenge-response
method to detect and tag interactive deepfake audio calls. We developed a
comprehensive taxonomy of audio challenges based on the human auditory system,
linguistics, and environmental factors, yielding 20 prospective challenges.
These were tested against leading voice-cloning systems using a novel dataset
comprising 18,600 original and 1.6 million deepfake samples from 100 users.
PITCH's prospective challenges enhanced machine detection capabilities to 88.7%
AUROC score on the full unbalanced dataset, enabling us to shortlist 10
functional challenges that balance security and usability.
  For human evaluation and subsequent analyses, we filtered a challenging,
balanced subset. On this subset, human evaluators independently scored 72.6%
accuracy, while machines achieved 87.7%. Acknowledging that call environments
require higher human control, we aided call receivers in making decisions with
them using machines. Our solution uses an early warning system to tag
suspicious incoming calls as "Deepfake-likely." Contrary to prior findings, we
discovered that integrating human intuition with machine precision offers
complementary advantages. Our solution gave users maximum control and boosted
detection accuracy to 84.5%. Evidenced by this jump in accuracy, PITCH
demonstrated the potential for AI-assisted pre-screening in call verification
processes, offering an adaptable and usable approach to combat real-time
voice-cloning attacks. Code to reproduce and access data at
\url{https://github.com/mittalgovind/PITCH-Deepfakes}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing the analysis of murine neonatal ultrasonic vocalizations:
  Development, evaluation, and application of different mathematical models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.12957v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.12957v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rudolf Herdt, Louisa Kinzel, Johann Georg Maaß, Marvin Walther, Henning Fröhlich, Tim Schubert, Peter Maass, Christian Patrick Schaaf
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Rodents employ a broad spectrum of ultrasonic vocalizations (USVs) for social
communication. As these vocalizations offer valuable insights into affective
states, social interactions, and developmental stages of animals, various deep
learning approaches have aimed to automate both the quantitative (detection)
and qualitative (classification) analysis of USVs. Here, we present the first
systematic evaluation of different types of neural networks for USV
classification. We assessed various feedforward networks, including a
custom-built, fully-connected network and convolutional neural network,
different residual neural networks (ResNets), an EfficientNet, and a Vision
Transformer (ViT). Paired with a refined, entropy-based detection algorithm
(achieving recall of 94.9% and precision of 99.3%), the best architecture
(achieving 86.79% accuracy) was integrated into a fully automated pipeline
capable of analyzing extensive USV datasets with high reliability.
Additionally, users can specify an individual minimum accuracy threshold based
on their research needs. In this semi-automated setup, the pipeline selectively
classifies calls with high pseudo-probability, leaving the rest for manual
inspection. Our study focuses exclusively on neonatal USVs. As part of an
ongoing phenotyping study, our pipeline has proven to be a valuable tool for
identifying key differences in USVs produced by mice with autism-like
behaviors.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unsupervised Improved MVDR Beamforming for Sound Enhancement <span class="chip">INTERSPEECH 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.06310v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.06310v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jacob Kealey, John Hershey, François Grondin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural networks have recently become the dominant approach to sound
separation. Their good performance relies on large datasets of isolated
recordings. For speech and music, isolated single channel data are readily
available; however the same does not hold in the multi-channel case, and with
most other sound classes. Multi-channel methods have the potential to
outperform single channel approaches as they can exploit both spatial and
spectral features, but the lack of training data remains a challenge. We
propose unsupervised improved minimum variation distortionless response
(UIMVDR), which enables multi-channel separation to leverage in-the-wild
single-channel data through unsupervised training and beamforming. Results show
that UIMVDR generalizes well and improves separation performance compared to
supervised models, particularly in cases with limited supervised data. By using
data available online, it also reduces the effort required to gather data for
multi-channel approaches.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Proceedings of INTERSPEECH 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GE2E-AC: Generalized End-to-End Loss Training for Accent Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.14021v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.14021v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chihiro Watanabe, Hirokazu Kameoka
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accent classification or AC is a task to predict the accent type of an input
utterance, and it can be used as a preliminary step toward accented speech
recognition and accent conversion. Existing studies have often achieved such
classification by training a neural network model to minimize the
classification error of the predicted accent label, which can be obtained as a
model output. Since we optimize the entire model only from the perspective of
classification loss during training time in this approach, the model might
learn to predict the accent type from irrelevant features, such as individual
speaker identity, which are not informative during test time. To address this
problem, we propose a GE2E-AC, in which we train a model to extract accent
embedding or AE of an input utterance such that the AEs of the same accent
class get closer, instead of directly minimizing the classification loss. We
experimentally show the effectiveness of the proposed GE2E-AC, compared to the
baseline model trained with the conventional cross-entropy-based loss.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Asynchronous Microphone Array Calibration using Hybrid TDOA Information 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.05791v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.05791v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengjie Zhang, Jiang Wang, He Kong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Asynchronous microphone array calibration is a prerequisite for many audition
robot applications. A popular solution to the above calibration problem is the
batch form of Simultaneous Localisation and Mapping (SLAM), using the time
difference of arrival measurements between two microphones (TDOA-M), and the
robot (which serves as a moving sound source during calibration) odometry
information. In this paper, we introduce a new form of measurement for
microphone array calibration, i.e. the time difference of arrival between
adjacent sound events (TDOA-S) with respect to the microphone channels. We
propose to use TDOA-S and TDOA-M, called hybrid TDOA, together with odometry
measurements for bath SLAM-based calibration of asynchronous microphone arrays.
Extensive simulation and real-world experiments show that our method is more
independent of microphone number, less sensitive to initial values (when using
off-the-shelf algorithms such as Gauss-Newton iterations), and has better
calibration accuracy and robustness under various TDOA noises. Simulation
results also demonstrate that our method has a lower Cram\'er-Rao lower bound
(CRLB) for microphone parameters. To benefit the community, we open-source our
code and data at https://github.com/AISLAB-sustech/Hybrid-TDOA-Calib.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RealMAN: A Real-Recorded and Annotated Microphone Array <span class="highlight-title">Dataset</span> for
  Dynamic Speech Enhancement and Localization <span class="chip">NIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19959v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19959v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bing Yang, Changsheng Quan, Yabo Wang, Pengyu Wang, Yujie Yang, Ying Fang, Nian Shao, Hui Bu, Xin Xu, Xiaofei Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The training of deep learning-based multichannel speech enhancement and
source localization systems relies heavily on the simulation of room impulse
response and multichannel diffuse noise, due to the lack of large-scale
real-recorded datasets. However, the acoustic mismatch between simulated and
real-world data could degrade the model performance when applying in real-world
scenarios. To bridge this simulation-to-real gap, this paper presents a new
relatively large-scale Real-recorded and annotated Microphone Array
speech&Noise (RealMAN) dataset. The proposed dataset is valuable in two
aspects: 1) benchmarking speech enhancement and localization algorithms in real
scenarios; 2) offering a substantial amount of real-world training data for
potentially improving the performance of real-world applications. Specifically,
a 32-channel array with high-fidelity microphones is used for recording. A
loudspeaker is used for playing source speech signals (about 35 hours of
Mandarin speech). A total of 83.7 hours of speech signals (about 48.3 hours for
static speaker and 35.4 hours for moving speaker) are recorded in 32 different
scenes, and 144.5 hours of background noise are recorded in 31 different
scenes. Both speech and noise recording scenes cover various common indoor,
outdoor, semi-outdoor and transportation environments, which enables the
training of general-purpose speech enhancement and source localization
networks. To obtain the task-specific annotations, speaker location is
annotated with an omni-directional fisheye camera by automatically detecting
the loudspeaker. The direct-path signal is set as the target clean speech for
speech enhancement, which is obtained by filtering the source speech signal
with an estimated direct-path propagation filter.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accepted by NIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Speech Processing <span class="chip" style="font-size: 60%">23</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Augmentation through Laundering Attacks for Audio Spoof Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01108v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01108v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hashim Ali, Surya Subramani, Hafiz Malik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent text-to-speech (TTS) developments have made voice cloning (VC) more
realistic, affordable, and easily accessible. This has given rise to many
potential abuses of this technology, including Joe Biden's New Hampshire
deepfake robocall. Several methodologies have been proposed to detect such
clones. However, these methodologies have been trained and evaluated on
relatively clean databases. Recently, ASVspoof 5 Challenge introduced a new
crowd-sourced database of diverse acoustic conditions including various
spoofing attacks and codec conditions. This paper is our submission to the
ASVspoof 5 Challenge and aims to investigate the performance of Audio Spoof
Detection, trained using data augmentation through laundering attacks, on the
ASVSpoof 5 database. The results demonstrate that our system performs worst on
A18, A19, A20, A26, and A30 spoofing attacks and in the codec and compression
conditions of C08, C09, and C10.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MOSEL: 950,000 Hours of Speech Data for Open-Source Speech Foundation
  Model Training on EU Languages <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01036v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01036v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marco Gaido, Sara Papi, Luisa Bentivogli, Alessio Brutti, Mauro Cettolo, Roberto Gretter, Marco Matassoni, Mohamed Nabih, Matteo Negri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rise of foundation models (FMs), coupled with regulatory efforts
addressing their risks and impacts, has sparked significant interest in
open-source models. However, existing speech FMs (SFMs) fall short of full
compliance with the open-source principles, even if claimed otherwise, as no
existing SFM has model weights, code, and training data publicly available
under open-source terms. In this work, we take the first step toward filling
this gap by focusing on the 24 official languages of the European Union (EU).
We collect suitable training data by surveying automatic speech recognition
datasets and unlabeled speech corpora under open-source compliant licenses, for
a total of 950k hours. Additionally, we release automatic transcripts for 441k
hours of unlabeled data under the permissive CC-BY license, thereby
facilitating the creation of open-source SFMs for the EU languages.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Critical Assessment of Visual Sound Source Localization Models
  Including Negative Audio <span class="chip">ICASSP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01020v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01020v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xavier Juanola, Gloria Haro, Magdalena Fuentes
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The task of Visual Sound Source Localization (VSSL) involves identifying the
location of sound sources in visual scenes, integrating audio-visual data for
enhanced scene understanding. Despite advancements in state-of-the-art (SOTA)
models, we observe three critical flaws: i) The evaluation of the models is
mainly focused in sounds produced by objects that are visible in the image, ii)
The evaluation often assumes a prior knowledge of the size of the sounding
object, and iii) No universal threshold for localization in real-world
scenarios is established, as previous approaches only consider positive
examples without accounting for both positive and negative cases. In this
paper, we introduce a novel test set and metrics designed to complete the
current standard evaluation of VSSL models by testing them in scenarios where
none of the objects in the image corresponds to the audio input, i.e. a
negative audio. We consider three types of negative audio: silence, noise and
offscreen. Our analysis reveals that numerous SOTA models fail to appropriately
adjust their predictions based on audio input, suggesting that these models may
not be leveraging audio information as intended. Additionally, we provide a
comprehensive analysis of the range of maximum values in the estimated
audio-visual similarity maps, in both positive and negative audio cases, and
show that most of the models are not discriminative enough, making them unfit
to choose a universal threshold appropriate to perform sound localization
without any a priori information of the sounding object, that is, object size
and visibility.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to ICASSP 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Heterogeneous sound classification with the Broad Sound Taxonomy and
  <span class="highlight-title">Dataset</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00980v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00980v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Panagiota Anastasopoulou, Jessica Torrey, Xavier Serra, Frederic Font
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic sound classification has a wide range of applications in machine
listening, enabling context-aware sound processing and understanding. This
paper explores methodologies for automatically classifying heterogeneous sounds
characterized by high intra-class variability. Our study evaluates the
classification task using the Broad Sound Taxonomy, a two-level taxonomy
comprising 28 classes designed to cover a heterogeneous range of sounds with
semantic distinctions tailored for practical user applications. We construct a
dataset through manual annotation to ensure accuracy, diverse representation
within each class and relevance in real-world scenarios. We compare a variety
of both traditional and modern machine learning approaches to establish a
baseline for the task of heterogeneous sound classification. We investigate the
role of input features, specifically examining how acoustically derived sound
representations compare to embeddings extracted with pre-trained deep neural
networks that capture both acoustic and semantic information about sounds.
Experimental results illustrate that audio embeddings encoding acoustic and
semantic information achieve higher accuracy in the classification task. After
careful analysis of classification errors, we identify some underlying reasons
for failure and propose actions to mitigate them. The paper highlights the need
for deeper exploration of all stages of classification, understanding the data
and adopting methodologies capable of effectively handling data complexity and
generalizing in real-world sound environments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>DCASE2024, post-print, 5 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Do Music Generation Models Encode Music Theory? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00872v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00872v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Megan Wei, Michael Freeman, Chris Donahue, Chen Sun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Music foundation models possess impressive music generation capabilities.
When people compose music, they may infuse their understanding of music into
their work, by using notes and intervals to craft melodies, chords to build
progressions, and tempo to create a rhythmic feel. To what extent is this true
of music generation models? More specifically, are fundamental Western music
theory concepts observable within the "inner workings" of these models? Recent
work proposed leveraging latent audio representations from music generation
models towards music information retrieval tasks (e.g. genre classification,
emotion recognition), which suggests that high-level musical characteristics
are encoded within these models. However, probing individual music theory
concepts (e.g. tempo, pitch class, chord quality) remains under-explored. Thus,
we introduce SynTheory, a synthetic MIDI and audio music theory dataset,
consisting of tempos, time signatures, notes, intervals, scales, chords, and
chord progressions concepts. We then propose a framework to probe for these
music theory concepts in music foundation models (Jukebox and MusicGen) and
assess how strongly they encode these concepts within their internal
representations. Our findings suggest that music theory concepts are
discernible within foundation models and that the degree to which they are
detectable varies by model size and layer.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ISMIR 2024. Dataset:
  https://huggingface.co/datasets/meganwei/syntheory Code:
  https://github.com/brown-palm/syntheory Website:
  https://brown-palm.github.io/music-theory</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ VHASR: A Multimodal Speech Recognition System With Vision Hotwords <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00822v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00822v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiliang Hu, Zuchao Li, Ping Wang, Haojun Ai, Lefei Zhang, Hai Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The image-based multimodal automatic speech recognition (ASR) model enhances
speech recognition performance by incorporating audio-related image. However,
some works suggest that introducing image information to model does not help
improving ASR performance. In this paper, we propose a novel approach
effectively utilizing audio-related image information and set up VHASR, a
multimodal speech recognition system that uses vision as hotwords to strengthen
the model's speech recognition capability. Our system utilizes a dual-stream
architecture, which firstly transcribes the text on the two streams separately,
and then combines the outputs. We evaluate the proposed model on four datasets:
Flickr8k, ADE20k, COCO, and OpenImages. The experimental results show that
VHASR can effectively utilize key information in images to enhance the model's
speech recognition ability. Its performance not only surpasses unimodal ASR,
but also achieves SOTA among existing image-based multimodal ASR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 6 figures, accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving curriculum learning for target speaker extraction with
  synthetic speakers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00811v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00811v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yun Liu, Xuechen Liu, Junichi Ymagishi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Target speaker extraction (TSE) aims to isolate individual speaker voices
from complex speech environments. The effectiveness of TSE systems is often
compromised when the speaker characteristics are similar to each other. Recent
research has introduced curriculum learning (CL), in which TSE models are
trained incrementally on speech samples of increasing complexity. In CL
training, the model is first trained on samples with low speaker similarity
between the target and interference speakers, and then on samples with high
speaker similarity. To further improve CL, this paper uses a $k$-nearest
neighbor-based voice conversion method to simulate and generate speech of
diverse interference speakers, and then uses the generated data as part of the
CL. Experiments demonstrate that training data based on synthetic speakers can
effectively enhance the model's capabilities and significantly improve the
performance of multiple TSE systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by SLT2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Zero-Shot Text-to-Speech from Continuous Text Streams 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00767v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00767v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Trung Dang, David Aponte, Dung Tran, Tianyi Chen, Kazuhito Koishida
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing zero-shot text-to-speech (TTS) systems are typically designed to
process complete sentences and are constrained by the maximum duration for
which they have been trained. However, in many streaming applications, texts
arrive continuously in short chunks, necessitating instant responses from the
system. We identify the essential capabilities required for chunk-level
streaming and introduce LiveSpeech 2, a stream-aware model that supports
infinitely long speech generation, text-audio stream synchronization, and
seamless transitions between short speech chunks. To achieve these, we propose
(1) adopting Mamba, a class of sequence modeling distinguished by linear-time
decoding, which is augmented by cross-attention mechanisms for conditioning,
(2) utilizing rotary positional embeddings in the computation of
cross-attention, enabling the model to process an infinite text stream by
sliding a window, and (3) decoding with semantic guidance, a technique that
aligns speech with the transcript during inference with minimal overhead.
Experimental results demonstrate that our models are competitive with
state-of-the-art language model-based zero-shot TTS models, while also
providing flexibility to support a wide range of streaming scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Conformer Encoder May Reverse the Time Dimension <span class="chip">ICASSP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00680v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00680v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Robin Schmitt, Albert Zeyer, Mohammad Zeineldeen, Ralf Schlüter, Hermann Ney
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We sometimes observe monotonically decreasing cross-attention weights in our
Conformer-based global attention-based encoder-decoder (AED) models. Further
investigation shows that the Conformer encoder internally reverses the sequence
in the time dimension. We analyze the initial behavior of the decoder
cross-attention mechanism and find that it encourages the Conformer encoder
self-attention to build a connection between the initial frames and all other
informative frames. Furthermore, we show that, at some point in training, the
self-attention module of the Conformer starts dominating the output over the
preceding feed-forward module, which then only allows the reversed information
to pass through. We propose several methods and ideas of how this flipping can
be avoided. Additionally, we investigate a novel method to obtain
label-frame-position alignments by using the gradients of the label log
probabilities w.r.t. the encoder input frames.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to ICASSP 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Contribution of soundscape appropriateness to soundscape quality
  assessment in space: a mediating variable affecting acoustic comfort 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00667v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00667v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinhao Yang, Guangyu Zhang, Xiaodong Lu, Yuan Zhang, Jian Kang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Soundscape appropriateness (SA) provides supplemental information on the
matching degree between auditory information and the surrounding scene in
soundscape perception. This indicator has been integrated into the standard ISO
process for collecting soundscape data, forming a component of the sound
quality assessment questionnaire. However, its role in soundscape quality
assessment has not been fully understood. Herein, we present the findings from
soundscape data collected from Beiling Park in Shenyang, China. A method was
developed that integrates mediation effect models with multiscale
geographically weighted regression (MGWR) models to explore the mediating role
of SA in the impact of sound source types on soundscape quality, as well as the
spatial heterogeneity of this mediation effect. The results confirm that SA
does mediates the influence of sound source types on acoustics comfort (AC).
Specifically, natural sounds (indirect effect / total effect = 0.19 / 0.19),
traffic sounds (indirect effect / total effect = -0.46 / -0.65), and commercial
sounds (indirect effect / total effect = -0.25 / -0.12) impact the perception
of AC by either enhancing or reducing SA. Moreover, the relationships among
variables depicted in this model demonstrate spatial heterogeneity,
demonstrating that in urban open spaces with complex constructures, local
spatial models may be needed for soundscape assessment. The research reaffirms
the significance of SA in urban open spaces. In terms of practical implications
for urban and landscape planners, when sound sources cannot be controlled or
altered, coordinating between the sound and the surrounding environment through
landscape optimisation could also improve the quality of the soundscape through
enhancing SA and help achieve the goal of creating healthy urban open spaces.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Revision submitted to Journal of Environmental Management</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ End-to-End Speech Recognition with <span class="highlight-title">Pre-train</span>ed Masked Language Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00528v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00528v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yosuke Higuchi, Tetsuji Ogawa, Tetsunori Kobayashi, Shinji Watanabe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a novel approach to end-to-end automatic speech recognition (ASR)
that utilizes pre-trained masked language models (LMs) to facilitate the
extraction of linguistic information. The proposed models, BERT-CTC and BECTRA,
are specifically designed to effectively integrate pre-trained LMs (e.g., BERT)
into end-to-end ASR models. BERT-CTC adapts BERT for connectionist temporal
classification (CTC) by addressing the constraint of the conditional
independence assumption between output tokens. This enables explicit
conditioning of BERT's contextualized embeddings in the ASR process, seamlessly
merging audio and linguistic information through an iterative refinement
algorithm. BECTRA extends BERT-CTC to the transducer framework and trains the
decoder network using a vocabulary suitable for ASR training. This aims to
bridge the gap between the text processed in end-to-end ASR and BERT, as these
models have distinct vocabularies with varying text formats and styles, such as
the presence of punctuation. Experimental results on various ASR tasks
demonstrate that the proposed models improve over both the CTC and
transducer-based baselines, owing to the incorporation of BERT knowledge.
Moreover, our in-depth analysis and investigation verify the effectiveness of
the proposed formulations and architectural designs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Wanna Hear Your Voice: Adaptive, Effective, and Language-Agnostic
  Approach in Voice Extraction <span class="chip">ICASSP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00527v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00527v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        The Hieu Pham, Phuong Thanh Tran Nguyen, Xuan Tho Nguyen, Duc Dung Nguyen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The research on audio clue-based target speaker extraction (TSE) has mostly
focused on modeling the mixture and reference speech, achieving high
performance in English due to the availability of large datasets. However, less
attention has been given to the consistent properties of human speech across
languages. To bridge this gap, we introduce WHYV (Wanna Hear Your Voice), which
addresses the challenge of transferring TSE models from one language to another
without fine-tuning. In this work, we proposed a gating mechanism that be able
to modify specific frequencies based on the speaker's acoustic features. The
model achieves an SI-SDR of 17.3544 on clean English speech and 13.2032 on
clean speech mixed with Wham! noise, outperforming all other models in its
ability to adapt to different languages.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to ICASSP 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">Pre-train</span>ing with Synthetic Patterns for Audio <span class="chip">ICASSP'25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00511v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00511v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuchi Ishikawa, Tatsuya Komatsu, Yoshimitsu Aoki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose to pre-train audio encoders using synthetic
patterns instead of real audio data. Our proposed framework consists of two key
elements. The first one is Masked Autoencoder (MAE), a self-supervised learning
framework that learns from reconstructing data from randomly masked
counterparts. MAEs tend to focus on low-level information such as visual
patterns and regularities within data. Therefore, it is unimportant what is
portrayed in the input, whether it be images, audio mel-spectrograms, or even
synthetic patterns. This leads to the second key element, which is synthetic
data. Synthetic data, unlike real audio, is free from privacy and licensing
infringement issues. By combining MAEs and synthetic patterns, our framework
enables the model to learn generalized feature representations without real
data, while addressing the issues related to real audio. To evaluate the
efficacy of our framework, we conduct extensive experiments across a total of
13 audio tasks and 17 synthetic datasets. The experiments provide insights into
which types of synthetic patterns are effective for audio. Our results
demonstrate that our framework achieves performance comparable to models
pre-trained on AudioSet-2M and partially outperforms image-based pre-training
methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to ICASSP'25</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multi-Scale Temporal <span class="highlight-title">Transformer</span> For Speech Emotion Recognition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00390v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00390v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhipeng Li, Xiaofen Xing, Yuanbo Fang, Weibin Zhang, Hengsheng Fan, Xiangmin Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Speech emotion recognition plays a crucial role in human-machine interaction
systems. Recently various optimized Transformers have been successfully applied
to speech emotion recognition. However, the existing Transformer architectures
focus more on global information and require large computation. On the other
hand, abundant speech emotional representations exist locally on different
parts of the input speech. To tackle these problems, we propose a Multi-Scale
TRansfomer (MSTR) for speech emotion recognition. It comprises of three main
components: (1) a multi-scale temporal feature operator, (2) a fractal
self-attention module, and (3) a scale mixer module. These three components can
effectively enhance the transformer's ability to learn multi-scale local
emotion representations. Experimental results demonstrate that the proposed
MSTR model significantly outperforms a vanilla Transformer and other
state-of-the-art methods across three speech emotion datasets: IEMOCAP, MELD
and, CREMAD. In addition, it can greatly reduce the computational cost.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EmoKnob: Enhance Voice Cloning with Fine-Grained Emotion Control <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.00316v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.00316v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haozhe Chen, Run Chen, Julia Hirschberg
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While recent advances in Text-to-Speech (TTS) technology produce natural and
expressive speech, they lack the option for users to select emotion and control
intensity. We propose EmoKnob, a framework that allows fine-grained emotion
control in speech synthesis with few-shot demonstrative samples of arbitrary
emotion. Our framework leverages the expressive speaker representation space
made possible by recent advances in foundation voice cloning models. Based on
the few-shot capability of our emotion control framework, we propose two
methods to apply emotion control on emotions described by open-ended text,
enabling an intuitive interface for controlling a diverse array of nuanced
emotions. To facilitate a more systematic emotional speech synthesis field, we
introduce a set of evaluation metrics designed to rigorously assess the
faithfulness and recognizability of emotion control frameworks. Through
objective and subjective evaluations, we show that our emotion control
framework effectively embeds emotions into speech and surpasses emotion
expressiveness of commercial TTS services.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Recent Advances in Speech Language Models: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.03751v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.03751v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenqian Cui, Dianzhi Yu, Xiaoqi Jiao, Ziqiao Meng, Guangyan Zhang, Qichao Wang, Yiwen Guo, Irwin King
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have recently garnered significant attention,
primarily for their capabilities in text-based interactions. However, natural
human interaction often relies on speech, necessitating a shift towards
voice-based models. A straightforward approach to achieve this involves a
pipeline of ``Automatic Speech Recognition (ASR) + LLM + Text-to-Speech (TTS)",
where input speech is transcribed to text, processed by an LLM, and then
converted back to speech. Despite being straightforward, this method suffers
from inherent limitations, such as information loss during modality conversion
and error accumulation across the three stages. To address these issues, Speech
Language Models (SpeechLMs) -- end-to-end models that generate speech without
converting from text -- have emerged as a promising alternative. This survey
paper provides the first comprehensive overview of recent methodologies for
constructing SpeechLMs, detailing the key components of their architecture and
the various training recipes integral to their development. Additionally, we
systematically survey the various capabilities of SpeechLMs, categorize the
evaluation metrics for SpeechLMs, and discuss the challenges and future
research directions in this rapidly evolving field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PITCH: AI-assisted Tagging of Deepfake Audio Calls using
  Challenge-Response 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.18085v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.18085v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Govind Mittal, Arthur Jakobsson, Kelly O. Marshall, Chinmay Hegde, Nasir Memon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rise of AI voice-cloning technology, particularly audio Real-time
Deepfakes (RTDFs), has intensified social engineering attacks by enabling
real-time voice impersonation that bypasses conventional enrollment-based
authentication. To address this, we propose PITCH, a robust challenge-response
method to detect and tag interactive deepfake audio calls. We developed a
comprehensive taxonomy of audio challenges based on the human auditory system,
linguistics, and environmental factors, yielding 20 prospective challenges.
These were tested against leading voice-cloning systems using a novel dataset
comprising 18,600 original and 1.6 million deepfake samples from 100 users.
PITCH's prospective challenges enhanced machine detection capabilities to 88.7%
AUROC score on the full unbalanced dataset, enabling us to shortlist 10
functional challenges that balance security and usability.
  For human evaluation and subsequent analyses, we filtered a challenging,
balanced subset. On this subset, human evaluators independently scored 72.6%
accuracy, while machines achieved 87.7%. Acknowledging that call environments
require higher human control, we aided call receivers in making decisions with
them using machines. Our solution uses an early warning system to tag
suspicious incoming calls as "Deepfake-likely." Contrary to prior findings, we
discovered that integrating human intuition with machine precision offers
complementary advantages. Our solution gave users maximum control and boosted
detection accuracy to 84.5%. Evidenced by this jump in accuracy, PITCH
demonstrated the potential for AI-assisted pre-screening in call verification
processes, offering an adaptable and usable approach to combat real-time
voice-cloning attacks. Code to reproduce and access data at
\url{https://github.com/mittalgovind/PITCH-Deepfakes}.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing the analysis of murine neonatal ultrasonic vocalizations:
  Development, evaluation, and application of different mathematical models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.12957v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.12957v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rudolf Herdt, Louisa Kinzel, Johann Georg Maaß, Marvin Walther, Henning Fröhlich, Tim Schubert, Peter Maass, Christian Patrick Schaaf
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Rodents employ a broad spectrum of ultrasonic vocalizations (USVs) for social
communication. As these vocalizations offer valuable insights into affective
states, social interactions, and developmental stages of animals, various deep
learning approaches have aimed to automate both the quantitative (detection)
and qualitative (classification) analysis of USVs. Here, we present the first
systematic evaluation of different types of neural networks for USV
classification. We assessed various feedforward networks, including a
custom-built, fully-connected network and convolutional neural network,
different residual neural networks (ResNets), an EfficientNet, and a Vision
Transformer (ViT). Paired with a refined, entropy-based detection algorithm
(achieving recall of 94.9% and precision of 99.3%), the best architecture
(achieving 86.79% accuracy) was integrated into a fully automated pipeline
capable of analyzing extensive USV datasets with high reliability.
Additionally, users can specify an individual minimum accuracy threshold based
on their research needs. In this semi-automated setup, the pipeline selectively
classifies calls with high pseudo-probability, leaving the rest for manual
inspection. Our study focuses exclusively on neonatal USVs. As part of an
ongoing phenotyping study, our pipeline has proven to be a valuable tool for
identifying key differences in USVs produced by mice with autism-like
behaviors.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unsupervised Improved MVDR Beamforming for Sound Enhancement <span class="chip">INTERSPEECH 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.06310v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.06310v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jacob Kealey, John Hershey, François Grondin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural networks have recently become the dominant approach to sound
separation. Their good performance relies on large datasets of isolated
recordings. For speech and music, isolated single channel data are readily
available; however the same does not hold in the multi-channel case, and with
most other sound classes. Multi-channel methods have the potential to
outperform single channel approaches as they can exploit both spatial and
spectral features, but the lack of training data remains a challenge. We
propose unsupervised improved minimum variation distortionless response
(UIMVDR), which enables multi-channel separation to leverage in-the-wild
single-channel data through unsupervised training and beamforming. Results show
that UIMVDR generalizes well and improves separation performance compared to
supervised models, particularly in cases with limited supervised data. By using
data available online, it also reduces the effort required to gather data for
multi-channel approaches.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Proceedings of INTERSPEECH 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GE2E-AC: Generalized End-to-End Loss Training for Accent Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.14021v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.14021v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chihiro Watanabe, Hirokazu Kameoka
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accent classification or AC is a task to predict the accent type of an input
utterance, and it can be used as a preliminary step toward accented speech
recognition and accent conversion. Existing studies have often achieved such
classification by training a neural network model to minimize the
classification error of the predicted accent label, which can be obtained as a
model output. Since we optimize the entire model only from the perspective of
classification loss during training time in this approach, the model might
learn to predict the accent type from irrelevant features, such as individual
speaker identity, which are not informative during test time. To address this
problem, we propose a GE2E-AC, in which we train a model to extract accent
embedding or AE of an input utterance such that the AEs of the same accent
class get closer, instead of directly minimizing the classification loss. We
experimentally show the effectiveness of the proposed GE2E-AC, compared to the
baseline model trained with the conventional cross-entropy-based loss.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Asynchronous Microphone Array Calibration using Hybrid TDOA Information 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.05791v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.05791v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengjie Zhang, Jiang Wang, He Kong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Asynchronous microphone array calibration is a prerequisite for many audition
robot applications. A popular solution to the above calibration problem is the
batch form of Simultaneous Localisation and Mapping (SLAM), using the time
difference of arrival measurements between two microphones (TDOA-M), and the
robot (which serves as a moving sound source during calibration) odometry
information. In this paper, we introduce a new form of measurement for
microphone array calibration, i.e. the time difference of arrival between
adjacent sound events (TDOA-S) with respect to the microphone channels. We
propose to use TDOA-S and TDOA-M, called hybrid TDOA, together with odometry
measurements for bath SLAM-based calibration of asynchronous microphone arrays.
Extensive simulation and real-world experiments show that our method is more
independent of microphone number, less sensitive to initial values (when using
off-the-shelf algorithms such as Gauss-Newton iterations), and has better
calibration accuracy and robustness under various TDOA noises. Simulation
results also demonstrate that our method has a lower Cram\'er-Rao lower bound
(CRLB) for microphone parameters. To benefit the community, we open-source our
code and data at https://github.com/AISLAB-sustech/Hybrid-TDOA-Calib.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RealMAN: A Real-Recorded and Annotated Microphone Array <span class="highlight-title">Dataset</span> for
  Dynamic Speech Enhancement and Localization <span class="chip">NIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.19959v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.19959v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bing Yang, Changsheng Quan, Yabo Wang, Pengyu Wang, Yujie Yang, Ying Fang, Nian Shao, Hui Bu, Xin Xu, Xiaofei Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The training of deep learning-based multichannel speech enhancement and
source localization systems relies heavily on the simulation of room impulse
response and multichannel diffuse noise, due to the lack of large-scale
real-recorded datasets. However, the acoustic mismatch between simulated and
real-world data could degrade the model performance when applying in real-world
scenarios. To bridge this simulation-to-real gap, this paper presents a new
relatively large-scale Real-recorded and annotated Microphone Array
speech&Noise (RealMAN) dataset. The proposed dataset is valuable in two
aspects: 1) benchmarking speech enhancement and localization algorithms in real
scenarios; 2) offering a substantial amount of real-world training data for
potentially improving the performance of real-world applications. Specifically,
a 32-channel array with high-fidelity microphones is used for recording. A
loudspeaker is used for playing source speech signals (about 35 hours of
Mandarin speech). A total of 83.7 hours of speech signals (about 48.3 hours for
static speaker and 35.4 hours for moving speaker) are recorded in 32 different
scenes, and 144.5 hours of background noise are recorded in 31 different
scenes. Both speech and noise recording scenes cover various common indoor,
outdoor, semi-outdoor and transportation environments, which enables the
training of general-purpose speech enhancement and source localization
networks. To obtain the task-specific annotations, speaker location is
annotated with an omni-directional fisheye camera by automatically detecting
the loudspeaker. The direct-path signal is set as the target clean speech for
speech enhancement, which is obtained by filtering the source speech signal
with an estimated direct-path propagation filter.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accepted by NIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Inclusive ASR for Disfluent Speech: Cascaded Large-Scale <span class="highlight-title">Self-Supervised</span>
  Learning with Targeted Fine-Tuning and Data Augmentation <span class="chip">INTERSPEECH</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.10177v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.10177v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dena Mujtaba, Nihar R. Mahapatra, Megan Arney, J. Scott Yaruss, Caryn Herring, Jia Bin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic speech recognition (ASR) systems often falter while processing
stuttering-related disfluencies -- such as involuntary blocks and word
repetitions -- yielding inaccurate transcripts. A critical barrier to progress
is the scarcity of large, annotated disfluent speech datasets. Therefore, we
present an inclusive ASR design approach, leveraging large-scale
self-supervised learning on standard speech followed by targeted fine-tuning
and data augmentation on a smaller, curated dataset of disfluent speech. Our
data augmentation technique enriches training datasets with various
disfluencies, enhancing ASR processing of these speech patterns. Results show
that fine-tuning wav2vec 2.0 with even a relatively small, labeled dataset,
alongside data augmentation, can significantly reduce word error rates for
disfluent speech. Our approach not only advances ASR inclusivity for people who
stutter, but also paves the way for ASRs that can accommodate wider speech
variations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Included in 2024 Proceedings of INTERSPEECH</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Artificial Intelligence <span class="chip" style="font-size: 60%">78</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Iteration of Thought: Leveraging Inner Dialogue for Autonomous Large
  Language Model Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.12618v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.12618v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Santosh Kumar Radha, Yasamin Nouri Jelyani, Ara Ghukasyan, Oktay Goktas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Iterative human engagement is a common and effective means of leveraging the
advanced language processing power of large language models (LLMs). Using
well-structured prompts in a conversational manner, human users can effectively
influence an LLM to develop more thoughtful and accurate responses. Motivated
by this insight, we propose the Iteration of Thought (IoT) framework for
enhancing LLM responses by generating "thought"-provoking prompts vis a vis an
input query and the current iteration of an LLM's response. Unlike static or
semi-static approaches, e.g. Chain of Thought (CoT) or Tree of Thoughts (ToT),
IoT adapts its reasoning path dynamically, based on evolving context, and
without generating alternate explorative thoughts which are ultimately
discarded. The three components of the IoT framework are (1) an Inner Dialogue
Agent (IDA) responsible for generating instructive, context-specific prompts;
(2) an LLM Agent (LLMA) that processes these prompts to refine its responses;
and (3) an iterative prompting loop that implements a conversation between the
former two components. We introduce two variants of our framework: Autonomous
Iteration of Thought (AIoT), where an LLM decides when to stop iterating, and
Guided Iteration of Thought (GIoT), which always forces a fixed number
iterations. We investigate the performance of IoT across various datasets,
spanning complex reasoning tasks from the GPQA dataset, explorative
problem-solving in Game of 24, puzzle solving in Mini Crosswords, and multi-hop
question answering from the HotpotQA dataset. Our results show that IoT
represents a viable paradigm for autonomous response refinement in LLMs,
showcasing significant improvements over CoT and thereby enabling more adaptive
and efficient reasoning systems that minimize human intervention.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AIPatient: Simulating Patients with EHRs and LLM Powered Agentic
  Workflow 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18924v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18924v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huizi Yu, Jiayan Zhou, Lingyao Li, Shan Chen, Jack Gallifant, Anye Shi, Xiang Li, Wenyue Hua, Mingyu Jin, Guang Chen, Yang Zhou, Zhao Li, Trisha Gupte, Ming-Li Chen, Zahra Azizi, Yongfeng Zhang, Themistocles L. Assimes, Xin Ma, Danielle S. Bitterman, Lin Lu, Lizhou Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Simulated patient systems play a crucial role in modern medical education and
research, providing safe, integrative learning environments and enabling
clinical decision-making simulations. Large Language Models (LLM) could advance
simulated patient systems by replicating medical conditions and patient-doctor
interactions with high fidelity and low cost. However, ensuring the
effectiveness and trustworthiness of these systems remains a challenge, as they
require a large, diverse, and precise patient knowledgebase, along with a
robust and stable knowledge diffusion to users. Here, we developed AIPatient,
an advanced simulated patient system with AIPatient Knowledge Graph (AIPatient
KG) as the input and the Reasoning Retrieval-Augmented Generation (Reasoning
RAG) agentic workflow as the generation backbone. AIPatient KG samples data
from Electronic Health Records (EHRs) in the Medical Information Mart for
Intensive Care (MIMIC)-III database, producing a clinically diverse and
relevant cohort of 1,495 patients with high knowledgebase validity (F1 0.89).
Reasoning RAG leverages six LLM powered agents spanning tasks including
retrieval, KG query generation, abstraction, checker, rewrite, and
summarization. This agentic framework reaches an overall accuracy of 94.15% in
EHR-based medical Question Answering (QA), outperforming benchmarks that use
either no agent or only partial agent integration. Our system also presents
high readability (median Flesch Reading Ease 77.23; median Flesch Kincaid Grade
5.6), robustness (ANOVA F-value 0.6126, p>0.1), and stability (ANOVA F-value
0.782, p>0.1). The promising performance of the AIPatient system highlights its
potential to support a wide range of applications, including medical education,
model evaluation, and system integration.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>42 pages, 6 figures, 7 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FLRT: Fluent Student-Teacher Redteaming 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.17447v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.17447v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        T. Ben Thompson, Michael Sklar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Many publicly available language models have been safety tuned to reduce the
likelihood of toxic or liability-inducing text. To redteam or jailbreak these
models for compliance with toxic requests, users and security analysts have
developed adversarial prompting techniques. One attack method is to apply
discrete optimization techniques to the prompt. However, the resulting attack
strings are often gibberish text, easily filtered by defenders due to high
measured perplexity, and may fail for unseen tasks and/or well-tuned models. In
this work, we improve existing algorithms (primarily GCG and BEAST) to develop
powerful and fluent attacks on safety-tuned models like Llama-2 and Phi-3. Our
technique centers around a new distillation-based approach that encourages the
victim model to emulate a toxified finetune, either in terms of output
probabilities or internal activations. To encourage human-fluent attacks, we
add a multi-model perplexity penalty and a repetition penalty to the objective.
We also enhance optimizer strength by allowing token insertions, token swaps,
and token deletions and by using longer attack sequences. The resulting process
is able to reliably jailbreak the most difficult target models with prompts
that appear similar to human-written prompts. On Advbench we achieve attack
success rates $>93$% for Llama-2-7B, Llama-3-8B, and Vicuna-7B, while
maintaining model-measured perplexity $<33$; we achieve $95$% attack success
for Phi-3, though with higher perplexity. We also find a universally-optimized
single fluent prompt that induces $>88$% compliance on previously unseen tasks
across Llama-2-7B, Phi-3-mini and Vicuna-7B and transfers to other black-box
models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Measuring and Mitigating Bias for Tabular <span class="highlight-title">Dataset</span>s with Multiple
  Protected Attributes <span class="chip">ECAI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.19300v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.19300v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manh Khoi Duong, Stefan Conrad
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Motivated by the recital (67) of the current corrigendum of the AI Act in the
European Union, we propose and present measures and mitigation strategies for
discrimination in tabular datasets. We specifically focus on datasets that
contain multiple protected attributes, such as nationality, age, and sex. This
makes measuring and mitigating bias more challenging, as many existing methods
are designed for a single protected attribute. This paper comes with a twofold
contribution: Firstly, new discrimination measures are introduced. These
measures are categorized in our framework along with existing ones, guiding
researchers and practitioners in choosing the right measure to assess the
fairness of the underlying dataset. Secondly, a novel application of an
existing bias mitigation method, FairDo, is presented. We show that this
strategy can mitigate any type of discrimination, including intersectional
discrimination, by transforming the dataset. By conducting experiments on
real-world datasets (Adult, Bank, COMPAS), we demonstrate that de-biasing
datasets with multiple protected attributes is possible. All transformed
datasets show a reduction in discrimination, on average by 28%. Further, these
datasets do not compromise any of the tested machine learning models'
performances significantly compared to the original datasets. Conclusively,
this study demonstrates the effectiveness of the mitigation strategy used and
contributes to the ongoing discussion on the implementation of the European
Union's AI Act.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submission accepted in AEQUITAS'24 (co-located with ECAI 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Paths to Equilibrium in Games <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.18079v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.18079v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bora Yongacoglu, Gürdal Arslan, Lacra Pavel, Serdar Yüksel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In multi-agent reinforcement learning (MARL) and game theory, agents
repeatedly interact and revise their strategies as new data arrives, producing
a sequence of strategy profiles. This paper studies sequences of strategies
satisfying a pairwise constraint inspired by policy updating in reinforcement
learning, where an agent who is best responding in one period does not switch
its strategy in the next period. This constraint merely requires that
optimizing agents do not switch strategies, but does not constrain the
non-optimizing agents in any way, and thus allows for exploration. Sequences
with this property are called satisficing paths, and arise naturally in many
MARL algorithms. A fundamental question about strategic dynamics is such: for a
given game and initial strategy profile, is it always possible to construct a
satisficing path that terminates at an equilibrium? The resolution of this
question has implications about the capabilities or limitations of a class of
MARL algorithms. We answer this question in the affirmative for normal-form
games. Our analysis reveals a counterintuitive insight that reward
deteriorating strategic updates are key to driving play to equilibrium along a
satisficing path.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Conversational Complexity for Assessing Risk in Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.01247v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.01247v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        John Burden, Manuel Cebrian, Jose Hernandez-Orallo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) present a dual-use dilemma: they enable
beneficial applications while harboring potential for harm, particularly
through conversational interactions. Despite various safeguards, advanced LLMs
remain vulnerable. A watershed case was Kevin Roose's notable conversation with
Bing, which elicited harmful outputs after extended interaction. This contrasts
with simpler early jailbreaks that produced similar content more easily,
raising the question: How much conversational effort is needed to elicit
harmful information from LLMs? We propose two measures: Conversational Length
(CL), which quantifies the conversation length used to obtain a specific
response, and Conversational Complexity (CC), defined as the Kolmogorov
complexity of the user's instruction sequence leading to the response. To
address the incomputability of Kolmogorov complexity, we approximate CC using a
reference LLM to estimate the compressibility of user instructions. Applying
this approach to a large red-teaming dataset, we perform a quantitative
analysis examining the statistical distribution of harmful and harmless
conversational lengths and complexities. Our empirical findings suggest that
this distributional analysis and the minimisation of CC serve as valuable tools
for understanding AI safety, offering insights into the accessibility of
harmful information. This work establishes a foundation for a new perspective
on LLM safety, centered around the algorithmic complexity of pathways to harm.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Inference Optimization of Foundation Models on AI Accelerators <span class="chip">KDD 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.09111v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.09111v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Youngsuk Park, Kailash Budhathoki, Liangfu Chen, Jonas Kübler, Jiaji Huang, Matthäus Kleindessner, Jun Huan, Volkan Cevher, Yida Wang, George Karypis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Powerful foundation models, including large language models (LLMs), with
Transformer architectures have ushered in a new era of Generative AI across
various industries. Industry and research community have witnessed a large
number of new applications, based on those foundation models. Such applications
include question and answer, customer services, image and video generation, and
code completions, among others. However, as the number of model parameters
reaches to hundreds of billions, their deployment incurs prohibitive inference
costs and high latency in real-world scenarios. As a result, the demand for
cost-effective and fast inference using AI accelerators is ever more higher. To
this end, our tutorial offers a comprehensive discussion on complementary
inference optimization techniques using AI accelerators. Beginning with an
overview of basic Transformer architectures and deep learning system
frameworks, we deep dive into system optimization techniques for fast and
memory-efficient attention computations and discuss how they can be implemented
efficiently on AI accelerators. Next, we describe architectural elements that
are key for fast transformer inference. Finally, we examine various model
compression and fast decoding strategies in the same context.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>[v2] Tutorial website added [v1] Tutorial published at KDD 2024.
  Camera-ready version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Dual-Space Knowledge Distillation for Large Language Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17328v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17328v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Songming Zhang, Xue Zhang, Zengkui Sun, Yufeng Chen, Jinan Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge distillation (KD) is known as a promising solution to compress
large language models (LLMs) via transferring their knowledge to smaller
models. During this process, white-box KD methods usually minimize the distance
between the output distributions of the two models so that more knowledge can
be transferred. However, in the current white-box KD framework, the output
distributions are from the respective output spaces of the two models, using
their own prediction heads. We argue that the space discrepancy will lead to
low similarity between the teacher model and the student model on both
representation and distribution levels. Furthermore, this discrepancy also
hinders the KD process between models with different vocabularies, which is
common for current LLMs. To address these issues, we propose a dual-space
knowledge distillation (DSKD) framework that unifies the output spaces of the
two models for KD. On the basis of DSKD, we further develop a cross-model
attention mechanism, which can automatically align the representations of the
two models with different vocabularies. Thus, our framework is not only
compatible with various distance functions for KD (e.g., KL divergence) like
the current framework, but also supports KD between any two LLMs regardless of
their vocabularies. Experiments on task-agnostic instruction-following
benchmarks show that DSKD significantly outperforms the current white-box KD
framework with various distance functions, and also surpasses existing KD
methods for LLMs with different vocabularies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The camera-ready version for EMNLP 2024 main conference. 17 pages, 11
  figures, code available at: https://github.com/songmzhang/DSKD</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ What is the Role of Large Language Models in the Evolution of Astronomy
  Research? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.20252v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.20252v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Morgan Fouesneau, Ivelina G. Momcheva, Urmila Chadayammuri, Mariia Demianenko, Antoine Dumont, Raphael E. Hviding, K. Angelique Kahle, Nadiia Pulatova, Bhavesh Rajpoot, Marten B. Scheuck, Rhys Seeburger, Dmitry Semenov, Jaime I. Villaseñor
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  ChatGPT and other state-of-the-art large language models (LLMs) are rapidly
transforming multiple fields, offering powerful tools for a wide range of
applications. These models, commonly trained on vast datasets, exhibit
human-like text generation capabilities, making them useful for research tasks
such as ideation, literature review, coding, drafting, and outreach. We
conducted a study involving 13 astronomers at different career stages and
research fields to explore LLM applications across diverse tasks over several
months and to evaluate their performance in research-related activities. This
work was accompanied by an anonymous survey assessing participants' experiences
and attitudes towards LLMs. We provide a detailed analysis of the tasks
attempted and the survey answers, along with specific output examples. Our
findings highlight both the potential and limitations of LLMs in supporting
research while also addressing general and research-specific ethical
considerations. We conclude with a series of recommendations, emphasizing the
need for researchers to complement LLMs with critical thinking and domain
expertise, ensuring these tools serve as aids rather than substitutes for
rigorous scientific inquiry.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Paper submitted to RASTI. We share our experience, ethical and legal
  concerns (5.3), and recommendations for individuals and journals (6.). We
  welcome feedback</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ <span class="highlight-title">★</span> Mitigating Shortcut Learning with Diffusion Counterfactuals and Diverse
  Ensembles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.16176v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.16176v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luca Scimeca, Alexander Rubinstein, Damien Teney, Seong Joon Oh, Armand Mihai Nicolicioiu, <span class="highlight-author">Yoshua Bengio</span>
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spurious correlations in the data, where multiple cues are predictive of the
target labels, often lead to a phenomenon known as shortcut learning, where a
model relies on erroneous, easy-to-learn cues while ignoring reliable ones. In
this work, we propose DiffDiv an ensemble diversification framework exploiting
Diffusion Probabilistic Models (DPMs) to mitigate this form of bias. We show
that at particular training intervals, DPMs can generate images with novel
feature combinations, even when trained on samples displaying correlated input
features. We leverage this crucial property to generate synthetic
counterfactuals to increase model diversity via ensemble disagreement. We show
that DPM-guided diversification is sufficient to remove dependence on shortcut
cues, without a need for additional supervised signals. We further empirically
quantify its efficacy on several diversification objectives, and finally show
improved generalization and diversification on par with prior work that relies
on auxiliary data collection.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: substantial text overlap with arXiv:2310.02230</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DRIM: Learning Disentangled Representations from Incomplete Multimodal
  Healthcare Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.17055v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.17055v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lucas Robinet, Ahmad Berjaoui, Ziad Kheil, Elizabeth Cohen-Jonathan Moyal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Real-life medical data is often multimodal and incomplete, fueling the
growing need for advanced deep learning models capable of integrating them
efficiently. The use of diverse modalities, including histopathology slides,
MRI, and genetic data, offers unprecedented opportunities to improve prognosis
prediction and to unveil new treatment pathways. Contrastive learning, widely
used for deriving representations from paired data in multimodal tasks, assumes
that different views contain the same task-relevant information and leverages
only shared information. This assumption becomes restrictive when handling
medical data since each modality also harbors specific knowledge relevant to
downstream tasks. We introduce DRIM, a new multimodal method for capturing
these shared and unique representations, despite data sparsity. More
specifically, given a set of modalities, we aim to encode a representation for
each one that can be divided into two components: one encapsulating
patient-related information common across modalities and the other,
encapsulating modality-specific details. This is achieved by increasing the
shared information among different patient modalities while minimizing the
overlap between shared and unique components within each modality. Our method
outperforms state-of-the-art algorithms on glioma patients survival prediction
tasks, while being robust to missing modalities. To promote reproducibility,
the code is made publicly available at https://github.com/Lucas-rbnt/DRIM
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Use of Large Language Models (LLM) for Cyber Threat Intelligence
  (CTI) in Cybercrime Forums 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.03354v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.03354v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vanessa Clairoux-Trepanier, Isa-May Beauchamp, Estelle Ruellan, Masarah Paquet-Clouston, Serge-Olivier Paquette, Eric Clay
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) can be used to analyze cyber threat intelligence
(CTI) data from cybercrime forums, which contain extensive information and key
discussions about emerging cyber threats. However, to date, the level of
accuracy and efficiency of LLMs for such critical tasks has yet to be
thoroughly evaluated. Hence, this study assesses the performance of an LLM
system built on the OpenAI GPT-3.5-turbo model [8] to extract CTI information.
To do so, a random sample of more than 700 daily conversations from three
cybercrime forums - XSS, Exploit_in, and RAMP - was extracted, and the LLM
system was instructed to summarize the conversations and predict 10 key CTI
variables, such as whether a large organization and/or a critical
infrastructure is being targeted, with only simple human-language instructions.
Then, two coders reviewed each conversation and evaluated whether the
information extracted by the LLM was accurate. The LLM system performed well,
with an average accuracy score of 96.23%, an average precision of 90% and an
average recall of 88.2%. Various ways to enhance the model were uncovered, such
as the need to help the LLM distinguish between stories and past events, as
well as being careful with verb tenses in prompts. Nevertheless, the results of
this study highlight the relevance of using LLMs for cyber threat intelligence.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.10774v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.10774v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liyan Tang, Philippe Laban, Greg Durrett
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recognizing if LLM output can be grounded in evidence is central to many
tasks in NLP: retrieval-augmented generation, summarization, document-grounded
dialogue, and more. Current approaches to this kind of fact-checking are based
on verifying each piece of a model generation against potential evidence using
an LLM. However, this process can be very computationally expensive, requiring
many calls to a model to check a single response. In this work, we show how to
build small fact-checking models that have GPT-4-level performance but for 400x
lower cost. We do this by constructing synthetic training data with GPT-4,
which involves creating realistic yet challenging instances of factual errors
via a structured generation procedure. Training on this data teaches models to
check each fact in the claim and recognize synthesis of information across
sentences. For evaluation, we unify datasets from recent work on fact-checking
and grounding LLM generations into a new benchmark, LLM-AggreFact. Our best
system MiniCheck-FT5 (770M parameters) outperforms all systems of comparable
size and reaches GPT-4 accuracy. We release LLM-AggreFact, code for data
synthesis, and models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ NeuroPath: A Neural Pathway <span class="highlight-title">Transformer</span> for Joining the Dots of Human
  Connectomes <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.17510v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.17510v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziquan Wei, Tingting Dan, Jiaqi Ding, Guorong Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although modern imaging technologies allow us to study connectivity between
two distinct brain regions in-vivo, an in-depth understanding of how anatomical
structure supports brain function and how spontaneous functional fluctuations
emerge remarkable cognition is still elusive. Meanwhile, tremendous efforts
have been made in the realm of machine learning to establish the nonlinear
mapping between neuroimaging data and phenotypic traits. However, the absence
of neuroscience insight in the current approaches poses significant challenges
in understanding cognitive behavior from transient neural activities. To
address this challenge, we put the spotlight on the coupling mechanism of
structural connectivity (SC) and functional connectivity (FC) by formulating
such network neuroscience question into an expressive graph representation
learning problem for high-order topology. Specifically, we introduce the
concept of topological detour to characterize how a ubiquitous instance of FC
(direct link) is supported by neural pathways (detour) physically wired by SC,
which forms a cyclic loop interacted by brain structure and function. In the
clich\'e of machine learning, the multi-hop detour pathway underlying SC-FC
coupling allows us to devise a novel multi-head self-attention mechanism within
Transformer to capture multi-modal feature representation from paired graphs of
SC and FC. Taken together, we propose a biological-inspired deep model, coined
as NeuroPath, to find putative connectomic feature representations from the
unprecedented amount of neuroimages, which can be plugged into various
downstream applications such as task recognition and disease diagnosis. We have
evaluated NeuroPath on large-scale public datasets including HCP and UK Biobank
under supervised and zero-shot learning, where the state-of-the-art performance
by our NeuroPath indicates great potential in network neuroscience.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Early Detection of Coronary Heart Disease Using Hybrid Quantum Machine
  Learning Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.10932v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.10932v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mehroush Banday, Sherin Zafar, Parul Agarwal, M Afshar Alam, Abubeker K M
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Coronary heart disease (CHD) is a severe cardiac disease, and hence, its
early diagnosis is essential as it improves treatment results and saves money
on medical care. The prevailing development of quantum computing and machine
learning (ML) technologies may bring practical improvement to the performance
of CHD diagnosis. Quantum machine learning (QML) is receiving tremendous
interest in various disciplines due to its higher performance and capabilities.
A quantum leap in the healthcare industry will increase processing power and
optimise multiple models. Techniques for QML have the potential to forecast
cardiac disease and help in early detection. To predict the risk of coronary
heart disease, a hybrid approach utilizing an ensemble machine learning model
based on QML classifiers is presented in this paper. Our approach, with its
unique ability to address multidimensional healthcare data, reassures the
method's robustness by fusing quantum and classical ML algorithms in a
multi-step inferential framework. The marked rise in heart disease and death
rates impacts worldwide human health and the global economy. Reducing cardiac
morbidity and mortality requires early detection of heart disease. In this
research, a hybrid approach utilizes techniques with quantum computing
capabilities to tackle complex problems that are not amenable to conventional
machine learning algorithms and to minimize computational expenses. The
proposed method has been developed in the Raspberry Pi 5 Graphics Processing
Unit (GPU) platform and tested on a broad dataset that integrates clinical and
imaging data from patients suffering from CHD and healthy controls. Compared to
classical machine learning models, the accuracy, sensitivity, F1 score, and
specificity of the proposed hybrid QML model used with CHD are manifold higher.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>I found a mistake in methodology presentation. Also I have observed
  more precised results with new dataset. So my research guide ask me to modify
  the current version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Divide And Conquer: Learning Chaotic Dynamical Systems With Multistep
  Penalty Neural Ordinary Differential Equations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.00568v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.00568v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dibyajyoti Chakraborty, Seung Whan Chung, Troy Arcomano, Romit Maulik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Forecasting high-dimensional dynamical systems is a fundamental challenge in
various fields, such as geosciences and engineering. Neural Ordinary
Differential Equations (NODEs), which combine the power of neural networks and
numerical solvers, have emerged as a promising algorithm for forecasting
complex nonlinear dynamical systems. However, classical techniques used for
NODE training are ineffective for learning chaotic dynamical systems. In this
work, we propose a novel NODE-training approach that allows for robust learning
of chaotic dynamical systems. Our method addresses the challenges of
non-convexity and exploding gradients associated with underlying chaotic
dynamics. Training data trajectories from such systems are split into multiple,
non-overlapping time windows. In addition to the deviation from the training
data, the optimization loss term further penalizes the discontinuities of the
predicted trajectory between the time windows. The window size is selected
based on the fastest Lyapunov time scale of the system. Multi-step penalty(MP)
method is first demonstrated on Lorenz equation, to illustrate how it improves
the loss landscape and thereby accelerates the optimization convergence. MP
method can optimize chaotic systems in a manner similar to least-squares
shadowing with significantly lower computational costs. Our proposed algorithm,
denoted the Multistep Penalty NODE, is applied to chaotic systems such as the
Kuramoto-Sivashinsky equation, the two-dimensional Kolmogorov flow, and ERA5
reanalysis data for the atmosphere. It is observed that MP-NODE provide viable
performance for such chaotic systems, not only for short-term trajectory
predictions but also for invariant statistics that are hallmarks of the chaotic
nature of these dynamics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages, 17 Figures, submitted to Computer Methods in Applied
  Mechanics and Engineering</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Outlier Gradient Analysis: Efficiently Improving Deep Learning Model
  Performance via Hessian-Free Influence Functions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.03869v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.03869v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anshuman Chhabra, Bo Li, Jian Chen, Prasant Mohapatra, Hongfu Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A core data-centric learning challenge is the identification of training
samples that are detrimental to model performance. Influence functions serve as
a prominent tool for this task and offer a robust framework for assessing
training data influence on model predictions. Despite their widespread use,
their high computational cost associated with calculating the inverse of the
Hessian matrix pose constraints, particularly when analyzing large-sized deep
models. In this paper, we establish a bridge between identifying detrimental
training samples via influence functions and outlier gradient detection. This
transformation not only presents a straightforward and Hessian-free formulation
but also provides insights into the role of the gradient in sample impact.
Through systematic empirical evaluations, we first validate the hypothesis of
our proposed outlier gradient analysis approach on synthetic datasets. We then
demonstrate its effectiveness in detecting mislabeled samples in vision models
and selecting data samples for improving performance of natural language
processing transformer models. We also extend its use to influential sample
identification for fine-tuning Large Language Models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ OmniHands: Towards Robust 4D Hand Mesh Recovery via A Versatile
  <span class="highlight-title">Transformer</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.20330v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.20330v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dixuan Lin, Yuxiang Zhang, Mengcheng Li, Yebin Liu, Wei Jing, Qi Yan, Qianying Wang, Hongwen Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce OmniHands, a universal approach to recovering
interactive hand meshes and their relative movement from monocular or
multi-view inputs. Our approach addresses two major limitations of previous
methods: lacking a unified solution for handling various hand image inputs and
neglecting the positional relationship of two hands within images. To overcome
these challenges, we develop a universal architecture with novel tokenization
and contextual feature fusion strategies, capable of adapting to a variety of
tasks. Specifically, we propose a Relation-aware Two-Hand Tokenization (RAT)
method to embed positional relation information into the hand tokens. In this
way, our network can handle both single-hand and two-hand inputs and explicitly
leverage relative hand positions, facilitating the reconstruction of intricate
hand interactions in real-world scenarios. As such tokenization indicates the
relative relationship of two hands, it also supports more effective feature
fusion. To this end, we further develop a 4D Interaction Reasoning (FIR) module
to fuse hand tokens in 4D with attention and decode them into 3D hand meshes
and relative temporal movements. The efficacy of our approach is validated on
several benchmark datasets. The results on in-the-wild videos and real-world
scenarios demonstrate the superior performances of our approach for interactive
hand reconstruction. More video results can be found on the project page:
https://OmniHand.github.io.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>An extended journal version of 4DHands, featured with versatile
  module that can adapt to temporal task and multi-view task. Additional
  detailed comparison experiments and results presentation have been added.
  More demo videos can be seen at our project page: https://OmniHand.github.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ OLAPH: Improving Factuality in Biomedical Long-form Question Answering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.12701v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.12701v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minbyul Jeong, Hyeon Hwang, Chanwoong Yoon, Taewhoo Lee, Jaewoo Kang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the medical domain, numerous scenarios necessitate the long-form
generation ability of large language models (LLMs). Specifically, when
addressing patients' questions, it is essential that the model's response
conveys factual claims, highlighting the need for an automated method to
evaluate those claims. Thus, we introduce MedLFQA, a benchmark dataset
reconstructed using long-form question-answering datasets related to the
biomedical domain. We use MedLFQA to facilitate a cost-effective automatic
evaluations of factuality. We also propose OLAPH, a simple and novel framework
that utilizes cost-effective and multifaceted automatic evaluation to construct
a synthetic preference set and answers questions in our preferred manner. Our
framework leads us to train LLMs step-by-step to reduce hallucinations and
include crucial medical claims. We highlight that, even on evaluation metrics
not used during training, LLMs trained with our OLAPH framework demonstrate
significant performance improvement in factuality. Our findings reveal that a
7B LLM trained with our OLAPH framework can provide long answers comparable to
the medical experts' answers in terms of factuality. We believe that our work
could shed light on gauging the long-text generation ability of LLMs in the
medical domain. Our code and datasets are available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HOLA-Drone: Hypergraphic Open-ended Learning for Zero-Shot Multi-Drone
  Cooperative Pursuit 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.08767v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.08767v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yang Li, Dengyu Zhang, Junfan Chen, Ying Wen, Qingrui Zhang, Shaoshuai Mou, Wei Pan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Zero-shot coordination (ZSC) is a significant challenge in multi-agent
collaboration, aiming to develop agents that can coordinate with unseen
partners they have not encountered before. Recent cutting-edge ZSC methods have
primarily focused on two-player video games such as OverCooked!2 and Hanabi. In
this paper, we extend the scope of ZSC research to the multi-drone cooperative
pursuit scenario, exploring how to construct a drone agent capable of
coordinating with multiple unseen partners to capture multiple evaders. We
propose a novel Hypergraphic Open-ended Learning Algorithm (HOLA-Drone) that
continuously adapts the learning objective based on our hypergraphic-form game
modeling, aiming to improve cooperative abilities with multiple unknown drone
teammates. To empirically verify the effectiveness of HOLA-Drone, we build two
different unseen drone teammate pools to evaluate their performance in
coordination with various unseen partners. The experimental results demonstrate
that HOLA-Drone outperforms the baseline methods in coordination with unseen
drone teammates. Furthermore, real-world experiments validate the feasibility
of HOLA-Drone in physical systems. Videos can be found on the project
homepage~\url{https://sites.google.com/view/hola-drone}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Ladder Bottom-up Convolutional Bidirectional Variational Autoencoder for
  Image Translation of Dotted Arabic Expiration Dates 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.14069v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.14069v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ahmed Zidane, Ghada Soliman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes an approach of Ladder Bottom-up Convolutional
Bidirectional Variational Autoencoder (LCBVAE) architecture for the encoder and
decoder, which is trained on the image translation of the dotted Arabic
expiration dates by reconstructing the Arabic dotted expiration dates into
filled-in expiration dates. We employed a customized and adapted version of
Convolutional Recurrent Neural Network CRNN model to meet our specific
requirements and enhance its performance in our context, and then trained the
custom CRNN model with the filled-in images from the year of 2019 to 2027 to
extract the expiration dates and assess the model performance of LCBVAE on the
expiration date recognition. The pipeline of (LCBVAE+CRNN) can be then
integrated into an automated sorting systems for extracting the expiry dates
and sorting the products accordingly during the manufacture stage.
Additionally, it can overcome the manual entry of expiration dates that can be
time-consuming and inefficient at the merchants. Due to the lack of the
availability of the dotted Arabic expiration date images, we created an Arabic
dot-matrix True Type Font (TTF) for the generation of the synthetic images. We
trained the model with unrealistic synthetic dates of 60,000 images and
performed the testing on a realistic synthetic date of 3000 images from the
year of 2019 to 2027, represented as yyyy/mm/dd. In our study, we demonstrated
the significance of latent bottleneck layer with improving the generalization
when the size is increased up to 1024 in downstream transfer learning tasks as
for image translation. The proposed approach achieved an accuracy of 97% on the
image translation with using the LCBVAE architecture that can be generalized
for any downstream learning tasks as for image translation and reconstruction.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>* Corresponding author. E-mail address: ghada.soliman@orange.com
  https://doi.org/10.1117/1.JEI.33.5.053024 Received: 14 April 2024; Accepted:
  28 August 2024; Published: 30 September 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing GANs with Contrastive Learning-Based Multistage Progressive
  Finetuning SNN and RL-Based External Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.20340v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.20340v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Osama Mustafa
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The application of deep learning in cancer research, particularly in early
diagnosis, case understanding, and treatment strategy design, emphasizes the
need for high-quality data. Generative AI, especially Generative Adversarial
Networks (GANs), has emerged as a leading solution to challenges like class
imbalance, robust learning, and model training, while addressing issues
stemming from patient privacy and the scarcity of real data. Despite their
promise, GANs face several challenges, both inherent and specific to
histopathology data. Inherent issues include training imbalance, mode collapse,
linear learning from insufficient discriminator feedback, and hard boundary
convergence due to stringent feedback. Histopathology data presents a unique
challenge with its complex representation, high spatial resolution, and
multiscale features. To address these challenges, we propose a framework
consisting of two components. First, we introduce a contrastive learning-based
Multistage Progressive Finetuning Siamese Neural Network (MFT-SNN) for
assessing the similarity between histopathology patches. Second, we implement a
Reinforcement Learning-based External Optimizer (RL-EO) within the GAN training
loop, serving as a reward signal generator. The modified discriminator loss
function incorporates a weighted reward, guiding the GAN to maximize this
reward while minimizing loss. This approach offers an external optimization
guide to the discriminator, preventing generator overfitting and ensuring
smooth convergence. Our proposed solution has been benchmarked against
state-of-the-art (SOTA) GANs and a Denoising Diffusion Probabilistic model,
outperforming previous SOTA across various metrics, including FID score, KID
score, Perceptual Path Length, and downstream classification tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Creative Problem Solving in Large Language and Vision Models -- What
  Would it Take? <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.01453v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.01453v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lakshmi Nair, Evana Gizzi, Jivko Sinapov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We advocate for a strong integration of Computational Creativity (CC) with
research in large language and vision models (LLVMs) to address a key
limitation of these models, i.e., creative problem solving. We present
preliminary experiments showing how CC principles can be applied to address
this limitation. Our goal is to foster discussions on creative problem solving
in LLVMs and CC at prestigious ML venues. Our code is available at:
https://github.com/lnairGT/creative-problem-solving-LLMs
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Merging LoRAs like Playing LEGO: Pushing the Modularity of LoRA to
  Extremes Through Rank-Wise Clustering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.16167v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.16167v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziyu Zhao, Tao Shen, Didi Zhu, Zexi Li, Jing Su, Xuwu Wang, Kun Kuang, Fei Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low-Rank Adaptation (LoRA) has emerged as a popular technique for fine-tuning
large language models (LLMs) to various domains due to its modular design and
widespread availability on platforms like Huggingface. This modularity has
sparked interest in combining multiple LoRAs to enhance LLM capabilities.
However, existing methods for LoRA composition primarily focus on task-specific
adaptations that require additional training, and current model merging
techniques often fail to fully leverage LoRA's modular nature, leading to
parameter interference and performance degradation. In this paper, we
investigate the feasibility of disassembling and reassembling multiple LoRAs at
a finer granularity, analogous to assembling LEGO blocks. We introduce the
concept of Minimal Semantic Units (MSUs), where the parameters corresponding to
each rank in LoRA function as independent units. These MSUs demonstrate
permutation invariance and concatenation-summation equivalence properties,
enabling flexible combinations to create new LoRAs. Building on these insights,
we propose the LoRA-LEGO framework. This framework conducts rank-wise parameter
clustering by grouping MSUs from different LoRAs into $k$ clusters. The
centroid of each cluster serves as a representative MSU, enabling the assembly
of a merged LoRA with an adjusted rank of $k$. Additionally, we apply a dual
reweighting strategy to optimize the scale of the merged LoRA. Experiments
across various benchmarks demonstrate that our method outperforms existing
approaches in LoRA merging.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BMFT: Achieving Fairness via Bias-based Weight Masking Fine-tuning <span class="chip">MICCAI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.06890v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.06890v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuyang Xue, Junyu Yan, Raman Dutt, Fasih Haider, Jingshuai Liu, Steven McDonagh, Sotirios A. Tsaftaris
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Developing models with robust group fairness properties is paramount,
particularly in ethically sensitive domains such as medical diagnosis. Recent
approaches to achieving fairness in machine learning require a substantial
amount of training data and depend on model retraining, which may not be
practical in real-world scenarios. To mitigate these challenges, we propose
Bias-based Weight Masking Fine-Tuning (BMFT), a novel post-processing method
that enhances the fairness of a trained model in significantly fewer epochs
without requiring access to the original training data. BMFT produces a mask
over model parameters, which efficiently identifies the weights contributing
the most towards biased predictions. Furthermore, we propose a two-step
debiasing strategy, wherein the feature extractor undergoes initial fine-tuning
on the identified bias-influenced weights, succeeded by a fine-tuning phase on
a reinitialised classification layer to uphold discriminative performance.
Extensive experiments across four dermatological datasets and two sensitive
attributes demonstrate that BMFT outperforms existing state-of-the-art (SOTA)
techniques in both diagnostic accuracy and fairness metrics. Our findings
underscore the efficacy and robustness of BMFT in advancing fairness across
various out-of-distribution (OOD) settings. Our code is available at:
https://github.com/vios-s/BMFT
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by MICCAI 2024 FAIMI Workshop Oral</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LUMA: A Benchmark <span class="highlight-title">Dataset</span> for Learning from Uncertain and Multimodal
  Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.09864v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.09864v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Grigor Bezirganyan, Sana Sellami, Laure Berti-Équille, Sébastien Fournier
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Deep Learning enhances decision-making by integrating diverse
information sources, such as texts, images, audio, and videos. To develop
trustworthy multimodal approaches, it is essential to understand how
uncertainty impacts these models. We propose LUMA, a unique benchmark dataset,
featuring audio, image, and textual data from 50 classes, for learning from
uncertain and multimodal data. It extends the well-known CIFAR 10/100 dataset
with audio samples extracted from three audio corpora, and text data generated
using the Gemma-7B Large Language Model (LLM). The LUMA dataset enables the
controlled injection of varying types and degrees of uncertainty to achieve and
tailor specific experiments and benchmarking initiatives. LUMA is also
available as a Python package including the functions for generating multiple
variants of the dataset with controlling the diversity of the data, the amount
of noise for each modality, and adding out-of-distribution samples. A baseline
pre-trained model is also provided alongside three uncertainty quantification
methods: Monte-Carlo Dropout, Deep Ensemble, and Reliable Conflictive
Multi-View Learning. This comprehensive dataset and its benchmarking tools are
intended to promote and support the development, evaluation, and benchmarking
of trustworthy and robust multimodal deep learning approaches. We anticipate
that the LUMA dataset will help the ICLR community to design more trustworthy
and robust machine learning approaches for safety critical applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring Utility in a Real-World Warehouse Optimization Problem:
  Formulation Based on Quantum Annealers and Preliminary Results 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.09706v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.09706v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eneko Osaba, Esther Villar-Rodriguez, Antón Asla
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the current NISQ-era, one of the major challenges faced by researchers and
practitioners lies in figuring out how to combine quantum and classical
computing in the most efficient and innovative way. In this paper, we present a
mechanism coined as Quantum Initialization for Warehouse Optimization Problem
that resorts to D-Wave's Quantum Annealer. The module has been specifically
designed to be embedded into already existing classical software dedicated to
the optimization of a real-world industrial problem. We preliminary tested the
implemented mechanism through a two-phase experiment against the classical
version of the software.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>2 pages, 2 figures. Paper presented at the 5th IEEE International
  Conference on Quantum Computing and Engineering (IEEE QCE 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Backdoor Attacks for LLMs with Weak-To-Strong Knowledge Distillation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.17946v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.17946v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuai Zhao, Leilei Gan, Zhongliang Guo, Xiaobao Wu, Luwei Xiao, Xiaoyu Xu, Cong-Duy Nguyen, Luu Anh Tuan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite being widely applied due to their exceptional capabilities, Large
Language Models (LLMs) have been proven to be vulnerable to backdoor attacks.
These attacks introduce targeted vulnerabilities into LLMs by poisoning
training samples and full-parameter fine-tuning. However, this kind of backdoor
attack is limited since they require significant computational resources,
especially as the size of LLMs increases. Besides, parameter-efficient
fine-tuning (PEFT) offers an alternative but the restricted parameter updating
may impede the alignment of triggers with target labels. In this study, we
first verify that backdoor attacks with PEFT may encounter challenges in
achieving feasible performance. To address these issues and improve the
effectiveness of backdoor attacks with PEFT, we propose a novel backdoor attack
algorithm from weak to strong based on feature alignment-enhanced knowledge
distillation (W2SAttack). Specifically, we poison small-scale language models
through full-parameter fine-tuning to serve as the teacher model. The teacher
model then covertly transfers the backdoor to the large-scale student model
through feature alignment-enhanced knowledge distillation, which employs PEFT.
Theoretical analysis reveals that W2SAttack has the potential to augment the
effectiveness of backdoor attacks. We demonstrate the superior performance of
W2SAttack on classification tasks across four language models, four backdoor
attack algorithms, and two different architectures of teacher models.
Experimental results indicate success rates close to 100% for backdoor attacks
targeting PEFT.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SDC-HSDD-NDSA: Structure Detecting Cluster by Hierarchical Secondary
  Directed Differential with Normalized Density and Self-Adaption 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2307.00677v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2307.00677v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Shu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Density-based clustering could be the most popular clustering algorithm since
it can identify clusters of arbitrary shape as long as they are separated by
low-density regions. However, a high-density region that is not separated by
low-density ones might also have different structures belonging to multiple
clusters. As far as we know, all previous density-based clustering algorithms
fail to detect such structures. In this paper, we provide a novel density-based
clustering scheme that can not only detect clusters separated by low-density
regions but also detect structures in high-density regions not separated by
low-density ones. The algorithm employs secondary directed differential,
hierarchy, normalized density, as well as the self-adaption coefficient, and
thus is called Structure Detecting Cluster by Hierarchical Secondary Directed
Differential with Normalized Density and Self-Adaption, dubbed by
SDC-HSDD-NDSA. The algorithm is run on several datasets to verify its
effectiveness, robustness, as well as granularity independence, and results
demonstrate that it has the ability that previous ones do not have. The Python
code is on https://github.com/Hao-B-Shu/SDC-HSDD-NDSA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>35 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On The Planning Abilities of OpenAI's o1 Models: Feasibility,
  Optimality, and Generalizability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19924v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19924v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kevin Wang, Junbo Li, Neel P. Bhatt, Yihan Xi, Qiang Liu, Ufuk Topcu, Zhangyang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in Large Language Models (LLMs) have showcased their
ability to perform complex reasoning tasks, but their effectiveness in planning
remains underexplored. In this study, we evaluate the planning capabilities of
OpenAI's o1 models across a variety of benchmark tasks, focusing on three key
aspects: feasibility, optimality, and generalizability. Through empirical
evaluations on constraint-heavy tasks (e.g., $\textit{Barman}$,
$\textit{Tyreworld}$) and spatially complex environments (e.g.,
$\textit{Termes}$, $\textit{Floortile}$), we highlight o1-preview's strengths
in self-evaluation and constraint-following, while also identifying bottlenecks
in decision-making and memory management, particularly in tasks requiring
robust spatial reasoning. Our results reveal that o1-preview outperforms GPT-4
in adhering to task constraints and managing state transitions in structured
environments. However, the model often generates suboptimal solutions with
redundant actions and struggles to generalize effectively in spatially complex
tasks. This pilot study provides foundational insights into the planning
limitations of LLMs, offering key directions for future research on improving
memory management, decision-making, and generalization in LLM-based planning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Updated link to code repository</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Universal Vulnerabilities in Large Language Models: Backdoor Attacks for
  In-context Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.05949v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.05949v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuai Zhao, Meihuizi Jia, Luu Anh Tuan, Fengjun Pan, Jinming Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In-context learning, a paradigm bridging the gap between pre-training and
fine-tuning, has demonstrated high efficacy in several NLP tasks, especially in
few-shot settings. Despite being widely applied, in-context learning is
vulnerable to malicious attacks. In this work, we raise security concerns
regarding this paradigm. Our studies demonstrate that an attacker can
manipulate the behavior of large language models by poisoning the demonstration
context, without the need for fine-tuning the model. Specifically, we design a
new backdoor attack method, named ICLAttack, to target large language models
based on in-context learning. Our method encompasses two types of attacks:
poisoning demonstration examples and poisoning demonstration prompts, which can
make models behave in alignment with predefined intentions. ICLAttack does not
require additional fine-tuning to implant a backdoor, thus preserving the
model's generality. Furthermore, the poisoned examples are correctly labeled,
enhancing the natural stealth of our attack method. Extensive experimental
results across several language models, ranging in size from 1.3B to 180B
parameters, demonstrate the effectiveness of our attack method, exemplified by
a high average attack success rate of 95.0% across the three datasets on OPT
models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Measuring Orthogonality in Representations of Generative Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.03728v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.03728v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Robin C. Geyer, Alessandro Torcinovich, João B. Carvalho, Alexander Meyer, Joachim M. Buhmann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In unsupervised representation learning, models aim to distill essential
features from high-dimensional data into lower-dimensional learned
representations, guided by inductive biases. Understanding the characteristics
that make a good representation remains a topic of ongoing research.
Disentanglement of independent generative processes has long been credited with
producing high-quality representations. However, focusing solely on
representations that adhere to the stringent requirements of most
disentanglement metrics, may result in overlooking many high-quality
representations, well suited for various downstream tasks. These metrics often
demand that generative factors be encoded in distinct, single dimensions
aligned with the canonical basis of the representation space.
  Motivated by these observations, we propose two novel metrics:
Importance-Weighted Orthogonality (IWO) and Importance-Weighted Rank (IWR).
These metrics evaluate the mutual orthogonality and rank of generative factor
subspaces. Throughout extensive experiments on common downstream tasks, over
several benchmark datasets and models, IWO and IWR consistently show stronger
correlations with downstream task performance than traditional disentanglement
metrics. Our findings suggest that representation quality is closer related to
the orthogonality of independent generative processes rather than their
disentanglement, offering a new direction for evaluating and improving
unsupervised learning models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BlendScape: Enabling End-User Customization of Video-Conferencing
  Environments through Generative AI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.13947v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.13947v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shwetha Rajaram, Nels Numan, Balasaravanan Thoravi Kumaravel, Nicolai Marquardt, Andrew D. Wilson
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Today's video-conferencing tools support a rich range of professional and
social activities, but their generic meeting environments cannot be dynamically
adapted to align with distributed collaborators' needs. To enable end-user
customization, we developed BlendScape, a rendering and composition system for
video-conferencing participants to tailor environments to their meeting context
by leveraging AI image generation techniques. BlendScape supports flexible
representations of task spaces by blending users' physical or digital
backgrounds into unified environments and implements multimodal interaction
techniques to steer the generation. Through an exploratory study with 15
end-users, we investigated whether and how they would find value in using
generative AI to customize video-conferencing environments. Participants
envisioned using a system like BlendScape to facilitate collaborative
activities in the future, but required further controls to mitigate distracting
or unrealistic visual elements. We implemented scenarios to demonstrate
BlendScape's expressiveness for supporting environment design strategies from
prior work and propose composition techniques to improve the quality of
environments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACM UIST 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Famba-V: Fast Vision Mamba with Cross-Layer Token Fusion <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.09808v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.09808v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hui Shen, Zhongwei Wan, Xin Wang, Mi Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mamba and Vision Mamba (Vim) models have shown their potential as an
alternative to methods based on Transformer architecture. This work introduces
Fast Mamba for Vision (Famba-V), a cross-layer token fusion technique to
enhance the training efficiency of Vim models. The key idea of Famba-V is to
identify and fuse similar tokens across different Vim layers based on a suit of
cross-layer strategies instead of simply applying token fusion uniformly across
all the layers that existing works propose. We evaluate the performance of
Famba-V on CIFAR-100. Our results show that Famba-V is able to enhance the
training efficiency of Vim models by reducing both training time and peak
memory usage during training. Moreover, the proposed cross-layer strategies
allow Famba-V to deliver superior accuracy-efficiency trade-offs. These results
all together demonstrate Famba-V as a promising efficiency enhancement
technique for Vim models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Camera ready version of ECCV 2024 The Fourth Workshop on
  Computational Aspects of Deep Learning (Best Paper Award)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Symbolic XAI -- Explanation Through Human Understandable Logical
  Relationships Between Features 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.17198v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.17198v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thomas Schnake, Farnoush Rezaei Jafari, Jonas Lederer, Ping Xiong, Shinichi Nakajima, Stefan Gugler, Grégoire Montavon, Klaus-Robert Müller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Explainable Artificial Intelligence (XAI) plays a crucial role in fostering
transparency and trust in AI systems, where traditional XAI approaches
typically offer one level of abstraction for explanations, often in the form of
heatmaps highlighting single or multiple input features. However, we ask
whether abstract reasoning or problem-solving strategies of a model may also be
relevant, as these align more closely with how humans approach solutions to
problems. We propose a framework, called Symbolic XAI, that attributes
relevance to symbolic queries expressing logical relationships between input
features, thereby capturing the abstract reasoning behind a model's
predictions. The methodology is built upon a simple yet general multi-order
decomposition of model predictions. This decomposition can be specified using
higher-order propagation-based relevance methods, such as GNN-LRP, or
perturbation-based explanation methods commonly used in XAI. The effectiveness
of our framework is demonstrated in the domains of natural language processing
(NLP), vision, and quantum chemistry (QC), where abstract symbolic domain
knowledge is abundant and of significant interest to users. The Symbolic XAI
framework provides an understanding of the model's decision-making process that
is both flexible for customization by the user and human-readable through
logical formulas.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Generative Approach to Control Complex Physical Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.06494v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.06494v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Long Wei, Peiyan Hu, Ruiqi Feng, Haodong Feng, Yixuan Du, Tao Zhang, Rui Wang, Yue Wang, Zhi-Ming Ma, Tailin Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Controlling the evolution of complex physical systems is a fundamental task
across science and engineering. Classical techniques suffer from limited
applicability or huge computational costs. On the other hand, recent deep
learning and reinforcement learning-based approaches often struggle to optimize
long-term control sequences under the constraints of system dynamics. In this
work, we introduce Diffusion Physical systems Control (DiffPhyCon), a new class
of method to address the physical systems control problem. DiffPhyCon excels by
simultaneously minimizing both the learned generative energy function and the
predefined control objectives across the entire trajectory and control
sequence. Thus, it can explore globally and plan near-optimal control
sequences. Moreover, we enhance DiffPhyCon with prior reweighting, enabling the
discovery of control sequences that significantly deviate from the training
distribution. We test our method on three tasks: 1D Burgers' equation, 2D
jellyfish movement control, and 2D high-dimensional smoke control, where our
generated jellyfish dataset is released as a benchmark for complex physical
system control research. Our method outperforms widely applied classical
approaches and state-of-the-art deep learning and reinforcement learning
methods. Notably, DiffPhyCon unveils an intriguing fast-close-slow-open pattern
observed in the jellyfish, aligning with established findings in the field of
fluid dynamics. The project website, jellyfish dataset, and code can be found
at https://github.com/AI4Science-WestlakeU/diffphycon.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Cheap Talking Algorithms 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.07867v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.07867v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniele Condorelli, Massimiliano Furlan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We simulate behaviour of two independent reinforcement learning algorithms
playing the Crawford and Sobel (1982) game of strategic information
transmission. We adopt memoryless algorithms to capture learning in a static
game where a large population interacts anonymously. We show that sender and
receiver converge to Nash equilibrium play. The level of informativeness of the
sender's cheap talk decreases as the bias increases and, at intermediate level
of the bias, it matches the level predicted by the Pareto optimal equilibrium
or by the second best one. Conclusions are robust to alternative specifications
of the learning hyperparameters and of the game.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ See Detail Say Clear: Towards Brain CT Report Generation via
  Pathological Clue-driven Representation Learning <span class="chip">EMNLP2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19676v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19676v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengxin Zheng, Junzhong Ji, Yanzhao Shi, Xiaodan Zhang, Liangqiong Qu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Brain CT report generation is significant to aid physicians in diagnosing
cranial diseases. Recent studies concentrate on handling the consistency
between visual and textual pathological features to improve the coherence of
report. However, there exist some challenges: 1) Redundant visual representing:
Massive irrelevant areas in 3D scans distract models from representing salient
visual contexts. 2) Shifted semantic representing: Limited medical corpus
causes difficulties for models to transfer the learned textual representations
to generative layers. This study introduces a Pathological Clue-driven
Representation Learning (PCRL) model to build cross-modal representations based
on pathological clues and naturally adapt them for accurate report generation.
Specifically, we construct pathological clues from perspectives of segmented
regions, pathological entities, and report themes, to fully grasp visual
pathological patterns and learn cross-modal feature representations. To adapt
the representations for the text generation task, we bridge the gap between
representation learning and report generation by using a unified large language
model (LLM) with task-tailored instructions. These crafted instructions enable
the LLM to be flexibly fine-tuned across tasks and smoothly transfer the
semantic representation for report generation. Experiments demonstrate that our
method outperforms previous methods and achieves SoTA performance. Our code is
available at "https://github.com/Chauncey-Jheng/PCRL-MRG".
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Our work has been accepted by EMNLP2024 findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Bone: Block Affine Transformation as Parameter Efficient Fine-tuning
  Methods for Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15371v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15371v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiale Kang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low-Rank Adaptation (LoRA) has achieved remarkable training results by
freezing the original weights and training only low-rank matrices, establishing
itself as the predominant fine-tuning method for LLMs. In pursuit of
performance closer to full-parameter training, a series of LoRA variants have
emerged, such as LoRA+, PISSA, Olora, and LoRA-GA. However, these improvements
complicate the initial setup of model training and increase initialization
time. More importantly, they overlook the internal interactions of the original
weight information. To address these issues, we introduce a novel theory,
``Weight Guide'' aimed at continuously guiding trainable matrices through the
original weights during training to enhance the utilization of weight
information. Based on this theory, we designed a new PEFT technique called Bone
(\textbf{B}l\textbf{o}ck Affi\textbf{ne}), which not only enhances the
utilization of original weight information but also emphasizes the internal
connections between weights, leading to faster convergence and better data
fitting. Experimental comparisons across two different LLM architectures
(LLaMA2, RWKV6) and various parameter scales demonstrate that the Bone
structure can achieve rapid convergence and superior data fitting without the
need for complex initialization. For example, when fine-tuning LLaMA2-7B on the
MetaMathQA dataset and validating on GSM8k and math benchmarks, Bone achieved
fine-tuning scores of 49.36 and 8.8, respectively, outperforming PISSA by
5.84\% and 1.96\%.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Separation and Collapse of Equilibria Inequalities on AND-OR Trees
  without Shape Constraints 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.20138v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.20138v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fuki Ito, Toshio Suzuki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Herein, we investigate the zero-error randomized complexity, which is the
least cost against the worst input, of AND-OR tree computation by imposing
various restrictions on the algorithm to find the Boolean value of the root of
that tree and no restrictions on the tree shape. When a tree satisfies a
certain condition regarding its symmetry, directional algorithms proposed by
Saks and Wigderson (1986), special randomized algorithms, are known to achieve
the randomized complexity. Furthermore, there is a known example of a tree that
is so unbalanced that no directional algorithm achieves the randomized
complexity (Vereshchagin 1998). In this study, we aim to identify where
deviations arise between the general randomized Boolean decision tree and its
special case, directional algorithms. In this paper, we show that for any
AND-OR tree, randomized depth-first algorithms, which form a broader class
compared with directional algorithms, have the same equilibrium as that of the
directional algorithms. Thus, we get the collapse result on equilibria
inequalities that holds for an arbitrary AND-OR tree. This implies that there
exists a case where even depth-first algorithms cannot be the fastest, leading
to the separation result on equilibria inequality. Additionally, a new
algorithm is introduced as a key concept for proof of the separation result.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>42 pages, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Uniqueness of LLaMA3-70B Series with Per-Channel Quantization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.15301v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.15301v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minghai Qin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We have observed a distinctive quantization-related behavior in the
LLaMA3/3.1-70B models that is absent in both the LLaMA2-70B and
LLaMA3/3.1/3.2-1B/3B/8B/405B models. Quantization is a crucial technique for
deploying large language models (LLMs) efficiently. The impact of W8A8
post-training quantization on model accuracy, especially on the recently
released LLaMA3/3.1 model series, remains contentious. In this paper, we
explore three key questions: What makes the LLaMA3-70B model series uniquely
vulnerable to quantization? Why is this the case? And how can the issue be
addressed? We empirically investigate multiple LLMs featured on an open LLM
leaderboard, discovering that the LLaMA3-70B model series have a unique
accuracy degradation behavior with W8A8 per-channel post-training quantization.
In contrast, other model series such as LLaMA2, LLaMA3/3.1-8B, LLaMA3.2, Qwen,
Mixtral, Mistral, Phi-3, and Falcon demonstrate robust performance with W8A8.
Contrary to previous assertions attributing degradation to the large dynamic
range of activations, our findings indicate that the weight distribution of the
LLaMA3-70B is the primary factor behind the vulnerability. By meticulously
analyzing the distinct characteristics of weight distributions across
Transformer blocks, we propose two solutions that make different tradeoffs in
hardware/software overhead. First, we propose a mixed strategy where less than
3\% of the layers employ finer per-group W8A8 quantization granularity. Second,
we introduce a bi-smoothing strategy that balances quantization errors between
weights and activations while maintaining per-channel quantization throughout.
Experimental results demonstrate that both strategies effectively preserve the
accuracy of the entire LLaMA3-70B model series under W8A8 quantization,
achieving performance on par with their FP16 counterparts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>27 pages, 41 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Future You: A Conversation with an AI-Generated Future Self Reduces
  Anxiety, Negative Emotions, and Increases Future Self-Continuity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.12514v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.12514v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pat Pataranutaporn, Kavin Winson, Peggy Yin, Auttasak Lapapirojn, Pichayoot Ouppaphan, Monchai Lertsutthiwong, Pattie Maes, Hal Hershfield
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce "Future You," an interactive, brief, single-session, digital
chat intervention designed to improve future self-continuity--the degree of
connection an individual feels with a temporally distant future self--a
characteristic that is positively related to mental health and wellbeing. Our
system allows users to chat with a relatable yet AI-powered virtual version of
their future selves that is tuned to their future goals and personal qualities.
To make the conversation realistic, the system generates a "synthetic
memory"--a unique backstory for each user--that creates a throughline between
the user's present age (between 18-30) and their life at age 60. The "Future
You" character also adopts the persona of an age-progressed image of the user's
present self. After a brief interaction with the "Future You" character, users
reported decreased anxiety, and increased future self-continuity. This is the
first study successfully demonstrating the use of personalized AI-generated
characters to improve users' future self-continuity and wellbeing.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Toward General-Purpose Robots via Foundation Models: A <span class="highlight-title">Survey</span> and
  Meta-Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.08782v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.08782v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yafei Hu, Quanting Xie, Vidhi Jain, Jonathan Francis, Jay Patrikar, Nikhil Keetha, Seungchan Kim, Yaqi Xie, Tianyi Zhang, Hao-Shu Fang, Shibo Zhao, Shayegan Omidshafiei, Dong-Ki Kim, Ali-akbar Agha-mohammadi, Katia Sycara, Matthew Johnson-Roberson, Dhruv Batra, Xiaolong Wang, Sebastian Scherer, Chen Wang, Zsolt Kira, Fei Xia, Yonatan Bisk
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Building general-purpose robots that operate seamlessly in any environment,
with any object, and utilizing various skills to complete diverse tasks has
been a long-standing goal in Artificial Intelligence. However, as a community,
we have been constraining most robotic systems by designing them for specific
tasks, training them on specific datasets, and deploying them within specific
environments. These systems require extensively-labeled data and task-specific
models. When deployed in real-world scenarios, such systems face several
generalization issues and struggle to remain robust to distribution shifts.
Motivated by the impressive open-set performance and content generation
capabilities of web-scale, large-capacity pre-trained models (i.e., foundation
models) in research fields such as Natural Language Processing (NLP) and
Computer Vision (CV), we devote this survey to exploring (i) how these existing
foundation models from NLP and CV can be applied to the field of
general-purpose robotics, and also exploring (ii) what a robotics-specific
foundation model would look like. We begin by providing a generalized
formulation of how foundation models are used in robotics, and the fundamental
barriers to making generalist robots universally applicable. Next, we establish
a taxonomy to discuss current work exploring ways to leverage existing
foundation models for robotics and develop ones catered to robotics. Finally,
we discuss key challenges and promising future directions in using foundation
models for enabling general-purpose robotic systems. We encourage readers to
view our living GitHub repository 2 of resources, including papers reviewed in
this survey, as well as related projects and repositories for developing
foundation models for robotics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Read Over the Lines: Attacking LLMs and Toxicity Detection Systems with
  ASCII Art to Mask Profanity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18708v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18708v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sergey Berezin, Reza Farahbakhsh, Noel Crespi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a novel family of adversarial attacks that exploit the inability
of language models to interpret ASCII art. To evaluate these attacks, we
propose the ToxASCII benchmark and develop two custom ASCII art fonts: one
leveraging special tokens and another using text-filled letter shapes. Our
attacks achieve a perfect 1.0 Attack Success Rate across ten models, including
OpenAI's o1-preview and LLaMA 3.1.
  Warning: this paper contains examples of toxic language used for research
purposes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fine-Tuning and Deploying Large Language Models Over Edges: Issues and
  Approaches 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.10691v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.10691v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanjie Dong, Haijun Zhang, Chengming Li, Song Guo, Victor C. M. Leung, Xiping Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Since the invention of GPT2--1.5B in 2019, large language models (LLMs) have
transitioned from specialized models to versatile foundation models. The LLMs
exhibit impressive zero-shot ability, however, require fine-tuning on local
datasets and significant resources for deployment. Traditional fine-tuning
techniques with the first-order optimizers require substantial GPU memory that
exceeds mainstream hardware capability. Therefore, memory-efficient methods are
motivated to be investigated. Model compression techniques can reduce energy
consumption, operational costs, and environmental impact so that to support
sustainable artificial intelligence advancements. Additionally, large-scale
foundation models have expanded to create images, audio, videos, and
multi-modal contents, further emphasizing the need for efficient deployment.
Therefore, we are motivated to present a comprehensive overview of the
prevalent memory-efficient fine-tuning methods over the network edge. We also
review the state-of-the-art literatures on model compression to provide a
vision on deploying LLMs over the network edge.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unlabeled Debiasing in Downstream Tasks via Class-wise Low Variance
  Regularization <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19541v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19541v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shahed Masoudian, Markus Frohman, Navid Rekabsaz, Markus Schedl
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language models frequently inherit societal biases from their training data.
Numerous techniques have been proposed to mitigate these biases during both the
pre-training and fine-tuning stages. However, fine-tuning a pre-trained
debiased language model on a downstream task can reintroduce biases into the
model. Additionally, existing debiasing methods for downstream tasks either (i)
require labels of protected attributes (e.g., age, race, or political views)
that are often not available or (ii) rely on indicators of bias, which
restricts their applicability to gender debiasing since they rely on
gender-specific words. To address this, we introduce a novel debiasing
regularization technique based on the class-wise variance of embeddings.
Crucially, our method does not require attribute labels and targets any
attribute, thus addressing the shortcomings of existing debiasing methods. Our
experiments on encoder language models and three datasets demonstrate that our
method outperforms existing strong debiasing baselines that rely on target
attribute labels while maintaining performance on the target task.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Shaking Up VLMs: Comparing <span class="highlight-title">Transformer</span>s and Structured State Space
  Models for Vision & Language Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05395v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05395v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Georgios Pantazopoulos, Malvina Nikandrou, Alessandro Suglia, Oliver Lemon, Arash Eshghi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study explores replacing Transformers in Visual Language Models (VLMs)
with Mamba, a recent structured state space model (SSM) that demonstrates
promising performance in sequence modeling. We test models up to 3B parameters
under controlled conditions, showing that Mamba-based VLMs outperforms
Transformers-based VLMs in captioning, question answering, and reading
comprehension. However, we find that Transformers achieve greater performance
in visual grounding and the performance gap widens with scale. We explore two
hypotheses to explain this phenomenon: 1) the effect of task-agnostic visual
encoding on the updates of the hidden states, and 2) the difficulty in
performing visual grounding from the perspective of in-context multimodal
retrieval. Our results indicate that a task-aware encoding yields minimal
performance gains on grounding, however, Transformers significantly outperform
Mamba at in-context multimodal retrieval. Overall, Mamba shows promising
performance on tasks where the correct output relies on a summary of the image
but struggles when retrieval of explicit information from the context is
required.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Individual mapping of large polymorphic shrubs in high mountains using
  satellite images and deep learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.17985v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.17985v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rohaifa Khaldi, Siham Tabik, Sergio Puertas-Ruiz, Julio Peñas de Giles, José Antonio Hódar Correa, Regino Zamora, Domingo Alcaraz Segura
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Monitoring the distribution and size of long-living large shrubs, such as
junipers, is crucial for assessing the long-term impacts of global change on
high-mountain ecosystems. While deep learning models have shown remarkable
success in object segmentation, adapting these models to detect shrub species
with polymorphic nature remains challenging. In this research, we release a
large dataset of individual shrub delineations on freely available satellite
imagery and use an instance segmentation model to map all junipers over the
treeline for an entire biosphere reserve (Sierra Nevada, Spain). To optimize
performance, we introduced a novel dual data construction approach: using
photo-interpreted (PI) data for model development and fieldwork (FW) data for
validation. To account for the polymorphic nature of junipers during model
evaluation, we developed a soft version of the Intersection over Union metric.
Finally, we assessed the uncertainty of the resulting map in terms of canopy
cover and density of shrubs per size class. Our model achieved an F1-score in
shrub delineation of 87.87% on the PI data and 76.86% on the FW data. The R2
and RMSE of the observed versus predicted relationship were 0.63 and 6.67% for
canopy cover, and 0.90 and 20.62 for shrub density. The greater density of
larger shrubs in lower altitudes and smaller shrubs in higher altitudes
observed in the model outputs was also present in the PI and FW data,
suggesting an altitudinal uplift in the optimal performance of the species.
This study demonstrates that deep learning applied on freely available
high-resolution satellite imagery is useful to detect medium to large shrubs of
high ecological value at the regional scale, which could be expanded to other
high-mountains worldwide and to historical and forthcoming imagery.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>24 pages, 11 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Stochastic Direct Search Method for Blind Resource Allocation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2210.05222v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2210.05222v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Juliette Achddou, Olivier Cappe, Aurélien Garivier
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Motivated by programmatic advertising optimization, we consider the task of
sequentially allocating budget across a set of resources. At every time step, a
feasible allocation is chosen and only a corresponding random return is
observed. The goal is to maximize the cumulative expected sum of returns. This
is a realistic model for budget allocation across subdivisions of marketing
campaigns, with the objective of maximizing the number of conversions. We study
direct search (also known as pattern search) methods for linearly constrained
and derivative-free optimization in the presence of noise, which apply in
particular to sequential budget allocation. These algorithms, which do not rely
on hierarchical partitioning of the resource space, are easy to implement; they
respect the operational constraints of resource allocation by avoiding
evaluation outside of the feasible domain; and they are also compatible with
warm start by being (approximate) descent algorithms. However, they have not
yet been analyzed from the perspective of cumulative regret. We show that
direct search methods achieves finite regret in the deterministic and
unconstrained case. In the presence of evaluation noise and linear constraints,
we propose a simple extension of direct search that achieves a regret
upper-bound of the order of $T^{2/3}$. We also propose an accelerated version
of the algorithm, relying on repeated sequential testing, that significantly
improves the practical behavior of the approach.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multi-Designated Detector Watermarking for Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.17518v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.17518v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhengan Huang, Gongxian Zeng, Xin Mu, Yu Wang, Yue Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we initiate the study of \emph{multi-designated detector
watermarking (MDDW)} for large language models (LLMs). This technique allows
model providers to generate watermarked outputs from LLMs with two key
properties: (i) only specific, possibly multiple, designated detectors can
identify the watermarks, and (ii) there is no perceptible degradation in the
output quality for ordinary users. We formalize the security definitions for
MDDW and present a framework for constructing MDDW for any LLM using
multi-designated verifier signatures (MDVS). Recognizing the significant
economic value of LLM outputs, we introduce claimability as an optional
security feature for MDDW, enabling model providers to assert ownership of LLM
outputs within designated-detector settings. To support claimable MDDW, we
propose a generic transformation converting any MDVS to a claimable MDVS. Our
implementation of the MDDW scheme highlights its advanced functionalities and
flexibility over existing methods, with satisfactory performance metrics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Segment-Anything Models Achieve Zero-shot Robustness in Autonomous
  Driving 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.09839v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.09839v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jun Yan, Pengyu Wang, Danni Wang, Weiquan Huang, Daniel Watzenig, Huilin Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Semantic segmentation is a significant perception task in autonomous driving.
It suffers from the risks of adversarial examples. In the past few years, deep
learning has gradually transitioned from convolutional neural network (CNN)
models with a relatively small number of parameters to foundation models with a
huge number of parameters. The segment-anything model (SAM) is a generalized
image segmentation framework that is capable of handling various types of
images and is able to recognize and segment arbitrary objects in an image
without the need to train on a specific object. It is a unified model that can
handle diverse downstream tasks, including semantic segmentation, object
detection, and tracking. In the task of semantic segmentation for autonomous
driving, it is significant to study the zero-shot adversarial robustness of
SAM. Therefore, we deliver a systematic empirical study on the robustness of
SAM without additional training. Based on the experimental results, the
zero-shot adversarial robustness of the SAM under the black-box corruptions and
white-box adversarial attacks is acceptable, even without the need for
additional training. The finding of this study is insightful in that the
gigantic model parameters and huge amounts of training data lead to the
phenomenon of emergence, which builds a guarantee of adversarial robustness.
SAM is a vision foundation model that can be regarded as an early prototype of
an artificial general intelligence (AGI) pipeline. In such a pipeline, a
unified model can handle diverse tasks. Therefore, this research not only
inspects the impact of vision foundation models on safe autonomous driving but
also provides a perspective on developing trustworthy AGI. The code is
available at: https://github.com/momo1986/robust_sam_iv.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to IAVVC 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Transductive Active Learning: Theory and Applications 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.15898v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.15898v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jonas Hübotter, Bhavya Sukhija, Lenart Treven, Yarden As, Andreas Krause
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We generalize active learning to address real-world settings with concrete
prediction targets where sampling is restricted to an accessible region of the
domain, while prediction targets may lie outside this region. We analyze a
family of decision rules that sample adaptively to minimize uncertainty about
prediction targets. We are the first to show, under general regularity
assumptions, that such decision rules converge uniformly to the smallest
possible uncertainty obtainable from the accessible data. We demonstrate their
strong sample efficiency in two key applications: Active few-shot fine-tuning
of large neural networks and safe Bayesian optimization, where they improve
significantly upon the state-of-the-art.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: substantial text overlap with arXiv:2402.15441</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Model-based Preference Optimization in Abstractive Summarization without
  Human Feedback <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18618v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18618v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jaepill Choi, Kyubyung Chae, Jiwoo Song, Yohan Jo, Taesup Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In abstractive summarization, the challenge of producing concise and accurate
summaries arises from the vast amount of information contained in the source
document. Consequently, although Large Language Models (LLMs) can generate
fluent text, they often introduce inaccuracies by hallucinating content not
found in the original source. While supervised fine-tuning methods that
maximize likelihood contribute to this issue, they do not consistently enhance
the faithfulness of the summaries. Preference-based optimization methods, such
as Direct Preference Optimization (DPO), can further refine the model to align
with human preferences. However, these methods still heavily depend on costly
human feedback. In this work, we introduce a novel and straightforward approach
called Model-based Preference Optimization (MPO) to fine-tune LLMs for improved
summarization abilities without any human feedback. By leveraging the model's
inherent summarization capabilities, we create a preference dataset that is
fully generated by the model using different decoding strategies. Our
experiments on standard summarization datasets and various metrics demonstrate
that our proposed MPO significantly enhances the quality of generated summaries
without relying on human feedback.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Generalized Learning of Coefficients in Spectral Graph Convolutional
  Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04813v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04813v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mustafa Coşkun, Ananth Grama, Mehmet Koyutürk
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spectral Graph Convolutional Networks (GCNs) have gained popularity in graph
machine learning applications due, in part, to their flexibility in
specification of network propagation rules. These propagation rules are often
constructed as polynomial filters whose coefficients are learned using label
information during training. In contrast to learned polynomial filters,
explicit filter functions are useful in capturing relationships between network
topology and distribution of labels across the network. A number of algorithms
incorporating either approach have been proposed; however the relationship
between filter functions and polynomial approximations is not fully resolved.
This is largely due to the ill-conditioned nature of the linear systems that
must be solved to derive polynomial approximations of filter functions. To
address this challenge, we propose a novel Arnoldi orthonormalization-based
algorithm, along with a unifying approach, called G-Arnoldi-GCN that can
efficiently and effectively approximate a given filter function with a
polynomial. We evaluate G-Arnoldi-GCN in the context of multi-class node
classification across ten datasets with diverse topological characteristics.
Our experiments show that G-Arnoldi-GCN consistently outperforms
state-of-the-art methods when suitable filter functions are employed. Overall,
G-Arnoldi-GCN opens important new directions in graph machine learning by
enabling the explicit design and application of diverse filter functions. Code
link: https://github.com/mustafaCoskunAgu/GArnoldi-GCN
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ UniSumEval: Towards Unified, Fine-Grained, Multi-Dimensional
  Summarization Evaluation for LLMs <span class="chip">EMNLP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19898v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19898v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuho Lee, Taewon Yun, Jason Cai, Hang Su, Hwanjun Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing benchmarks for summarization quality evaluation often lack diverse
input scenarios, focus on narrowly defined dimensions (e.g., faithfulness), and
struggle with subjective and coarse-grained annotation schemes. To address
these shortcomings, we create UniSumEval benchmark, which extends the range of
input context (e.g., domain, length) and provides fine-grained,
multi-dimensional annotations. We use AI assistance in data creation,
identifying potentially hallucinogenic input texts, and also helping human
annotators reduce the difficulty of fine-grained annotation tasks. With
UniSumEval, we benchmark nine latest language models as summarizers, offering
insights into their performance across varying input contexts and evaluation
dimensions. Furthermore, we conduct a thorough comparison of SOTA automated
summary evaluators. Our benchmark data will be available at
https://github.com/DISL-Lab/UniSumEval-v1.0.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP-Findings 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Recursive deep learning framework for forecasting the decadal world
  economic outlook 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2301.10874v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2301.10874v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianyi Wang, Rodney Beard, John Hawkins, Rohitash Chandra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The gross domestic product (GDP) is the most widely used indicator in
macroeconomics and the main tool for measuring a country's economic output. Due
to the diversity and complexity of the world economy, a wide range of models
have been used, but there are challenges in making decadal GDP forecasts given
unexpected changes such as emergence of catastrophic world events including
pandemics and wars. Deep learning models are well suited for modelling temporal
sequences and time series forecasting. In this paper, we develop a deep
learning framework to forecast the GDP growth rate of the world economy over a
decade. We use the Penn World Table as the data source featuring 13 countries
prior to the COVID-19 pandemic, such as Australia, China, India, and the United
States. We present a recursive deep learning framework to predict the GDP
growth rate in the next ten years. We test prominent deep learning models and
compare their results with traditional econometric models for selected
developed and developing countries. Our decadal forecasts reveal that that most
of the developed countries would experience economic growth slowdown,
stagnation and even recession within five years (2020-2024). Furthermore, our
model forecasts show that only China, France, and India would experience stable
GDP growth.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Obliviate: Neutralizing Task-agnostic Backdoors within the
  Parameter-efficient Fine-tuning Paradigm 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.14119v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.14119v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jaehan Kim, Minkyoo Song, Seung Ho Na, Seungwon Shin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Parameter-efficient fine-tuning (PEFT) has become a key training strategy for
large language models. However, its reliance on fewer trainable parameters
poses security risks, such as task-agnostic backdoors. Despite their severe
impact on a wide range of tasks, there is no practical defense solution
available that effectively counters task-agnostic backdoors within the context
of PEFT. In this study, we introduce Obliviate, a PEFT-integrable backdoor
defense. We develop two techniques aimed at amplifying benign neurons within
PEFT layers and penalizing the influence of trigger tokens. Our evaluations
across three major PEFT architectures show that our method can significantly
reduce the attack success rate of the state-of-the-art task-agnostic backdoors
(83.6%$\downarrow$). Furthermore, our method exhibits robust defense
capabilities against both task-specific backdoors and adaptive attacks. Source
code will be obtained at https://github.com/obliviateARR/Obliviate.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Identifiable Shared Component Analysis of Unpaired Multimodal Mixtures 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19422v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19422v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Subash Timilsina, Sagar Shrestha, Xiao Fu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A core task in multi-modal learning is to integrate information from multiple
feature spaces (e.g., text and audio), offering modality-invariant essential
representations of data. Recent research showed that, classical tools such as
{\it canonical correlation analysis} (CCA) provably identify the shared
components up to minor ambiguities, when samples in each modality are generated
from a linear mixture of shared and private components. Such identifiability
results were obtained under the condition that the cross-modality samples are
aligned/paired according to their shared information. This work takes a step
further, investigating shared component identifiability from multi-modal linear
mixtures where cross-modality samples are unaligned. A distribution divergence
minimization-based loss is proposed, under which a suite of sufficient
conditions ensuring identifiability of the shared components are derived. Our
conditions are based on cross-modality distribution discrepancy
characterization and density-preserving transform removal, which are much
milder than existing studies relying on independent component analysis. More
relaxed conditions are also provided via adding reasonable structural
constraints, motivated by available side information in various applications.
The identifiability claims are thoroughly validated using synthetic and
real-world data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Redefining Data Pairing for Motion Retargeting Leveraging a Human Body
  Prior <span class="chip">IROS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.13208v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.13208v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiyana Figuera, Soogeun Park, Hyemin Ahn
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose MR HuBo(Motion Retargeting leveraging a HUman BOdy prior), a
cost-effective and convenient method to collect high-quality upper body paired
<robot, human> pose data, which is essential for data-driven motion retargeting
methods. Unlike existing approaches which collect <robot, human> pose data by
converting human MoCap poses into robot poses, our method goes in reverse. We
first sample diverse random robot poses, and then convert them into human
poses. However, since random robot poses can result in extreme and infeasible
human poses, we propose an additional technique to sort out extreme poses by
exploiting a human body prior trained from a large amount of human pose data.
Our data collection method can be used for any humanoid robots, if one designs
or optimizes the system's hyperparameters which include a size scale factor and
the joint angle ranges for sampling. In addition to this data collection
method, we also present a two-stage motion retargeting neural network that can
be trained via supervised learning on a large amount of paired data. Compared
to other learning-based methods trained via unsupervised learning, we found
that our deep neural network trained with ample high-quality paired data
achieved notable performance. Our experiments also show that our data filtering
method yields better retargeting results than training the model with raw and
noisy data. Our code and video results are available on
https://sites.google.com/view/mr-hubo/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 5 Figures, Accepted at IROS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Identifying Knowledge Editing Types in Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19663v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19663v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaopeng Li, Shangwen Wang, Shezheng Song, Bin Ji, Huijun Liu, Shasha Li, Jun Ma, Jie Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge editing has emerged as an efficient technology for updating the
knowledge of large language models (LLMs), attracting increasing attention in
recent years. However, there is a lack of effective measures to prevent the
malicious misuse of this technology, which could lead to harmful edits in LLMs.
These malicious modifications could cause LLMs to generate toxic content,
misleading users into inappropriate actions. In front of this risk, we
introduce a new task, Knowledge Editing Type Identification (KETI), aimed at
identifying different types of edits in LLMs, thereby providing timely alerts
to users when encountering illicit edits. As part of this task, we propose
KETIBench, which includes five types of harmful edits covering most popular
toxic types, as well as one benign factual edit. We develop four classical
classification models and three BERT-based models as baseline identifiers for
both open-source and closed-source LLMs. Our experimental results, across 42
trials involving two models and three knowledge editing methods, demonstrate
that all seven baseline identifiers achieve decent identification performance,
highlighting the feasibility of identifying malicious edits in LLMs. Additional
analyses reveal that the performance of the identifiers is independent of the
reliability of the knowledge editing methods and exhibits cross-domain
generalization, enabling the identification of edits from unknown sources. All
data and code are available in https://github.com/xpq-tech/KETI. Warning: This
paper contains examples of toxic text.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Foundation Model for Zero-shot Logical Query Reasoning <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.07198v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.07198v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mikhail Galkin, Jincheng Zhou, Bruno Ribeiro, Jian Tang, Zhaocheng Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Complex logical query answering (CLQA) in knowledge graphs (KGs) goes beyond
simple KG completion and aims at answering compositional queries comprised of
multiple projections and logical operations. Existing CLQA methods that learn
parameters bound to certain entity or relation vocabularies can only be applied
to the graph they are trained on which requires substantial training time
before being deployed on a new graph. Here we present UltraQuery, the first
foundation model for inductive reasoning that can zero-shot answer logical
queries on any KG. The core idea of UltraQuery is to derive both projections
and logical operations as vocabulary-independent functions which generalize to
new entities and relations in any KG. With the projection operation initialized
from a pre-trained inductive KG reasoning model, UltraQuery can solve CLQA on
any KG after finetuning on a single dataset. Experimenting on 23 datasets,
UltraQuery in the zero-shot inference mode shows competitive or better query
answering performance than best available baselines and sets a new state of the
art on 15 of them.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CPL: Critical Plan Step Learning Boosts LLM Generalization in Reasoning
  Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.08642v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.08642v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianlong Wang, Junzhe Chen, Xueting Han, Jing Bai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Post-training, particularly reinforcement learning (RL) using
self-play-generated data, has become a new learning paradigm for large language
models (LLMs). However, scaling RL to develop a general reasoner remains a
research challenge, as existing methods focus on task-specific reasoning
without adequately addressing generalization across a broader range of tasks.
Moreover, unlike traditional RL with limited action space, LLMs operate in an
infinite space, making it crucial to search for valuable and diverse strategies
to solve problems effectively. To address this, we propose searching within the
action space on high-level abstract plans to enhance model generalization and
introduce Critical Plan Step Learning (CPL), comprising: 1) searching on plan,
using Monte Carlo Tree Search (MCTS) to explore diverse plan steps in
multi-step reasoning tasks, and 2) learning critical plan steps through
Step-level Advantage Preference Optimization (Step-APO), which integrates
advantage estimates for step preference obtained via MCTS into Direct
Preference Optimization (DPO). This combination helps the model effectively
learn critical plan steps, enhancing both reasoning capabilities and
generalization. Experimental results demonstrate that our method, trained
exclusively on GSM8K and MATH, not only significantly improves performance on
GSM8K (+10.5%) and MATH (+6.5%), but also enhances out-of-domain reasoning
benchmarks, such as HumanEval (+12.2%), GPQA (+8.6%), ARC-C (+4.0%), MMLU-STEM
(+2.2%), and BBH (+1.8%).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Weak-to-Strong Reasoning <span class="chip">EMNLP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13647v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13647v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuqing Yang, Yan Ma, Pengfei Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  When large language models (LLMs) exceed human-level capabilities, it becomes
increasingly challenging to provide full-scale and accurate supervision for
these models. Weak-to-strong learning, which leverages a less capable model to
unlock the latent abilities of a stronger model, proves valuable in this
context. Yet, the efficacy of this approach for complex reasoning tasks is
still untested. Furthermore, tackling reasoning tasks under the weak-to-strong
setting currently lacks efficient methods to avoid blindly imitating the weak
supervisor including its errors. In this paper, we introduce a progressive
learning framework that enables the strong model to autonomously refine its
training data, without requiring input from either a more advanced model or
human-annotated data. This framework begins with supervised fine-tuning on a
selective small but high-quality dataset, followed by preference optimization
on contrastive samples identified by the strong model itself. Extensive
experiments on the GSM8K and MATH datasets demonstrate that our method
significantly enhances the reasoning capabilities of Llama2-70b using three
separate weak models. This method is further validated in a forward-looking
experimental setup, where Llama3-8b-instruct effectively supervises Llama3-70b
on the highly challenging OlympicArena dataset. This work paves the way for a
more scalable and sophisticated strategy to enhance AI reasoning powers. All
relevant code and resources are available in
\url{https://github.com/GAIR-NLP/weak-to-strong-reasoning}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>EMNLP Findings 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ How Far Are We from Intelligent Visual Deductive Reasoning? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.04732v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.04732v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yizhe Zhang, He Bai, Ruixiang Zhang, Jiatao Gu, Shuangfei Zhai, Josh Susskind, Navdeep Jaitly
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vision-Language Models (VLMs) have recently demonstrated incredible strides
on diverse vision language tasks. We dig into vision-based deductive reasoning,
a more sophisticated but less explored realm, and find previously unexposed
blindspots in the current SOTA VLMs. Specifically, we leverage Raven's
Progressive Matrices (RPMs), to assess VLMs' abilities to perform multi-hop
relational and deductive reasoning relying solely on visual clues. We perform
comprehensive evaluations of several popular VLMs employing standard strategies
such as in-context learning, self-consistency, and Chain-of-thoughts (CoT) on
three diverse datasets, including the Mensa IQ test, IntelligenceTest, and
RAVEN. The results reveal that despite the impressive capabilities of LLMs in
text-based reasoning, we are still far from achieving comparable proficiency in
visual deductive reasoning. We found that certain standard strategies that are
effective when applied to LLMs do not seamlessly translate to the challenges
presented by visual reasoning tasks. A detailed analysis reveals that VLMs
struggle to solve these tasks mainly because they are unable to perceive and
comprehend multiple, confounding abstract patterns in RPM examples.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>COLM 2024. https://github.com/apple/ml-rpm-bench</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Identifying Spurious Correlations using Counterfactual Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.02186v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.02186v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joseph Paul Cohen, Louis Blankemeier, Akshay Chaudhari
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Models driven by spurious correlations often yield poor generalization
performance. We propose the counterfactual (CF) alignment method to detect and
quantify spurious correlations of black box classifiers. Our methodology is
based on counterfactual images generated with respect to one classifier being
input into other classifiers to see if they also induce changes in the outputs
of these classifiers. The relationship between these responses can be
quantified and used to identify specific instances where a spurious correlation
exists. This is validated by observing intuitive trends in a face-attribute
face-attribute and waterbird classifiers, as well as by fabricating spurious
correlations and detecting their presence, both visually and quantitatively.
Furthermore, utilizing the CF alignment method, we demonstrate that we can
evaluate robust optimization methods (GroupDRO, JTT, and FLAC) by detecting a
reduction in spurious correlations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TRANSAGENT: An LLM-Based Multi-Agent System for Code Translation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19894v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19894v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiqiang Yuan, Weitong Chen, Hanlin Wang, Kai Yu, Xin Peng, Yiling Lou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Code translation converts code from one programming language to another while
maintaining its original functionality, which is crucial for software
migration, system refactoring, and cross-platform development. Traditional
rule-based methods rely on manually-written rules, which can be time-consuming
and often result in less readable code. To overcome this, learning-based
methods have been developed, leveraging parallel data to train models for
automated code translation. More recently, the advance of Large Language Models
(LLMs) further boosts learning-based code translation. Although promising,
LLM-translated program still suffers from diverse quality issues (e.g., syntax
errors and semantic errors). In particular, it can be challenging for LLMs to
self-debug these errors when simply provided with the corresponding error
messages.
  In this work, we propose a novel LLM-based multi-agent system TRANSAGENT,
which enhances LLM-based code translation by fixing the syntax errors and
semantic errors with the synergy between four LLM-based agents, including
Initial Code Translator, Syntax Error Fixer, Code Aligner, and Semantic Error
Fixer. The main insight of TRANSAGENT is to first localize the error code block
in the target program based on the execution alignment between the target and
source program, which can narrow down the fixing space and thus lower down the
fixing difficulties. To evaluate TRANSAGENT, we first construct a new benchmark
from recent programming tasks to mitigate the potential data leakage issue. On
our benchmark, TRANSAGENT outperforms the latest LLM-based code translation
technique UniTrans in both translation effectiveness and efficiency;
additionally, our evaluation on different LLMs show the generalization of
TRANSAGENT and our ablation study shows the contribution of each agent.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evaluating Image Hallucination in Text-to-Image Generation with
  Question-Answering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.12784v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.12784v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Youngsun Lim, Hojun Choi, Pin-Yu Chen, Hyunjung Shim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the impressive success of text-to-image (TTI) generation models,
existing studies overlook the issue of whether these models accurately convey
factual information. In this paper, we focus on the problem of image
hallucination, where images created by generation models fail to faithfully
depict factual content. To address this, we introduce I-HallA (Image
Hallucination evaluation with Question Answering), a novel automated evaluation
metric that measures the factuality of generated images through visual question
answering (VQA). We also introduce I-HallA v1.0, a curated benchmark dataset
for this purpose. As part of this process, we develop a pipeline that generates
high-quality question-answer pairs using multiple GPT-4 Omni-based agents, with
human judgments to ensure accuracy. Our evaluation protocols measure image
hallucination by testing if images from existing text-to-image models can
correctly respond to these questions. The I-HallA v1.0 dataset comprises 1.2K
diverse image-text pairs across nine categories with 1,000 rigorously curated
questions covering various compositional challenges. We evaluate five
text-to-image models using I-HallA and reveal that these state-of-the-art
models often fail to accurately convey factual information. Moreover, we
validate the reliability of our metric by demonstrating a strong Spearman
correlation (rho=0.95) with human judgments. We believe our benchmark dataset
and metric can serve as a foundation for developing factually accurate
text-to-image generation models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Cloud-based XAI Services for Assessing Open Repository Models Under
  Adversarial Attacks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.12261v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.12261v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zerui Wang, Yan Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The opacity of AI models necessitates both validation and evaluation before
their integration into services. To investigate these models, explainable AI
(XAI) employs methods that elucidate the relationship between input features
and output predictions. The operations of XAI extend beyond the execution of a
single algorithm, involving a series of activities that include preprocessing
data, adjusting XAI to align with model parameters, invoking the model to
generate predictions, and summarizing the XAI results. Adversarial attacks are
well-known threats that aim to mislead AI models. The assessment complexity,
especially for XAI, increases when open-source AI models are subject to
adversarial attacks, due to various combinations. To automate the numerous
entities and tasks involved in XAI-based assessments, we propose a cloud-based
service framework that encapsulates computing components as microservices and
organizes assessment tasks into pipelines. The current XAI tools are not
inherently service-oriented. This framework also integrates open XAI tool
libraries as part of the pipeline composition. We demonstrate the application
of XAI services for assessing five quality attributes of AI models: (1)
computational cost, (2) performance, (3) robustness, (4) explanation deviation,
and (5) explanation resilience across computer vision and tabular cases. The
service framework generates aggregated analysis that showcases the quality
attributes for more than a hundred combination scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>2024 IEEE International Conference on Software Services Engineering
  (SSE)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Block-Attention for Efficient RAG 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15355v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15355v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        East Sun, Yan Wang, Lan Tian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Block-Attention, an attention mechanism designed to address the
increased inference latency and cost in Retrieval-Augmented Generation (RAG)
scenarios. Traditional approaches often encode the entire context. Instead,
Block-Attention divides retrieved documents into discrete blocks, with each
block independently calculating key-value (KV) states except for the final
block. In RAG scenarios, by defining each passage as a block, Block-Attention
enables us to reuse the KV states of passages that have been seen before,
thereby significantly reducing the latency and the computation overhead during
inference. The implementation of Block-Attention involves block segmentation,
position re-encoding, and fine-tuning the LLM to adapt to the Block-Attention
mechanism. Experiments on four RAG benchmarks demonstrate that after block
fine-tuning, the Block-Attention model achieves performance comparable to
self-attention models (68.4\% vs 67.9\% on Llama3) or even superior performance
(62.8\% vs 59.6\% on Mistral). Notably, Block-Attention significantly reduces
the time to first token (TTFT) and floating point operations (FLOPs) to a very
low level. It only takes 45 ms to output the first token for an input sequence
with a total length of 32K. Compared to the self-attention models, the time
consumption and corresponding FLOPs are reduced by 98.7\% and 99.8\%,
respectively.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring Semantic Clustering in Deep Reinforcement Learning for Video
  Games 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.17411v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.17411v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liang Zhang, Justin Lieffers, Adarsh Pyarelal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we investigate the semantic clustering properties of deep
reinforcement learning (DRL) for video games, enriching our understanding of
the internal dynamics of DRL and advancing its interpretability. In this
context, semantic clustering refers to the inherent capacity of neural networks
to internally group video inputs based on semantic similarity. To achieve this,
we propose a novel DRL architecture that integrates a semantic clustering
module featuring both feature dimensionality reduction and online clustering.
This module seamlessly integrates into the DRL training pipeline, addressing
instability issues observed in previous t-SNE-based analysis methods and
eliminating the necessity for extensive manual annotation of semantic analysis.
Through experiments, we validate the effectiveness of the proposed module and
the semantic clustering properties in DRL for video games. Additionally, based
on these properties, we introduce new analytical methods to help understand the
hierarchical structure of policies and the semantic distribution within the
feature space.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Almost Sure Convergence of Average Reward Temporal Difference Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19546v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19546v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ethan Blaser, Shangtong Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tabular average reward Temporal Difference (TD) learning is perhaps the
simplest and the most fundamental policy evaluation algorithm in average reward
reinforcement learning. After at least 25 years since its discovery, we are
finally able to provide a long-awaited almost sure convergence analysis.
Namely, we are the first to prove that, under very mild conditions, tabular
average reward TD converges almost surely to a sample path dependent fixed
point. Key to this success is a new general stochastic approximation result
concerning nonexpansive mappings with Markovian and additive noise, built on
recent advances in stochastic Krasnoselskii-Mann iterations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ReactZyme: A Benchmark for Enzyme-Reaction Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.13659v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.13659v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenqing Hua, Bozitao Zhong, Sitao Luan, Liang Hong, Guy Wolf, Doina Precup, Shuangjia Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Enzymes, with their specific catalyzed reactions, are necessary for all
aspects of life, enabling diverse biological processes and adaptations.
Predicting enzyme functions is essential for understanding biological pathways,
guiding drug development, enhancing bioproduct yields, and facilitating
evolutionary studies. Addressing the inherent complexities, we introduce a new
approach to annotating enzymes based on their catalyzed reactions. This method
provides detailed insights into specific reactions and is adaptable to newly
discovered reactions, diverging from traditional classifications by protein
family or expert-derived reaction classes. We employ machine learning
algorithms to analyze enzyme reaction datasets, delivering a much more refined
view on the functionality of enzymes. Our evaluation leverages the largest
enzyme-reaction dataset to date, derived from the SwissProt and Rhea databases
with entries up to January 8, 2024. We frame the enzyme-reaction prediction as
a retrieval problem, aiming to rank enzymes by their catalytic ability for
specific reactions. With our model, we can recruit proteins for novel reactions
and predict reactions in novel proteins, facilitating enzyme discovery and
function annotation (https://github.com/WillHua127/ReactZyme).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Provably Efficient Exploration in Inverse Constrained Reinforcement
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15963v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15963v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bo Yue, Jian Li, Guiliang Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To obtain the optimal constraints in complex environments, Inverse
Constrained Reinforcement Learning (ICRL) seeks to recover these constraints
from expert demonstrations in a data-driven manner. Existing ICRL algorithms
collect training samples from an interactive environment. However, the efficacy
and efficiency of these sampling strategies remain unknown. To bridge this gap,
we introduce a strategic exploration framework with guaranteed efficiency.
Specifically, we define a feasible constraint set for ICRL problems and
investigate how expert policy and environmental dynamics influence the
optimality of constraints. Motivated by our findings, we propose two
exploratory algorithms to achieve efficient constraint inference via 1)
dynamically reducing the bounded aggregate error of cost estimation and 2)
strategically constraining the exploration policy. Both algorithms are
theoretically grounded with tractable sample complexity. We empirically
demonstrate the performance of our algorithms under various environments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unveiling Factual Recall Behaviors of Large Language Models through
  Knowledge Neurons 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.03247v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.03247v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yifei Wang, Yuheng Chen, Wanting Wen, Yu Sheng, Linjing Li, Daniel Dajun Zeng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we investigate whether Large Language Models (LLMs) actively
recall or retrieve their internal repositories of factual knowledge when faced
with reasoning tasks. Through an analysis of LLMs' internal factual recall at
each reasoning step via Knowledge Neurons, we reveal that LLMs fail to harness
the critical factual associations under certain circumstances. Instead, they
tend to opt for alternative, shortcut-like pathways to answer reasoning
questions. By manually manipulating the recall process of parametric knowledge
in LLMs, we demonstrate that enhancing this recall process directly improves
reasoning performance whereas suppressing it leads to notable degradation.
Furthermore, we assess the effect of Chain-of-Thought (CoT) prompting, a
powerful technique for addressing complex reasoning tasks. Our findings
indicate that CoT can intensify the recall of factual knowledge by encouraging
LLMs to engage in orderly and reliable reasoning. Furthermore, we explored how
contextual conflicts affect the retrieval of facts during the reasoning process
to gain a comprehensive understanding of the factual recall behaviors of LLMs.
Code and data will be available soon.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy
  Curvature of Attention <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.00760v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.00760v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Susung Hong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Conditional diffusion models have shown remarkable success in visual content
generation, producing high-quality samples across various domains, largely due
to classifier-free guidance (CFG). Recent attempts to extend guidance to
unconditional models have relied on heuristic techniques, resulting in
suboptimal generation quality and unintended effects. In this work, we propose
Smoothed Energy Guidance (SEG), a novel training- and condition-free approach
that leverages the energy-based perspective of the self-attention mechanism to
enhance image generation. By defining the energy of self-attention, we
introduce a method to reduce the curvature of the energy landscape of attention
and use the output as the unconditional prediction. Practically, we control the
curvature of the energy landscape by adjusting the Gaussian kernel parameter
while keeping the guidance scale parameter fixed. Additionally, we present a
query blurring method that is equivalent to blurring the entire attention
weights without incurring quadratic complexity in the number of tokens. In our
experiments, SEG achieves a Pareto improvement in both quality and the
reduction of side effects. The code is available at
https://github.com/SusungHong/SEG-SDXL.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Automatic Quantification of Serial PET/CT Images for Pediatric Hodgkin
  Lymphoma Patients Using a Longitudinally-Aware Segmentation Network 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.08611v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.08611v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xin Tie, Muheon Shin, Changhee Lee, Scott B. Perlman, Zachary Huemann, Amy J. Weisman, Sharon M. Castellino, Kara M. Kelly, Kathleen M. McCarten, Adina L. Alazraki, Junjie Hu, Steve Y. Cho, Tyler J. Bradshaw
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  $\textbf{Purpose}$: Automatic quantification of longitudinal changes in PET
scans for lymphoma patients has proven challenging, as residual disease in
interim-therapy scans is often subtle and difficult to detect. Our goal was to
develop a longitudinally-aware segmentation network (LAS-Net) that can quantify
serial PET/CT images for pediatric Hodgkin lymphoma patients.
$\textbf{Materials and Methods}$: This retrospective study included baseline
(PET1) and interim (PET2) PET/CT images from 297 patients enrolled in two
Children's Oncology Group clinical trials (AHOD1331 and AHOD0831). LAS-Net
incorporates longitudinal cross-attention, allowing relevant features from PET1
to inform the analysis of PET2. Model performance was evaluated using Dice
coefficients for PET1 and detection F1 scores for PET2. Additionally, we
extracted and compared quantitative PET metrics, including metabolic tumor
volume (MTV) and total lesion glycolysis (TLG) in PET1, as well as qPET and
$\Delta$SUVmax in PET2, against physician measurements. We quantified their
agreement using Spearman's $\rho$ correlations and employed bootstrap
resampling for statistical analysis. $\textbf{Results}$: LAS-Net detected
residual lymphoma in PET2 with an F1 score of 0.606 (precision/recall:
0.615/0.600), outperforming all comparator methods (P<0.01). For baseline
segmentation, LAS-Net achieved a mean Dice score of 0.772. In PET
quantification, LAS-Net's measurements of qPET, $\Delta$SUVmax, MTV and TLG
were strongly correlated with physician measurements, with Spearman's $\rho$ of
0.78, 0.80, 0.93 and 0.96, respectively. The performance remained high, with a
slight decrease, in an external testing cohort. $\textbf{Conclusion}$: LAS-Net
demonstrated significant improvements in quantifying PET metrics across serial
scans, highlighting the value of longitudinal awareness in evaluating
multi-time-point imaging datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>There are 6 figures and 4 tables in the main text. The supplementary
  material is appended to the main text</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Using Contrastive Learning with Generative Similarity to Learn Spaces
  that Capture Human Inductive Biases 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.19420v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.19420v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Raja Marjieh, Sreejan Kumar, Declan Campbell, Liyi Zhang, Gianluca Bencomo, Jake Snell, Thomas L. Griffiths
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Humans rely on strong inductive biases to learn from few examples and
abstract useful information from sensory data. Instilling such biases in
machine learning models has been shown to improve their performance on various
benchmarks including few-shot learning, robustness, and alignment. However,
finding effective training procedures to achieve that goal can be challenging
as psychologically-rich training data such as human similarity judgments are
expensive to scale, and Bayesian models of human inductive biases are often
intractable for complex, realistic domains. Here, we address this challenge by
introducing a Bayesian notion of generative similarity whereby two datapoints
are considered similar if they are likely to have been sampled from the same
distribution. This measure can be applied to complex generative processes,
including probabilistic programs. We show that generative similarity can be
used to define a contrastive learning objective even when its exact form is
intractable, enabling learning of spatial embeddings that express specific
inductive biases. We demonstrate the utility of our approach by showing that it
can be used to capture human inductive biases for geometric shapes, distinguish
different abstract drawing styles that are parameterized by probabilistic
programs, and capture abstract high-level categories that enable
generalization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Closed-Form Interpretation of Neural Network Classifiers with Symbolic
  Gradients 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.04978v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.04978v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sebastian Johann Wetzel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  I introduce a unified framework for finding a closed-form interpretation of
any single neuron in an artificial neural network. Using this framework I
demonstrate how to interpret neural network classifiers to reveal closed-form
expressions of the concepts encoded in their decision boundaries. In contrast
to neural network-based regression, for classification, it is in general
impossible to express the neural network in the form of a symbolic equation
even if the neural network itself bases its classification on a quantity that
can be written as a closed-form equation. The interpretation framework is based
on embedding trained neural networks into an equivalence class of functions
that encode the same concept. I interpret these neural networks by finding an
intersection between the equivalence class and human-readable equations defined
by a symbolic search space. The approach is not limited to classifiers or full
neural networks and can be applied to arbitrary neurons in hidden layers or
latent spaces.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Machine Learning <span class="chip" style="font-size: 60%">81</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Iteration of Thought: Leveraging Inner Dialogue for Autonomous Large
  Language Model Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.12618v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.12618v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Santosh Kumar Radha, Yasamin Nouri Jelyani, Ara Ghukasyan, Oktay Goktas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Iterative human engagement is a common and effective means of leveraging the
advanced language processing power of large language models (LLMs). Using
well-structured prompts in a conversational manner, human users can effectively
influence an LLM to develop more thoughtful and accurate responses. Motivated
by this insight, we propose the Iteration of Thought (IoT) framework for
enhancing LLM responses by generating "thought"-provoking prompts vis a vis an
input query and the current iteration of an LLM's response. Unlike static or
semi-static approaches, e.g. Chain of Thought (CoT) or Tree of Thoughts (ToT),
IoT adapts its reasoning path dynamically, based on evolving context, and
without generating alternate explorative thoughts which are ultimately
discarded. The three components of the IoT framework are (1) an Inner Dialogue
Agent (IDA) responsible for generating instructive, context-specific prompts;
(2) an LLM Agent (LLMA) that processes these prompts to refine its responses;
and (3) an iterative prompting loop that implements a conversation between the
former two components. We introduce two variants of our framework: Autonomous
Iteration of Thought (AIoT), where an LLM decides when to stop iterating, and
Guided Iteration of Thought (GIoT), which always forces a fixed number
iterations. We investigate the performance of IoT across various datasets,
spanning complex reasoning tasks from the GPQA dataset, explorative
problem-solving in Game of 24, puzzle solving in Mini Crosswords, and multi-hop
question answering from the HotpotQA dataset. Our results show that IoT
represents a viable paradigm for autonomous response refinement in LLMs,
showcasing significant improvements over CoT and thereby enabling more adaptive
and efficient reasoning systems that minimize human intervention.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Measuring and Mitigating Bias for Tabular <span class="highlight-title">Dataset</span>s with Multiple
  Protected Attributes <span class="chip">ECAI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.19300v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.19300v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manh Khoi Duong, Stefan Conrad
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Motivated by the recital (67) of the current corrigendum of the AI Act in the
European Union, we propose and present measures and mitigation strategies for
discrimination in tabular datasets. We specifically focus on datasets that
contain multiple protected attributes, such as nationality, age, and sex. This
makes measuring and mitigating bias more challenging, as many existing methods
are designed for a single protected attribute. This paper comes with a twofold
contribution: Firstly, new discrimination measures are introduced. These
measures are categorized in our framework along with existing ones, guiding
researchers and practitioners in choosing the right measure to assess the
fairness of the underlying dataset. Secondly, a novel application of an
existing bias mitigation method, FairDo, is presented. We show that this
strategy can mitigate any type of discrimination, including intersectional
discrimination, by transforming the dataset. By conducting experiments on
real-world datasets (Adult, Bank, COMPAS), we demonstrate that de-biasing
datasets with multiple protected attributes is possible. All transformed
datasets show a reduction in discrimination, on average by 28%. Further, these
datasets do not compromise any of the tested machine learning models'
performances significantly compared to the original datasets. Conclusively,
this study demonstrates the effectiveness of the mitigation strategy used and
contributes to the ongoing discussion on the implementation of the European
Union's AI Act.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submission accepted in AEQUITAS'24 (co-located with ECAI 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Paths to Equilibrium in Games <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.18079v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.18079v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bora Yongacoglu, Gürdal Arslan, Lacra Pavel, Serdar Yüksel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In multi-agent reinforcement learning (MARL) and game theory, agents
repeatedly interact and revise their strategies as new data arrives, producing
a sequence of strategy profiles. This paper studies sequences of strategies
satisfying a pairwise constraint inspired by policy updating in reinforcement
learning, where an agent who is best responding in one period does not switch
its strategy in the next period. This constraint merely requires that
optimizing agents do not switch strategies, but does not constrain the
non-optimizing agents in any way, and thus allows for exploration. Sequences
with this property are called satisficing paths, and arise naturally in many
MARL algorithms. A fundamental question about strategic dynamics is such: for a
given game and initial strategy profile, is it always possible to construct a
satisficing path that terminates at an equilibrium? The resolution of this
question has implications about the capabilities or limitations of a class of
MARL algorithms. We answer this question in the affirmative for normal-form
games. Our analysis reveals a counterintuitive insight that reward
deteriorating strategic updates are key to driving play to equilibrium along a
satisficing path.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Generative Expansion of Small <span class="highlight-title">Dataset</span>s: An Expansive Graph Approach <span class="chip">ICASSP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.17238v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.17238v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vahid Jebraeeli, Bo Jiang, Hamid Krim, Derya Cansever
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Limited data availability in machine learning significantly impacts
performance and generalization. Traditional augmentation methods enhance
moderately sufficient datasets. GANs struggle with convergence when generating
diverse samples. Diffusion models, while effective, have high computational
costs. We introduce an Expansive Synthesis model generating large-scale,
information-rich datasets from minimal samples. It uses expander graph mappings
and feature interpolation to preserve data distribution and feature
relationships. The model leverages neural networks' non-linear latent space,
captured by a Koopman operator, to create a linear feature space for dataset
expansion. An autoencoder with self-attention layers and optimal transport
refines distributional consistency. We validate by comparing classifiers
trained on generated data to those trained on original datasets. Results show
comparable performance, demonstrating the model's potential to augment training
data effectively. This work advances data generation, addressing scarcity in
machine learning applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 3 figures and 2 tables. Under review in ICASSP 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Inference Optimization of Foundation Models on AI Accelerators <span class="chip">KDD 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.09111v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.09111v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Youngsuk Park, Kailash Budhathoki, Liangfu Chen, Jonas Kübler, Jiaji Huang, Matthäus Kleindessner, Jun Huan, Volkan Cevher, Yida Wang, George Karypis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Powerful foundation models, including large language models (LLMs), with
Transformer architectures have ushered in a new era of Generative AI across
various industries. Industry and research community have witnessed a large
number of new applications, based on those foundation models. Such applications
include question and answer, customer services, image and video generation, and
code completions, among others. However, as the number of model parameters
reaches to hundreds of billions, their deployment incurs prohibitive inference
costs and high latency in real-world scenarios. As a result, the demand for
cost-effective and fast inference using AI accelerators is ever more higher. To
this end, our tutorial offers a comprehensive discussion on complementary
inference optimization techniques using AI accelerators. Beginning with an
overview of basic Transformer architectures and deep learning system
frameworks, we deep dive into system optimization techniques for fast and
memory-efficient attention computations and discuss how they can be implemented
efficiently on AI accelerators. Next, we describe architectural elements that
are key for fast transformer inference. Finally, we examine various model
compression and fast decoding strategies in the same context.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>[v2] Tutorial website added [v1] Tutorial published at KDD 2024.
  Camera-ready version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Dynamic Pricing in Securities Lending Market: Application in Revenue
  Optimization for an Agent Lender Portfolio 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.13687v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.13687v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jing Xu, Yung-Cheng Hsu, William Biscarri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Securities lending is an important part of the financial market structure,
where agent lenders help long term institutional investors to lend out their
securities to short sellers in exchange for a lending fee. Agent lenders within
the market seek to optimize revenue by lending out securities at the highest
rate possible. Typically, this rate is set by hard-coded business rules or
standard supervised machine learning models. These approaches are often
difficult to scale and are not adaptive to changing market conditions. Unlike a
traditional stock exchange with a centralized limit order book, the securities
lending market is organized similarly to an e-commerce marketplace, where agent
lenders and borrowers can transact at any agreed price in a bilateral fashion.
This similarity suggests that the use of typical methods for addressing dynamic
pricing problems in e-commerce could be effective in the securities lending
market. We show that existing contextual bandit frameworks can be successfully
utilized in the securities lending market. Using offline evaluation on real
historical data, we show that the contextual bandit approach can consistently
outperform typical approaches by at least 15% in terms of total revenue
generated.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Short vs. Long-term Coordination of Drones: When Distributed
  Optimization Meets Deep Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.09852v7">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.09852v7.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chuhao Qin, Evangelos Pournaras
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Swarms of autonomous interactive drones can provide compelling sensing
capabilities in Smart City applications, such as traffic monitoring. This paper
focuses on the task assignment problem for large-scale spatio-temporal sensing
by a drone swarm. However, existing approaches have distinct challenges:
distributed evolutionary optimization, such as collective learning, lacks
long-term adaptability in dynamic environments, while deep reinforcement
learning (DRL) is limited to scale effectively due to the curse of
dimensionality. Therefore, this paper proposes a novel synergetic optimization
approach by integrating long-term DRL and short-term collective learning.
Through this approach, each drone independently and proactively determines its
flying direction and recharging location using DRL, while evolving their
navigation and sensing policies through collective learning based on a
structured tree communication model. Extensive experiments with datasets
generated from realistic urban mobility demonstrate an outstanding performance
of the proposed solution in complex scenarios. New insights show that this
approach provides a win-win synthesis of short-term and long-term strategies
for drone-based traffic monitoring, with short-term methods addressing training
complexity and energy management, while long-term methods preserving high
sensing performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Clustering Three-Way Data with Outliers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.05288v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.05288v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Katharine M. Clark, Paul D. McNicholas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Matrix-variate distributions are a recent addition to the model-based
clustering field, thereby making it possible to analyze data in matrix form
with complex structure such as images and time series. Due to its recent
appearance, there is limited literature on matrix-variate data, with even less
on dealing with outliers in these models. An approach for clustering
matrix-variate normal data with outliers is discussed. The approach, which uses
the distribution of subset log-likelihoods, extends the OCLUST algorithm to
matrix-variate normal data and uses an iterative approach to detect and trim
outliers.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ <span class="highlight-title">★</span> Mitigating Shortcut Learning with Diffusion Counterfactuals and Diverse
  Ensembles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.16176v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.16176v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luca Scimeca, Alexander Rubinstein, Damien Teney, Seong Joon Oh, Armand Mihai Nicolicioiu, <span class="highlight-author">Yoshua Bengio</span>
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spurious correlations in the data, where multiple cues are predictive of the
target labels, often lead to a phenomenon known as shortcut learning, where a
model relies on erroneous, easy-to-learn cues while ignoring reliable ones. In
this work, we propose DiffDiv an ensemble diversification framework exploiting
Diffusion Probabilistic Models (DPMs) to mitigate this form of bias. We show
that at particular training intervals, DPMs can generate images with novel
feature combinations, even when trained on samples displaying correlated input
features. We leverage this crucial property to generate synthetic
counterfactuals to increase model diversity via ensemble disagreement. We show
that DPM-guided diversification is sufficient to remove dependence on shortcut
cues, without a need for additional supervised signals. We further empirically
quantify its efficacy on several diversification objectives, and finally show
improved generalization and diversification on par with prior work that relies
on auxiliary data collection.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: substantial text overlap with arXiv:2310.02230</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DRIM: Learning Disentangled Representations from Incomplete Multimodal
  Healthcare Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.17055v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.17055v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lucas Robinet, Ahmad Berjaoui, Ziad Kheil, Elizabeth Cohen-Jonathan Moyal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Real-life medical data is often multimodal and incomplete, fueling the
growing need for advanced deep learning models capable of integrating them
efficiently. The use of diverse modalities, including histopathology slides,
MRI, and genetic data, offers unprecedented opportunities to improve prognosis
prediction and to unveil new treatment pathways. Contrastive learning, widely
used for deriving representations from paired data in multimodal tasks, assumes
that different views contain the same task-relevant information and leverages
only shared information. This assumption becomes restrictive when handling
medical data since each modality also harbors specific knowledge relevant to
downstream tasks. We introduce DRIM, a new multimodal method for capturing
these shared and unique representations, despite data sparsity. More
specifically, given a set of modalities, we aim to encode a representation for
each one that can be divided into two components: one encapsulating
patient-related information common across modalities and the other,
encapsulating modality-specific details. This is achieved by increasing the
shared information among different patient modalities while minimizing the
overlap between shared and unique components within each modality. Our method
outperforms state-of-the-art algorithms on glioma patients survival prediction
tasks, while being robust to missing modalities. To promote reproducibility,
the code is made publicly available at https://github.com/Lucas-rbnt/DRIM
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ NeuroPath: A Neural Pathway <span class="highlight-title">Transformer</span> for Joining the Dots of Human
  Connectomes <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.17510v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.17510v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziquan Wei, Tingting Dan, Jiaqi Ding, Guorong Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although modern imaging technologies allow us to study connectivity between
two distinct brain regions in-vivo, an in-depth understanding of how anatomical
structure supports brain function and how spontaneous functional fluctuations
emerge remarkable cognition is still elusive. Meanwhile, tremendous efforts
have been made in the realm of machine learning to establish the nonlinear
mapping between neuroimaging data and phenotypic traits. However, the absence
of neuroscience insight in the current approaches poses significant challenges
in understanding cognitive behavior from transient neural activities. To
address this challenge, we put the spotlight on the coupling mechanism of
structural connectivity (SC) and functional connectivity (FC) by formulating
such network neuroscience question into an expressive graph representation
learning problem for high-order topology. Specifically, we introduce the
concept of topological detour to characterize how a ubiquitous instance of FC
(direct link) is supported by neural pathways (detour) physically wired by SC,
which forms a cyclic loop interacted by brain structure and function. In the
clich\'e of machine learning, the multi-hop detour pathway underlying SC-FC
coupling allows us to devise a novel multi-head self-attention mechanism within
Transformer to capture multi-modal feature representation from paired graphs of
SC and FC. Taken together, we propose a biological-inspired deep model, coined
as NeuroPath, to find putative connectomic feature representations from the
unprecedented amount of neuroimages, which can be plugged into various
downstream applications such as task recognition and disease diagnosis. We have
evaluated NeuroPath on large-scale public datasets including HCP and UK Biobank
under supervised and zero-shot learning, where the state-of-the-art performance
by our NeuroPath indicates great potential in network neuroscience.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Early Detection of Coronary Heart Disease Using Hybrid Quantum Machine
  Learning Approach 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.10932v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.10932v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mehroush Banday, Sherin Zafar, Parul Agarwal, M Afshar Alam, Abubeker K M
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Coronary heart disease (CHD) is a severe cardiac disease, and hence, its
early diagnosis is essential as it improves treatment results and saves money
on medical care. The prevailing development of quantum computing and machine
learning (ML) technologies may bring practical improvement to the performance
of CHD diagnosis. Quantum machine learning (QML) is receiving tremendous
interest in various disciplines due to its higher performance and capabilities.
A quantum leap in the healthcare industry will increase processing power and
optimise multiple models. Techniques for QML have the potential to forecast
cardiac disease and help in early detection. To predict the risk of coronary
heart disease, a hybrid approach utilizing an ensemble machine learning model
based on QML classifiers is presented in this paper. Our approach, with its
unique ability to address multidimensional healthcare data, reassures the
method's robustness by fusing quantum and classical ML algorithms in a
multi-step inferential framework. The marked rise in heart disease and death
rates impacts worldwide human health and the global economy. Reducing cardiac
morbidity and mortality requires early detection of heart disease. In this
research, a hybrid approach utilizes techniques with quantum computing
capabilities to tackle complex problems that are not amenable to conventional
machine learning algorithms and to minimize computational expenses. The
proposed method has been developed in the Raspberry Pi 5 Graphics Processing
Unit (GPU) platform and tested on a broad dataset that integrates clinical and
imaging data from patients suffering from CHD and healthy controls. Compared to
classical machine learning models, the accuracy, sensitivity, F1 score, and
specificity of the proposed hybrid QML model used with CHD are manifold higher.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>I found a mistake in methodology presentation. Also I have observed
  more precised results with new dataset. So my research guide ask me to modify
  the current version</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Divide And Conquer: Learning Chaotic Dynamical Systems With Multistep
  Penalty Neural Ordinary Differential Equations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.00568v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.00568v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dibyajyoti Chakraborty, Seung Whan Chung, Troy Arcomano, Romit Maulik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Forecasting high-dimensional dynamical systems is a fundamental challenge in
various fields, such as geosciences and engineering. Neural Ordinary
Differential Equations (NODEs), which combine the power of neural networks and
numerical solvers, have emerged as a promising algorithm for forecasting
complex nonlinear dynamical systems. However, classical techniques used for
NODE training are ineffective for learning chaotic dynamical systems. In this
work, we propose a novel NODE-training approach that allows for robust learning
of chaotic dynamical systems. Our method addresses the challenges of
non-convexity and exploding gradients associated with underlying chaotic
dynamics. Training data trajectories from such systems are split into multiple,
non-overlapping time windows. In addition to the deviation from the training
data, the optimization loss term further penalizes the discontinuities of the
predicted trajectory between the time windows. The window size is selected
based on the fastest Lyapunov time scale of the system. Multi-step penalty(MP)
method is first demonstrated on Lorenz equation, to illustrate how it improves
the loss landscape and thereby accelerates the optimization convergence. MP
method can optimize chaotic systems in a manner similar to least-squares
shadowing with significantly lower computational costs. Our proposed algorithm,
denoted the Multistep Penalty NODE, is applied to chaotic systems such as the
Kuramoto-Sivashinsky equation, the two-dimensional Kolmogorov flow, and ERA5
reanalysis data for the atmosphere. It is observed that MP-NODE provide viable
performance for such chaotic systems, not only for short-term trajectory
predictions but also for invariant statistics that are hallmarks of the chaotic
nature of these dynamics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages, 17 Figures, submitted to Computer Methods in Applied
  Mechanics and Engineering</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Outlier Gradient Analysis: Efficiently Improving Deep Learning Model
  Performance via Hessian-Free Influence Functions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.03869v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.03869v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anshuman Chhabra, Bo Li, Jian Chen, Prasant Mohapatra, Hongfu Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A core data-centric learning challenge is the identification of training
samples that are detrimental to model performance. Influence functions serve as
a prominent tool for this task and offer a robust framework for assessing
training data influence on model predictions. Despite their widespread use,
their high computational cost associated with calculating the inverse of the
Hessian matrix pose constraints, particularly when analyzing large-sized deep
models. In this paper, we establish a bridge between identifying detrimental
training samples via influence functions and outlier gradient detection. This
transformation not only presents a straightforward and Hessian-free formulation
but also provides insights into the role of the gradient in sample impact.
Through systematic empirical evaluations, we first validate the hypothesis of
our proposed outlier gradient analysis approach on synthetic datasets. We then
demonstrate its effectiveness in detecting mislabeled samples in vision models
and selecting data samples for improving performance of natural language
processing transformer models. We also extend its use to influential sample
identification for fine-tuning Large Language Models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evidence Is All You Need: Ordering Imaging Studies via Language Model
  Alignment with the ACR Appropriateness Criteria 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19177v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19177v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michael S. Yao, Allison Chae, Charles E. Kahn Jr., Walter R. Witschey, James C. Gee, Hersh Sagreiya, Osbert Bastani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diagnostic imaging studies are an increasingly important component of the
workup and management of acutely presenting patients. However, ordering
appropriate imaging studies according to evidence-based medical guidelines is a
challenging task with a high degree of variability between healthcare
providers. To address this issue, recent work has investigated if generative AI
and large language models can be leveraged to help clinicians order relevant
imaging studies for patients. However, it is challenging to ensure that these
tools are correctly aligned with medical guidelines, such as the American
College of Radiology's Appropriateness Criteria (ACR AC). In this study, we
introduce a framework to intelligently leverage language models by recommending
imaging studies for patient cases that are aligned with evidence-based
guidelines. We make available a novel dataset of patient "one-liner" scenarios
to power our experiments, and optimize state-of-the-art language models to
achieve an accuracy on par with clinicians in image ordering. Finally, we
demonstrate that our language model-based pipeline can be used as intelligent
assistants by clinicians to support image ordering workflows and improve the
accuracy of imaging study ordering according to the ACR AC. Our work
demonstrates and validates a strategy to leverage AI-based software to improve
trustworthy clinical decision making in alignment with expert evidence-based
guidelines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages main text, 4 figures, 1 table</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FELRec: Efficient Handling of Item Cold-Start With Dynamic
  Representation Learning in Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2210.16928v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2210.16928v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kuba Weimann, Tim O. F. Conrad
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems suffer from the cold-start problem whenever a new user
joins the platform or a new item is added to the catalog. To address item
cold-start, we propose to replace the embedding layer in sequential
recommenders with a dynamic storage that has no learnable weights and can keep
an arbitrary number of representations. In this paper, we present FELRec, a
large embedding network that refines the existing representations of users and
items in a recursive manner, as new information becomes available. In contrast
to similar approaches, our model represents new users and items without side
information and time-consuming finetuning, instead it runs a single forward
pass over a sequence of existing representations. During item cold-start, our
method outperforms similar method by 29.50%-47.45%. Further, our proposed model
generalizes well to previously unseen datasets in zero-shot settings. The
source code is publicly available at https://github.com/kweimann/FELRec .
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MobileMEF: Fast and Efficient Method for Multi-Exposure Fusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.07932v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.07932v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lucas Nedel Kirsten, Zhicheng Fu, Nikhil Ambha Madhusudhana
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in camera design and imaging technology have enabled the
capture of high-quality images using smartphones. However, due to the limited
dynamic range of digital cameras, the quality of photographs captured in
environments with highly imbalanced lighting often results in poor-quality
images. To address this issue, most devices capture multi-exposure frames and
then use some multi-exposure fusion method to merge those frames into a final
fused image. Nevertheless, most traditional and current deep learning
approaches are unsuitable for real-time applications on mobile devices due to
their heavy computational and memory requirements. We propose a new method for
multi-exposure fusion based on an encoder-decoder deep learning architecture
with efficient building blocks tailored for mobile devices. This efficient
design makes our model capable of processing 4K resolution images in less than
2 seconds on mid-range smartphones. Our method outperforms state-of-the-art
techniques regarding full-reference quality measures and computational
efficiency (runtime and memory usage), making it ideal for real-time
applications on hardware-constrained devices. Our code is available at:
https://github.com/LucasKirsten/MobileMEF.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing GANs with Contrastive Learning-Based Multistage Progressive
  Finetuning SNN and RL-Based External Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.20340v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.20340v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Osama Mustafa
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The application of deep learning in cancer research, particularly in early
diagnosis, case understanding, and treatment strategy design, emphasizes the
need for high-quality data. Generative AI, especially Generative Adversarial
Networks (GANs), has emerged as a leading solution to challenges like class
imbalance, robust learning, and model training, while addressing issues
stemming from patient privacy and the scarcity of real data. Despite their
promise, GANs face several challenges, both inherent and specific to
histopathology data. Inherent issues include training imbalance, mode collapse,
linear learning from insufficient discriminator feedback, and hard boundary
convergence due to stringent feedback. Histopathology data presents a unique
challenge with its complex representation, high spatial resolution, and
multiscale features. To address these challenges, we propose a framework
consisting of two components. First, we introduce a contrastive learning-based
Multistage Progressive Finetuning Siamese Neural Network (MFT-SNN) for
assessing the similarity between histopathology patches. Second, we implement a
Reinforcement Learning-based External Optimizer (RL-EO) within the GAN training
loop, serving as a reward signal generator. The modified discriminator loss
function incorporates a weighted reward, guiding the GAN to maximize this
reward while minimizing loss. This approach offers an external optimization
guide to the discriminator, preventing generator overfitting and ensuring
smooth convergence. Our proposed solution has been benchmarked against
state-of-the-art (SOTA) GANs and a Denoising Diffusion Probabilistic model,
outperforming previous SOTA across various metrics, including FID score, KID
score, Perceptual Path Length, and downstream classification tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Low-Energy On-Device Personalization for MCUs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.08040v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.08040v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yushan Huang, Ranya Aloufi, Xavier Cadet, Yuchen Zhao, Payam Barnaghi, Hamed Haddadi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Microcontroller Units (MCUs) are ideal platforms for edge applications due to
their low cost and energy consumption, and are widely used in various
applications, including personalized machine learning tasks, where customized
models can enhance the task adaptation. However, existing approaches for local
on-device personalization mostly support simple ML architectures or require
complex local pre-training/training, leading to high energy consumption and
negating the low-energy advantage of MCUs. In this paper, we introduce
$MicroT$, an efficient and low-energy MCU personalization approach. $MicroT$
includes a robust, general, but tiny feature extractor, developed through
self-supervised knowledge distillation, which trains a task-specific head to
enable independent on-device personalization with minimal energy and
computational requirements. MicroT implements an MCU-optimized early-exit
inference mechanism called stage-decision to further reduce energy costs. This
mechanism allows for user-configurable exit criteria (stage-decision ratio) to
adaptively balance energy cost with model performance. We evaluated MicroT
using two models, three datasets, and two MCU boards. $MicroT$ outperforms
traditional transfer learning (TTL) and two SOTA approaches by 2.12 - 11.60%
across two models and three datasets. Targeting widely used energy-aware edge
devices, MicroT's on-device training requires no additional complex operations,
halving the energy cost compared to SOTA approaches by up to 2.28X while
keeping SRAM usage below 1MB. During local inference, MicroT reduces energy
cost by 14.17% compared to TTL across two boards and two datasets, highlighting
its suitability for long-term use on energy-aware resource-constrained MCUs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to The 9th ACM/IEEE Symposium on Edge Computing (SEC 2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Creative Problem Solving in Large Language and Vision Models -- What
  Would it Take? <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.01453v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.01453v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lakshmi Nair, Evana Gizzi, Jivko Sinapov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We advocate for a strong integration of Computational Creativity (CC) with
research in large language and vision models (LLVMs) to address a key
limitation of these models, i.e., creative problem solving. We present
preliminary experiments showing how CC principles can be applied to address
this limitation. Our goal is to foster discussions on creative problem solving
in LLVMs and CC at prestigious ML venues. Our code is available at:
https://github.com/lnairGT/creative-problem-solving-LLMs
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to EMNLP 2024 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Classifier-free graph diffusion for molecular property targeting <span class="chip">ECML</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.17397v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.17397v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matteo Ninniri, Marco Podda, Davide Bacciu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work focuses on the task of property targeting: that is, generating
molecules conditioned on target chemical properties to expedite candidate
screening for novel drug and materials development. DiGress is a recent
diffusion model for molecular graphs whose distinctive feature is allowing
property targeting through classifier-based (CB) guidance. While CB guidance
may work to generate molecular-like graphs, we hint at the fact that its
assumptions apply poorly to the chemical domain. Based on this insight we
propose a classifier-free DiGress (FreeGress), which works by directly
injecting the conditioning information into the training process. CF guidance
is convenient given its less stringent assumptions and since it does not
require to train an auxiliary property regressor, thus halving the number of
trainable parameters in the model. We empirically show that our model yields up
to 79% improvement in Mean Absolute Error with respect to DiGress on property
targeting tasks on QM9 and ZINC-250k benchmarks. As an additional contribution,
we propose a simple yet powerful approach to improve chemical validity of
generated samples, based on the observation that certain chemical properties
such as molecular weight correlate with the number of atoms in molecules.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Proceedings of ECML PKDD 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning Confidence Bounds for Classification with Imbalanced Data <span class="chip">ECAI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.11878v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.11878v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matt Clifford, Jonathan Erskine, Alexander Hepburn, Raúl Santos-Rodríguez, Dario Garcia-Garcia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Class imbalance poses a significant challenge in classification tasks, where
traditional approaches often lead to biased models and unreliable predictions.
Undersampling and oversampling techniques have been commonly employed to
address this issue, yet they suffer from inherent limitations stemming from
their simplistic approach such as loss of information and additional biases
respectively. In this paper, we propose a novel framework that leverages
learning theory and concentration inequalities to overcome the shortcomings of
traditional solutions. We focus on understanding the uncertainty in a
class-dependent manner, as captured by confidence bounds that we directly embed
into the learning process. By incorporating class-dependent estimates, our
method can effectively adapt to the varying degrees of imbalance across
different classes, resulting in more robust and reliable classification
outcomes. We empirically show how our framework provides a promising direction
for handling imbalanced data in classification tasks, offering practitioners a
valuable tool for building more accurate and trustworthy models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ECAI 2024 main track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Counterfactual Explanations for Medical Image Classification and
  Regression using Diffusion Autoencoder 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.01571v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.01571v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matan Atad, David Schinz, Hendrik Moeller, Robert Graf, Benedikt Wiestler, Daniel Rueckert, Nassir Navab, Jan S. Kirschke, Matthias Keicher
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Counterfactual explanations (CEs) aim to enhance the interpretability of
machine learning models by illustrating how alterations in input features would
affect the resulting predictions. Common CE approaches require an additional
model and are typically constrained to binary counterfactuals. In contrast, we
propose a novel method that operates directly on the latent space of a
generative model, specifically a Diffusion Autoencoder (DAE). This approach
offers inherent interpretability by enabling the generation of CEs and the
continuous visualization of the model's internal representation across decision
boundaries.
  Our method leverages the DAE's ability to encode images into a semantically
rich latent space in an unsupervised manner, eliminating the need for labeled
data or separate feature extraction models. We show that these latent
representations are helpful for medical condition classification and the
ordinal regression of severity pathologies, such as vertebral compression
fractures (VCF) and diabetic retinopathy (DR). Beyond binary CEs, our method
supports the visualization of ordinal CEs using a linear model, providing
deeper insights into the model's decision-making process and enhancing
interpretability.
  Experiments across various medical imaging datasets demonstrate the method's
advantages in interpretability and versatility. The linear manifold of the
DAE's latent space allows for meaningful interpolation and manipulation, making
it a powerful tool for exploring medical image properties. Our code is
available at https://doi.org/10.5281/zenodo.13859266.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for publication at the Journal of Machine Learning for
  Biomedical Imaging (MELBA) https://melba-journal.org/2024:024. arXiv admin
  note: text overlap with arXiv:2303.12031</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Gradient-Free Training of Recurrent Neural Networks using Random
  Perturbations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.08967v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.08967v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jesus Garcia Fernandez, Sander Keemink, Marcel van Gerven
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recurrent neural networks (RNNs) hold immense potential for computations due
to their Turing completeness and sequential processing capabilities, yet
existing methods for their training encounter efficiency challenges.
Backpropagation through time (BPTT), the prevailing method, extends the
backpropagation (BP) algorithm by unrolling the RNN over time. However, this
approach suffers from significant drawbacks, including the need to interleave
forward and backward phases and store exact gradient information. Furthermore,
BPTT has been shown to struggle to propagate gradient information for long
sequences, leading to vanishing gradients. An alternative strategy to using
gradient-based methods like BPTT involves stochastically approximating
gradients through perturbation-based methods. This learning approach is
exceptionally simple, necessitating only forward passes in the network and a
global reinforcement signal as feedback. Despite its simplicity, the random
nature of its updates typically leads to inefficient optimization, limiting its
effectiveness in training neural networks. In this study, we present a new
approach to perturbation-based learning in RNNs whose performance is
competitive with BPTT, while maintaining the inherent advantages over
gradient-based learning. To this end, we extend the recently introduced
activity-based node perturbation (ANP) method to operate in the time domain,
leading to more efficient learning and generalization. We subsequently conduct
a range of experiments to validate our approach. Our results show similar
performance, convergence time and scalability compared to BPTT, strongly
outperforming standard node and weight perturbation methods. These findings
suggest that perturbation-based learning methods offer a versatile alternative
to gradient-based methods for training RNNs which can be ideally suited for
neuromorphic computing applications
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HUMAP: Hierarchical Uniform Manifold Approximation and Projection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2106.07718v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2106.07718v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wilson E. Marcílio-Jr, Danilo M. Eler, Fernando V. Paulovich, Rafael M. Martins
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Dimensionality reduction (DR) techniques help analysts to understand patterns
in high-dimensional spaces. These techniques, often represented by scatter
plots, are employed in diverse science domains and facilitate similarity
analysis among clusters and data samples. For datasets containing many
granularities or when analysis follows the information visualization mantra,
hierarchical DR techniques are the most suitable approach since they present
major structures beforehand and details on demand. This work presents HUMAP, a
novel hierarchical dimensionality reduction technique designed to be flexible
on preserving local and global structures and preserve the mental map
throughout hierarchical exploration. We provide empirical evidence of our
technique's superiority compared with current hierarchical approaches and show
a case study applying HUMAP for dataset labelling.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing the analysis of murine neonatal ultrasonic vocalizations:
  Development, evaluation, and application of different mathematical models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.12957v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.12957v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rudolf Herdt, Louisa Kinzel, Johann Georg Maaß, Marvin Walther, Henning Fröhlich, Tim Schubert, Peter Maass, Christian Patrick Schaaf
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Rodents employ a broad spectrum of ultrasonic vocalizations (USVs) for social
communication. As these vocalizations offer valuable insights into affective
states, social interactions, and developmental stages of animals, various deep
learning approaches have aimed to automate both the quantitative (detection)
and qualitative (classification) analysis of USVs. Here, we present the first
systematic evaluation of different types of neural networks for USV
classification. We assessed various feedforward networks, including a
custom-built, fully-connected network and convolutional neural network,
different residual neural networks (ResNets), an EfficientNet, and a Vision
Transformer (ViT). Paired with a refined, entropy-based detection algorithm
(achieving recall of 94.9% and precision of 99.3%), the best architecture
(achieving 86.79% accuracy) was integrated into a fully automated pipeline
capable of analyzing extensive USV datasets with high reliability.
Additionally, users can specify an individual minimum accuracy threshold based
on their research needs. In this semi-automated setup, the pipeline selectively
classifies calls with high pseudo-probability, leaving the rest for manual
inspection. Our study focuses exclusively on neonatal USVs. As part of an
ongoing phenotyping study, our pipeline has proven to be a valuable tool for
identifying key differences in USVs produced by mice with autism-like
behaviors.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Vicious Classifiers: Assessing Inference-time Data Reconstruction Risk
  in Edge Computing <span class="chip">BMVC 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2212.04223v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2212.04223v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammad Malekzadeh, Deniz Gunduz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Privacy-preserving inference in edge computing paradigms encourages the users
of machine-learning services to locally run a model on their private input and
only share the models outputs for a target task with the server. We study how a
vicious server can reconstruct the input data by observing only the models
outputs while keeping the target accuracy very close to that of a honest server
by jointly training a target model (to run at users' side) and an attack model
for data reconstruction (to secretly use at servers' side). We present a new
measure to assess the inference-time reconstruction risk. Evaluations on six
benchmark datasets show the model's input can be approximately reconstructed
from the outputs of a single inference. We propose a primary defense mechanism
to distinguish vicious versus honest classifiers at inference time. By studying
such a risk associated with emerging ML services our work has implications for
enhancing privacy in edge computing. We discuss open challenges and directions
for future studies and release our code as a benchmark for the community at
https://github.com/mmalekzadeh/vicious-classifiers .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published at BMVC 2024 workshop on Privacy, Fairness, Accountability
  and Transparency in Computer Vision</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing Fairness through Reweighting: A Path to Attain the Sufficiency
  Rule <span class="chip">ECAI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.14126v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.14126v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuan Zhao, Klaus Broelemann, Salvatore Ruggieri, Gjergji Kasneci
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce an innovative approach to enhancing the empirical risk
minimization (ERM) process in model training through a refined reweighting
scheme of the training data to enhance fairness. This scheme aims to uphold the
sufficiency rule in fairness by ensuring that optimal predictors maintain
consistency across diverse sub-groups. We employ a bilevel formulation to
address this challenge, wherein we explore sample reweighting strategies.
Unlike conventional methods that hinge on model size, our formulation bases
generalization complexity on the space of sample weights. We discretize the
weights to improve training speed. Empirical validation of our method showcases
its effectiveness and robustness, revealing a consistent improvement in the
balance between prediction performance and fairness metrics across various
experiments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accepted at ECAI 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Merging LoRAs like Playing LEGO: Pushing the Modularity of LoRA to
  Extremes Through Rank-Wise Clustering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.16167v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.16167v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziyu Zhao, Tao Shen, Didi Zhu, Zexi Li, Jing Su, Xuwu Wang, Kun Kuang, Fei Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low-Rank Adaptation (LoRA) has emerged as a popular technique for fine-tuning
large language models (LLMs) to various domains due to its modular design and
widespread availability on platforms like Huggingface. This modularity has
sparked interest in combining multiple LoRAs to enhance LLM capabilities.
However, existing methods for LoRA composition primarily focus on task-specific
adaptations that require additional training, and current model merging
techniques often fail to fully leverage LoRA's modular nature, leading to
parameter interference and performance degradation. In this paper, we
investigate the feasibility of disassembling and reassembling multiple LoRAs at
a finer granularity, analogous to assembling LEGO blocks. We introduce the
concept of Minimal Semantic Units (MSUs), where the parameters corresponding to
each rank in LoRA function as independent units. These MSUs demonstrate
permutation invariance and concatenation-summation equivalence properties,
enabling flexible combinations to create new LoRAs. Building on these insights,
we propose the LoRA-LEGO framework. This framework conducts rank-wise parameter
clustering by grouping MSUs from different LoRAs into $k$ clusters. The
centroid of each cluster serves as a representative MSU, enabling the assembly
of a merged LoRA with an adjusted rank of $k$. Additionally, we apply a dual
reweighting strategy to optimize the scale of the merged LoRA. Experiments
across various benchmarks demonstrate that our method outperforms existing
approaches in LoRA merging.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BMFT: Achieving Fairness via Bias-based Weight Masking Fine-tuning <span class="chip">MICCAI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.06890v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.06890v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuyang Xue, Junyu Yan, Raman Dutt, Fasih Haider, Jingshuai Liu, Steven McDonagh, Sotirios A. Tsaftaris
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Developing models with robust group fairness properties is paramount,
particularly in ethically sensitive domains such as medical diagnosis. Recent
approaches to achieving fairness in machine learning require a substantial
amount of training data and depend on model retraining, which may not be
practical in real-world scenarios. To mitigate these challenges, we propose
Bias-based Weight Masking Fine-Tuning (BMFT), a novel post-processing method
that enhances the fairness of a trained model in significantly fewer epochs
without requiring access to the original training data. BMFT produces a mask
over model parameters, which efficiently identifies the weights contributing
the most towards biased predictions. Furthermore, we propose a two-step
debiasing strategy, wherein the feature extractor undergoes initial fine-tuning
on the identified bias-influenced weights, succeeded by a fine-tuning phase on
a reinitialised classification layer to uphold discriminative performance.
Extensive experiments across four dermatological datasets and two sensitive
attributes demonstrate that BMFT outperforms existing state-of-the-art (SOTA)
techniques in both diagnostic accuracy and fairness metrics. Our findings
underscore the efficacy and robustness of BMFT in advancing fairness across
various out-of-distribution (OOD) settings. Our code is available at:
https://github.com/vios-s/BMFT
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by MICCAI 2024 FAIMI Workshop Oral</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LUMA: A Benchmark <span class="highlight-title">Dataset</span> for Learning from Uncertain and Multimodal
  Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.09864v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.09864v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Grigor Bezirganyan, Sana Sellami, Laure Berti-Équille, Sébastien Fournier
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Deep Learning enhances decision-making by integrating diverse
information sources, such as texts, images, audio, and videos. To develop
trustworthy multimodal approaches, it is essential to understand how
uncertainty impacts these models. We propose LUMA, a unique benchmark dataset,
featuring audio, image, and textual data from 50 classes, for learning from
uncertain and multimodal data. It extends the well-known CIFAR 10/100 dataset
with audio samples extracted from three audio corpora, and text data generated
using the Gemma-7B Large Language Model (LLM). The LUMA dataset enables the
controlled injection of varying types and degrees of uncertainty to achieve and
tailor specific experiments and benchmarking initiatives. LUMA is also
available as a Python package including the functions for generating multiple
variants of the dataset with controlling the diversity of the data, the amount
of noise for each modality, and adding out-of-distribution samples. A baseline
pre-trained model is also provided alongside three uncertainty quantification
methods: Monte-Carlo Dropout, Deep Ensemble, and Reliable Conflictive
Multi-View Learning. This comprehensive dataset and its benchmarking tools are
intended to promote and support the development, evaluation, and benchmarking
of trustworthy and robust multimodal deep learning approaches. We anticipate
that the LUMA dataset will help the ICLR community to design more trustworthy
and robust machine learning approaches for safety critical applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SDC-HSDD-NDSA: Structure Detecting Cluster by Hierarchical Secondary
  Directed Differential with Normalized Density and Self-Adaption 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2307.00677v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2307.00677v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Shu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Density-based clustering could be the most popular clustering algorithm since
it can identify clusters of arbitrary shape as long as they are separated by
low-density regions. However, a high-density region that is not separated by
low-density ones might also have different structures belonging to multiple
clusters. As far as we know, all previous density-based clustering algorithms
fail to detect such structures. In this paper, we provide a novel density-based
clustering scheme that can not only detect clusters separated by low-density
regions but also detect structures in high-density regions not separated by
low-density ones. The algorithm employs secondary directed differential,
hierarchy, normalized density, as well as the self-adaption coefficient, and
thus is called Structure Detecting Cluster by Hierarchical Secondary Directed
Differential with Normalized Density and Self-Adaption, dubbed by
SDC-HSDD-NDSA. The algorithm is run on several datasets to verify its
effectiveness, robustness, as well as granularity independence, and results
demonstrate that it has the ability that previous ones do not have. The Python
code is on https://github.com/Hao-B-Shu/SDC-HSDD-NDSA.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>35 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On The Planning Abilities of OpenAI's o1 Models: Feasibility,
  Optimality, and Generalizability 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19924v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19924v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kevin Wang, Junbo Li, Neel P. Bhatt, Yihan Xi, Qiang Liu, Ufuk Topcu, Zhangyang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in Large Language Models (LLMs) have showcased their
ability to perform complex reasoning tasks, but their effectiveness in planning
remains underexplored. In this study, we evaluate the planning capabilities of
OpenAI's o1 models across a variety of benchmark tasks, focusing on three key
aspects: feasibility, optimality, and generalizability. Through empirical
evaluations on constraint-heavy tasks (e.g., $\textit{Barman}$,
$\textit{Tyreworld}$) and spatially complex environments (e.g.,
$\textit{Termes}$, $\textit{Floortile}$), we highlight o1-preview's strengths
in self-evaluation and constraint-following, while also identifying bottlenecks
in decision-making and memory management, particularly in tasks requiring
robust spatial reasoning. Our results reveal that o1-preview outperforms GPT-4
in adhering to task constraints and managing state transitions in structured
environments. However, the model often generates suboptimal solutions with
redundant actions and struggles to generalize effectively in spatially complex
tasks. This pilot study provides foundational insights into the planning
limitations of LLMs, offering key directions for future research on improving
memory management, decision-making, and generalization in LLM-based planning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Updated link to code repository</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Model-independent variable selection via the rule-based variable
  priority 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.09003v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.09003v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Min Lu, Hemant Ishwaran
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While achieving high prediction accuracy is a fundamental goal in machine
learning, an equally important task is finding a small number of features with
high explanatory power. One popular selection technique is permutation
importance, which assesses a variable's impact by measuring the change in
prediction error after permuting the variable. However, this can be problematic
due to the need to create artificial data, a problem shared by other methods as
well. Another problem is that variable selection methods can be limited by
being model-specific. We introduce a new model-independent approach, Variable
Priority (VarPro), which works by utilizing rules without the need to generate
artificial data or evaluate prediction error. The method is relatively easy to
use, requiring only the calculation of sample averages of simple statistics,
and can be applied to many data settings, including regression, classification,
and survival. We investigate the asymptotic properties of VarPro and show,
among other things, that VarPro has a consistent filtering property for noise
variables. Empirical studies using synthetic and real-world data show the
method achieves a balanced performance and compares favorably to many
state-of-the-art procedures currently used for variable selection.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Statistical signatures of abstraction in deep neural networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.01656v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.01656v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Carlo Orientale Caputo, Matteo Marsili
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study how abstract representations emerge in a Deep Belief Network (DBN)
trained on benchmark datasets. Our analysis targets the principles of learning
in the early stages of information processing, starting from the "primordial
soup" of the under-sampling regime. As the data is processed by deeper and
deeper layers, features are detected and removed, transferring more and more
"context-invariant" information to deeper layers. We show that the
representation approaches an universal model -- the Hierarchical Feature Model
(HFM) -- determined by the principle of maximal relevance. Relevance quantifies
the uncertainty on the model of the data, thus suggesting that "meaning" --
i.e. syntactic information -- is that part of the data which is not yet
captured by a model. Our analysis shows that shallow layers are well described
by pairwise Ising models, which provide a representation of the data in terms
of generic, low order features. We also show that plasticity increases with
depth, in a similar way as it does in the brain. These findings suggest that
DBNs are capable of extracting a hierarchy of features from the data which is
consistent with the principle of maximal relevance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The estimate of the Kullback-Leibler distance used in the paper is
  affected by strong sampling errors. Additional statistical analysis is needed</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Measuring Orthogonality in Representations of Generative Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.03728v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.03728v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Robin C. Geyer, Alessandro Torcinovich, João B. Carvalho, Alexander Meyer, Joachim M. Buhmann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In unsupervised representation learning, models aim to distill essential
features from high-dimensional data into lower-dimensional learned
representations, guided by inductive biases. Understanding the characteristics
that make a good representation remains a topic of ongoing research.
Disentanglement of independent generative processes has long been credited with
producing high-quality representations. However, focusing solely on
representations that adhere to the stringent requirements of most
disentanglement metrics, may result in overlooking many high-quality
representations, well suited for various downstream tasks. These metrics often
demand that generative factors be encoded in distinct, single dimensions
aligned with the canonical basis of the representation space.
  Motivated by these observations, we propose two novel metrics:
Importance-Weighted Orthogonality (IWO) and Importance-Weighted Rank (IWR).
These metrics evaluate the mutual orthogonality and rank of generative factor
subspaces. Throughout extensive experiments on common downstream tasks, over
several benchmark datasets and models, IWO and IWR consistently show stronger
correlations with downstream task performance than traditional disentanglement
metrics. Our findings suggest that representation quality is closer related to
the orthogonality of independent generative processes rather than their
disentanglement, offering a new direction for evaluating and improving
unsupervised learning models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Is Tokenization Needed for Masked Particle Modelling? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.12589v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.12589v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Matthew Leigh, Samuel Klein, François Charton, Tobias Golling, Lukas Heinrich, Michael Kagan, Inês Ochoa, Margarita Osadchy
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we significantly enhance masked particle modeling (MPM), a
self-supervised learning scheme for constructing highly expressive
representations of unordered sets relevant to developing foundation models for
high-energy physics. In MPM, a model is trained to recover the missing elements
of a set, a learning objective that requires no labels and can be applied
directly to experimental data. We achieve significant performance improvements
over previous work on MPM by addressing inefficiencies in the implementation
and incorporating a more powerful decoder. We compare several pre-training
tasks and introduce new reconstruction methods that utilize conditional
generative models without data tokenization or discretization. We show that
these new methods outperform the tokenized learning objective from the original
MPM on a new test bed for foundation models for jets, which includes using a
wide variety of downstream tasks relevant to jet physics, such as
classification, secondary vertex finding, and track identification.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Symbolic XAI -- Explanation Through Human Understandable Logical
  Relationships Between Features 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.17198v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.17198v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thomas Schnake, Farnoush Rezaei Jafari, Jonas Lederer, Ping Xiong, Shinichi Nakajima, Stefan Gugler, Grégoire Montavon, Klaus-Robert Müller
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Explainable Artificial Intelligence (XAI) plays a crucial role in fostering
transparency and trust in AI systems, where traditional XAI approaches
typically offer one level of abstraction for explanations, often in the form of
heatmaps highlighting single or multiple input features. However, we ask
whether abstract reasoning or problem-solving strategies of a model may also be
relevant, as these align more closely with how humans approach solutions to
problems. We propose a framework, called Symbolic XAI, that attributes
relevance to symbolic queries expressing logical relationships between input
features, thereby capturing the abstract reasoning behind a model's
predictions. The methodology is built upon a simple yet general multi-order
decomposition of model predictions. This decomposition can be specified using
higher-order propagation-based relevance methods, such as GNN-LRP, or
perturbation-based explanation methods commonly used in XAI. The effectiveness
of our framework is demonstrated in the domains of natural language processing
(NLP), vision, and quantum chemistry (QC), where abstract symbolic domain
knowledge is abundant and of significant interest to users. The Symbolic XAI
framework provides an understanding of the model's decision-making process that
is both flexible for customization by the user and human-readable through
logical formulas.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FLeNS: Federated Learning with Enhanced Nesterov-Newton Sketch 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15216v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15216v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sunny Gupta, Mohit Jindal, Pankhi Kashyap, Pranav Jeevan, Amit Sethi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Federated learning faces a critical challenge in balancing communication
efficiency with rapid convergence, especially for second-order methods. While
Newton-type algorithms achieve linear convergence in communication rounds,
transmitting full Hessian matrices is often impractical due to quadratic
complexity. We introduce Federated Learning with Enhanced Nesterov-Newton
Sketch (FLeNS), a novel method that harnesses both the acceleration
capabilities of Nesterov's method and the dimensionality reduction benefits of
Hessian sketching. FLeNS approximates the centralized Newton's method without
relying on the exact Hessian, significantly reducing communication overhead. By
combining Nesterov's acceleration with adaptive Hessian sketching, FLeNS
preserves crucial second-order information while preserving the rapid
convergence characteristics. Our theoretical analysis, grounded in statistical
learning, demonstrates that FLeNS achieves super-linear convergence rates in
communication rounds - a notable advancement in federated optimization. We
provide rigorous convergence guarantees and characterize tradeoffs between
acceleration, sketch size, and convergence speed. Extensive empirical
evaluation validates our theoretical findings, showcasing FLeNS's
state-of-the-art performance with reduced communication requirements,
particularly in privacy-sensitive and edge-computing scenarios. The code is
available at https://github.com/sunnyinAI/FLeNS
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 3 figures, 2 Tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CompassDock: Comprehensive Accurate Assessment Approach for Deep
  Learning-Based Molecular Docking in Inference and Fine-Tuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.06841v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.06841v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ahmet Sarigun, Vedran Franke, Bora Uyar, Altuna Akalin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Datasets used for molecular docking, such as PDBBind, contain technical
variability - they are noisy. Although the origins of the noise have been
discussed, a comprehensive analysis of the physical, chemical, and bioactivity
characteristics of the datasets is still lacking. To address this gap, we
introduce the Comprehensive Accurate Assessment (Compass). Compass integrates
two key components: PoseCheck, which examines ligand strain energy,
protein-ligand steric clashes, and interactions, and AA-Score, a new empirical
scoring function for calculating binding affinity energy. Together, these form
a unified workflow that assesses both the physical/chemical properties and
bioactivity favorability of ligands and protein-ligand interactions. Our
analysis of the PDBBind dataset using Compass reveals substantial noise in the
ground truth data. Additionally, we propose CompassDock, which incorporates the
Compass module with DiffDock, the state-of-the-art deep learning-based
molecular docking method, to enable accurate assessment of docked ligands
during inference. Finally, we present a new paradigm for enhancing molecular
docking model performance by fine-tuning with Compass Scores, which encompass
binding affinity energy, strain energy, and the number of steric clashes
identified by Compass. Our results show that, while fine-tuning without Compass
improves the percentage of docked poses with RMSD < 2{\AA}, it leads to a
decrease in physical/chemical and bioactivity favorability. In contrast,
fine-tuning with Compass shows a limited improvement in RMSD < 2{\AA} but
enhances the physical/chemical and bioactivity favorability of the ligand
conformation. The source code is available publicly at
https://github.com/BIMSBbioinfo/CompassDock.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Generative Approach to Control Complex Physical Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.06494v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.06494v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Long Wei, Peiyan Hu, Ruiqi Feng, Haodong Feng, Yixuan Du, Tao Zhang, Rui Wang, Yue Wang, Zhi-Ming Ma, Tailin Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Controlling the evolution of complex physical systems is a fundamental task
across science and engineering. Classical techniques suffer from limited
applicability or huge computational costs. On the other hand, recent deep
learning and reinforcement learning-based approaches often struggle to optimize
long-term control sequences under the constraints of system dynamics. In this
work, we introduce Diffusion Physical systems Control (DiffPhyCon), a new class
of method to address the physical systems control problem. DiffPhyCon excels by
simultaneously minimizing both the learned generative energy function and the
predefined control objectives across the entire trajectory and control
sequence. Thus, it can explore globally and plan near-optimal control
sequences. Moreover, we enhance DiffPhyCon with prior reweighting, enabling the
discovery of control sequences that significantly deviate from the training
distribution. We test our method on three tasks: 1D Burgers' equation, 2D
jellyfish movement control, and 2D high-dimensional smoke control, where our
generated jellyfish dataset is released as a benchmark for complex physical
system control research. Our method outperforms widely applied classical
approaches and state-of-the-art deep learning and reinforcement learning
methods. Notably, DiffPhyCon unveils an intriguing fast-close-slow-open pattern
observed in the jellyfish, aligning with established findings in the field of
fluid dynamics. The project website, jellyfish dataset, and code can be found
at https://github.com/AI4Science-WestlakeU/diffphycon.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing Image Classification in Small and Unbalanced <span class="highlight-title">Dataset</span>s through
  Synthetic Data Augmentation <span class="chip">MICCAI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.10286v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.10286v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Neil De La Fuente, Mireia Majó, Irina Luzko, Henry Córdova, Gloria Fernández-Esparrach, Jorge Bernal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate and robust medical image classification is a challenging task,
especially in application domains where available annotated datasets are small
and present high imbalance between target classes. Considering that data
acquisition is not always feasible, especially for underrepresented classes,
our approach introduces a novel synthetic augmentation strategy using
class-specific Variational Autoencoders (VAEs) and latent space interpolation
to improve discrimination capabilities.
  By generating realistic, varied synthetic data that fills feature space gaps,
we address issues of data scarcity and class imbalance. The method presented in
this paper relies on the interpolation of latent representations within each
class, thus enriching the training set and improving the model's
generalizability and diagnostic accuracy. The proposed strategy was tested in a
small dataset of 321 images created to train and validate an automatic method
for assessing the quality of cleanliness of esophagogastroduodenoscopy images.
By combining real and synthetic data, an increase of over 18\% in the accuracy
of the most challenging underrepresented class was observed. The proposed
strategy not only benefited the underrepresented class but also led to a
general improvement in other metrics, including a 6\% increase in global
accuracy and precision.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>MICCAI 2024 (CLIP Workshop)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Scalable Data Assimilation with Message Passing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.12968v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.12968v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Oscar Key, So Takao, Daniel Giles, Marc Peter Deisenroth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Data assimilation is a core component of numerical weather prediction
systems. The large quantity of data processed during assimilation requires the
computation to be distributed across increasingly many compute nodes, yet
existing approaches suffer from synchronisation overhead in this setting. In
this paper, we exploit the formulation of data assimilation as a Bayesian
inference problem and apply a message-passing algorithm to solve the spatial
inference problem. Since message passing is inherently based on local
computations, this approach lends itself to parallel and distributed
computation. In combination with a GPU-accelerated implementation, we can scale
the algorithm to very large grid sizes while retaining good accuracy and
compute and memory requirements.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Finding Shared Decodable Concepts and their Negations in the Brain 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.17663v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.17663v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cory Efird, Alex Murphy, Joel Zylberberg, Alona Fyshe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prior work has offered evidence for functional localization in the brain;
different anatomical regions preferentially activate for certain types of
visual input. For example, the fusiform face area preferentially activates for
visual stimuli that include a face. However, the spectrum of visual semantics
is extensive, and only a few semantically-tuned patches of cortex have so far
been identified in the human brain. Using a multimodal (natural language and
image) neural network architecture (CLIP) we train a highly accurate
contrastive model that maps brain responses during naturalistic image viewing
to CLIP embeddings. We then use a novel adaptation of the DBSCAN clustering
algorithm to cluster the parameters of these participant-specific contrastive
models. This reveals what we call Shared Decodable Concepts (SDCs): clusters in
CLIP space that are decodable from common sets of voxels across multiple
participants.
  Examining the images most and least associated with each SDC cluster gives us
additional insight into the semantic properties of each SDC. We note SDCs for
previously reported visual features (e.g. orientation tuning in early visual
cortex) as well as visual semantic concepts such as faces, places and bodies.
In cases where our method finds multiple clusters for a visuo-semantic concept,
the least associated images allow us to dissociate between confounding factors.
For example, we discovered two clusters of food images, one driven by color,
the other by shape. We also uncover previously unreported areas such as regions
of extrastriate body area (EBA) tuned for legs/hands and sensitivity to
numerosity in right intraparietal sulcus, and more. Thus, our
contrastive-learning methodology better characterizes new and existing
visuo-semantic representations in the brain by leveraging multimodal neural
network representations and a novel adaptation of clustering algorithms.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Uniqueness of LLaMA3-70B Series with Per-Channel Quantization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.15301v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.15301v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minghai Qin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We have observed a distinctive quantization-related behavior in the
LLaMA3/3.1-70B models that is absent in both the LLaMA2-70B and
LLaMA3/3.1/3.2-1B/3B/8B/405B models. Quantization is a crucial technique for
deploying large language models (LLMs) efficiently. The impact of W8A8
post-training quantization on model accuracy, especially on the recently
released LLaMA3/3.1 model series, remains contentious. In this paper, we
explore three key questions: What makes the LLaMA3-70B model series uniquely
vulnerable to quantization? Why is this the case? And how can the issue be
addressed? We empirically investigate multiple LLMs featured on an open LLM
leaderboard, discovering that the LLaMA3-70B model series have a unique
accuracy degradation behavior with W8A8 per-channel post-training quantization.
In contrast, other model series such as LLaMA2, LLaMA3/3.1-8B, LLaMA3.2, Qwen,
Mixtral, Mistral, Phi-3, and Falcon demonstrate robust performance with W8A8.
Contrary to previous assertions attributing degradation to the large dynamic
range of activations, our findings indicate that the weight distribution of the
LLaMA3-70B is the primary factor behind the vulnerability. By meticulously
analyzing the distinct characteristics of weight distributions across
Transformer blocks, we propose two solutions that make different tradeoffs in
hardware/software overhead. First, we propose a mixed strategy where less than
3\% of the layers employ finer per-group W8A8 quantization granularity. Second,
we introduce a bi-smoothing strategy that balances quantization errors between
weights and activations while maintaining per-channel quantization throughout.
Experimental results demonstrate that both strategies effectively preserve the
accuracy of the entire LLaMA3-70B model series under W8A8 quantization,
achieving performance on par with their FP16 counterparts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>27 pages, 41 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Toward General-Purpose Robots via Foundation Models: A <span class="highlight-title">Survey</span> and
  Meta-Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.08782v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.08782v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yafei Hu, Quanting Xie, Vidhi Jain, Jonathan Francis, Jay Patrikar, Nikhil Keetha, Seungchan Kim, Yaqi Xie, Tianyi Zhang, Hao-Shu Fang, Shibo Zhao, Shayegan Omidshafiei, Dong-Ki Kim, Ali-akbar Agha-mohammadi, Katia Sycara, Matthew Johnson-Roberson, Dhruv Batra, Xiaolong Wang, Sebastian Scherer, Chen Wang, Zsolt Kira, Fei Xia, Yonatan Bisk
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Building general-purpose robots that operate seamlessly in any environment,
with any object, and utilizing various skills to complete diverse tasks has
been a long-standing goal in Artificial Intelligence. However, as a community,
we have been constraining most robotic systems by designing them for specific
tasks, training them on specific datasets, and deploying them within specific
environments. These systems require extensively-labeled data and task-specific
models. When deployed in real-world scenarios, such systems face several
generalization issues and struggle to remain robust to distribution shifts.
Motivated by the impressive open-set performance and content generation
capabilities of web-scale, large-capacity pre-trained models (i.e., foundation
models) in research fields such as Natural Language Processing (NLP) and
Computer Vision (CV), we devote this survey to exploring (i) how these existing
foundation models from NLP and CV can be applied to the field of
general-purpose robotics, and also exploring (ii) what a robotics-specific
foundation model would look like. We begin by providing a generalized
formulation of how foundation models are used in robotics, and the fundamental
barriers to making generalist robots universally applicable. Next, we establish
a taxonomy to discuss current work exploring ways to leverage existing
foundation models for robotics and develop ones catered to robotics. Finally,
we discuss key challenges and promising future directions in using foundation
models for enabling general-purpose robotic systems. We encourage readers to
view our living GitHub repository 2 of resources, including papers reviewed in
this survey, as well as related projects and repositories for developing
foundation models for robotics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mutatis Mutandis: Revisiting the Comparator in Discrimination Testing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.13693v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.13693v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jose M. Alvarez, Salvatore Ruggieri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Testing for discrimination consists of deriving a profile, known as the
comparator, similar to the profile making the discrimination claim, known as
the complainant, and comparing the outcomes of these two profiles. An important
aspect for establishing discrimination is evidence, often obtained via
discrimination testing tools that implement the complainant-comparator pair. In
this work, we revisit the role of the comparator in discrimination testing. We
argue for the causal modeling nature of deriving the comparator, and introduce
a two-kinds classification for the comparator: the ceteris paribus (CP), and
mutatis mutandis (MM) comparators. The CP comparator is the standard one among
discrimination testing, representing an idealized comparison as it aims for
having a complainant-comparator pair that only differs on membership to the
protected attribute. As an alternative to it, we define the MM comparator,
which requires that the comparator represents what would have been of the
complainant without the effects of the protected attribute on the non-protected
attributes. The complainant-comparator pair, in that case, may also be
dissimilar in terms of all attributes. We illustrate these two comparators and
their impact on discrimination testing using a real illustrative example.
Importantly, we position generative models and, overall, machine learning
methods as useful tools for constructing the MM comparator and, in turn,
achieving more complex and realistic comparisons when testing for
discrimination.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SpeedUpNet: A Plug-and-Play Adapter Network for Accelerating
  Text-to-Image Diffusion Models <span class="chip">ECCV 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.08887v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.08887v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weilong Chai, DanDan Zheng, Jiajiong Cao, Zhiquan Chen, Changbao Wang, Chenguang Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-image diffusion models (SD) exhibit significant advancements while
requiring extensive computational resources. Existing acceleration methods
usually require extensive training and are not universally applicable.
LCM-LoRA, trainable once for diverse models, offers universality but rarely
considers ensuring the consistency of generated content before and after
acceleration. This paper proposes SpeedUpNet (SUN), an innovative acceleration
module, to address the challenges of universality and consistency. Exploiting
the role of cross-attention layers in U-Net for SD models, we introduce an
adapter specifically designed for these layers, quantifying the offset in image
generation caused by negative prompts relative to positive prompts. This
learned offset demonstrates stability across a range of models, enhancing SUN's
universality. To improve output consistency, we propose a Multi-Step
Consistency (MSC) loss, which stabilizes the offset and ensures fidelity in
accelerated content. Experiments on SD v1.5 show that SUN leads to an overall
speedup of more than 10 times compared to the baseline 25-step DPM-solver++,
and offers two extra advantages: (1) training-free integration into various
fine-tuned Stable-Diffusion models and (2) state-of-the-art FIDs of the
generated data set before and after acceleration guided by random combinations
of positive and negative prompts. Code is available:
https://williechai.github.io/speedup-plugin-for-stable-diffusions.github.io.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ECCV 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Shaking Up VLMs: Comparing <span class="highlight-title">Transformer</span>s and Structured State Space
  Models for Vision & Language Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.05395v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.05395v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Georgios Pantazopoulos, Malvina Nikandrou, Alessandro Suglia, Oliver Lemon, Arash Eshghi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study explores replacing Transformers in Visual Language Models (VLMs)
with Mamba, a recent structured state space model (SSM) that demonstrates
promising performance in sequence modeling. We test models up to 3B parameters
under controlled conditions, showing that Mamba-based VLMs outperforms
Transformers-based VLMs in captioning, question answering, and reading
comprehension. However, we find that Transformers achieve greater performance
in visual grounding and the performance gap widens with scale. We explore two
hypotheses to explain this phenomenon: 1) the effect of task-agnostic visual
encoding on the updates of the hidden states, and 2) the difficulty in
performing visual grounding from the perspective of in-context multimodal
retrieval. Our results indicate that a task-aware encoding yields minimal
performance gains on grounding, however, Transformers significantly outperform
Mamba at in-context multimodal retrieval. Overall, Mamba shows promising
performance on tasks where the correct output relies on a summary of the image
but struggles when retrieval of explicit information from the context is
required.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Removing the need for ground truth UWB data collection: <span class="highlight-title">self-supervised</span>
  ranging error correction using deep reinforcement learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.19262v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.19262v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dieter Coppens, Ben Van Herbruggen, Adnan Shahid, Eli De Poorter
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Indoor positioning using UWB technology has gained interest due to its
centimeter-level accuracy potential. However, multipath effects and
non-line-of-sight conditions cause ranging errors between anchors and tags.
Existing approaches for mitigating these ranging errors rely on collecting
large labeled datasets, making them impractical for real-world deployments.
This paper proposes a novel self-supervised deep reinforcement learning
approach that does not require labeled ground truth data. A reinforcement
learning agent uses the channel impulse response as a state and predicts
corrections to minimize the error between corrected and estimated ranges. The
agent learns, self-supervised, by iteratively improving corrections that are
generated by combining the predictability of trajectories with filtering and
smoothening. Experiments on real-world UWB measurements demonstrate comparable
performance to state-of-the-art supervised methods, overcoming data dependency
and lack of generalizability limitations. This makes self-supervised deep
reinforcement learning a promising solution for practical and scalable
UWB-ranging error correction.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 9 figures and 5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A POD-TANN approach for the multiscale modeling of materials and
  macroelement derivation in geomechanics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.07165v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.07165v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Giovanni Piunno, Ioannis Stefanou, Cristina Jommi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces a novel approach that combines Proper Orthogonal
Decomposition (POD) with Thermodynamics-based Artificial Neural Networks (TANN)
to capture the macroscopic behavior of complex inelastic systems and derive
macroelements in geomechanics.
  The methodology leverages POD to extract macroscopic Internal State Variables
from microscopic state information, thereby enriching the macroscopic state
description used to train an energy potential network within the TANN
framework. The thermodynamic consistency provided by TANN, combined with the
hierarchical nature of POD, allows to reproduce complex, non-linear inelastic
material behaviors as well as macroscopic geomechanical systems responses.
  The approach is validated through applications of increasing complexity,
demonstrating its capability to reproduce high-fidelity simulation data. The
applications proposed include the homogenization of continuous inelastic
representative unit cells and the derivation of a macroelement for a
geotechnical system involving a monopile in a clay layer subjected to
horizontal loading. Eventually, the projection operators directly obtained via
POD, are exploit to easily reconstruct the microscopic fields.
  The results indicate that the POD-TANN approach not only offers accuracy in
reproducing the studied constitutive responses, but also reduces computational
costs, making it a practical tool for the multiscale modeling of heterogeneous
inelastic geomechanical systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>46 pages, Submitted to International Journal for Numerical and
  Analytical Methods in Geomechanics</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A TextGCN-Based Decoding Approach for Improving Remote Sensing Image
  Captioning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.18467v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.18467v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Swadhin Das, Raksha Sharma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Remote sensing images are highly valued for their ability to address complex
real-world issues such as risk management, security, and meteorology. However,
manually captioning these images is challenging and requires specialized
knowledge across various domains. This letter presents an approach for
automatically describing (captioning) remote sensing images. We propose a novel
encoder-decoder setup that deploys a Text Graph Convolutional Network (TextGCN)
and multi-layer LSTMs. The embeddings generated by TextGCN enhance the
decoder's understanding by capturing the semantic relationships among words at
both the sentence and corpus levels. Furthermore, we advance our approach with
a comparison-based beam search method to ensure fairness in the search strategy
for generating the final caption. We present an extensive evaluation of our
approach against various other state-of-the-art encoder-decoder frameworks. We
evaluated our method across three datasets using seven metrics: BLEU-1 to
BLEU-4, METEOR, ROUGE-L, and CIDEr. The results demonstrate that our approach
significantly outperforms other state-of-the-art encoder-decoder methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Transductive Active Learning: Theory and Applications 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.15898v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.15898v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jonas Hübotter, Bhavya Sukhija, Lenart Treven, Yarden As, Andreas Krause
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We generalize active learning to address real-world settings with concrete
prediction targets where sampling is restricted to an accessible region of the
domain, while prediction targets may lie outside this region. We analyze a
family of decision rules that sample adaptively to minimize uncertainty about
prediction targets. We are the first to show, under general regularity
assumptions, that such decision rules converge uniformly to the smallest
possible uncertainty obtainable from the accessible data. We demonstrate their
strong sample efficiency in two key applications: Active few-shot fine-tuning
of large neural networks and safe Bayesian optimization, where they improve
significantly upon the state-of-the-art.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>arXiv admin note: substantial text overlap with arXiv:2402.15441</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Generalized Learning of Coefficients in Spectral Graph Convolutional
  Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.04813v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.04813v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mustafa Coşkun, Ananth Grama, Mehmet Koyutürk
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spectral Graph Convolutional Networks (GCNs) have gained popularity in graph
machine learning applications due, in part, to their flexibility in
specification of network propagation rules. These propagation rules are often
constructed as polynomial filters whose coefficients are learned using label
information during training. In contrast to learned polynomial filters,
explicit filter functions are useful in capturing relationships between network
topology and distribution of labels across the network. A number of algorithms
incorporating either approach have been proposed; however the relationship
between filter functions and polynomial approximations is not fully resolved.
This is largely due to the ill-conditioned nature of the linear systems that
must be solved to derive polynomial approximations of filter functions. To
address this challenge, we propose a novel Arnoldi orthonormalization-based
algorithm, along with a unifying approach, called G-Arnoldi-GCN that can
efficiently and effectively approximate a given filter function with a
polynomial. We evaluate G-Arnoldi-GCN in the context of multi-class node
classification across ten datasets with diverse topological characteristics.
Our experiments show that G-Arnoldi-GCN consistently outperforms
state-of-the-art methods when suitable filter functions are employed. Overall,
G-Arnoldi-GCN opens important new directions in graph machine learning by
enabling the explicit design and application of diverse filter functions. Code
link: https://github.com/mustafaCoskunAgu/GArnoldi-GCN
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Recursive deep learning framework for forecasting the decadal world
  economic outlook 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2301.10874v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2301.10874v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianyi Wang, Rodney Beard, John Hawkins, Rohitash Chandra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The gross domestic product (GDP) is the most widely used indicator in
macroeconomics and the main tool for measuring a country's economic output. Due
to the diversity and complexity of the world economy, a wide range of models
have been used, but there are challenges in making decadal GDP forecasts given
unexpected changes such as emergence of catastrophic world events including
pandemics and wars. Deep learning models are well suited for modelling temporal
sequences and time series forecasting. In this paper, we develop a deep
learning framework to forecast the GDP growth rate of the world economy over a
decade. We use the Penn World Table as the data source featuring 13 countries
prior to the COVID-19 pandemic, such as Australia, China, India, and the United
States. We present a recursive deep learning framework to predict the GDP
growth rate in the next ten years. We test prominent deep learning models and
compare their results with traditional econometric models for selected
developed and developing countries. Our decadal forecasts reveal that that most
of the developed countries would experience economic growth slowdown,
stagnation and even recession within five years (2020-2024). Furthermore, our
model forecasts show that only China, France, and India would experience stable
GDP growth.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Obliviate: Neutralizing Task-agnostic Backdoors within the
  Parameter-efficient Fine-tuning Paradigm 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.14119v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.14119v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jaehan Kim, Minkyoo Song, Seung Ho Na, Seungwon Shin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Parameter-efficient fine-tuning (PEFT) has become a key training strategy for
large language models. However, its reliance on fewer trainable parameters
poses security risks, such as task-agnostic backdoors. Despite their severe
impact on a wide range of tasks, there is no practical defense solution
available that effectively counters task-agnostic backdoors within the context
of PEFT. In this study, we introduce Obliviate, a PEFT-integrable backdoor
defense. We develop two techniques aimed at amplifying benign neurons within
PEFT layers and penalizing the influence of trigger tokens. Our evaluations
across three major PEFT architectures show that our method can significantly
reduce the attack success rate of the state-of-the-art task-agnostic backdoors
(83.6%$\downarrow$). Furthermore, our method exhibits robust defense
capabilities against both task-specific backdoors and adaptive attacks. Source
code will be obtained at https://github.com/obliviateARR/Obliviate.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unsupervised Concept Drift Detection based on Parallel Activations of
  Neural Network 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.07776v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.07776v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joanna Komorniczak, Paweł Ksieniewicz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Practical applications of artificial intelligence increasingly often have to
deal with the streaming properties of real data, which, considering the time
factor, are subject to phenomena such as periodicity and more or less chaotic
degeneration - resulting directly in the concept drifts. The modern concept
drift detectors almost always assume immediate access to labels, which due to
their cost, limited availability and possible delay has been shown to be
unrealistic. This work proposes an unsupervised Parallel Activations Drift
Detector, utilizing the outputs of an untrained neural network, presenting its
key design elements, intuitions about processing properties, and a pool of
computer experiments demonstrating its competitiveness with state-of-the-art
methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Identifiable Shared Component Analysis of Unpaired Multimodal Mixtures 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19422v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19422v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Subash Timilsina, Sagar Shrestha, Xiao Fu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A core task in multi-modal learning is to integrate information from multiple
feature spaces (e.g., text and audio), offering modality-invariant essential
representations of data. Recent research showed that, classical tools such as
{\it canonical correlation analysis} (CCA) provably identify the shared
components up to minor ambiguities, when samples in each modality are generated
from a linear mixture of shared and private components. Such identifiability
results were obtained under the condition that the cross-modality samples are
aligned/paired according to their shared information. This work takes a step
further, investigating shared component identifiability from multi-modal linear
mixtures where cross-modality samples are unaligned. A distribution divergence
minimization-based loss is proposed, under which a suite of sufficient
conditions ensuring identifiability of the shared components are derived. Our
conditions are based on cross-modality distribution discrepancy
characterization and density-preserving transform removal, which are much
milder than existing studies relying on independent component analysis. More
relaxed conditions are also provided via adding reasonable structural
constraints, motivated by available side information in various applications.
The identifiability claims are thoroughly validated using synthetic and
real-world data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Redefining Data Pairing for Motion Retargeting Leveraging a Human Body
  Prior <span class="chip">IROS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.13208v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.13208v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiyana Figuera, Soogeun Park, Hyemin Ahn
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose MR HuBo(Motion Retargeting leveraging a HUman BOdy prior), a
cost-effective and convenient method to collect high-quality upper body paired
<robot, human> pose data, which is essential for data-driven motion retargeting
methods. Unlike existing approaches which collect <robot, human> pose data by
converting human MoCap poses into robot poses, our method goes in reverse. We
first sample diverse random robot poses, and then convert them into human
poses. However, since random robot poses can result in extreme and infeasible
human poses, we propose an additional technique to sort out extreme poses by
exploiting a human body prior trained from a large amount of human pose data.
Our data collection method can be used for any humanoid robots, if one designs
or optimizes the system's hyperparameters which include a size scale factor and
the joint angle ranges for sampling. In addition to this data collection
method, we also present a two-stage motion retargeting neural network that can
be trained via supervised learning on a large amount of paired data. Compared
to other learning-based methods trained via unsupervised learning, we found
that our deep neural network trained with ample high-quality paired data
achieved notable performance. Our experiments also show that our data filtering
method yields better retargeting results than training the model with raw and
noisy data. Our code and video results are available on
https://sites.google.com/view/mr-hubo/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 5 Figures, Accepted at IROS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Unsupervised Meta-Learning via In-Context Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.16124v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.16124v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anna Vettoruzzo, Lorenzo Braccaioli, Joaquin Vanschoren, Marlena Nowaczyk
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Unsupervised meta-learning aims to learn feature representations from
unsupervised datasets that can transfer to downstream tasks with limited
labeled data. In this paper, we propose a novel approach to unsupervised
meta-learning that leverages the generalization abilities of in-context
learning observed in transformer architectures. Our method reframes
meta-learning as a sequence modeling problem, enabling the transformer encoder
to learn task context from support images and utilize it to predict query
images. At the core of our approach lies the creation of diverse tasks
generated using a combination of data augmentations and a mixing strategy that
challenges the model during training while fostering generalization to unseen
tasks at test time. Experimental results on benchmark datasets showcase the
superiority of our approach over existing unsupervised meta-learning baselines,
establishing it as the new state-of-the-art in the field. Remarkably, our
method achieves competitive results with supervised and self-supervised
approaches, underscoring the efficacy of the model in leveraging generalization
over memorization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MDA: An Interpretable Multi-Modal Fusion with Missing Modalities and
  Intrinsic Noise 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.10569v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.10569v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lin Fan, Yafei Ou, Cenyang Zheng, Pengyu Dai, Tamotsu Kamishima, Masayuki Ikebe, Kenji Suzuki, Xun Gong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-modal fusion is crucial in medical data research, enabling a
comprehensive understanding of diseases and improving diagnostic performance by
combining diverse modalities. However, multi-modal fusion faces challenges,
including capturing interactions between modalities, addressing missing
modalities, handling erroneous modal information, and ensuring
interpretability. Many existing researchers tend to design different solutions
for these problems, often overlooking the commonalities among them. This paper
proposes a novel multi-modal fusion framework that achieves adaptive adjustment
over the weights of each modality by introducing the Modal-Domain Attention
(MDA). It aims to facilitate the fusion of multi-modal information while
allowing for the inclusion of missing modalities or intrinsic noise, thereby
enhancing the representation of multi-modal data. We provide visualizations of
accuracy changes and MDA weights by observing the process of modal fusion,
offering a comprehensive analysis of its interpretability. Extensive
experiments on various gastrointestinal disease benchmarks, the proposed MDA
maintains high accuracy even in the presence of missing modalities and
intrinsic noise. One thing worth mentioning is that the visualization of MDA is
highly consistent with the conclusions of existing clinical studies on the
dependence of different diseases on various modalities. Code and dataset will
be made available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FLEX: Expert-level False-Less EXecution Metric for Reliable Text-to-SQL
  Benchmark 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19014v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19014v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Heegyu Kim, Taeyang Jeon, Seunghwan Choi, Seungtaek Choi, Hyunsouk Cho
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text-to-SQL technology has become crucial for translating natural language
into SQL queries in various industries, enabling non-technical users to perform
complex data operations. The need for accurate evaluation methods has increased
as these systems have grown more sophisticated. However, we found that the
Execution Accuracy (EX), the most promising evaluation metric, still shows a
substantial portion of false positives and negatives compared to human
evaluation. Thus, this paper introduces FLEX (False-Less EXecution), a novel
approach to evaluating text-to-SQL systems using large language models (LLMs)
to emulate human expert-level evaluation of SQL queries. Our method shows
significantly higher agreement with human expert judgments, improving Cohen's
kappa from 61 to 78.17. Re-evaluating top-performing models on the Spider and
BIRD benchmarks using FLEX reveals substantial shifts in performance rankings,
with an average performance decrease of 3.15 due to false positive corrections
and an increase of 6.07 from addressing false negatives. This work contributes
to a more accurate and nuanced evaluation of text-to-SQL systems, potentially
reshaping our understanding of state-of-the-art performance in this field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>preprint, under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Foundation Model for Zero-shot Logical Query Reasoning <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.07198v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.07198v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mikhail Galkin, Jincheng Zhou, Bruno Ribeiro, Jian Tang, Zhaocheng Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Complex logical query answering (CLQA) in knowledge graphs (KGs) goes beyond
simple KG completion and aims at answering compositional queries comprised of
multiple projections and logical operations. Existing CLQA methods that learn
parameters bound to certain entity or relation vocabularies can only be applied
to the graph they are trained on which requires substantial training time
before being deployed on a new graph. Here we present UltraQuery, the first
foundation model for inductive reasoning that can zero-shot answer logical
queries on any KG. The core idea of UltraQuery is to derive both projections
and logical operations as vocabulary-independent functions which generalize to
new entities and relations in any KG. With the projection operation initialized
from a pre-trained inductive KG reasoning model, UltraQuery can solve CLQA on
any KG after finetuning on a single dataset. Experimenting on 23 datasets,
UltraQuery in the zero-shot inference mode shows competitive or better query
answering performance than best available baselines and sets a new state of the
art on 15 of them.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CPL: Critical Plan Step Learning Boosts LLM Generalization in Reasoning
  Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.08642v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.08642v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianlong Wang, Junzhe Chen, Xueting Han, Jing Bai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Post-training, particularly reinforcement learning (RL) using
self-play-generated data, has become a new learning paradigm for large language
models (LLMs). However, scaling RL to develop a general reasoner remains a
research challenge, as existing methods focus on task-specific reasoning
without adequately addressing generalization across a broader range of tasks.
Moreover, unlike traditional RL with limited action space, LLMs operate in an
infinite space, making it crucial to search for valuable and diverse strategies
to solve problems effectively. To address this, we propose searching within the
action space on high-level abstract plans to enhance model generalization and
introduce Critical Plan Step Learning (CPL), comprising: 1) searching on plan,
using Monte Carlo Tree Search (MCTS) to explore diverse plan steps in
multi-step reasoning tasks, and 2) learning critical plan steps through
Step-level Advantage Preference Optimization (Step-APO), which integrates
advantage estimates for step preference obtained via MCTS into Direct
Preference Optimization (DPO). This combination helps the model effectively
learn critical plan steps, enhancing both reasoning capabilities and
generalization. Experimental results demonstrate that our method, trained
exclusively on GSM8K and MATH, not only significantly improves performance on
GSM8K (+10.5%) and MATH (+6.5%), but also enhances out-of-domain reasoning
benchmarks, such as HumanEval (+12.2%), GPQA (+8.6%), ARC-C (+4.0%), MMLU-STEM
(+2.2%), and BBH (+1.8%).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Federated Instruction Tuning of LLMs with Domain Coverage Augmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.20135v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.20135v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zezhou Wang, Yaxin Du, Zhuzhong Qian, Siheng Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Federated Domain-specific Instruction Tuning (FedDIT) utilizes limited
cross-client private data alongside server-side public data for instruction
augmentation, ultimately enhancing model performance within specific domains.
While the factors affecting FedDIT remain unclear and existing instruction
augmentation methods mainly focus on the centralized setting without
considering the distributed environment. Our experiments reveal that the
cross-client domain coverage, rather than data heterogeneity, drives model
performance in FedDIT. In response, we propose FedDCA, which optimizes domain
coverage through greedy client center selection and retrieval-based
augmentation. To alleviate client-side computational burdens, FedDCA$^*$ uses
heterogeneous encoders with server-side feature alignment. Extensive
experiments across four distinct domains (code, medical, financial, and
mathematical) substantiate the effectiveness of both methods. Additionally, we
investigate privacy preservation against memory extraction attacks utilizing
varying amounts of public data. Results show no significant correlation between
the volume of public data and the privacy-preserving capability. However, as
the fine-tuning round increases, the risk of privacy leakage reduces or
converges.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Accelerating Communication in Deep Learning Recommendation Model
  Training with Dual-Level Adaptive Lossy Compression <span class="chip">SC '24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.04272v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.04272v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Feng, Boyuan Zhang, Fanjiang Ye, Min Si, Ching-Hsiang Chu, Jiannan Tian, Chunxing Yin, Summer Deng, Yuchen Hao, Pavan Balaji, Tong Geng, Dingwen Tao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  DLRM is a state-of-the-art recommendation system model that has gained
widespread adoption across various industry applications. The large size of
DLRM models, however, necessitates the use of multiple devices/GPUs for
efficient training. A significant bottleneck in this process is the
time-consuming all-to-all communication required to collect embedding data from
all devices. To mitigate this, we introduce a method that employs error-bounded
lossy compression to reduce the communication data size and accelerate DLRM
training. We develop a novel error-bounded lossy compression algorithm,
informed by an in-depth analysis of embedding data features, to achieve high
compression ratios. Moreover, we introduce a dual-level adaptive strategy for
error-bound adjustment, spanning both table-wise and iteration-wise aspects, to
balance the compression benefits with the potential impacts on accuracy. We
further optimize our compressor for PyTorch tensors on GPUs, minimizing
compression overhead. Evaluation shows that our method achieves a 1.38$\times$
training speedup with a minimal accuracy impact.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>camera-ready version for SC '24</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GlycanML: A Multi-Task and Multi-Structure Benchmark for Glycan Machine
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.16206v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.16206v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minghao Xu, Yunteng Geng, Yihang Zhang, Ling Yang, Jian Tang, Wentao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Glycans are basic biomolecules and perform essential functions within living
organisms. The rapid increase of functional glycan data provides a good
opportunity for machine learning solutions to glycan understanding. However,
there still lacks a standard machine learning benchmark for glycan property and
function prediction. In this work, we fill this blank by building a
comprehensive benchmark for Glycan Machine Learning (GlycanML). The GlycanML
benchmark consists of diverse types of tasks including glycan taxonomy
prediction, glycan immunogenicity prediction, glycosylation type prediction,
and protein-glycan interaction prediction. Glycans can be represented by both
sequences and graphs in GlycanML, which enables us to extensively evaluate
sequence-based models and graph neural networks (GNNs) on benchmark tasks.
Furthermore, by concurrently performing eight glycan taxonomy prediction tasks,
we introduce the GlycanML-MTL testbed for multi-task learning (MTL) algorithms.
Also, we evaluate how taxonomy prediction can boost other three function
prediction tasks by MTL. Experimental results show the superiority of modeling
glycans with multi-relational GNNs, and suitable MTL methods can further boost
model performance. We provide all datasets and source codes at
https://github.com/GlycanML/GlycanML and maintain a leaderboard at
https://GlycanML.github.io/project
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Research project paper. All code and data are released</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Federated Learning with Reduced Information Leakage and Computation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.06341v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.06341v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tongxin Yin, Xuwei Tan, Xueru Zhang, Mohammad Mahdi Khalili, Mingyan Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Federated learning (FL) is a distributed learning paradigm that allows
multiple decentralized clients to collaboratively learn a common model without
sharing local data. Although local data is not exposed directly, privacy
concerns nonetheless exist as clients' sensitive information can be inferred
from intermediate computations. Moreover, such information leakage accumulates
substantially over time as the same data is repeatedly used during the
iterative learning process. As a result, it can be particularly difficult to
balance the privacy-accuracy trade-off when designing privacy-preserving FL
algorithms. This paper introduces Upcycled-FL, a simple yet effective strategy
that applies first-order approximation at every even round of model update.
Under this strategy, half of the FL updates incur no information leakage and
require much less computational and transmission costs. We first conduct the
theoretical analysis on the convergence (rate) of Upcycled-FL and then apply
two perturbation mechanisms to preserve privacy. Extensive experiments on both
synthetic and real-world data show that the Upcycled-FL strategy can be adapted
to many existing FL frameworks and consistently improve the privacy-accuracy
trade-off.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by Transactions on Machine Learning Research (TMLR)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Identifying Spurious Correlations using Counterfactual Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.02186v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.02186v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Joseph Paul Cohen, Louis Blankemeier, Akshay Chaudhari
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Models driven by spurious correlations often yield poor generalization
performance. We propose the counterfactual (CF) alignment method to detect and
quantify spurious correlations of black box classifiers. Our methodology is
based on counterfactual images generated with respect to one classifier being
input into other classifiers to see if they also induce changes in the outputs
of these classifiers. The relationship between these responses can be
quantified and used to identify specific instances where a spurious correlation
exists. This is validated by observing intuitive trends in a face-attribute
face-attribute and waterbird classifiers, as well as by fabricating spurious
correlations and detecting their presence, both visually and quantitatively.
Furthermore, utilizing the CF alignment method, we demonstrate that we can
evaluate robust optimization methods (GroupDRO, JTT, and FLAC) by detecting a
reduction in spurious correlations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FedDTG:Federated Data-Free Knowledge Distillation via Three-Player
  Generative Adversarial Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2201.03169v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2201.03169v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lingzhi Gao, Zhenyuan Zhang, Chao Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While existing federated learning approaches primarily focus on aggregating
local models to construct a global model, in realistic settings, some clients
may be reluctant to share their private models due to the inclusion of
privacy-sensitive information. Knowledge distillation, which can extract model
knowledge without accessing model parameters, is well-suited for this federated
scenario. However, most distillation methods in federated learning (federated
distillation) require a proxy dataset, which is difficult to obtain in the real
world. Therefore, in this paper, we introduce a distributed three-player
Generative Adversarial Network (GAN) to implement data-free mutual distillation
and propose an effective method called FedDTG. We confirmed that the fake
samples generated by GAN can make federated distillation more efficient and
robust. Additionally, the distillation process between clients can deliver good
individual client performance while simultaneously acquiring global knowledge
and protecting data privacy. Our extensive experiments on benchmark vision
datasets demonstrate that our method outperforms other federated distillation
algorithms in terms of generalization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs <span class="chip">ICLR
  2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.02262v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.02262v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qingru Zhang, Chandan Singh, Liyuan Liu, Xiaodong Liu, Bin Yu, Jianfeng Gao, Tuo Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In human-written articles, we often leverage the subtleties of text style,
such as bold and italics, to guide the attention of readers. These textual
emphases are vital for the readers to grasp the conveyed information. When
interacting with large language models (LLMs), we have a similar need --
steering the model to pay closer attention to user-specified information, e.g.,
an instruction. Existing methods, however, are constrained to process plain
text and do not support such a mechanism. This motivates us to introduce PASTA
-- Post-hoc Attention STeering Approach, a method that allows LLMs to read text
with user-specified emphasis marks. To this end, PASTA identifies a small
subset of attention heads and applies precise attention reweighting on them,
directing the model attention to user-specified parts. Like prompting, PASTA is
applied at inference time and does not require changing any model parameters.
Experiments demonstrate that PASTA can substantially enhance an LLM's ability
to follow user instructions or integrate new knowledge from user inputs,
leading to a significant performance improvement on a variety of tasks, e.g.,
an average accuracy improvement of 22% for LLAMA-7B. Our code is publicly
available at https://github.com/QingruZhang/PASTA .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The 12th International Conference on Learning Representations (ICLR
  2024)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Block-Attention for Efficient RAG 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15355v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15355v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        East Sun, Yan Wang, Lan Tian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce Block-Attention, an attention mechanism designed to address the
increased inference latency and cost in Retrieval-Augmented Generation (RAG)
scenarios. Traditional approaches often encode the entire context. Instead,
Block-Attention divides retrieved documents into discrete blocks, with each
block independently calculating key-value (KV) states except for the final
block. In RAG scenarios, by defining each passage as a block, Block-Attention
enables us to reuse the KV states of passages that have been seen before,
thereby significantly reducing the latency and the computation overhead during
inference. The implementation of Block-Attention involves block segmentation,
position re-encoding, and fine-tuning the LLM to adapt to the Block-Attention
mechanism. Experiments on four RAG benchmarks demonstrate that after block
fine-tuning, the Block-Attention model achieves performance comparable to
self-attention models (68.4\% vs 67.9\% on Llama3) or even superior performance
(62.8\% vs 59.6\% on Mistral). Notably, Block-Attention significantly reduces
the time to first token (TTFT) and floating point operations (FLOPs) to a very
low level. It only takes 45 ms to output the first token for an input sequence
with a total length of 32K. Compared to the self-attention models, the time
consumption and corresponding FLOPs are reduced by 98.7\% and 99.8\%,
respectively.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A SSM is Polymerized from Multivariate Time Series 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.20310v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.20310v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haixiang Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For multivariate time series (MTS) tasks, previous state space models (SSMs)
followed the modeling paradigm of Transformer-based methods. However, none of
them explicitly model the complex dependencies of MTS: the Channel Dependency
variations with Time (CDT). In view of this, we delve into the derivation of
SSM, which involves approximating continuously updated functions by orthogonal
function basis. We then develop Poly-Mamba, a novel method for MTS forecasting.
Its core concept is to expand the original orthogonal function basis space into
a multivariate orthogonal function space containing variable mixing terms, and
make a projection on this space so as to explicitly describe the CDT by
weighted coefficients. In Poly-Mamba, we propose the Multivariate Orthogonal
Polynomial Approximation (MOPA) as a simplified implementation of this concept.
For the simple linear relationship between channels, we propose Linear Channel
Mixing (LCM) and generate CDT patterns adaptively for different channels
through a proposed Order Combining method. Experiments on six real-world
datasets demonstrate that Poly-Mamba outperforms the SOTA methods, especially
when dealing with datasets having a large number of channels and complex
correlations. The codes and log files will be released at:
https://github.com/Joeland4/Poly-Mamba.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Privacy Evaluation Benchmarks for NLP Models <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15868v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15868v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Huang, Yinggui Wang, Cen Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  By inducing privacy attacks on NLP models, attackers can obtain sensitive
information such as training data and model parameters, etc. Although
researchers have studied, in-depth, several kinds of attacks in NLP models,
they are non-systematic analyses. It lacks a comprehensive understanding of the
impact caused by the attacks. For example, we must consider which scenarios can
apply to which attacks, what the common factors are that affect the performance
of different attacks, the nature of the relationships between different
attacks, and the influence of various datasets and models on the effectiveness
of the attacks, etc. Therefore, we need a benchmark to holistically assess the
privacy risks faced by NLP models. In this paper, we present a privacy attack
and defense evaluation benchmark in the field of NLP, which includes the
conventional/small models and large language models (LLMs). This benchmark
supports a variety of models, datasets, and protocols, along with standardized
modules for comprehensive evaluation of attacks and defense strategies. Based
on the above framework, we present a study on the association between auxiliary
data from different domains and the strength of privacy attacks. And we provide
an improved attack method in this scenario with the help of Knowledge
Distillation (KD). Furthermore, we propose a chained framework for privacy
attacks. Allowing a practitioner to chain multiple attacks to achieve a
higher-level attack objective. Based on this, we provide some defense and
enhanced attack strategies. The code for reproducing the results can be found
at https://github.com/user2311717757/nlp_doctor.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Findings of EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ParFormer: A Vision <span class="highlight-title">Transformer</span> with Parallel Mixer and Sparse Channel
  Attention Patch Embedding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.15004v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.15004v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Novendra Setyawan, Ghufron Wahyu Kurniawan, Chi-Chia Sun, Jun-Wei Hsieh, Jing-Ming Guo, Wen-Kai Kuo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Convolutional Neural Networks (CNNs) and Transformers have achieved
remarkable success in computer vision tasks. However, their deep architectures
often lead to high computational redundancy, making them less suitable for
resource-constrained environments, such as edge devices. This paper introduces
ParFormer, a novel vision transformer that addresses this challenge by
incorporating a Parallel Mixer and a Sparse Channel Attention Patch Embedding
(SCAPE). By combining convolutional and attention mechanisms, ParFormer
improves feature extraction. This makes spatial feature extraction more
efficient and cuts down on unnecessary computation. The SCAPE module further
reduces computational redundancy while preserving essential feature information
during down-sampling. Experimental results on the ImageNet-1K dataset show that
ParFormer-T achieves 78.9\% Top-1 accuracy with a high throughput on a GPU that
outperforms other small models with 2.56$\times$ higher throughput than
MobileViT-S, 0.24\% faster than FasterNet-T2, and 1.79$\times$ higher than
EdgeNeXt-S. For edge device deployment, ParFormer-T excels with a throughput of
278.1 images/sec, which is 1.38 $\times$ higher than EdgeNeXt-S and
2.36$\times$ higher than MobileViT-S, making it highly suitable for real-time
applications in resource-constrained settings. The larger variant, ParFormer-L,
reaches 83.5\% Top-1 accuracy, offering a balanced trade-off between accuracy
and efficiency, surpassing many state-of-the-art models. In COCO object
detection, ParFormer-M achieves 40.7 AP for object detection and 37.6 AP for
instance segmentation, surpassing models like ResNet-50, PVT-S and
PoolFormer-S24 with significantly higher efficiency. These results validate
ParFormer as a highly efficient and scalable model for both high-performance
and resource-constrained scenarios, making it an ideal solution for edge-based
AI applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under Review in IEEE Transactions on Cognitive and Developmental
  System</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Almost Sure Convergence of Average Reward Temporal Difference Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.19546v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.19546v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ethan Blaser, Shangtong Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tabular average reward Temporal Difference (TD) learning is perhaps the
simplest and the most fundamental policy evaluation algorithm in average reward
reinforcement learning. After at least 25 years since its discovery, we are
finally able to provide a long-awaited almost sure convergence analysis.
Namely, we are the first to prove that, under very mild conditions, tabular
average reward TD converges almost surely to a sample path dependent fixed
point. Key to this success is a new general stochastic approximation result
concerning nonexpansive mappings with Markovian and additive noise, built on
recent advances in stochastic Krasnoselskii-Mann iterations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ReactZyme: A Benchmark for Enzyme-Reaction Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.13659v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.13659v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenqing Hua, Bozitao Zhong, Sitao Luan, Liang Hong, Guy Wolf, Doina Precup, Shuangjia Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Enzymes, with their specific catalyzed reactions, are necessary for all
aspects of life, enabling diverse biological processes and adaptations.
Predicting enzyme functions is essential for understanding biological pathways,
guiding drug development, enhancing bioproduct yields, and facilitating
evolutionary studies. Addressing the inherent complexities, we introduce a new
approach to annotating enzymes based on their catalyzed reactions. This method
provides detailed insights into specific reactions and is adaptable to newly
discovered reactions, diverging from traditional classifications by protein
family or expert-derived reaction classes. We employ machine learning
algorithms to analyze enzyme reaction datasets, delivering a much more refined
view on the functionality of enzymes. Our evaluation leverages the largest
enzyme-reaction dataset to date, derived from the SwissProt and Rhea databases
with entries up to January 8, 2024. We frame the enzyme-reaction prediction as
a retrieval problem, aiming to rank enzymes by their catalytic ability for
specific reactions. With our model, we can recruit proteins for novel reactions
and predict reactions in novel proteins, facilitating enzyme discovery and
function annotation (https://github.com/WillHua127/ReactZyme).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Provably Efficient Exploration in Inverse Constrained Reinforcement
  Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.15963v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.15963v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bo Yue, Jian Li, Guiliang Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  To obtain the optimal constraints in complex environments, Inverse
Constrained Reinforcement Learning (ICRL) seeks to recover these constraints
from expert demonstrations in a data-driven manner. Existing ICRL algorithms
collect training samples from an interactive environment. However, the efficacy
and efficiency of these sampling strategies remain unknown. To bridge this gap,
we introduce a strategic exploration framework with guaranteed efficiency.
Specifically, we define a feasible constraint set for ICRL problems and
investigate how expert policy and environmental dynamics influence the
optimality of constraints. Motivated by our findings, we propose two
exploratory algorithms to achieve efficient constraint inference via 1)
dynamically reducing the bounded aggregate error of cost estimation and 2)
strategically constraining the exploration policy. Both algorithms are
theoretically grounded with tractable sample complexity. We empirically
demonstrate the performance of our algorithms under various environments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy
  Curvature of Attention <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.00760v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.00760v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Susung Hong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Conditional diffusion models have shown remarkable success in visual content
generation, producing high-quality samples across various domains, largely due
to classifier-free guidance (CFG). Recent attempts to extend guidance to
unconditional models have relied on heuristic techniques, resulting in
suboptimal generation quality and unintended effects. In this work, we propose
Smoothed Energy Guidance (SEG), a novel training- and condition-free approach
that leverages the energy-based perspective of the self-attention mechanism to
enhance image generation. By defining the energy of self-attention, we
introduce a method to reduce the curvature of the energy landscape of attention
and use the output as the unconditional prediction. Practically, we control the
curvature of the energy landscape by adjusting the Gaussian kernel parameter
while keeping the guidance scale parameter fixed. Additionally, we present a
query blurring method that is equivalent to blurring the entire attention
weights without incurring quadratic complexity in the number of tokens. In our
experiments, SEG achieves a Pareto improvement in both quality and the
reduction of side effects. The code is available at
https://github.com/SusungHong/SEG-SDXL.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to NeurIPS 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Using Contrastive Learning with Generative Similarity to Learn Spaces
  that Capture Human Inductive Biases 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.19420v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.19420v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Raja Marjieh, Sreejan Kumar, Declan Campbell, Liyi Zhang, Gianluca Bencomo, Jake Snell, Thomas L. Griffiths
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Humans rely on strong inductive biases to learn from few examples and
abstract useful information from sensory data. Instilling such biases in
machine learning models has been shown to improve their performance on various
benchmarks including few-shot learning, robustness, and alignment. However,
finding effective training procedures to achieve that goal can be challenging
as psychologically-rich training data such as human similarity judgments are
expensive to scale, and Bayesian models of human inductive biases are often
intractable for complex, realistic domains. Here, we address this challenge by
introducing a Bayesian notion of generative similarity whereby two datapoints
are considered similar if they are likely to have been sampled from the same
distribution. This measure can be applied to complex generative processes,
including probabilistic programs. We show that generative similarity can be
used to define a contrastive learning objective even when its exact form is
intractable, enabling learning of spatial embeddings that express specific
inductive biases. We demonstrate the utility of our approach by showing that it
can be used to capture human inductive biases for geometric shapes, distinguish
different abstract drawing styles that are parameterized by probabilistic
programs, and capture abstract high-level categories that enable
generalization.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Closed-Form Interpretation of Neural Network Classifiers with Symbolic
  Gradients 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.04978v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.04978v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sebastian Johann Wetzel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  I introduce a unified framework for finding a closed-form interpretation of
any single neuron in an artificial neural network. Using this framework I
demonstrate how to interpret neural network classifiers to reveal closed-form
expressions of the concepts encoded in their decision boundaries. In contrast
to neural network-based regression, for classification, it is in general
impossible to express the neural network in the form of a symbolic equation
even if the neural network itself bases its classification on a quantity that
can be written as a closed-form equation. The interpretation framework is based
on embedding trained neural networks into an equivalence class of functions
that encode the same concept. I interpret these neural networks by finding an
intersection between the equivalence class and human-readable equations defined
by a symbolic search space. The approach is not limited to classifiers or full
neural networks and can be applied to arbitrary neurons in hidden layers or
latent spaces.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>

</body>

<footer>
    <div>
        <time id="build-timestamp" datetime="2024-10-09T05:28:19.752145498Z">
            2024-10-09 05:28:19 UTC
        </time>
    </div>
</footer>
<script src="index.js"></script>
</html>
